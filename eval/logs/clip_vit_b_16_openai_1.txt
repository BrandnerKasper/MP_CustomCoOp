args2: backbone=, config_file=configs/trainers/CoOp/vit_b16.yaml, dataset_config_file=configs/datasets/caltech101.yaml, eval_only=False, head=, load_epoch=None, model_dir=, no_train=False,  opts: ['TRAINER.COOP.N_CTX', '16', 'TRAINER.COOP.CSC', 'False', 'TRAINER.COOP.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '1'], output_dir=output/Caltech/1, resume=, root=/home/brandnerkasper/Uni/MP/MP_CustomCoOp/data, seed=1, source_domains=None, target_domains=None, trainer=CoOp, transforms=None
Setting fixed seed: 1
***************
** Arguments **
***************
config_file: configs/trainers/CoOp/vit_b16.yaml
csc: False
ctp: end
dataset_config_file: configs/datasets/caltech101.yaml
n_ctx: 16
opts: ['TRAINER.COOP.N_CTX', '16', 'TRAINER.COOP.CSC', 'False', 'TRAINER.COOP.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '1']
output_dir: output/Caltech/1
root: /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data
seed: 1
shots: 1
trainer: CoOp
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 4
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 1
  ROOT: /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/Caltech/1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 2.0.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 22.04.3 LTS (x86_64)
GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.35

Python version: 3.10.12 (main, Jul  5 2023, 18:54:27) [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-6.2.0-32-generic-x86_64-with-glibc2.35
Is CUDA available: True
CUDA runtime version: 11.5.119
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce GTX 970
Nvidia driver version: 525.125.06
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                       x86_64
CPU op-mode(s):                     32-bit, 64-bit
Address sizes:                      39 bits physical, 48 bits virtual
Byte Order:                         Little Endian
CPU(s):                             4
On-line CPU(s) list:                0-3
Vendor ID:                          GenuineIntel
Model name:                         Intel(R) Xeon(R) CPU E3-1225 v3 @ 3.20GHz
CPU family:                         6
Model:                              60
Thread(s) per core:                 1
Core(s) per socket:                 4
Socket(s):                          1
Stepping:                           3
CPU max MHz:                        3600,0000
CPU min MHz:                        800,0000
BogoMIPS:                           6397.95
Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt dtherm ida arat pln pts md_clear flush_l1d
Virtualization:                     VT-x
L1d cache:                          128 KiB (4 instances)
L1i cache:                          128 KiB (4 instances)
L2 cache:                           1 MiB (4 instances)
L3 cache:                           8 MiB (1 instance)
NUMA node(s):                       1
NUMA node0 CPU(s):                  0-3
Vulnerability Gather data sampling: Not affected
Vulnerability Itlb multihit:        KVM: Mitigation: VMX disabled
Vulnerability L1tf:                 Mitigation; PTE Inversion; VMX conditional cache flushes, SMT disabled
Vulnerability Mds:                  Mitigation; Clear CPU buffers; SMT disabled
Vulnerability Meltdown:             Mitigation; PTI
Vulnerability Mmio stale data:      Unknown: No mitigations
Vulnerability Retbleed:             Not affected
Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl
Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:           Mitigation; Retpolines, IBPB conditional, IBRS_FW, STIBP disabled, RSB filling, PBRSB-eIBRS Not affected
Vulnerability Srbds:                Mitigation; Microcode
Vulnerability Tsx async abort:      Not affected

Versions of relevant libraries:
[pip3] numpy==1.25.2
[pip3] open-clip-torch==2.20.0
[pip3] torch==2.0.1
[pip3] torchaudio==2.0.2
[pip3] torchvision==0.15.2
[conda] blas                      1.0                         mkl  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] mkl                       2023.1.0         h213fc3f_46343  
[conda] mkl-service               2.4.0           py310h5eee18b_1  
[conda] mkl_fft                   1.3.6           py310h1128e8f_1  
[conda] mkl_random                1.2.2           py310h1128e8f_1  
[conda] numpy                     1.25.2          py310h5f9d8c6_0  
[conda] numpy-base                1.25.2          py310hb5e798b_0  
[conda] open-clip-torch           2.20.0                   pypi_0    pypi
[conda] pytorch                   2.0.1           py3.10_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchaudio                2.0.2               py310_cu117    pytorch
[conda] torchtriton               2.0.0                     py310    pytorch
[conda] torchvision               0.15.2              py310_cu117    pytorch
        Pillow (9.4.0)

Loading trainer: CoOp
Loading dataset: Caltech101
Reading split from /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data/caltech-101/split_fewshot/shot_1-seed_1.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  100
# train_x  100
# val      100
# test     2,465
---------  ----------
Loading CLIP (backbone: ViT-B/16)
CLIP(
  (visual): VisionTransformer(
    (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (transformer): Transformer(
    (resblocks): Sequential(
      (0): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (6): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (7): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (8): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (9): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (10): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (11): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (token_embedding): Embedding(49408, 512)
  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
)
Building custom CLIP
Initializing a generic context
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Turning off gradients in both the image and the text encoder
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/Caltech/1/tensorboard)
epoch [1/200] batch [1/3] time 2.558 (2.558) data 0.294 (0.294) loss 2.6816 (2.6816) acc 53.1250 (53.1250) lr 1.0000e-05 eta 0:25:32
epoch [1/200] batch [2/3] time 1.467 (2.013) data 0.000 (0.147) loss 2.5449 (2.6133) acc 53.1250 (53.1250) lr 1.0000e-05 eta 0:20:03
epoch [1/200] batch [3/3] time 1.463 (1.829) data 0.000 (0.098) loss 2.3613 (2.5293) acc 65.6250 (57.2917) lr 2.0000e-03 eta 0:18:12
epoch [2/200] batch [1/3] time 1.681 (1.681) data 0.232 (0.232) loss 2.5215 (2.5215) acc 43.7500 (43.7500) lr 2.0000e-03 eta 0:16:41
epoch [2/200] batch [2/3] time 1.431 (1.556) data 0.000 (0.116) loss 1.6309 (2.0762) acc 56.2500 (50.0000) lr 2.0000e-03 eta 0:15:25
epoch [2/200] batch [3/3] time 1.459 (1.524) data 0.000 (0.078) loss 1.8018 (1.9847) acc 56.2500 (52.0833) lr 1.9999e-03 eta 0:15:05
epoch [3/200] batch [1/3] time 1.708 (1.708) data 0.235 (0.235) loss 1.0938 (1.0938) acc 68.7500 (68.7500) lr 1.9999e-03 eta 0:16:52
epoch [3/200] batch [2/3] time 1.458 (1.583) data 0.000 (0.117) loss 0.9702 (1.0320) acc 75.0000 (71.8750) lr 1.9999e-03 eta 0:15:37
epoch [3/200] batch [3/3] time 1.498 (1.555) data 0.000 (0.078) loss 0.9980 (1.0207) acc 68.7500 (70.8333) lr 1.9995e-03 eta 0:15:18
epoch [4/200] batch [1/3] time 1.937 (1.937) data 0.239 (0.239) loss 0.6748 (0.6748) acc 84.3750 (84.3750) lr 1.9995e-03 eta 0:19:02
epoch [4/200] batch [2/3] time 1.442 (1.689) data 0.000 (0.120) loss 0.8955 (0.7852) acc 78.1250 (81.2500) lr 1.9995e-03 eta 0:16:35
epoch [4/200] batch [3/3] time 1.494 (1.624) data 0.000 (0.080) loss 0.8223 (0.7975) acc 81.2500 (81.2500) lr 1.9989e-03 eta 0:15:55
epoch [5/200] batch [1/3] time 1.720 (1.720) data 0.228 (0.228) loss 1.0107 (1.0107) acc 71.8750 (71.8750) lr 1.9989e-03 eta 0:16:49
epoch [5/200] batch [2/3] time 1.466 (1.593) data 0.000 (0.114) loss 0.9448 (0.9778) acc 78.1250 (75.0000) lr 1.9989e-03 eta 0:15:33
epoch [5/200] batch [3/3] time 1.452 (1.546) data 0.000 (0.076) loss 0.8208 (0.9255) acc 75.0000 (75.0000) lr 1.9980e-03 eta 0:15:04
epoch [6/200] batch [1/3] time 1.678 (1.678) data 0.238 (0.238) loss 0.8169 (0.8169) acc 84.3750 (84.3750) lr 1.9980e-03 eta 0:16:19
epoch [6/200] batch [2/3] time 1.440 (1.559) data 0.000 (0.119) loss 0.8833 (0.8501) acc 75.0000 (79.6875) lr 1.9980e-03 eta 0:15:08
epoch [6/200] batch [3/3] time 1.451 (1.523) data 0.000 (0.079) loss 0.8433 (0.8478) acc 78.1250 (79.1667) lr 1.9969e-03 eta 0:14:46
epoch [7/200] batch [1/3] time 1.670 (1.670) data 0.232 (0.232) loss 0.4031 (0.4031) acc 78.1250 (78.1250) lr 1.9969e-03 eta 0:16:10
epoch [7/200] batch [2/3] time 1.433 (1.551) data 0.000 (0.116) loss 0.8506 (0.6268) acc 81.2500 (79.6875) lr 1.9969e-03 eta 0:14:59
epoch [7/200] batch [3/3] time 1.440 (1.514) data 0.000 (0.078) loss 0.7363 (0.6633) acc 78.1250 (79.1667) lr 1.9956e-03 eta 0:14:36
epoch [8/200] batch [1/3] time 1.665 (1.665) data 0.223 (0.223) loss 1.6514 (1.6514) acc 68.7500 (68.7500) lr 1.9956e-03 eta 0:16:02
epoch [8/200] batch [2/3] time 1.443 (1.554) data 0.000 (0.112) loss 0.3958 (1.0236) acc 87.5000 (78.1250) lr 1.9956e-03 eta 0:14:56
epoch [8/200] batch [3/3] time 1.443 (1.517) data 0.000 (0.075) loss 0.7339 (0.9270) acc 68.7500 (75.0000) lr 1.9940e-03 eta 0:14:33
epoch [9/200] batch [1/3] time 1.664 (1.664) data 0.219 (0.219) loss 0.5195 (0.5195) acc 90.6250 (90.6250) lr 1.9940e-03 eta 0:15:56
epoch [9/200] batch [2/3] time 1.445 (1.555) data 0.000 (0.110) loss 0.7080 (0.6138) acc 81.2500 (85.9375) lr 1.9940e-03 eta 0:14:52
epoch [9/200] batch [3/3] time 1.436 (1.515) data 0.000 (0.073) loss 1.3457 (0.8577) acc 68.7500 (80.2083) lr 1.9921e-03 eta 0:14:28
epoch [10/200] batch [1/3] time 1.667 (1.667) data 0.223 (0.223) loss 0.5293 (0.5293) acc 87.5000 (87.5000) lr 1.9921e-03 eta 0:15:53
epoch [10/200] batch [2/3] time 1.436 (1.552) data 0.000 (0.112) loss 0.4893 (0.5093) acc 84.3750 (85.9375) lr 1.9921e-03 eta 0:14:46
epoch [10/200] batch [3/3] time 1.437 (1.514) data 0.000 (0.074) loss 0.7886 (0.6024) acc 78.1250 (83.3333) lr 1.9900e-03 eta 0:14:22
epoch [11/200] batch [1/3] time 1.653 (1.653) data 0.220 (0.220) loss 1.0049 (1.0049) acc 75.0000 (75.0000) lr 1.9900e-03 eta 0:15:40
epoch [11/200] batch [2/3] time 1.431 (1.542) data 0.000 (0.110) loss 0.6206 (0.8127) acc 84.3750 (79.6875) lr 1.9900e-03 eta 0:14:35
epoch [11/200] batch [3/3] time 1.430 (1.504) data 0.000 (0.073) loss 0.4851 (0.7035) acc 90.6250 (83.3333) lr 1.9877e-03 eta 0:14:13
epoch [12/200] batch [1/3] time 1.675 (1.675) data 0.239 (0.239) loss 0.8452 (0.8452) acc 78.1250 (78.1250) lr 1.9877e-03 eta 0:15:47
epoch [12/200] batch [2/3] time 1.433 (1.554) data 0.000 (0.120) loss 0.8628 (0.8540) acc 75.0000 (76.5625) lr 1.9877e-03 eta 0:14:37
epoch [12/200] batch [3/3] time 1.435 (1.514) data 0.000 (0.080) loss 0.8716 (0.8599) acc 75.0000 (76.0417) lr 1.9851e-03 eta 0:14:13
epoch [13/200] batch [1/3] time 1.670 (1.670) data 0.228 (0.228) loss 0.8833 (0.8833) acc 81.2500 (81.2500) lr 1.9851e-03 eta 0:15:40
epoch [13/200] batch [2/3] time 1.441 (1.556) data 0.000 (0.114) loss 1.0352 (0.9592) acc 78.1250 (79.6875) lr 1.9851e-03 eta 0:14:34
epoch [13/200] batch [3/3] time 1.444 (1.519) data 0.000 (0.076) loss 0.2445 (0.7210) acc 90.6250 (83.3333) lr 1.9823e-03 eta 0:14:11
epoch [14/200] batch [1/3] time 1.658 (1.658) data 0.221 (0.221) loss 0.9614 (0.9614) acc 68.7500 (68.7500) lr 1.9823e-03 eta 0:15:28
epoch [14/200] batch [2/3] time 1.438 (1.548) data 0.000 (0.111) loss 0.4224 (0.6919) acc 84.3750 (76.5625) lr 1.9823e-03 eta 0:14:25
epoch [14/200] batch [3/3] time 1.446 (1.514) data 0.000 (0.074) loss 0.7314 (0.7051) acc 84.3750 (79.1667) lr 1.9792e-03 eta 0:14:04
epoch [15/200] batch [1/3] time 1.663 (1.663) data 0.223 (0.223) loss 0.6479 (0.6479) acc 84.3750 (84.3750) lr 1.9792e-03 eta 0:15:26
epoch [15/200] batch [2/3] time 1.442 (1.552) data 0.000 (0.111) loss 0.8247 (0.7363) acc 75.0000 (79.6875) lr 1.9792e-03 eta 0:14:22
epoch [15/200] batch [3/3] time 1.447 (1.517) data 0.000 (0.074) loss 0.4182 (0.6303) acc 90.6250 (83.3333) lr 1.9759e-03 eta 0:14:01
epoch [16/200] batch [1/3] time 1.669 (1.669) data 0.222 (0.222) loss 0.9976 (0.9976) acc 71.8750 (71.8750) lr 1.9759e-03 eta 0:15:24
epoch [16/200] batch [2/3] time 1.442 (1.555) data 0.000 (0.111) loss 0.6831 (0.8403) acc 81.2500 (76.5625) lr 1.9759e-03 eta 0:14:20
epoch [16/200] batch [3/3] time 1.438 (1.516) data 0.000 (0.074) loss 0.6367 (0.7725) acc 81.2500 (78.1250) lr 1.9724e-03 eta 0:13:56
epoch [17/200] batch [1/3] time 1.669 (1.669) data 0.230 (0.230) loss 0.7944 (0.7944) acc 78.1250 (78.1250) lr 1.9724e-03 eta 0:15:19
epoch [17/200] batch [2/3] time 1.444 (1.556) data 0.000 (0.115) loss 0.5972 (0.6958) acc 84.3750 (81.2500) lr 1.9724e-03 eta 0:14:15
epoch [17/200] batch [3/3] time 1.445 (1.519) data 0.000 (0.077) loss 0.4326 (0.6081) acc 87.5000 (83.3333) lr 1.9686e-03 eta 0:13:54
epoch [18/200] batch [1/3] time 1.669 (1.669) data 0.224 (0.224) loss 0.4509 (0.4509) acc 90.6250 (90.6250) lr 1.9686e-03 eta 0:15:14
epoch [18/200] batch [2/3] time 1.452 (1.560) data 0.000 (0.112) loss 0.4548 (0.4529) acc 84.3750 (87.5000) lr 1.9686e-03 eta 0:14:13
epoch [18/200] batch [3/3] time 1.458 (1.526) data 0.000 (0.075) loss 0.6704 (0.5254) acc 78.1250 (84.3750) lr 1.9646e-03 eta 0:13:53
epoch [19/200] batch [1/3] time 1.676 (1.676) data 0.234 (0.234) loss 0.7759 (0.7759) acc 81.2500 (81.2500) lr 1.9646e-03 eta 0:15:13
epoch [19/200] batch [2/3] time 1.446 (1.561) data 0.000 (0.117) loss 0.5391 (0.6575) acc 81.2500 (81.2500) lr 1.9646e-03 eta 0:14:09
epoch [19/200] batch [3/3] time 1.454 (1.525) data 0.000 (0.078) loss 0.9126 (0.7425) acc 78.1250 (80.2083) lr 1.9603e-03 eta 0:13:48
epoch [20/200] batch [1/3] time 1.818 (1.818) data 0.305 (0.305) loss 0.3228 (0.3228) acc 87.5000 (87.5000) lr 1.9603e-03 eta 0:16:25
epoch [20/200] batch [2/3] time 1.464 (1.641) data 0.000 (0.153) loss 0.7280 (0.5254) acc 87.5000 (87.5000) lr 1.9603e-03 eta 0:14:47
epoch [20/200] batch [3/3] time 1.492 (1.591) data 0.000 (0.102) loss 0.7236 (0.5915) acc 84.3750 (86.4583) lr 1.9558e-03 eta 0:14:19
epoch [21/200] batch [1/3] time 1.744 (1.744) data 0.224 (0.224) loss 0.5513 (0.5513) acc 84.3750 (84.3750) lr 1.9558e-03 eta 0:15:39
epoch [21/200] batch [2/3] time 1.514 (1.629) data 0.000 (0.112) loss 0.3706 (0.4609) acc 93.7500 (89.0625) lr 1.9558e-03 eta 0:14:36
epoch [21/200] batch [3/3] time 1.480 (1.579) data 0.000 (0.075) loss 0.5566 (0.4928) acc 78.1250 (85.4167) lr 1.9511e-03 eta 0:14:08
epoch [22/200] batch [1/3] time 1.750 (1.750) data 0.227 (0.227) loss 1.2090 (1.2090) acc 65.6250 (65.6250) lr 1.9511e-03 eta 0:15:37
epoch [22/200] batch [2/3] time 1.477 (1.613) data 0.000 (0.114) loss 0.5898 (0.8994) acc 90.6250 (78.1250) lr 1.9511e-03 eta 0:14:23
epoch [22/200] batch [3/3] time 1.514 (1.580) data 0.000 (0.076) loss 0.4417 (0.7468) acc 87.5000 (81.2500) lr 1.9461e-03 eta 0:14:03
epoch [23/200] batch [1/3] time 1.708 (1.708) data 0.243 (0.243) loss 0.2817 (0.2817) acc 93.7500 (93.7500) lr 1.9461e-03 eta 0:15:10
epoch [23/200] batch [2/3] time 1.521 (1.614) data 0.000 (0.121) loss 0.6787 (0.4802) acc 84.3750 (89.0625) lr 1.9461e-03 eta 0:14:18
epoch [23/200] batch [3/3] time 1.442 (1.557) data 0.000 (0.081) loss 0.6323 (0.5309) acc 84.3750 (87.5000) lr 1.9409e-03 eta 0:13:46
epoch [24/200] batch [1/3] time 1.661 (1.661) data 0.225 (0.225) loss 0.4417 (0.4417) acc 90.6250 (90.6250) lr 1.9409e-03 eta 0:14:40
epoch [24/200] batch [2/3] time 1.444 (1.553) data 0.000 (0.113) loss 0.1661 (0.3039) acc 96.8750 (93.7500) lr 1.9409e-03 eta 0:13:41
epoch [24/200] batch [3/3] time 1.433 (1.513) data 0.000 (0.075) loss 0.5977 (0.4018) acc 81.2500 (89.5833) lr 1.9354e-03 eta 0:13:18
epoch [25/200] batch [1/3] time 1.683 (1.683) data 0.228 (0.228) loss 0.4055 (0.4055) acc 87.5000 (87.5000) lr 1.9354e-03 eta 0:14:46
epoch [25/200] batch [2/3] time 1.439 (1.561) data 0.000 (0.114) loss 0.6465 (0.5260) acc 78.1250 (82.8125) lr 1.9354e-03 eta 0:13:41
epoch [25/200] batch [3/3] time 1.442 (1.521) data 0.000 (0.076) loss 0.4316 (0.4945) acc 87.5000 (84.3750) lr 1.9298e-03 eta 0:13:18
epoch [26/200] batch [1/3] time 1.670 (1.670) data 0.224 (0.224) loss 0.7793 (0.7793) acc 78.1250 (78.1250) lr 1.9298e-03 eta 0:14:34
epoch [26/200] batch [2/3] time 1.460 (1.565) data 0.000 (0.112) loss 0.8945 (0.8369) acc 81.2500 (79.6875) lr 1.9298e-03 eta 0:13:38
epoch [26/200] batch [3/3] time 1.456 (1.529) data 0.000 (0.075) loss 0.3875 (0.6871) acc 84.3750 (81.2500) lr 1.9239e-03 eta 0:13:17
epoch [27/200] batch [1/3] time 1.689 (1.689) data 0.236 (0.236) loss 0.5747 (0.5747) acc 71.8750 (71.8750) lr 1.9239e-03 eta 0:14:40
epoch [27/200] batch [2/3] time 1.463 (1.576) data 0.000 (0.118) loss 0.6260 (0.6003) acc 81.2500 (76.5625) lr 1.9239e-03 eta 0:13:39
epoch [27/200] batch [3/3] time 1.478 (1.544) data 0.000 (0.079) loss 0.2935 (0.4980) acc 93.7500 (82.2917) lr 1.9178e-03 eta 0:13:21
epoch [28/200] batch [1/3] time 1.674 (1.674) data 0.227 (0.227) loss 0.7471 (0.7471) acc 84.3750 (84.3750) lr 1.9178e-03 eta 0:14:27
epoch [28/200] batch [2/3] time 1.435 (1.554) data 0.000 (0.114) loss 0.6523 (0.6997) acc 81.2500 (82.8125) lr 1.9178e-03 eta 0:13:23
epoch [28/200] batch [3/3] time 1.452 (1.520) data 0.000 (0.076) loss 0.3018 (0.5671) acc 93.7500 (86.4583) lr 1.9114e-03 eta 0:13:04
epoch [29/200] batch [1/3] time 1.665 (1.665) data 0.227 (0.227) loss 0.6069 (0.6069) acc 78.1250 (78.1250) lr 1.9114e-03 eta 0:14:17
epoch [29/200] batch [2/3] time 1.446 (1.556) data 0.000 (0.114) loss 0.4460 (0.5265) acc 87.5000 (82.8125) lr 1.9114e-03 eta 0:13:19
epoch [29/200] batch [3/3] time 1.440 (1.517) data 0.000 (0.076) loss 0.3572 (0.4701) acc 93.7500 (86.4583) lr 1.9048e-03 eta 0:12:58
epoch [30/200] batch [1/3] time 1.668 (1.668) data 0.227 (0.227) loss 0.2417 (0.2417) acc 93.7500 (93.7500) lr 1.9048e-03 eta 0:14:13
epoch [30/200] batch [2/3] time 1.446 (1.557) data 0.000 (0.114) loss 0.2827 (0.2622) acc 90.6250 (92.1875) lr 1.9048e-03 eta 0:13:15
epoch [30/200] batch [3/3] time 1.451 (1.521) data 0.000 (0.076) loss 0.4788 (0.3344) acc 84.3750 (89.5833) lr 1.8980e-03 eta 0:12:55
epoch [31/200] batch [1/3] time 1.663 (1.663) data 0.226 (0.226) loss 0.3403 (0.3403) acc 90.6250 (90.6250) lr 1.8980e-03 eta 0:14:06
epoch [31/200] batch [2/3] time 1.463 (1.563) data 0.000 (0.113) loss 0.5820 (0.4612) acc 87.5000 (89.0625) lr 1.8980e-03 eta 0:13:14
epoch [31/200] batch [3/3] time 1.552 (1.559) data 0.000 (0.075) loss 0.5254 (0.4826) acc 81.2500 (86.4583) lr 1.8910e-03 eta 0:13:10
epoch [32/200] batch [1/3] time 1.700 (1.700) data 0.237 (0.237) loss 0.8198 (0.8198) acc 81.2500 (81.2500) lr 1.8910e-03 eta 0:14:20
epoch [32/200] batch [2/3] time 1.455 (1.577) data 0.000 (0.119) loss 0.5303 (0.6750) acc 84.3750 (82.8125) lr 1.8910e-03 eta 0:13:16
epoch [32/200] batch [3/3] time 1.515 (1.557) data 0.000 (0.079) loss 0.5879 (0.6460) acc 87.5000 (84.3750) lr 1.8838e-03 eta 0:13:04
epoch [33/200] batch [1/3] time 1.728 (1.728) data 0.249 (0.249) loss 0.5210 (0.5210) acc 87.5000 (87.5000) lr 1.8838e-03 eta 0:14:29
epoch [33/200] batch [2/3] time 1.466 (1.597) data 0.000 (0.125) loss 0.3628 (0.4419) acc 90.6250 (89.0625) lr 1.8838e-03 eta 0:13:21
epoch [33/200] batch [3/3] time 1.436 (1.543) data 0.000 (0.083) loss 0.2451 (0.3763) acc 96.8750 (91.6667) lr 1.8763e-03 eta 0:12:53
epoch [34/200] batch [1/3] time 1.675 (1.675) data 0.232 (0.232) loss 0.5713 (0.5713) acc 87.5000 (87.5000) lr 1.8763e-03 eta 0:13:57
epoch [34/200] batch [2/3] time 1.446 (1.560) data 0.000 (0.116) loss 0.5850 (0.5781) acc 81.2500 (84.3750) lr 1.8763e-03 eta 0:12:58
epoch [34/200] batch [3/3] time 1.445 (1.522) data 0.000 (0.078) loss 1.1172 (0.7578) acc 68.7500 (79.1667) lr 1.8686e-03 eta 0:12:37
epoch [35/200] batch [1/3] time 1.677 (1.677) data 0.233 (0.233) loss 0.2822 (0.2822) acc 93.7500 (93.7500) lr 1.8686e-03 eta 0:13:53
epoch [35/200] batch [2/3] time 1.443 (1.560) data 0.000 (0.117) loss 0.2568 (0.2695) acc 90.6250 (92.1875) lr 1.8686e-03 eta 0:12:53
epoch [35/200] batch [3/3] time 1.439 (1.520) data 0.000 (0.078) loss 0.5049 (0.3480) acc 84.3750 (89.5833) lr 1.8607e-03 eta 0:12:32
epoch [36/200] batch [1/3] time 1.669 (1.669) data 0.230 (0.230) loss 0.5903 (0.5903) acc 84.3750 (84.3750) lr 1.8607e-03 eta 0:13:44
epoch [36/200] batch [2/3] time 1.432 (1.550) data 0.000 (0.115) loss 0.4216 (0.5060) acc 90.6250 (87.5000) lr 1.8607e-03 eta 0:12:44
epoch [36/200] batch [3/3] time 1.446 (1.516) data 0.000 (0.077) loss 0.3469 (0.4530) acc 90.6250 (88.5417) lr 1.8526e-03 eta 0:12:25
epoch [37/200] batch [1/3] time 1.685 (1.685) data 0.242 (0.242) loss 0.4783 (0.4783) acc 90.6250 (90.6250) lr 1.8526e-03 eta 0:13:47
epoch [37/200] batch [2/3] time 1.445 (1.565) data 0.000 (0.121) loss 0.6074 (0.5428) acc 78.1250 (84.3750) lr 1.8526e-03 eta 0:12:47
epoch [37/200] batch [3/3] time 1.436 (1.522) data 0.000 (0.081) loss 0.5005 (0.5287) acc 87.5000 (85.4167) lr 1.8443e-03 eta 0:12:24
epoch [38/200] batch [1/3] time 1.670 (1.670) data 0.230 (0.230) loss 0.2483 (0.2483) acc 93.7500 (93.7500) lr 1.8443e-03 eta 0:13:34
epoch [38/200] batch [2/3] time 1.500 (1.585) data 0.000 (0.115) loss 0.4753 (0.3618) acc 93.7500 (93.7500) lr 1.8443e-03 eta 0:12:51
epoch [38/200] batch [3/3] time 1.553 (1.574) data 0.001 (0.077) loss 0.7734 (0.4990) acc 81.2500 (89.5833) lr 1.8358e-03 eta 0:12:45
epoch [39/200] batch [1/3] time 1.771 (1.771) data 0.242 (0.242) loss 0.1693 (0.1693) acc 96.8750 (96.8750) lr 1.8358e-03 eta 0:14:19
epoch [39/200] batch [2/3] time 1.457 (1.614) data 0.000 (0.121) loss 0.6738 (0.4216) acc 87.5000 (92.1875) lr 1.8358e-03 eta 0:13:01
epoch [39/200] batch [3/3] time 1.456 (1.561) data 0.000 (0.081) loss 0.4629 (0.4353) acc 87.5000 (90.6250) lr 1.8271e-03 eta 0:12:34
epoch [40/200] batch [1/3] time 1.688 (1.688) data 0.249 (0.249) loss 0.9434 (0.9434) acc 78.1250 (78.1250) lr 1.8271e-03 eta 0:13:33
epoch [40/200] batch [2/3] time 1.447 (1.568) data 0.000 (0.125) loss 0.7524 (0.8479) acc 78.1250 (78.1250) lr 1.8271e-03 eta 0:12:33
epoch [40/200] batch [3/3] time 1.468 (1.534) data 0.000 (0.083) loss 0.6753 (0.7904) acc 84.3750 (80.2083) lr 1.8181e-03 eta 0:12:16
epoch [41/200] batch [1/3] time 1.750 (1.750) data 0.240 (0.240) loss 0.4854 (0.4854) acc 93.7500 (93.7500) lr 1.8181e-03 eta 0:13:58
epoch [41/200] batch [2/3] time 1.530 (1.640) data 0.000 (0.120) loss 0.5015 (0.4934) acc 90.6250 (92.1875) lr 1.8181e-03 eta 0:13:03
epoch [41/200] batch [3/3] time 1.631 (1.637) data 0.000 (0.080) loss 0.4148 (0.4672) acc 87.5000 (90.6250) lr 1.8090e-03 eta 0:13:00
epoch [42/200] batch [1/3] time 1.847 (1.847) data 0.257 (0.257) loss 0.4856 (0.4856) acc 87.5000 (87.5000) lr 1.8090e-03 eta 0:14:39
epoch [42/200] batch [2/3] time 1.526 (1.686) data 0.000 (0.129) loss 0.1006 (0.2931) acc 100.0000 (93.7500) lr 1.8090e-03 eta 0:13:21
epoch [42/200] batch [3/3] time 1.488 (1.620) data 0.000 (0.086) loss 0.6616 (0.4160) acc 87.5000 (91.6667) lr 1.7997e-03 eta 0:12:47
epoch [43/200] batch [1/3] time 1.761 (1.761) data 0.223 (0.223) loss 0.7715 (0.7715) acc 84.3750 (84.3750) lr 1.7997e-03 eta 0:13:53
epoch [43/200] batch [2/3] time 1.504 (1.633) data 0.000 (0.112) loss 0.9150 (0.8433) acc 75.0000 (79.6875) lr 1.7997e-03 eta 0:12:50
epoch [43/200] batch [3/3] time 1.499 (1.588) data 0.000 (0.074) loss 0.7090 (0.7985) acc 75.0000 (78.1250) lr 1.7902e-03 eta 0:12:27
epoch [44/200] batch [1/3] time 1.753 (1.753) data 0.244 (0.244) loss 0.4568 (0.4568) acc 87.5000 (87.5000) lr 1.7902e-03 eta 0:13:44
epoch [44/200] batch [2/3] time 1.498 (1.626) data 0.000 (0.122) loss 0.4436 (0.4502) acc 84.3750 (85.9375) lr 1.7902e-03 eta 0:12:42
epoch [44/200] batch [3/3] time 1.493 (1.582) data 0.000 (0.081) loss 0.6055 (0.5020) acc 87.5000 (86.4583) lr 1.7804e-03 eta 0:12:20
epoch [45/200] batch [1/3] time 1.683 (1.683) data 0.230 (0.230) loss 0.3750 (0.3750) acc 90.6250 (90.6250) lr 1.7804e-03 eta 0:13:06
epoch [45/200] batch [2/3] time 1.442 (1.562) data 0.000 (0.115) loss 0.8970 (0.6360) acc 78.1250 (84.3750) lr 1.7804e-03 eta 0:12:08
epoch [45/200] batch [3/3] time 1.441 (1.522) data 0.000 (0.077) loss 0.2944 (0.5221) acc 93.7500 (87.5000) lr 1.7705e-03 eta 0:11:47
epoch [46/200] batch [1/3] time 1.669 (1.669) data 0.234 (0.234) loss 0.2515 (0.2515) acc 90.6250 (90.6250) lr 1.7705e-03 eta 0:12:54
epoch [46/200] batch [2/3] time 1.447 (1.558) data 0.000 (0.117) loss 0.2360 (0.2437) acc 93.7500 (92.1875) lr 1.7705e-03 eta 0:12:01
epoch [46/200] batch [3/3] time 1.449 (1.522) data 0.000 (0.078) loss 0.5259 (0.3378) acc 87.5000 (90.6250) lr 1.7604e-03 eta 0:11:42
epoch [47/200] batch [1/3] time 1.689 (1.689) data 0.242 (0.242) loss 0.5288 (0.5288) acc 84.3750 (84.3750) lr 1.7604e-03 eta 0:12:58
epoch [47/200] batch [2/3] time 1.432 (1.560) data 0.000 (0.121) loss 0.7041 (0.6165) acc 81.2500 (82.8125) lr 1.7604e-03 eta 0:11:57
epoch [47/200] batch [3/3] time 1.441 (1.521) data 0.000 (0.081) loss 0.5337 (0.5889) acc 87.5000 (84.3750) lr 1.7501e-03 eta 0:11:37
epoch [48/200] batch [1/3] time 1.660 (1.660) data 0.225 (0.225) loss 0.5542 (0.5542) acc 84.3750 (84.3750) lr 1.7501e-03 eta 0:12:40
epoch [48/200] batch [2/3] time 1.446 (1.553) data 0.000 (0.112) loss 0.3931 (0.4736) acc 90.6250 (87.5000) lr 1.7501e-03 eta 0:11:49
epoch [48/200] batch [3/3] time 1.439 (1.515) data 0.000 (0.075) loss 0.1555 (0.3676) acc 100.0000 (91.6667) lr 1.7396e-03 eta 0:11:30
epoch [49/200] batch [1/3] time 1.671 (1.671) data 0.232 (0.232) loss 0.6279 (0.6279) acc 78.1250 (78.1250) lr 1.7396e-03 eta 0:12:40
epoch [49/200] batch [2/3] time 1.444 (1.557) data 0.000 (0.116) loss 0.8887 (0.7583) acc 81.2500 (79.6875) lr 1.7396e-03 eta 0:11:47
epoch [49/200] batch [3/3] time 1.446 (1.520) data 0.000 (0.077) loss 0.0468 (0.5211) acc 100.0000 (86.4583) lr 1.7290e-03 eta 0:11:28
epoch [50/200] batch [1/3] time 1.681 (1.681) data 0.235 (0.235) loss 0.2991 (0.2991) acc 93.7500 (93.7500) lr 1.7290e-03 eta 0:12:39
epoch [50/200] batch [2/3] time 1.439 (1.560) data 0.000 (0.118) loss 0.3860 (0.3425) acc 90.6250 (92.1875) lr 1.7290e-03 eta 0:11:43
epoch [50/200] batch [3/3] time 1.438 (1.520) data 0.000 (0.078) loss 0.2988 (0.3280) acc 90.6250 (91.6667) lr 1.7181e-03 eta 0:11:23
epoch [51/200] batch [1/3] time 1.675 (1.675) data 0.240 (0.240) loss 0.4668 (0.4668) acc 90.6250 (90.6250) lr 1.7181e-03 eta 0:12:32
epoch [51/200] batch [2/3] time 1.435 (1.555) data 0.000 (0.120) loss 0.3037 (0.3853) acc 93.7500 (92.1875) lr 1.7181e-03 eta 0:11:36
epoch [51/200] batch [3/3] time 1.441 (1.517) data 0.000 (0.080) loss 0.8589 (0.5431) acc 81.2500 (88.5417) lr 1.7071e-03 eta 0:11:18
epoch [52/200] batch [1/3] time 1.723 (1.723) data 0.268 (0.268) loss 0.8042 (0.8042) acc 84.3750 (84.3750) lr 1.7071e-03 eta 0:12:48
epoch [52/200] batch [2/3] time 1.498 (1.611) data 0.000 (0.134) loss 0.2173 (0.5107) acc 93.7500 (89.0625) lr 1.7071e-03 eta 0:11:56
epoch [52/200] batch [3/3] time 1.528 (1.583) data 0.000 (0.089) loss 0.3486 (0.4567) acc 90.6250 (89.5833) lr 1.6959e-03 eta 0:11:42
epoch [53/200] batch [1/3] time 1.745 (1.745) data 0.309 (0.309) loss 0.3577 (0.3577) acc 93.7500 (93.7500) lr 1.6959e-03 eta 0:12:53
epoch [53/200] batch [2/3] time 1.437 (1.591) data 0.000 (0.154) loss 0.4600 (0.4088) acc 90.6250 (92.1875) lr 1.6959e-03 eta 0:11:43
epoch [53/200] batch [3/3] time 1.500 (1.561) data 0.000 (0.103) loss 0.4016 (0.4064) acc 90.6250 (91.6667) lr 1.6845e-03 eta 0:11:28
epoch [54/200] batch [1/3] time 1.746 (1.746) data 0.236 (0.236) loss 0.2712 (0.2712) acc 84.3750 (84.3750) lr 1.6845e-03 eta 0:12:48
epoch [54/200] batch [2/3] time 1.539 (1.643) data 0.000 (0.118) loss 0.5093 (0.3903) acc 81.2500 (82.8125) lr 1.6845e-03 eta 0:12:01
epoch [54/200] batch [3/3] time 1.532 (1.606) data 0.000 (0.079) loss 0.4614 (0.4140) acc 93.7500 (86.4583) lr 1.6730e-03 eta 0:11:43
epoch [55/200] batch [1/3] time 1.776 (1.776) data 0.235 (0.235) loss 0.5645 (0.5645) acc 90.6250 (90.6250) lr 1.6730e-03 eta 0:12:56
epoch [55/200] batch [2/3] time 1.475 (1.626) data 0.000 (0.118) loss 0.5547 (0.5596) acc 90.6250 (90.6250) lr 1.6730e-03 eta 0:11:48
epoch [55/200] batch [3/3] time 1.453 (1.568) data 0.000 (0.079) loss 0.1398 (0.4196) acc 96.8750 (92.7083) lr 1.6613e-03 eta 0:11:22
epoch [56/200] batch [1/3] time 1.716 (1.716) data 0.224 (0.224) loss 0.7070 (0.7070) acc 78.1250 (78.1250) lr 1.6613e-03 eta 0:12:24
epoch [56/200] batch [2/3] time 1.448 (1.582) data 0.000 (0.112) loss 0.3103 (0.5087) acc 93.7500 (85.9375) lr 1.6613e-03 eta 0:11:24
epoch [56/200] batch [3/3] time 1.436 (1.533) data 0.000 (0.075) loss 0.3867 (0.4680) acc 93.7500 (88.5417) lr 1.6494e-03 eta 0:11:02
epoch [57/200] batch [1/3] time 1.672 (1.672) data 0.232 (0.232) loss 0.3770 (0.3770) acc 87.5000 (87.5000) lr 1.6494e-03 eta 0:12:00
epoch [57/200] batch [2/3] time 1.455 (1.564) data 0.000 (0.116) loss 0.2568 (0.3169) acc 96.8750 (92.1875) lr 1.6494e-03 eta 0:11:12
epoch [57/200] batch [3/3] time 1.492 (1.540) data 0.000 (0.078) loss 0.4065 (0.3468) acc 87.5000 (90.6250) lr 1.6374e-03 eta 0:11:00
epoch [58/200] batch [1/3] time 1.684 (1.684) data 0.243 (0.243) loss 0.3928 (0.3928) acc 87.5000 (87.5000) lr 1.6374e-03 eta 0:12:00
epoch [58/200] batch [2/3] time 1.444 (1.564) data 0.000 (0.122) loss 0.3772 (0.3850) acc 87.5000 (87.5000) lr 1.6374e-03 eta 0:11:07
epoch [58/200] batch [3/3] time 1.445 (1.524) data 0.000 (0.081) loss 0.3857 (0.3853) acc 90.6250 (88.5417) lr 1.6252e-03 eta 0:10:49
epoch [59/200] batch [1/3] time 1.673 (1.673) data 0.232 (0.232) loss 0.4651 (0.4651) acc 90.6250 (90.6250) lr 1.6252e-03 eta 0:11:51
epoch [59/200] batch [2/3] time 1.548 (1.611) data 0.000 (0.116) loss 0.2158 (0.3405) acc 96.8750 (93.7500) lr 1.6252e-03 eta 0:11:22
epoch [59/200] batch [3/3] time 1.453 (1.558) data 0.000 (0.077) loss 0.7051 (0.4620) acc 78.1250 (88.5417) lr 1.6129e-03 eta 0:10:59
epoch [60/200] batch [1/3] time 1.694 (1.694) data 0.244 (0.244) loss 0.4712 (0.4712) acc 90.6250 (90.6250) lr 1.6129e-03 eta 0:11:55
epoch [60/200] batch [2/3] time 1.440 (1.567) data 0.000 (0.122) loss 0.3142 (0.3927) acc 87.5000 (89.0625) lr 1.6129e-03 eta 0:10:59
epoch [60/200] batch [3/3] time 1.445 (1.526) data 0.000 (0.081) loss 0.4751 (0.4202) acc 84.3750 (87.5000) lr 1.6004e-03 eta 0:10:41
epoch [61/200] batch [1/3] time 1.675 (1.675) data 0.245 (0.245) loss 0.3606 (0.3606) acc 81.2500 (81.2500) lr 1.6004e-03 eta 0:11:41
epoch [61/200] batch [2/3] time 1.525 (1.600) data 0.000 (0.122) loss 0.5610 (0.4608) acc 84.3750 (82.8125) lr 1.6004e-03 eta 0:11:08
epoch [61/200] batch [3/3] time 1.457 (1.552) data 0.000 (0.082) loss 0.6670 (0.5295) acc 84.3750 (83.3333) lr 1.5878e-03 eta 0:10:47
epoch [62/200] batch [1/3] time 1.720 (1.720) data 0.240 (0.240) loss 0.2284 (0.2284) acc 90.6250 (90.6250) lr 1.5878e-03 eta 0:11:55
epoch [62/200] batch [2/3] time 1.486 (1.603) data 0.000 (0.120) loss 0.5059 (0.3671) acc 84.3750 (87.5000) lr 1.5878e-03 eta 0:11:05
epoch [62/200] batch [3/3] time 1.441 (1.549) data 0.000 (0.080) loss 0.5620 (0.4321) acc 87.5000 (87.5000) lr 1.5750e-03 eta 0:10:41
epoch [63/200] batch [1/3] time 1.685 (1.685) data 0.241 (0.241) loss 0.4199 (0.4199) acc 87.5000 (87.5000) lr 1.5750e-03 eta 0:11:35
epoch [63/200] batch [2/3] time 1.439 (1.562) data 0.000 (0.120) loss 0.3660 (0.3929) acc 87.5000 (87.5000) lr 1.5750e-03 eta 0:10:43
epoch [63/200] batch [3/3] time 1.433 (1.519) data 0.000 (0.080) loss 0.2000 (0.3286) acc 96.8750 (90.6250) lr 1.5621e-03 eta 0:10:24
epoch [64/200] batch [1/3] time 1.684 (1.684) data 0.237 (0.237) loss 0.3481 (0.3481) acc 96.8750 (96.8750) lr 1.5621e-03 eta 0:11:30
epoch [64/200] batch [2/3] time 1.445 (1.565) data 0.000 (0.118) loss 0.5698 (0.4590) acc 87.5000 (92.1875) lr 1.5621e-03 eta 0:10:40
epoch [64/200] batch [3/3] time 1.446 (1.525) data 0.000 (0.079) loss 0.2759 (0.3979) acc 90.6250 (91.6667) lr 1.5490e-03 eta 0:10:22
epoch [65/200] batch [1/3] time 1.662 (1.662) data 0.223 (0.223) loss 0.1626 (0.1626) acc 96.8750 (96.8750) lr 1.5490e-03 eta 0:11:16
epoch [65/200] batch [2/3] time 1.442 (1.552) data 0.000 (0.112) loss 0.2688 (0.2157) acc 90.6250 (93.7500) lr 1.5490e-03 eta 0:10:30
epoch [65/200] batch [3/3] time 1.442 (1.515) data 0.000 (0.074) loss 0.4548 (0.2954) acc 93.7500 (93.7500) lr 1.5358e-03 eta 0:10:13
epoch [66/200] batch [1/3] time 1.670 (1.670) data 0.229 (0.229) loss 0.4502 (0.4502) acc 84.3750 (84.3750) lr 1.5358e-03 eta 0:11:14
epoch [66/200] batch [2/3] time 1.447 (1.559) data 0.000 (0.115) loss 0.4592 (0.4547) acc 87.5000 (85.9375) lr 1.5358e-03 eta 0:10:28
epoch [66/200] batch [3/3] time 1.449 (1.522) data 0.000 (0.076) loss 0.1621 (0.3572) acc 96.8750 (89.5833) lr 1.5225e-03 eta 0:10:11
epoch [67/200] batch [1/3] time 1.682 (1.682) data 0.241 (0.241) loss 0.2334 (0.2334) acc 93.7500 (93.7500) lr 1.5225e-03 eta 0:11:14
epoch [67/200] batch [2/3] time 1.441 (1.561) data 0.000 (0.120) loss 0.3164 (0.2749) acc 93.7500 (93.7500) lr 1.5225e-03 eta 0:10:24
epoch [67/200] batch [3/3] time 1.449 (1.524) data 0.000 (0.080) loss 0.4771 (0.3423) acc 87.5000 (91.6667) lr 1.5090e-03 eta 0:10:08
epoch [68/200] batch [1/3] time 1.679 (1.679) data 0.234 (0.234) loss 0.3484 (0.3484) acc 90.6250 (90.6250) lr 1.5090e-03 eta 0:11:08
epoch [68/200] batch [2/3] time 1.436 (1.558) data 0.000 (0.117) loss 0.5659 (0.4572) acc 87.5000 (89.0625) lr 1.5090e-03 eta 0:10:18
epoch [68/200] batch [3/3] time 1.443 (1.519) data 0.000 (0.078) loss 0.7212 (0.5452) acc 87.5000 (88.5417) lr 1.4955e-03 eta 0:10:01
epoch [69/200] batch [1/3] time 1.673 (1.673) data 0.226 (0.226) loss 0.1658 (0.1658) acc 96.8750 (96.8750) lr 1.4955e-03 eta 0:11:00
epoch [69/200] batch [2/3] time 1.453 (1.563) data 0.000 (0.113) loss 0.3665 (0.2661) acc 87.5000 (92.1875) lr 1.4955e-03 eta 0:10:15
epoch [69/200] batch [3/3] time 1.436 (1.521) data 0.000 (0.075) loss 0.7729 (0.4351) acc 81.2500 (88.5417) lr 1.4818e-03 eta 0:09:57
epoch [70/200] batch [1/3] time 1.669 (1.669) data 0.231 (0.231) loss 0.3242 (0.3242) acc 93.7500 (93.7500) lr 1.4818e-03 eta 0:10:54
epoch [70/200] batch [2/3] time 1.438 (1.554) data 0.000 (0.115) loss 0.2234 (0.2738) acc 96.8750 (95.3125) lr 1.4818e-03 eta 0:10:07
epoch [70/200] batch [3/3] time 1.439 (1.515) data 0.000 (0.077) loss 0.2654 (0.2710) acc 93.7500 (94.7917) lr 1.4679e-03 eta 0:09:51
epoch [71/200] batch [1/3] time 1.663 (1.663) data 0.224 (0.224) loss 0.3191 (0.3191) acc 93.7500 (93.7500) lr 1.4679e-03 eta 0:10:46
epoch [71/200] batch [2/3] time 1.441 (1.552) data 0.000 (0.112) loss 0.6592 (0.4891) acc 84.3750 (89.0625) lr 1.4679e-03 eta 0:10:02
epoch [71/200] batch [3/3] time 1.441 (1.515) data 0.000 (0.075) loss 0.1081 (0.3621) acc 100.0000 (92.7083) lr 1.4540e-03 eta 0:09:46
epoch [72/200] batch [1/3] time 1.679 (1.679) data 0.240 (0.240) loss 0.2517 (0.2517) acc 90.6250 (90.6250) lr 1.4540e-03 eta 0:10:48
epoch [72/200] batch [2/3] time 1.444 (1.562) data 0.000 (0.120) loss 0.1050 (0.1784) acc 96.8750 (93.7500) lr 1.4540e-03 eta 0:10:01
epoch [72/200] batch [3/3] time 1.450 (1.524) data 0.000 (0.080) loss 0.4136 (0.2568) acc 87.5000 (91.6667) lr 1.4399e-03 eta 0:09:45
epoch [73/200] batch [1/3] time 1.678 (1.678) data 0.242 (0.242) loss 0.6025 (0.6025) acc 87.5000 (87.5000) lr 1.4399e-03 eta 0:10:42
epoch [73/200] batch [2/3] time 1.443 (1.561) data 0.000 (0.121) loss 0.2268 (0.4147) acc 96.8750 (92.1875) lr 1.4399e-03 eta 0:09:56
epoch [73/200] batch [3/3] time 1.450 (1.524) data 0.000 (0.081) loss 0.6831 (0.5042) acc 81.2500 (88.5417) lr 1.4258e-03 eta 0:09:40
epoch [74/200] batch [1/3] time 1.686 (1.686) data 0.234 (0.234) loss 0.1292 (0.1292) acc 93.7500 (93.7500) lr 1.4258e-03 eta 0:10:40
epoch [74/200] batch [2/3] time 1.443 (1.565) data 0.000 (0.117) loss 0.2208 (0.1750) acc 100.0000 (96.8750) lr 1.4258e-03 eta 0:09:53
epoch [74/200] batch [3/3] time 1.439 (1.523) data 0.000 (0.078) loss 0.2825 (0.2108) acc 87.5000 (93.7500) lr 1.4115e-03 eta 0:09:35
epoch [75/200] batch [1/3] time 1.675 (1.675) data 0.232 (0.232) loss 0.3313 (0.3313) acc 93.7500 (93.7500) lr 1.4115e-03 eta 0:10:31
epoch [75/200] batch [2/3] time 1.439 (1.557) data 0.000 (0.116) loss 0.5547 (0.4430) acc 90.6250 (92.1875) lr 1.4115e-03 eta 0:09:45
epoch [75/200] batch [3/3] time 1.442 (1.519) data 0.000 (0.077) loss 0.2385 (0.3748) acc 93.7500 (92.7083) lr 1.3971e-03 eta 0:09:29
epoch [76/200] batch [1/3] time 1.677 (1.677) data 0.237 (0.237) loss 0.2456 (0.2456) acc 93.7500 (93.7500) lr 1.3971e-03 eta 0:10:27
epoch [76/200] batch [2/3] time 1.445 (1.561) data 0.000 (0.118) loss 0.1975 (0.2216) acc 96.8750 (95.3125) lr 1.3971e-03 eta 0:09:42
epoch [76/200] batch [3/3] time 1.443 (1.522) data 0.000 (0.079) loss 0.4885 (0.3105) acc 87.5000 (92.7083) lr 1.3827e-03 eta 0:09:26
epoch [77/200] batch [1/3] time 1.674 (1.674) data 0.231 (0.231) loss 0.1340 (0.1340) acc 96.8750 (96.8750) lr 1.3827e-03 eta 0:10:21
epoch [77/200] batch [2/3] time 1.439 (1.557) data 0.000 (0.116) loss 0.6367 (0.3854) acc 78.1250 (87.5000) lr 1.3827e-03 eta 0:09:35
epoch [77/200] batch [3/3] time 1.443 (1.519) data 0.000 (0.077) loss 0.2466 (0.3391) acc 93.7500 (89.5833) lr 1.3681e-03 eta 0:09:20
epoch [78/200] batch [1/3] time 1.665 (1.665) data 0.224 (0.224) loss 0.7148 (0.7148) acc 84.3750 (84.3750) lr 1.3681e-03 eta 0:10:12
epoch [78/200] batch [2/3] time 1.442 (1.554) data 0.000 (0.112) loss 0.2773 (0.4961) acc 93.7500 (89.0625) lr 1.3681e-03 eta 0:09:30
epoch [78/200] batch [3/3] time 1.469 (1.525) data 0.000 (0.075) loss 0.2593 (0.4172) acc 93.7500 (90.6250) lr 1.3535e-03 eta 0:09:18
epoch [79/200] batch [1/3] time 1.708 (1.708) data 0.271 (0.271) loss 0.3245 (0.3245) acc 93.7500 (93.7500) lr 1.3535e-03 eta 0:10:23
epoch [79/200] batch [2/3] time 1.441 (1.574) data 0.000 (0.136) loss 0.2375 (0.2810) acc 93.7500 (93.7500) lr 1.3535e-03 eta 0:09:33
epoch [79/200] batch [3/3] time 1.532 (1.560) data 0.000 (0.090) loss 0.1343 (0.2321) acc 96.8750 (94.7917) lr 1.3387e-03 eta 0:09:26
epoch [80/200] batch [1/3] time 1.679 (1.679) data 0.241 (0.241) loss 0.2932 (0.2932) acc 93.7500 (93.7500) lr 1.3387e-03 eta 0:10:07
epoch [80/200] batch [2/3] time 1.459 (1.569) data 0.000 (0.120) loss 0.5342 (0.4137) acc 87.5000 (90.6250) lr 1.3387e-03 eta 0:09:26
epoch [80/200] batch [3/3] time 1.474 (1.537) data 0.000 (0.080) loss 0.6294 (0.4856) acc 84.3750 (88.5417) lr 1.3239e-03 eta 0:09:13
epoch [81/200] batch [1/3] time 1.807 (1.807) data 0.241 (0.241) loss 0.5806 (0.5806) acc 87.5000 (87.5000) lr 1.3239e-03 eta 0:10:48
epoch [81/200] batch [2/3] time 1.453 (1.630) data 0.000 (0.121) loss 0.2391 (0.4099) acc 93.7500 (90.6250) lr 1.3239e-03 eta 0:09:43
epoch [81/200] batch [3/3] time 1.446 (1.569) data 0.000 (0.081) loss 0.1455 (0.3217) acc 93.7500 (91.6667) lr 1.3090e-03 eta 0:09:20
epoch [82/200] batch [1/3] time 1.774 (1.774) data 0.326 (0.326) loss 0.4382 (0.4382) acc 96.8750 (96.8750) lr 1.3090e-03 eta 0:10:31
epoch [82/200] batch [2/3] time 1.476 (1.625) data 0.000 (0.163) loss 0.2212 (0.3297) acc 93.7500 (95.3125) lr 1.3090e-03 eta 0:09:36
epoch [82/200] batch [3/3] time 1.482 (1.577) data 0.000 (0.109) loss 0.0810 (0.2468) acc 100.0000 (96.8750) lr 1.2940e-03 eta 0:09:18
epoch [83/200] batch [1/3] time 1.675 (1.675) data 0.234 (0.234) loss 0.2759 (0.2759) acc 93.7500 (93.7500) lr 1.2940e-03 eta 0:09:51
epoch [83/200] batch [2/3] time 1.444 (1.559) data 0.000 (0.117) loss 0.2991 (0.2875) acc 93.7500 (93.7500) lr 1.2940e-03 eta 0:09:08
epoch [83/200] batch [3/3] time 1.444 (1.521) data 0.000 (0.078) loss 0.1639 (0.2463) acc 100.0000 (95.8333) lr 1.2790e-03 eta 0:08:53
epoch [84/200] batch [1/3] time 1.669 (1.669) data 0.234 (0.234) loss 0.7441 (0.7441) acc 84.3750 (84.3750) lr 1.2790e-03 eta 0:09:44
epoch [84/200] batch [2/3] time 1.438 (1.553) data 0.000 (0.117) loss 0.2803 (0.5122) acc 96.8750 (90.6250) lr 1.2790e-03 eta 0:09:02
epoch [84/200] batch [3/3] time 1.436 (1.514) data 0.000 (0.078) loss 0.2034 (0.4093) acc 100.0000 (93.7500) lr 1.2639e-03 eta 0:08:46
epoch [85/200] batch [1/3] time 1.670 (1.670) data 0.241 (0.241) loss 0.4102 (0.4102) acc 87.5000 (87.5000) lr 1.2639e-03 eta 0:09:39
epoch [85/200] batch [2/3] time 1.438 (1.554) data 0.000 (0.121) loss 0.5532 (0.4817) acc 90.6250 (89.0625) lr 1.2639e-03 eta 0:08:57
epoch [85/200] batch [3/3] time 1.447 (1.518) data 0.000 (0.080) loss 0.3662 (0.4432) acc 90.6250 (89.5833) lr 1.2487e-03 eta 0:08:43
epoch [86/200] batch [1/3] time 1.683 (1.683) data 0.236 (0.236) loss 0.1285 (0.1285) acc 96.8750 (96.8750) lr 1.2487e-03 eta 0:09:38
epoch [86/200] batch [2/3] time 1.443 (1.563) data 0.000 (0.118) loss 0.3384 (0.2335) acc 90.6250 (93.7500) lr 1.2487e-03 eta 0:08:55
epoch [86/200] batch [3/3] time 1.448 (1.524) data 0.000 (0.079) loss 0.2805 (0.2491) acc 90.6250 (92.7083) lr 1.2334e-03 eta 0:08:41
epoch [87/200] batch [1/3] time 1.660 (1.660) data 0.226 (0.226) loss 0.2812 (0.2812) acc 93.7500 (93.7500) lr 1.2334e-03 eta 0:09:26
epoch [87/200] batch [2/3] time 1.445 (1.552) data 0.000 (0.113) loss 0.4575 (0.3694) acc 90.6250 (92.1875) lr 1.2334e-03 eta 0:08:47
epoch [87/200] batch [3/3] time 1.437 (1.514) data 0.000 (0.075) loss 0.2698 (0.3362) acc 93.7500 (92.7083) lr 1.2181e-03 eta 0:08:33
epoch [88/200] batch [1/3] time 1.672 (1.672) data 0.225 (0.225) loss 0.3999 (0.3999) acc 93.7500 (93.7500) lr 1.2181e-03 eta 0:09:25
epoch [88/200] batch [2/3] time 1.462 (1.567) data 0.000 (0.112) loss 0.5342 (0.4670) acc 90.6250 (92.1875) lr 1.2181e-03 eta 0:08:48
epoch [88/200] batch [3/3] time 1.443 (1.526) data 0.000 (0.075) loss 0.1503 (0.3615) acc 96.8750 (93.7500) lr 1.2028e-03 eta 0:08:32
epoch [89/200] batch [1/3] time 1.714 (1.714) data 0.257 (0.257) loss 0.3206 (0.3206) acc 87.5000 (87.5000) lr 1.2028e-03 eta 0:09:34
epoch [89/200] batch [2/3] time 1.440 (1.577) data 0.000 (0.129) loss 0.4548 (0.3877) acc 87.5000 (87.5000) lr 1.2028e-03 eta 0:08:46
epoch [89/200] batch [3/3] time 1.458 (1.537) data 0.000 (0.086) loss 0.1843 (0.3199) acc 96.8750 (90.6250) lr 1.1874e-03 eta 0:08:31
epoch [90/200] batch [1/3] time 1.672 (1.672) data 0.225 (0.225) loss 0.5913 (0.5913) acc 87.5000 (87.5000) lr 1.1874e-03 eta 0:09:15
epoch [90/200] batch [2/3] time 1.571 (1.621) data 0.000 (0.113) loss 1.1123 (0.8518) acc 75.0000 (81.2500) lr 1.1874e-03 eta 0:08:56
epoch [90/200] batch [3/3] time 1.463 (1.569) data 0.000 (0.075) loss 0.3774 (0.6937) acc 87.5000 (83.3333) lr 1.1719e-03 eta 0:08:37
epoch [91/200] batch [1/3] time 1.769 (1.769) data 0.247 (0.247) loss 0.3113 (0.3113) acc 93.7500 (93.7500) lr 1.1719e-03 eta 0:09:41
epoch [91/200] batch [2/3] time 1.444 (1.607) data 0.000 (0.124) loss 0.1097 (0.2105) acc 96.8750 (95.3125) lr 1.1719e-03 eta 0:08:46
epoch [91/200] batch [3/3] time 1.453 (1.555) data 0.000 (0.083) loss 0.4543 (0.2918) acc 87.5000 (92.7083) lr 1.1564e-03 eta 0:08:28
epoch [92/200] batch [1/3] time 1.660 (1.660) data 0.225 (0.225) loss 0.3284 (0.3284) acc 93.7500 (93.7500) lr 1.1564e-03 eta 0:09:01
epoch [92/200] batch [2/3] time 1.440 (1.550) data 0.000 (0.112) loss 0.2734 (0.3009) acc 93.7500 (93.7500) lr 1.1564e-03 eta 0:08:23
epoch [92/200] batch [3/3] time 1.447 (1.516) data 0.000 (0.075) loss 0.3960 (0.3326) acc 87.5000 (91.6667) lr 1.1409e-03 eta 0:08:11
epoch [93/200] batch [1/3] time 1.687 (1.687) data 0.240 (0.240) loss 0.2402 (0.2402) acc 90.6250 (90.6250) lr 1.1409e-03 eta 0:09:04
epoch [93/200] batch [2/3] time 1.450 (1.568) data 0.000 (0.120) loss 0.3809 (0.3105) acc 93.7500 (92.1875) lr 1.1409e-03 eta 0:08:24
epoch [93/200] batch [3/3] time 1.443 (1.526) data 0.000 (0.080) loss 0.2274 (0.2828) acc 93.7500 (92.7083) lr 1.1253e-03 eta 0:08:09
epoch [94/200] batch [1/3] time 1.672 (1.672) data 0.233 (0.233) loss 0.3064 (0.3064) acc 93.7500 (93.7500) lr 1.1253e-03 eta 0:08:55
epoch [94/200] batch [2/3] time 1.433 (1.552) data 0.000 (0.117) loss 0.3579 (0.3322) acc 93.7500 (93.7500) lr 1.1253e-03 eta 0:08:15
epoch [94/200] batch [3/3] time 1.448 (1.518) data 0.000 (0.078) loss 0.1378 (0.2674) acc 96.8750 (94.7917) lr 1.1097e-03 eta 0:08:02
epoch [95/200] batch [1/3] time 1.676 (1.676) data 0.241 (0.241) loss 0.0732 (0.0732) acc 100.0000 (100.0000) lr 1.1097e-03 eta 0:08:51
epoch [95/200] batch [2/3] time 1.447 (1.561) data 0.000 (0.121) loss 0.3145 (0.1938) acc 90.6250 (95.3125) lr 1.1097e-03 eta 0:08:13
epoch [95/200] batch [3/3] time 1.443 (1.522) data 0.000 (0.081) loss 0.1958 (0.1945) acc 96.8750 (95.8333) lr 1.0941e-03 eta 0:07:59
epoch [96/200] batch [1/3] time 1.678 (1.678) data 0.243 (0.243) loss 0.2505 (0.2505) acc 96.8750 (96.8750) lr 1.0941e-03 eta 0:08:46
epoch [96/200] batch [2/3] time 1.443 (1.560) data 0.000 (0.122) loss 0.5557 (0.4031) acc 90.6250 (93.7500) lr 1.0941e-03 eta 0:08:08
epoch [96/200] batch [3/3] time 1.439 (1.520) data 0.000 (0.081) loss 0.2225 (0.3429) acc 93.7500 (93.7500) lr 1.0785e-03 eta 0:07:54
epoch [97/200] batch [1/3] time 1.684 (1.684) data 0.241 (0.241) loss 0.1874 (0.1874) acc 93.7500 (93.7500) lr 1.0785e-03 eta 0:08:43
epoch [97/200] batch [2/3] time 1.445 (1.565) data 0.000 (0.120) loss 0.3577 (0.2725) acc 87.5000 (90.6250) lr 1.0785e-03 eta 0:08:05
epoch [97/200] batch [3/3] time 1.453 (1.528) data 0.000 (0.080) loss 0.5166 (0.3539) acc 90.6250 (90.6250) lr 1.0628e-03 eta 0:07:51
epoch [98/200] batch [1/3] time 1.669 (1.669) data 0.230 (0.230) loss 0.4202 (0.4202) acc 87.5000 (87.5000) lr 1.0628e-03 eta 0:08:34
epoch [98/200] batch [2/3] time 1.540 (1.605) data 0.000 (0.115) loss 0.2722 (0.3462) acc 96.8750 (92.1875) lr 1.0628e-03 eta 0:08:12
epoch [98/200] batch [3/3] time 1.451 (1.553) data 0.000 (0.077) loss 0.0783 (0.2569) acc 100.0000 (94.7917) lr 1.0471e-03 eta 0:07:55
epoch [99/200] batch [1/3] time 1.691 (1.691) data 0.235 (0.235) loss 0.2330 (0.2330) acc 90.6250 (90.6250) lr 1.0471e-03 eta 0:08:35
epoch [99/200] batch [2/3] time 1.512 (1.601) data 0.000 (0.118) loss 0.5225 (0.3777) acc 93.7500 (92.1875) lr 1.0471e-03 eta 0:08:06
epoch [99/200] batch [3/3] time 1.508 (1.570) data 0.000 (0.078) loss 0.3862 (0.3806) acc 87.5000 (90.6250) lr 1.0314e-03 eta 0:07:55
epoch [100/200] batch [1/3] time 1.773 (1.773) data 0.268 (0.268) loss 0.4028 (0.4028) acc 93.7500 (93.7500) lr 1.0314e-03 eta 0:08:55
epoch [100/200] batch [2/3] time 1.465 (1.619) data 0.000 (0.134) loss 0.1243 (0.2635) acc 100.0000 (96.8750) lr 1.0314e-03 eta 0:08:07
epoch [100/200] batch [3/3] time 1.435 (1.558) data 0.000 (0.089) loss 0.1636 (0.2302) acc 96.8750 (96.8750) lr 1.0157e-03 eta 0:07:47
epoch [101/200] batch [1/3] time 1.680 (1.680) data 0.240 (0.240) loss 0.2073 (0.2073) acc 93.7500 (93.7500) lr 1.0157e-03 eta 0:08:22
epoch [101/200] batch [2/3] time 1.442 (1.561) data 0.000 (0.120) loss 0.1930 (0.2001) acc 96.8750 (95.3125) lr 1.0157e-03 eta 0:07:45
epoch [101/200] batch [3/3] time 1.438 (1.520) data 0.000 (0.080) loss 0.6025 (0.3343) acc 84.3750 (91.6667) lr 1.0000e-03 eta 0:07:31
epoch [102/200] batch [1/3] time 1.671 (1.671) data 0.226 (0.226) loss 0.3257 (0.3257) acc 87.5000 (87.5000) lr 1.0000e-03 eta 0:08:14
epoch [102/200] batch [2/3] time 1.436 (1.554) data 0.000 (0.113) loss 0.4622 (0.3939) acc 84.3750 (85.9375) lr 1.0000e-03 eta 0:07:38
epoch [102/200] batch [3/3] time 1.443 (1.517) data 0.000 (0.075) loss 0.2605 (0.3494) acc 93.7500 (88.5417) lr 9.8429e-04 eta 0:07:25
epoch [103/200] batch [1/3] time 1.661 (1.661) data 0.225 (0.225) loss 0.3489 (0.3489) acc 90.6250 (90.6250) lr 9.8429e-04 eta 0:08:06
epoch [103/200] batch [2/3] time 1.436 (1.548) data 0.000 (0.113) loss 0.4861 (0.4175) acc 93.7500 (92.1875) lr 9.8429e-04 eta 0:07:32
epoch [103/200] batch [3/3] time 1.440 (1.512) data 0.000 (0.075) loss 0.2642 (0.3664) acc 93.7500 (92.7083) lr 9.6859e-04 eta 0:07:20
epoch [104/200] batch [1/3] time 1.669 (1.669) data 0.225 (0.225) loss 0.0831 (0.0831) acc 100.0000 (100.0000) lr 9.6859e-04 eta 0:08:03
epoch [104/200] batch [2/3] time 1.450 (1.559) data 0.000 (0.113) loss 0.1526 (0.1179) acc 96.8750 (98.4375) lr 9.6859e-04 eta 0:07:30
epoch [104/200] batch [3/3] time 1.441 (1.520) data 0.000 (0.075) loss 0.2888 (0.1748) acc 96.8750 (97.9167) lr 9.5289e-04 eta 0:07:17
epoch [105/200] batch [1/3] time 1.667 (1.667) data 0.228 (0.228) loss 0.4917 (0.4917) acc 90.6250 (90.6250) lr 9.5289e-04 eta 0:07:58
epoch [105/200] batch [2/3] time 1.444 (1.556) data 0.000 (0.114) loss 0.3066 (0.3992) acc 93.7500 (92.1875) lr 9.5289e-04 eta 0:07:24
epoch [105/200] batch [3/3] time 1.440 (1.517) data 0.000 (0.076) loss 0.3904 (0.3962) acc 90.6250 (91.6667) lr 9.3721e-04 eta 0:07:12
epoch [106/200] batch [1/3] time 1.673 (1.673) data 0.225 (0.225) loss 0.1030 (0.1030) acc 96.8750 (96.8750) lr 9.3721e-04 eta 0:07:55
epoch [106/200] batch [2/3] time 1.445 (1.559) data 0.000 (0.113) loss 0.4497 (0.2763) acc 87.5000 (92.1875) lr 9.3721e-04 eta 0:07:21
epoch [106/200] batch [3/3] time 1.532 (1.550) data 0.000 (0.075) loss 0.2883 (0.2803) acc 93.7500 (92.7083) lr 9.2154e-04 eta 0:07:17
epoch [107/200] batch [1/3] time 1.765 (1.765) data 0.242 (0.242) loss 0.0746 (0.0746) acc 100.0000 (100.0000) lr 9.2154e-04 eta 0:08:15
epoch [107/200] batch [2/3] time 1.500 (1.632) data 0.000 (0.121) loss 0.1368 (0.1057) acc 96.8750 (98.4375) lr 9.2154e-04 eta 0:07:37
epoch [107/200] batch [3/3] time 1.495 (1.586) data 0.000 (0.081) loss 0.3157 (0.1757) acc 90.6250 (95.8333) lr 9.0589e-04 eta 0:07:22
epoch [108/200] batch [1/3] time 1.737 (1.737) data 0.231 (0.231) loss 0.2832 (0.2832) acc 93.7500 (93.7500) lr 9.0589e-04 eta 0:08:02
epoch [108/200] batch [2/3] time 1.514 (1.625) data 0.000 (0.116) loss 0.1882 (0.2357) acc 100.0000 (96.8750) lr 9.0589e-04 eta 0:07:30
epoch [108/200] batch [3/3] time 1.565 (1.605) data 0.000 (0.077) loss 0.3691 (0.2802) acc 93.7500 (95.8333) lr 8.9027e-04 eta 0:07:23
epoch [109/200] batch [1/3] time 1.795 (1.795) data 0.270 (0.270) loss 0.2163 (0.2163) acc 96.8750 (96.8750) lr 8.9027e-04 eta 0:08:13
epoch [109/200] batch [2/3] time 1.595 (1.695) data 0.001 (0.135) loss 0.4514 (0.3339) acc 90.6250 (93.7500) lr 8.9027e-04 eta 0:07:44
epoch [109/200] batch [3/3] time 1.516 (1.635) data 0.000 (0.090) loss 0.1073 (0.2583) acc 96.8750 (94.7917) lr 8.7467e-04 eta 0:07:26
epoch [110/200] batch [1/3] time 1.826 (1.826) data 0.250 (0.250) loss 0.1580 (0.1580) acc 93.7500 (93.7500) lr 8.7467e-04 eta 0:08:16
epoch [110/200] batch [2/3] time 1.504 (1.665) data 0.000 (0.125) loss 0.2649 (0.2114) acc 93.7500 (93.7500) lr 8.7467e-04 eta 0:07:31
epoch [110/200] batch [3/3] time 1.477 (1.603) data 0.000 (0.083) loss 0.0945 (0.1724) acc 93.7500 (93.7500) lr 8.5910e-04 eta 0:07:12
epoch [111/200] batch [1/3] time 1.782 (1.782) data 0.260 (0.260) loss 0.6890 (0.6890) acc 84.3750 (84.3750) lr 8.5910e-04 eta 0:07:59
epoch [111/200] batch [2/3] time 1.493 (1.638) data 0.000 (0.130) loss 0.1846 (0.4368) acc 96.8750 (90.6250) lr 8.5910e-04 eta 0:07:18
epoch [111/200] batch [3/3] time 1.432 (1.569) data 0.000 (0.087) loss 0.3784 (0.4173) acc 90.6250 (90.6250) lr 8.4357e-04 eta 0:06:58
epoch [112/200] batch [1/3] time 1.711 (1.711) data 0.241 (0.241) loss 0.0865 (0.0865) acc 100.0000 (100.0000) lr 8.4357e-04 eta 0:07:35
epoch [112/200] batch [2/3] time 1.546 (1.629) data 0.000 (0.121) loss 0.2502 (0.1684) acc 93.7500 (96.8750) lr 8.4357e-04 eta 0:07:11
epoch [112/200] batch [3/3] time 1.447 (1.568) data 0.003 (0.081) loss 0.4944 (0.2770) acc 84.3750 (92.7083) lr 8.2807e-04 eta 0:06:53
epoch [113/200] batch [1/3] time 1.704 (1.704) data 0.256 (0.256) loss 0.1855 (0.1855) acc 96.8750 (96.8750) lr 8.2807e-04 eta 0:07:28
epoch [113/200] batch [2/3] time 1.534 (1.619) data 0.000 (0.128) loss 0.8862 (0.5359) acc 71.8750 (84.3750) lr 8.2807e-04 eta 0:07:04
epoch [113/200] batch [3/3] time 1.437 (1.558) data 0.000 (0.085) loss 0.2974 (0.4564) acc 93.7500 (87.5000) lr 8.1262e-04 eta 0:06:46
epoch [114/200] batch [1/3] time 1.675 (1.675) data 0.233 (0.233) loss 0.2133 (0.2133) acc 93.7500 (93.7500) lr 8.1262e-04 eta 0:07:15
epoch [114/200] batch [2/3] time 1.438 (1.556) data 0.000 (0.116) loss 0.2781 (0.2457) acc 93.7500 (93.7500) lr 8.1262e-04 eta 0:06:43
epoch [114/200] batch [3/3] time 1.444 (1.519) data 0.000 (0.078) loss 0.3271 (0.2728) acc 96.8750 (94.7917) lr 7.9721e-04 eta 0:06:31
epoch [115/200] batch [1/3] time 1.676 (1.676) data 0.232 (0.232) loss 0.5107 (0.5107) acc 90.6250 (90.6250) lr 7.9721e-04 eta 0:07:10
epoch [115/200] batch [2/3] time 1.441 (1.558) data 0.000 (0.116) loss 0.0501 (0.2804) acc 100.0000 (95.3125) lr 7.9721e-04 eta 0:06:38
epoch [115/200] batch [3/3] time 1.449 (1.522) data 0.000 (0.077) loss 0.4290 (0.3299) acc 90.6250 (93.7500) lr 7.8186e-04 eta 0:06:28
epoch [116/200] batch [1/3] time 1.672 (1.672) data 0.223 (0.223) loss 0.3997 (0.3997) acc 87.5000 (87.5000) lr 7.8186e-04 eta 0:07:04
epoch [116/200] batch [2/3] time 1.441 (1.556) data 0.000 (0.112) loss 0.4592 (0.4294) acc 84.3750 (85.9375) lr 7.8186e-04 eta 0:06:33
epoch [116/200] batch [3/3] time 1.433 (1.515) data 0.000 (0.074) loss 0.0931 (0.3173) acc 96.8750 (89.5833) lr 7.6655e-04 eta 0:06:21
epoch [117/200] batch [1/3] time 1.661 (1.661) data 0.223 (0.223) loss 0.1517 (0.1517) acc 96.8750 (96.8750) lr 7.6655e-04 eta 0:06:57
epoch [117/200] batch [2/3] time 1.447 (1.554) data 0.000 (0.112) loss 0.4934 (0.3226) acc 87.5000 (92.1875) lr 7.6655e-04 eta 0:06:28
epoch [117/200] batch [3/3] time 1.435 (1.514) data 0.000 (0.074) loss 0.1556 (0.2669) acc 93.7500 (92.7083) lr 7.5131e-04 eta 0:06:17
epoch [118/200] batch [1/3] time 1.675 (1.675) data 0.240 (0.240) loss 0.1371 (0.1371) acc 96.8750 (96.8750) lr 7.5131e-04 eta 0:06:55
epoch [118/200] batch [2/3] time 1.437 (1.556) data 0.000 (0.120) loss 0.2983 (0.2177) acc 90.6250 (93.7500) lr 7.5131e-04 eta 0:06:24
epoch [118/200] batch [3/3] time 1.450 (1.521) data 0.000 (0.080) loss 0.4260 (0.2872) acc 90.6250 (92.7083) lr 7.3613e-04 eta 0:06:14
epoch [119/200] batch [1/3] time 1.666 (1.666) data 0.227 (0.227) loss 0.1218 (0.1218) acc 100.0000 (100.0000) lr 7.3613e-04 eta 0:06:48
epoch [119/200] batch [2/3] time 1.447 (1.557) data 0.000 (0.114) loss 0.2258 (0.1738) acc 93.7500 (96.8750) lr 7.3613e-04 eta 0:06:19
epoch [119/200] batch [3/3] time 1.445 (1.519) data 0.000 (0.076) loss 0.2092 (0.1856) acc 93.7500 (95.8333) lr 7.2101e-04 eta 0:06:09
epoch [120/200] batch [1/3] time 1.671 (1.671) data 0.224 (0.224) loss 0.2935 (0.2935) acc 93.7500 (93.7500) lr 7.2101e-04 eta 0:06:44
epoch [120/200] batch [2/3] time 1.446 (1.558) data 0.000 (0.112) loss 0.3660 (0.3297) acc 90.6250 (92.1875) lr 7.2101e-04 eta 0:06:15
epoch [120/200] batch [3/3] time 1.438 (1.518) data 0.000 (0.075) loss 0.5361 (0.3985) acc 90.6250 (91.6667) lr 7.0596e-04 eta 0:06:04
epoch [121/200] batch [1/3] time 1.664 (1.664) data 0.221 (0.221) loss 0.2101 (0.2101) acc 96.8750 (96.8750) lr 7.0596e-04 eta 0:06:37
epoch [121/200] batch [2/3] time 1.439 (1.551) data 0.000 (0.111) loss 0.2190 (0.2145) acc 96.8750 (96.8750) lr 7.0596e-04 eta 0:06:09
epoch [121/200] batch [3/3] time 1.439 (1.514) data 0.000 (0.074) loss 0.1810 (0.2034) acc 93.7500 (95.8333) lr 6.9098e-04 eta 0:05:58
epoch [122/200] batch [1/3] time 1.664 (1.664) data 0.225 (0.225) loss 0.3074 (0.3074) acc 87.5000 (87.5000) lr 6.9098e-04 eta 0:06:32
epoch [122/200] batch [2/3] time 1.446 (1.555) data 0.000 (0.113) loss 0.0341 (0.1707) acc 100.0000 (93.7500) lr 6.9098e-04 eta 0:06:05
epoch [122/200] batch [3/3] time 1.538 (1.549) data 0.000 (0.075) loss 0.2371 (0.1928) acc 93.7500 (93.7500) lr 6.7608e-04 eta 0:06:02
epoch [123/200] batch [1/3] time 1.762 (1.762) data 0.251 (0.251) loss 0.3770 (0.3770) acc 90.6250 (90.6250) lr 6.7608e-04 eta 0:06:50
epoch [123/200] batch [2/3] time 1.441 (1.601) data 0.000 (0.125) loss 0.2568 (0.3169) acc 93.7500 (92.1875) lr 6.7608e-04 eta 0:06:11
epoch [123/200] batch [3/3] time 1.438 (1.547) data 0.000 (0.084) loss 0.3752 (0.3363) acc 87.5000 (90.6250) lr 6.6126e-04 eta 0:05:57
epoch [124/200] batch [1/3] time 1.665 (1.665) data 0.227 (0.227) loss 0.3281 (0.3281) acc 90.6250 (90.6250) lr 6.6126e-04 eta 0:06:23
epoch [124/200] batch [2/3] time 1.440 (1.553) data 0.000 (0.114) loss 0.2156 (0.2719) acc 90.6250 (90.6250) lr 6.6126e-04 eta 0:05:55
epoch [124/200] batch [3/3] time 1.431 (1.512) data 0.000 (0.076) loss 0.3252 (0.2896) acc 87.5000 (89.5833) lr 6.4653e-04 eta 0:05:44
epoch [125/200] batch [1/3] time 1.666 (1.666) data 0.226 (0.226) loss 0.3311 (0.3311) acc 90.6250 (90.6250) lr 6.4653e-04 eta 0:06:18
epoch [125/200] batch [2/3] time 1.430 (1.548) data 0.000 (0.113) loss 0.1273 (0.2292) acc 96.8750 (93.7500) lr 6.4653e-04 eta 0:05:49
epoch [125/200] batch [3/3] time 1.436 (1.511) data 0.000 (0.075) loss 0.2529 (0.2371) acc 93.7500 (93.7500) lr 6.3188e-04 eta 0:05:39
epoch [126/200] batch [1/3] time 1.661 (1.661) data 0.225 (0.225) loss 0.2213 (0.2213) acc 96.8750 (96.8750) lr 6.3188e-04 eta 0:06:12
epoch [126/200] batch [2/3] time 1.440 (1.551) data 0.000 (0.112) loss 0.3640 (0.2927) acc 90.6250 (93.7500) lr 6.3188e-04 eta 0:05:45
epoch [126/200] batch [3/3] time 1.439 (1.513) data 0.000 (0.075) loss 0.1086 (0.2313) acc 96.8750 (94.7917) lr 6.1732e-04 eta 0:05:35
epoch [127/200] batch [1/3] time 1.655 (1.655) data 0.220 (0.220) loss 0.0970 (0.0970) acc 96.8750 (96.8750) lr 6.1732e-04 eta 0:06:05
epoch [127/200] batch [2/3] time 1.443 (1.549) data 0.000 (0.110) loss 0.2181 (0.1576) acc 96.8750 (96.8750) lr 6.1732e-04 eta 0:05:40
epoch [127/200] batch [3/3] time 1.441 (1.513) data 0.000 (0.074) loss 0.4463 (0.2538) acc 87.5000 (93.7500) lr 6.0285e-04 eta 0:05:31
epoch [128/200] batch [1/3] time 1.684 (1.684) data 0.242 (0.242) loss 0.3750 (0.3750) acc 87.5000 (87.5000) lr 6.0285e-04 eta 0:06:07
epoch [128/200] batch [2/3] time 1.444 (1.564) data 0.000 (0.121) loss 0.2074 (0.2912) acc 93.7500 (90.6250) lr 6.0285e-04 eta 0:05:39
epoch [128/200] batch [3/3] time 1.439 (1.522) data 0.000 (0.081) loss 0.4556 (0.3460) acc 87.5000 (89.5833) lr 5.8849e-04 eta 0:05:28
epoch [129/200] batch [1/3] time 1.662 (1.662) data 0.222 (0.222) loss 0.3757 (0.3757) acc 84.3750 (84.3750) lr 5.8849e-04 eta 0:05:57
epoch [129/200] batch [2/3] time 1.437 (1.550) data 0.000 (0.111) loss 0.4148 (0.3953) acc 90.6250 (87.5000) lr 5.8849e-04 eta 0:05:31
epoch [129/200] batch [3/3] time 1.444 (1.514) data 0.000 (0.074) loss 0.1807 (0.3237) acc 93.7500 (89.5833) lr 5.7422e-04 eta 0:05:22
epoch [130/200] batch [1/3] time 1.663 (1.663) data 0.222 (0.222) loss 0.4028 (0.4028) acc 93.7500 (93.7500) lr 5.7422e-04 eta 0:05:52
epoch [130/200] batch [2/3] time 1.440 (1.551) data 0.000 (0.111) loss 0.2213 (0.3121) acc 93.7500 (93.7500) lr 5.7422e-04 eta 0:05:27
epoch [130/200] batch [3/3] time 1.446 (1.516) data 0.000 (0.074) loss 0.4138 (0.3460) acc 93.7500 (93.7500) lr 5.6006e-04 eta 0:05:18
epoch [131/200] batch [1/3] time 1.671 (1.671) data 0.242 (0.242) loss 0.0712 (0.0712) acc 100.0000 (100.0000) lr 5.6006e-04 eta 0:05:49
epoch [131/200] batch [2/3] time 1.440 (1.556) data 0.000 (0.121) loss 0.2795 (0.1754) acc 90.6250 (95.3125) lr 5.6006e-04 eta 0:05:23
epoch [131/200] batch [3/3] time 1.437 (1.516) data 0.000 (0.081) loss 0.1554 (0.1687) acc 96.8750 (95.8333) lr 5.4601e-04 eta 0:05:13
epoch [132/200] batch [1/3] time 1.673 (1.673) data 0.233 (0.233) loss 0.1361 (0.1361) acc 96.8750 (96.8750) lr 5.4601e-04 eta 0:05:44
epoch [132/200] batch [2/3] time 1.436 (1.555) data 0.000 (0.116) loss 0.3193 (0.2277) acc 90.6250 (93.7500) lr 5.4601e-04 eta 0:05:18
epoch [132/200] batch [3/3] time 1.439 (1.516) data 0.000 (0.078) loss 0.2805 (0.2453) acc 90.6250 (92.7083) lr 5.3207e-04 eta 0:05:09
epoch [133/200] batch [1/3] time 1.671 (1.671) data 0.231 (0.231) loss 0.1523 (0.1523) acc 96.8750 (96.8750) lr 5.3207e-04 eta 0:05:39
epoch [133/200] batch [2/3] time 1.430 (1.550) data 0.000 (0.115) loss 0.2961 (0.2242) acc 87.5000 (92.1875) lr 5.3207e-04 eta 0:05:13
epoch [133/200] batch [3/3] time 1.439 (1.513) data 0.000 (0.077) loss 0.3589 (0.2691) acc 90.6250 (91.6667) lr 5.1825e-04 eta 0:05:04
epoch [134/200] batch [1/3] time 1.678 (1.678) data 0.242 (0.242) loss 0.3384 (0.3384) acc 87.5000 (87.5000) lr 5.1825e-04 eta 0:05:35
epoch [134/200] batch [2/3] time 1.447 (1.563) data 0.000 (0.121) loss 0.5537 (0.4460) acc 87.5000 (87.5000) lr 5.1825e-04 eta 0:05:10
epoch [134/200] batch [3/3] time 1.436 (1.521) data 0.000 (0.081) loss 0.5356 (0.4759) acc 87.5000 (87.5000) lr 5.0454e-04 eta 0:05:01
epoch [135/200] batch [1/3] time 1.667 (1.667) data 0.223 (0.223) loss 0.6030 (0.6030) acc 87.5000 (87.5000) lr 5.0454e-04 eta 0:05:28
epoch [135/200] batch [2/3] time 1.445 (1.556) data 0.000 (0.112) loss 0.3669 (0.4850) acc 90.6250 (89.0625) lr 5.0454e-04 eta 0:05:05
epoch [135/200] batch [3/3] time 1.435 (1.516) data 0.000 (0.074) loss 0.4519 (0.4740) acc 87.5000 (88.5417) lr 4.9096e-04 eta 0:04:55
epoch [136/200] batch [1/3] time 1.686 (1.686) data 0.240 (0.240) loss 0.4690 (0.4690) acc 93.7500 (93.7500) lr 4.9096e-04 eta 0:05:27
epoch [136/200] batch [2/3] time 1.431 (1.559) data 0.000 (0.120) loss 0.2369 (0.3530) acc 93.7500 (93.7500) lr 4.9096e-04 eta 0:05:00
epoch [136/200] batch [3/3] time 1.432 (1.516) data 0.000 (0.080) loss 0.1790 (0.2950) acc 96.8750 (94.7917) lr 4.7750e-04 eta 0:04:51
epoch [137/200] batch [1/3] time 1.655 (1.655) data 0.224 (0.224) loss 0.2520 (0.2520) acc 96.8750 (96.8750) lr 4.7750e-04 eta 0:05:16
epoch [137/200] batch [2/3] time 1.450 (1.552) data 0.000 (0.112) loss 0.1929 (0.2224) acc 93.7500 (95.3125) lr 4.7750e-04 eta 0:04:54
epoch [137/200] batch [3/3] time 1.436 (1.513) data 0.000 (0.075) loss 0.2445 (0.2298) acc 93.7500 (94.7917) lr 4.6417e-04 eta 0:04:46
epoch [138/200] batch [1/3] time 1.662 (1.662) data 0.222 (0.222) loss 0.2123 (0.2123) acc 96.8750 (96.8750) lr 4.6417e-04 eta 0:05:12
epoch [138/200] batch [2/3] time 1.440 (1.551) data 0.000 (0.111) loss 0.1826 (0.1974) acc 93.7500 (95.3125) lr 4.6417e-04 eta 0:04:50
epoch [138/200] batch [3/3] time 1.446 (1.516) data 0.000 (0.074) loss 0.3799 (0.2583) acc 87.5000 (92.7083) lr 4.5098e-04 eta 0:04:41
epoch [139/200] batch [1/3] time 1.666 (1.666) data 0.225 (0.225) loss 0.1077 (0.1077) acc 100.0000 (100.0000) lr 4.5098e-04 eta 0:05:08
epoch [139/200] batch [2/3] time 1.427 (1.546) data 0.000 (0.113) loss 0.3945 (0.2511) acc 87.5000 (93.7500) lr 4.5098e-04 eta 0:04:44
epoch [139/200] batch [3/3] time 1.436 (1.510) data 0.000 (0.075) loss 0.4387 (0.3136) acc 93.7500 (93.7500) lr 4.3792e-04 eta 0:04:36
epoch [140/200] batch [1/3] time 1.659 (1.659) data 0.223 (0.223) loss 0.3191 (0.3191) acc 90.6250 (90.6250) lr 4.3792e-04 eta 0:05:01
epoch [140/200] batch [2/3] time 1.443 (1.551) data 0.000 (0.111) loss 0.1688 (0.2440) acc 93.7500 (92.1875) lr 4.3792e-04 eta 0:04:40
epoch [140/200] batch [3/3] time 1.438 (1.513) data 0.000 (0.074) loss 0.0845 (0.1908) acc 100.0000 (94.7917) lr 4.2499e-04 eta 0:04:32
epoch [141/200] batch [1/3] time 1.680 (1.680) data 0.240 (0.240) loss 0.0681 (0.0681) acc 100.0000 (100.0000) lr 4.2499e-04 eta 0:05:00
epoch [141/200] batch [2/3] time 1.436 (1.558) data 0.000 (0.120) loss 0.2544 (0.1613) acc 93.7500 (96.8750) lr 4.2499e-04 eta 0:04:37
epoch [141/200] batch [3/3] time 1.448 (1.522) data 0.000 (0.080) loss 0.0708 (0.1311) acc 100.0000 (97.9167) lr 4.1221e-04 eta 0:04:29
epoch [142/200] batch [1/3] time 1.675 (1.675) data 0.230 (0.230) loss 0.3545 (0.3545) acc 93.7500 (93.7500) lr 4.1221e-04 eta 0:04:54
epoch [142/200] batch [2/3] time 1.447 (1.561) data 0.000 (0.115) loss 0.4226 (0.3885) acc 96.8750 (95.3125) lr 4.1221e-04 eta 0:04:33
epoch [142/200] batch [3/3] time 1.447 (1.523) data 0.000 (0.077) loss 0.2211 (0.3327) acc 93.7500 (94.7917) lr 3.9958e-04 eta 0:04:24
epoch [143/200] batch [1/3] time 1.674 (1.674) data 0.232 (0.232) loss 0.6748 (0.6748) acc 87.5000 (87.5000) lr 3.9958e-04 eta 0:04:49
epoch [143/200] batch [2/3] time 1.442 (1.558) data 0.000 (0.116) loss 0.1117 (0.3932) acc 96.8750 (92.1875) lr 3.9958e-04 eta 0:04:27
epoch [143/200] batch [3/3] time 1.441 (1.519) data 0.000 (0.077) loss 0.4167 (0.4011) acc 87.5000 (90.6250) lr 3.8709e-04 eta 0:04:19
epoch [144/200] batch [1/3] time 1.662 (1.662) data 0.225 (0.225) loss 0.2795 (0.2795) acc 93.7500 (93.7500) lr 3.8709e-04 eta 0:04:42
epoch [144/200] batch [2/3] time 1.435 (1.548) data 0.000 (0.113) loss 0.3386 (0.3091) acc 90.6250 (92.1875) lr 3.8709e-04 eta 0:04:21
epoch [144/200] batch [3/3] time 1.433 (1.510) data 0.000 (0.075) loss 0.1689 (0.2624) acc 96.8750 (93.7500) lr 3.7476e-04 eta 0:04:13
epoch [145/200] batch [1/3] time 1.676 (1.676) data 0.240 (0.240) loss 0.4927 (0.4927) acc 84.3750 (84.3750) lr 3.7476e-04 eta 0:04:39
epoch [145/200] batch [2/3] time 1.441 (1.558) data 0.000 (0.120) loss 0.3098 (0.4012) acc 90.6250 (87.5000) lr 3.7476e-04 eta 0:04:18
epoch [145/200] batch [3/3] time 1.445 (1.521) data 0.000 (0.080) loss 0.1395 (0.3140) acc 96.8750 (90.6250) lr 3.6258e-04 eta 0:04:10
epoch [146/200] batch [1/3] time 1.660 (1.660) data 0.222 (0.222) loss 0.1985 (0.1985) acc 96.8750 (96.8750) lr 3.6258e-04 eta 0:04:32
epoch [146/200] batch [2/3] time 1.441 (1.550) data 0.000 (0.111) loss 0.3037 (0.2511) acc 93.7500 (95.3125) lr 3.6258e-04 eta 0:04:12
epoch [146/200] batch [3/3] time 1.442 (1.514) data 0.000 (0.074) loss 0.1665 (0.2229) acc 96.8750 (95.8333) lr 3.5055e-04 eta 0:04:05
epoch [147/200] batch [1/3] time 1.664 (1.664) data 0.225 (0.225) loss 0.4309 (0.4309) acc 90.6250 (90.6250) lr 3.5055e-04 eta 0:04:27
epoch [147/200] batch [2/3] time 1.435 (1.550) data 0.000 (0.112) loss 0.2947 (0.3628) acc 96.8750 (93.7500) lr 3.5055e-04 eta 0:04:07
epoch [147/200] batch [3/3] time 1.443 (1.514) data 0.000 (0.075) loss 0.1198 (0.2818) acc 96.8750 (94.7917) lr 3.3869e-04 eta 0:04:00
epoch [148/200] batch [1/3] time 1.682 (1.682) data 0.241 (0.241) loss 0.1967 (0.1967) acc 93.7500 (93.7500) lr 3.3869e-04 eta 0:04:25
epoch [148/200] batch [2/3] time 1.437 (1.559) data 0.000 (0.121) loss 0.1653 (0.1810) acc 96.8750 (95.3125) lr 3.3869e-04 eta 0:04:04
epoch [148/200] batch [3/3] time 1.444 (1.521) data 0.000 (0.080) loss 0.1503 (0.1707) acc 93.7500 (94.7917) lr 3.2699e-04 eta 0:03:57
epoch [149/200] batch [1/3] time 1.666 (1.666) data 0.224 (0.224) loss 0.1666 (0.1666) acc 93.7500 (93.7500) lr 3.2699e-04 eta 0:04:18
epoch [149/200] batch [2/3] time 1.444 (1.555) data 0.000 (0.112) loss 0.1498 (0.1582) acc 96.8750 (95.3125) lr 3.2699e-04 eta 0:03:59
epoch [149/200] batch [3/3] time 1.444 (1.518) data 0.000 (0.075) loss 0.3369 (0.2178) acc 87.5000 (92.7083) lr 3.1545e-04 eta 0:03:52
epoch [150/200] batch [1/3] time 1.673 (1.673) data 0.234 (0.234) loss 0.0526 (0.0526) acc 100.0000 (100.0000) lr 3.1545e-04 eta 0:04:14
epoch [150/200] batch [2/3] time 1.437 (1.555) data 0.000 (0.117) loss 0.1793 (0.1159) acc 93.7500 (96.8750) lr 3.1545e-04 eta 0:03:54
epoch [150/200] batch [3/3] time 1.442 (1.517) data 0.000 (0.078) loss 0.0311 (0.0877) acc 100.0000 (97.9167) lr 3.0409e-04 eta 0:03:47
epoch [151/200] batch [1/3] time 1.675 (1.675) data 0.230 (0.230) loss 0.5874 (0.5874) acc 84.3750 (84.3750) lr 3.0409e-04 eta 0:04:09
epoch [151/200] batch [2/3] time 1.445 (1.560) data 0.000 (0.115) loss 0.3042 (0.4458) acc 90.6250 (87.5000) lr 3.0409e-04 eta 0:03:50
epoch [151/200] batch [3/3] time 1.443 (1.521) data 0.000 (0.077) loss 0.3096 (0.4004) acc 90.6250 (88.5417) lr 2.9289e-04 eta 0:03:43
epoch [152/200] batch [1/3] time 1.657 (1.657) data 0.223 (0.223) loss 0.5229 (0.5229) acc 87.5000 (87.5000) lr 2.9289e-04 eta 0:04:01
epoch [152/200] batch [2/3] time 1.442 (1.549) data 0.000 (0.112) loss 0.2072 (0.3651) acc 90.6250 (89.0625) lr 2.9289e-04 eta 0:03:44
epoch [152/200] batch [3/3] time 1.449 (1.516) data 0.000 (0.074) loss 0.0894 (0.2732) acc 100.0000 (92.7083) lr 2.8187e-04 eta 0:03:38
epoch [153/200] batch [1/3] time 1.658 (1.658) data 0.224 (0.224) loss 0.2566 (0.2566) acc 93.7500 (93.7500) lr 2.8187e-04 eta 0:03:57
epoch [153/200] batch [2/3] time 1.444 (1.551) data 0.000 (0.112) loss 0.2615 (0.2590) acc 90.6250 (92.1875) lr 2.8187e-04 eta 0:03:40
epoch [153/200] batch [3/3] time 1.439 (1.513) data 0.000 (0.075) loss 0.2434 (0.2538) acc 93.7500 (92.7083) lr 2.7103e-04 eta 0:03:33
epoch [154/200] batch [1/3] time 1.677 (1.677) data 0.233 (0.233) loss 0.0970 (0.0970) acc 100.0000 (100.0000) lr 2.7103e-04 eta 0:03:54
epoch [154/200] batch [2/3] time 1.442 (1.560) data 0.000 (0.116) loss 0.1046 (0.1008) acc 100.0000 (100.0000) lr 2.7103e-04 eta 0:03:36
epoch [154/200] batch [3/3] time 1.445 (1.521) data 0.000 (0.078) loss 0.1024 (0.1013) acc 96.8750 (98.9583) lr 2.6037e-04 eta 0:03:29
epoch [155/200] batch [1/3] time 1.666 (1.666) data 0.228 (0.228) loss 0.3757 (0.3757) acc 90.6250 (90.6250) lr 2.6037e-04 eta 0:03:48
epoch [155/200] batch [2/3] time 1.445 (1.556) data 0.000 (0.114) loss 0.2186 (0.2972) acc 93.7500 (92.1875) lr 2.6037e-04 eta 0:03:31
epoch [155/200] batch [3/3] time 1.444 (1.518) data 0.000 (0.076) loss 0.4299 (0.3414) acc 90.6250 (91.6667) lr 2.4989e-04 eta 0:03:24
epoch [156/200] batch [1/3] time 1.671 (1.671) data 0.226 (0.226) loss 0.1588 (0.1588) acc 96.8750 (96.8750) lr 2.4989e-04 eta 0:03:43
epoch [156/200] batch [2/3] time 1.442 (1.556) data 0.000 (0.113) loss 0.5522 (0.3555) acc 81.2500 (89.0625) lr 2.4989e-04 eta 0:03:26
epoch [156/200] batch [3/3] time 1.439 (1.517) data 0.000 (0.075) loss 0.2001 (0.3037) acc 96.8750 (91.6667) lr 2.3959e-04 eta 0:03:20
epoch [157/200] batch [1/3] time 1.661 (1.661) data 0.221 (0.221) loss 0.2656 (0.2656) acc 90.6250 (90.6250) lr 2.3959e-04 eta 0:03:37
epoch [157/200] batch [2/3] time 1.431 (1.546) data 0.000 (0.111) loss 0.3416 (0.3036) acc 93.7500 (92.1875) lr 2.3959e-04 eta 0:03:20
epoch [157/200] batch [3/3] time 1.444 (1.512) data 0.000 (0.074) loss 0.1237 (0.2436) acc 96.8750 (93.7500) lr 2.2949e-04 eta 0:03:15
epoch [158/200] batch [1/3] time 1.671 (1.671) data 0.231 (0.231) loss 0.1398 (0.1398) acc 93.7500 (93.7500) lr 2.2949e-04 eta 0:03:33
epoch [158/200] batch [2/3] time 1.438 (1.555) data 0.000 (0.116) loss 0.4180 (0.2789) acc 84.3750 (89.0625) lr 2.2949e-04 eta 0:03:17
epoch [158/200] batch [3/3] time 1.439 (1.516) data 0.000 (0.077) loss 0.0185 (0.1921) acc 100.0000 (92.7083) lr 2.1957e-04 eta 0:03:11
epoch [159/200] batch [1/3] time 1.671 (1.671) data 0.232 (0.232) loss 0.2651 (0.2651) acc 96.8750 (96.8750) lr 2.1957e-04 eta 0:03:28
epoch [159/200] batch [2/3] time 1.432 (1.551) data 0.000 (0.116) loss 0.1340 (0.1996) acc 96.8750 (96.8750) lr 2.1957e-04 eta 0:03:12
epoch [159/200] batch [3/3] time 1.444 (1.515) data 0.000 (0.077) loss 0.0558 (0.1517) acc 100.0000 (97.9167) lr 2.0984e-04 eta 0:03:06
epoch [160/200] batch [1/3] time 1.678 (1.678) data 0.240 (0.240) loss 0.2291 (0.2291) acc 93.7500 (93.7500) lr 2.0984e-04 eta 0:03:24
epoch [160/200] batch [2/3] time 1.439 (1.558) data 0.000 (0.120) loss 0.3027 (0.2659) acc 90.6250 (92.1875) lr 2.0984e-04 eta 0:03:08
epoch [160/200] batch [3/3] time 1.445 (1.521) data 0.000 (0.080) loss 0.2546 (0.2622) acc 96.8750 (93.7500) lr 2.0032e-04 eta 0:03:02
epoch [161/200] batch [1/3] time 1.681 (1.681) data 0.233 (0.233) loss 0.3762 (0.3762) acc 93.7500 (93.7500) lr 2.0032e-04 eta 0:03:20
epoch [161/200] batch [2/3] time 1.440 (1.561) data 0.000 (0.117) loss 0.1818 (0.2790) acc 93.7500 (93.7500) lr 2.0032e-04 eta 0:03:04
epoch [161/200] batch [3/3] time 1.447 (1.523) data 0.000 (0.078) loss 0.1055 (0.2212) acc 96.8750 (94.7917) lr 1.9098e-04 eta 0:02:58
epoch [162/200] batch [1/3] time 1.685 (1.685) data 0.239 (0.239) loss 0.4453 (0.4453) acc 87.5000 (87.5000) lr 1.9098e-04 eta 0:03:15
epoch [162/200] batch [2/3] time 1.437 (1.561) data 0.000 (0.120) loss 0.1494 (0.2974) acc 96.8750 (92.1875) lr 1.9098e-04 eta 0:02:59
epoch [162/200] batch [3/3] time 1.431 (1.518) data 0.000 (0.080) loss 0.3359 (0.3102) acc 93.7500 (92.7083) lr 1.8185e-04 eta 0:02:53
epoch [163/200] batch [1/3] time 1.673 (1.673) data 0.238 (0.238) loss 0.5337 (0.5337) acc 87.5000 (87.5000) lr 1.8185e-04 eta 0:03:09
epoch [163/200] batch [2/3] time 1.439 (1.556) data 0.000 (0.119) loss 0.1070 (0.3203) acc 100.0000 (93.7500) lr 1.8185e-04 eta 0:02:54
epoch [163/200] batch [3/3] time 1.441 (1.518) data 0.000 (0.079) loss 0.2191 (0.2866) acc 93.7500 (93.7500) lr 1.7292e-04 eta 0:02:48
epoch [164/200] batch [1/3] time 1.682 (1.682) data 0.240 (0.240) loss 0.1793 (0.1793) acc 96.8750 (96.8750) lr 1.7292e-04 eta 0:03:05
epoch [164/200] batch [2/3] time 1.447 (1.565) data 0.000 (0.120) loss 0.3030 (0.2411) acc 90.6250 (93.7500) lr 1.7292e-04 eta 0:02:50
epoch [164/200] batch [3/3] time 1.445 (1.525) data 0.000 (0.080) loss 0.0807 (0.1877) acc 96.8750 (94.7917) lr 1.6419e-04 eta 0:02:44
epoch [165/200] batch [1/3] time 1.677 (1.677) data 0.235 (0.235) loss 0.1785 (0.1785) acc 96.8750 (96.8750) lr 1.6419e-04 eta 0:02:59
epoch [165/200] batch [2/3] time 1.445 (1.561) data 0.000 (0.117) loss 0.2026 (0.1906) acc 93.7500 (95.3125) lr 1.6419e-04 eta 0:02:45
epoch [165/200] batch [3/3] time 1.437 (1.519) data 0.000 (0.078) loss 0.4631 (0.2814) acc 87.5000 (92.7083) lr 1.5567e-04 eta 0:02:39
epoch [166/200] batch [1/3] time 1.683 (1.683) data 0.241 (0.241) loss 0.1429 (0.1429) acc 96.8750 (96.8750) lr 1.5567e-04 eta 0:02:55
epoch [166/200] batch [2/3] time 1.436 (1.559) data 0.000 (0.120) loss 0.2593 (0.2011) acc 87.5000 (92.1875) lr 1.5567e-04 eta 0:02:40
epoch [166/200] batch [3/3] time 1.434 (1.517) data 0.000 (0.080) loss 0.3125 (0.2382) acc 93.7500 (92.7083) lr 1.4736e-04 eta 0:02:34
epoch [167/200] batch [1/3] time 1.673 (1.673) data 0.233 (0.233) loss 0.1558 (0.1558) acc 96.8750 (96.8750) lr 1.4736e-04 eta 0:02:48
epoch [167/200] batch [2/3] time 1.436 (1.554) data 0.000 (0.116) loss 0.1995 (0.1776) acc 93.7500 (95.3125) lr 1.4736e-04 eta 0:02:35
epoch [167/200] batch [3/3] time 1.442 (1.517) data 0.000 (0.078) loss 0.0533 (0.1362) acc 96.8750 (95.8333) lr 1.3926e-04 eta 0:02:30
epoch [168/200] batch [1/3] time 1.688 (1.688) data 0.244 (0.244) loss 0.2421 (0.2421) acc 93.7500 (93.7500) lr 1.3926e-04 eta 0:02:45
epoch [168/200] batch [2/3] time 1.447 (1.567) data 0.000 (0.122) loss 0.1063 (0.1742) acc 100.0000 (96.8750) lr 1.3926e-04 eta 0:02:32
epoch [168/200] batch [3/3] time 1.441 (1.525) data 0.000 (0.082) loss 0.2051 (0.1845) acc 93.7500 (95.8333) lr 1.3137e-04 eta 0:02:26
epoch [169/200] batch [1/3] time 1.663 (1.663) data 0.224 (0.224) loss 0.1539 (0.1539) acc 96.8750 (96.8750) lr 1.3137e-04 eta 0:02:37
epoch [169/200] batch [2/3] time 1.446 (1.554) data 0.000 (0.112) loss 0.3931 (0.2735) acc 90.6250 (93.7500) lr 1.3137e-04 eta 0:02:26
epoch [169/200] batch [3/3] time 1.438 (1.515) data 0.000 (0.075) loss 0.0461 (0.1977) acc 100.0000 (95.8333) lr 1.2369e-04 eta 0:02:20
epoch [170/200] batch [1/3] time 1.681 (1.681) data 0.241 (0.241) loss 0.4578 (0.4578) acc 87.5000 (87.5000) lr 1.2369e-04 eta 0:02:34
epoch [170/200] batch [2/3] time 1.448 (1.565) data 0.000 (0.121) loss 0.1506 (0.3042) acc 96.8750 (92.1875) lr 1.2369e-04 eta 0:02:22
epoch [170/200] batch [3/3] time 1.435 (1.521) data 0.000 (0.080) loss 0.4978 (0.3687) acc 90.6250 (91.6667) lr 1.1623e-04 eta 0:02:16
epoch [171/200] batch [1/3] time 1.676 (1.676) data 0.227 (0.227) loss 0.2683 (0.2683) acc 93.7500 (93.7500) lr 1.1623e-04 eta 0:02:29
epoch [171/200] batch [2/3] time 1.439 (1.557) data 0.000 (0.113) loss 0.2886 (0.2784) acc 93.7500 (93.7500) lr 1.1623e-04 eta 0:02:17
epoch [171/200] batch [3/3] time 1.441 (1.518) data 0.000 (0.076) loss 0.0509 (0.2026) acc 100.0000 (95.8333) lr 1.0899e-04 eta 0:02:12
epoch [172/200] batch [1/3] time 1.688 (1.688) data 0.241 (0.241) loss 0.5376 (0.5376) acc 87.5000 (87.5000) lr 1.0899e-04 eta 0:02:25
epoch [172/200] batch [2/3] time 1.441 (1.565) data 0.000 (0.121) loss 0.1466 (0.3421) acc 93.7500 (90.6250) lr 1.0899e-04 eta 0:02:12
epoch [172/200] batch [3/3] time 1.436 (1.522) data 0.000 (0.080) loss 0.3293 (0.3378) acc 90.6250 (90.6250) lr 1.0197e-04 eta 0:02:07
epoch [173/200] batch [1/3] time 1.670 (1.670) data 0.233 (0.233) loss 0.4915 (0.4915) acc 84.3750 (84.3750) lr 1.0197e-04 eta 0:02:18
epoch [173/200] batch [2/3] time 1.434 (1.552) data 0.000 (0.117) loss 0.0652 (0.2783) acc 100.0000 (92.1875) lr 1.0197e-04 eta 0:02:07
epoch [173/200] batch [3/3] time 1.439 (1.514) data 0.000 (0.078) loss 0.4934 (0.3500) acc 90.6250 (91.6667) lr 9.5173e-05 eta 0:02:02
epoch [174/200] batch [1/3] time 1.658 (1.658) data 0.222 (0.222) loss 0.2234 (0.2234) acc 96.8750 (96.8750) lr 9.5173e-05 eta 0:02:12
epoch [174/200] batch [2/3] time 1.436 (1.547) data 0.000 (0.111) loss 0.3247 (0.2740) acc 93.7500 (95.3125) lr 9.5173e-05 eta 0:02:02
epoch [174/200] batch [3/3] time 1.433 (1.509) data 0.000 (0.074) loss 0.0864 (0.2115) acc 96.8750 (95.8333) lr 8.8597e-05 eta 0:01:57
epoch [175/200] batch [1/3] time 1.664 (1.664) data 0.225 (0.225) loss 0.1530 (0.1530) acc 96.8750 (96.8750) lr 8.8597e-05 eta 0:02:08
epoch [175/200] batch [2/3] time 1.448 (1.556) data 0.000 (0.112) loss 0.1381 (0.1455) acc 93.7500 (95.3125) lr 8.8597e-05 eta 0:01:58
epoch [175/200] batch [3/3] time 1.442 (1.518) data 0.000 (0.075) loss 0.3374 (0.2095) acc 90.6250 (93.7500) lr 8.2245e-05 eta 0:01:53
epoch [176/200] batch [1/3] time 1.661 (1.661) data 0.221 (0.221) loss 0.0719 (0.0719) acc 100.0000 (100.0000) lr 8.2245e-05 eta 0:02:02
epoch [176/200] batch [2/3] time 1.447 (1.554) data 0.000 (0.111) loss 0.1074 (0.0896) acc 96.8750 (98.4375) lr 8.2245e-05 eta 0:01:53
epoch [176/200] batch [3/3] time 1.440 (1.516) data 0.000 (0.074) loss 0.0622 (0.0805) acc 100.0000 (98.9583) lr 7.6120e-05 eta 0:01:49
epoch [177/200] batch [1/3] time 1.681 (1.681) data 0.238 (0.238) loss 0.1957 (0.1957) acc 96.8750 (96.8750) lr 7.6120e-05 eta 0:01:59
epoch [177/200] batch [2/3] time 1.443 (1.562) data 0.000 (0.119) loss 0.3010 (0.2484) acc 93.7500 (95.3125) lr 7.6120e-05 eta 0:01:49
epoch [177/200] batch [3/3] time 1.436 (1.520) data 0.000 (0.079) loss 0.1757 (0.2241) acc 96.8750 (95.8333) lr 7.0224e-05 eta 0:01:44
epoch [178/200] batch [1/3] time 1.679 (1.679) data 0.240 (0.240) loss 0.5400 (0.5400) acc 87.5000 (87.5000) lr 7.0224e-05 eta 0:01:54
epoch [178/200] batch [2/3] time 1.441 (1.560) data 0.000 (0.120) loss 0.4402 (0.4901) acc 90.6250 (89.0625) lr 7.0224e-05 eta 0:01:44
epoch [178/200] batch [3/3] time 1.444 (1.522) data 0.000 (0.080) loss 0.1118 (0.3640) acc 96.8750 (91.6667) lr 6.4556e-05 eta 0:01:40
epoch [179/200] batch [1/3] time 1.662 (1.662) data 0.230 (0.230) loss 0.3079 (0.3079) acc 87.5000 (87.5000) lr 6.4556e-05 eta 0:01:47
epoch [179/200] batch [2/3] time 1.442 (1.552) data 0.000 (0.115) loss 0.3730 (0.3405) acc 90.6250 (89.0625) lr 6.4556e-05 eta 0:01:39
epoch [179/200] batch [3/3] time 1.445 (1.516) data 0.000 (0.077) loss 0.3267 (0.3359) acc 87.5000 (88.5417) lr 5.9119e-05 eta 0:01:35
epoch [180/200] batch [1/3] time 1.670 (1.670) data 0.226 (0.226) loss 0.0651 (0.0651) acc 100.0000 (100.0000) lr 5.9119e-05 eta 0:01:43
epoch [180/200] batch [2/3] time 1.436 (1.553) data 0.000 (0.113) loss 0.4714 (0.2682) acc 90.6250 (95.3125) lr 5.9119e-05 eta 0:01:34
epoch [180/200] batch [3/3] time 1.441 (1.516) data 0.000 (0.076) loss 0.4104 (0.3156) acc 90.6250 (93.7500) lr 5.3915e-05 eta 0:01:30
epoch [181/200] batch [1/3] time 1.660 (1.660) data 0.228 (0.228) loss 0.3865 (0.3865) acc 90.6250 (90.6250) lr 5.3915e-05 eta 0:01:37
epoch [181/200] batch [2/3] time 1.432 (1.546) data 0.000 (0.114) loss 0.2988 (0.3427) acc 90.6250 (90.6250) lr 5.3915e-05 eta 0:01:29
epoch [181/200] batch [3/3] time 1.436 (1.510) data 0.000 (0.076) loss 0.2942 (0.3265) acc 90.6250 (90.6250) lr 4.8943e-05 eta 0:01:26
epoch [182/200] batch [1/3] time 1.682 (1.682) data 0.231 (0.231) loss 0.1387 (0.1387) acc 93.7500 (93.7500) lr 4.8943e-05 eta 0:01:34
epoch [182/200] batch [2/3] time 1.440 (1.561) data 0.000 (0.116) loss 0.1028 (0.1208) acc 96.8750 (95.3125) lr 4.8943e-05 eta 0:01:25
epoch [182/200] batch [3/3] time 1.442 (1.521) data 0.000 (0.077) loss 0.2003 (0.1473) acc 93.7500 (94.7917) lr 4.4207e-05 eta 0:01:22
epoch [183/200] batch [1/3] time 1.678 (1.678) data 0.242 (0.242) loss 0.3582 (0.3582) acc 87.5000 (87.5000) lr 4.4207e-05 eta 0:01:28
epoch [183/200] batch [2/3] time 1.448 (1.563) data 0.000 (0.121) loss 0.1277 (0.2429) acc 96.8750 (92.1875) lr 4.4207e-05 eta 0:01:21
epoch [183/200] batch [3/3] time 1.446 (1.524) data 0.000 (0.081) loss 0.1203 (0.2020) acc 96.8750 (93.7500) lr 3.9706e-05 eta 0:01:17
epoch [184/200] batch [1/3] time 1.674 (1.674) data 0.240 (0.240) loss 0.2852 (0.2852) acc 93.7500 (93.7500) lr 3.9706e-05 eta 0:01:23
epoch [184/200] batch [2/3] time 1.437 (1.555) data 0.000 (0.120) loss 0.2998 (0.2925) acc 93.7500 (93.7500) lr 3.9706e-05 eta 0:01:16
epoch [184/200] batch [3/3] time 1.434 (1.515) data 0.000 (0.080) loss 0.3567 (0.3139) acc 96.8750 (94.7917) lr 3.5443e-05 eta 0:01:12
epoch [185/200] batch [1/3] time 1.662 (1.662) data 0.221 (0.221) loss 0.3623 (0.3623) acc 90.6250 (90.6250) lr 3.5443e-05 eta 0:01:18
epoch [185/200] batch [2/3] time 1.442 (1.552) data 0.000 (0.111) loss 0.2145 (0.2884) acc 96.8750 (93.7500) lr 3.5443e-05 eta 0:01:11
epoch [185/200] batch [3/3] time 1.440 (1.515) data 0.000 (0.074) loss 0.1230 (0.2333) acc 96.8750 (94.7917) lr 3.1417e-05 eta 0:01:08
epoch [186/200] batch [1/3] time 1.674 (1.674) data 0.233 (0.233) loss 0.2600 (0.2600) acc 93.7500 (93.7500) lr 3.1417e-05 eta 0:01:13
epoch [186/200] batch [2/3] time 1.440 (1.557) data 0.000 (0.117) loss 0.1920 (0.2260) acc 93.7500 (93.7500) lr 3.1417e-05 eta 0:01:06
epoch [186/200] batch [3/3] time 1.441 (1.519) data 0.000 (0.078) loss 0.2837 (0.2452) acc 93.7500 (93.7500) lr 2.7630e-05 eta 0:01:03
epoch [187/200] batch [1/3] time 1.690 (1.690) data 0.241 (0.241) loss 0.3088 (0.3088) acc 87.5000 (87.5000) lr 2.7630e-05 eta 0:01:09
epoch [187/200] batch [2/3] time 1.439 (1.564) data 0.000 (0.120) loss 0.2939 (0.3014) acc 93.7500 (90.6250) lr 2.7630e-05 eta 0:01:02
epoch [187/200] batch [3/3] time 1.438 (1.522) data 0.000 (0.080) loss 0.1429 (0.2486) acc 100.0000 (93.7500) lr 2.4083e-05 eta 0:00:59
epoch [188/200] batch [1/3] time 1.680 (1.680) data 0.240 (0.240) loss 0.0953 (0.0953) acc 96.8750 (96.8750) lr 2.4083e-05 eta 0:01:03
epoch [188/200] batch [2/3] time 1.431 (1.556) data 0.000 (0.120) loss 0.5068 (0.3011) acc 87.5000 (92.1875) lr 2.4083e-05 eta 0:00:57
epoch [188/200] batch [3/3] time 1.517 (1.543) data 0.000 (0.080) loss 0.3960 (0.3327) acc 87.5000 (90.6250) lr 2.0777e-05 eta 0:00:55
epoch [189/200] batch [1/3] time 1.704 (1.704) data 0.225 (0.225) loss 0.5186 (0.5186) acc 90.6250 (90.6250) lr 2.0777e-05 eta 0:00:59
epoch [189/200] batch [2/3] time 1.477 (1.590) data 0.000 (0.113) loss 0.2542 (0.3864) acc 93.7500 (92.1875) lr 2.0777e-05 eta 0:00:54
epoch [189/200] batch [3/3] time 1.458 (1.546) data 0.000 (0.075) loss 0.3638 (0.3788) acc 90.6250 (91.6667) lr 1.7713e-05 eta 0:00:51
epoch [190/200] batch [1/3] time 1.685 (1.685) data 0.233 (0.233) loss 0.1379 (0.1379) acc 96.8750 (96.8750) lr 1.7713e-05 eta 0:00:53
epoch [190/200] batch [2/3] time 1.451 (1.568) data 0.000 (0.116) loss 0.0690 (0.1035) acc 100.0000 (98.4375) lr 1.7713e-05 eta 0:00:48
epoch [190/200] batch [3/3] time 1.473 (1.536) data 0.000 (0.078) loss 0.0379 (0.0816) acc 100.0000 (98.9583) lr 1.4891e-05 eta 0:00:46
epoch [191/200] batch [1/3] time 1.655 (1.655) data 0.232 (0.232) loss 0.0611 (0.0611) acc 100.0000 (100.0000) lr 1.4891e-05 eta 0:00:48
epoch [191/200] batch [2/3] time 1.425 (1.540) data 0.000 (0.116) loss 0.0810 (0.0711) acc 100.0000 (100.0000) lr 1.4891e-05 eta 0:00:43
epoch [191/200] batch [3/3] time 1.424 (1.502) data 0.000 (0.077) loss 0.1331 (0.0917) acc 96.8750 (98.9583) lr 1.2312e-05 eta 0:00:40
epoch [192/200] batch [1/3] time 1.655 (1.655) data 0.234 (0.234) loss 0.4495 (0.4495) acc 90.6250 (90.6250) lr 1.2312e-05 eta 0:00:43
epoch [192/200] batch [2/3] time 1.421 (1.538) data 0.000 (0.117) loss 0.0812 (0.2653) acc 96.8750 (93.7500) lr 1.2312e-05 eta 0:00:38
epoch [192/200] batch [3/3] time 1.422 (1.499) data 0.000 (0.078) loss 0.1046 (0.2118) acc 96.8750 (94.7917) lr 9.9763e-06 eta 0:00:35
epoch [193/200] batch [1/3] time 1.643 (1.643) data 0.227 (0.227) loss 0.3130 (0.3130) acc 93.7500 (93.7500) lr 9.9763e-06 eta 0:00:37
epoch [193/200] batch [2/3] time 1.417 (1.530) data 0.000 (0.114) loss 0.1278 (0.2204) acc 96.8750 (95.3125) lr 9.9763e-06 eta 0:00:33
epoch [193/200] batch [3/3] time 1.426 (1.495) data 0.000 (0.076) loss 0.2803 (0.2404) acc 96.8750 (95.8333) lr 7.8853e-06 eta 0:00:31
epoch [194/200] batch [1/3] time 1.659 (1.659) data 0.241 (0.241) loss 0.2781 (0.2781) acc 93.7500 (93.7500) lr 7.8853e-06 eta 0:00:33
epoch [194/200] batch [2/3] time 1.421 (1.540) data 0.000 (0.121) loss 0.3843 (0.3312) acc 90.6250 (92.1875) lr 7.8853e-06 eta 0:00:29
epoch [194/200] batch [3/3] time 1.420 (1.500) data 0.000 (0.080) loss 0.2225 (0.2950) acc 93.7500 (92.7083) lr 6.0390e-06 eta 0:00:26
epoch [195/200] batch [1/3] time 1.645 (1.645) data 0.232 (0.232) loss 0.1860 (0.1860) acc 93.7500 (93.7500) lr 6.0390e-06 eta 0:00:27
epoch [195/200] batch [2/3] time 1.420 (1.532) data 0.000 (0.116) loss 0.2539 (0.2200) acc 90.6250 (92.1875) lr 6.0390e-06 eta 0:00:24
epoch [195/200] batch [3/3] time 1.419 (1.495) data 0.000 (0.077) loss 0.0372 (0.1590) acc 100.0000 (94.7917) lr 4.4380e-06 eta 0:00:22
epoch [196/200] batch [1/3] time 1.655 (1.655) data 0.239 (0.239) loss 0.5327 (0.5327) acc 87.5000 (87.5000) lr 4.4380e-06 eta 0:00:23
epoch [196/200] batch [2/3] time 1.417 (1.536) data 0.000 (0.119) loss 0.2001 (0.3664) acc 96.8750 (92.1875) lr 4.4380e-06 eta 0:00:19
epoch [196/200] batch [3/3] time 1.418 (1.497) data 0.000 (0.080) loss 0.1117 (0.2815) acc 96.8750 (93.7500) lr 3.0827e-06 eta 0:00:17
epoch [197/200] batch [1/3] time 1.634 (1.634) data 0.221 (0.221) loss 0.3125 (0.3125) acc 93.7500 (93.7500) lr 3.0827e-06 eta 0:00:17
epoch [197/200] batch [2/3] time 1.419 (1.526) data 0.000 (0.110) loss 0.1455 (0.2290) acc 93.7500 (93.7500) lr 3.0827e-06 eta 0:00:15
epoch [197/200] batch [3/3] time 1.416 (1.490) data 0.000 (0.074) loss 0.2146 (0.2242) acc 93.7500 (93.7500) lr 1.9733e-06 eta 0:00:13
epoch [198/200] batch [1/3] time 1.661 (1.661) data 0.240 (0.240) loss 0.2375 (0.2375) acc 93.7500 (93.7500) lr 1.9733e-06 eta 0:00:13
epoch [198/200] batch [2/3] time 1.423 (1.542) data 0.000 (0.120) loss 0.2515 (0.2445) acc 90.6250 (92.1875) lr 1.9733e-06 eta 0:00:10
epoch [198/200] batch [3/3] time 1.422 (1.502) data 0.000 (0.080) loss 0.3091 (0.2660) acc 93.7500 (92.7083) lr 1.1101e-06 eta 0:00:09
epoch [199/200] batch [1/3] time 1.657 (1.657) data 0.245 (0.245) loss 0.5073 (0.5073) acc 84.3750 (84.3750) lr 1.1101e-06 eta 0:00:08
epoch [199/200] batch [2/3] time 1.424 (1.540) data 0.000 (0.122) loss 0.3604 (0.4338) acc 93.7500 (89.0625) lr 1.1101e-06 eta 0:00:06
epoch [199/200] batch [3/3] time 1.418 (1.500) data 0.000 (0.082) loss 0.3491 (0.4056) acc 90.6250 (89.5833) lr 4.9344e-07 eta 0:00:04
epoch [200/200] batch [1/3] time 1.653 (1.653) data 0.233 (0.233) loss 0.2727 (0.2727) acc 93.7500 (93.7500) lr 4.9344e-07 eta 0:00:03
epoch [200/200] batch [2/3] time 1.420 (1.537) data 0.000 (0.116) loss 0.2354 (0.2540) acc 90.6250 (92.1875) lr 4.9344e-07 eta 0:00:01
epoch [200/200] batch [3/3] time 1.419 (1.497) data 0.000 (0.078) loss 0.1179 (0.2087) acc 100.0000 (94.7917) lr 1.2337e-07 eta 0:00:00
Checkpoint saved to output/Caltech/1/prompt_learner/model.pth.tar-200
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
=> result
* total: 2,465
* correct: 2,150
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 81.7%
Elapsed: 0:16:46
args2: backbone=, config_file=configs/trainers/CoOp/vit_b16.yaml, dataset_config_file=configs/datasets/caltech101.yaml, eval_only=False, head=, load_epoch=None, model_dir=, no_train=False,  opts: ['TRAINER.COOP.N_CTX', '16', 'TRAINER.COOP.CSC', 'False', 'TRAINER.COOP.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '1'], output_dir=output/Caltech/1/2, resume=, root=/home/brandnerkasper/Uni/MP/MP_CustomCoOp/data, seed=2, source_domains=None, target_domains=None, trainer=CoOp, transforms=None
Setting fixed seed: 2
***************
** Arguments **
***************
config_file: configs/trainers/CoOp/vit_b16.yaml
csc: False
ctp: end
dataset_config_file: configs/datasets/caltech101.yaml
n_ctx: 16
opts: ['TRAINER.COOP.N_CTX', '16', 'TRAINER.COOP.CSC', 'False', 'TRAINER.COOP.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '1']
output_dir: output/Caltech/1/2
root: /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data
seed: 2
shots: 1
trainer: CoOp
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 4
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 1
  ROOT: /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/Caltech/1/2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 2.0.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 22.04.3 LTS (x86_64)
GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.35

Python version: 3.10.12 (main, Jul  5 2023, 18:54:27) [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-6.2.0-32-generic-x86_64-with-glibc2.35
Is CUDA available: True
CUDA runtime version: 11.5.119
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce GTX 970
Nvidia driver version: 525.125.06
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                       x86_64
CPU op-mode(s):                     32-bit, 64-bit
Address sizes:                      39 bits physical, 48 bits virtual
Byte Order:                         Little Endian
CPU(s):                             4
On-line CPU(s) list:                0-3
Vendor ID:                          GenuineIntel
Model name:                         Intel(R) Xeon(R) CPU E3-1225 v3 @ 3.20GHz
CPU family:                         6
Model:                              60
Thread(s) per core:                 1
Core(s) per socket:                 4
Socket(s):                          1
Stepping:                           3
CPU max MHz:                        3600,0000
CPU min MHz:                        800,0000
BogoMIPS:                           6397.95
Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt dtherm ida arat pln pts md_clear flush_l1d
Virtualization:                     VT-x
L1d cache:                          128 KiB (4 instances)
L1i cache:                          128 KiB (4 instances)
L2 cache:                           1 MiB (4 instances)
L3 cache:                           8 MiB (1 instance)
NUMA node(s):                       1
NUMA node0 CPU(s):                  0-3
Vulnerability Gather data sampling: Not affected
Vulnerability Itlb multihit:        KVM: Mitigation: VMX disabled
Vulnerability L1tf:                 Mitigation; PTE Inversion; VMX conditional cache flushes, SMT disabled
Vulnerability Mds:                  Mitigation; Clear CPU buffers; SMT disabled
Vulnerability Meltdown:             Mitigation; PTI
Vulnerability Mmio stale data:      Unknown: No mitigations
Vulnerability Retbleed:             Not affected
Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl
Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:           Mitigation; Retpolines, IBPB conditional, IBRS_FW, STIBP disabled, RSB filling, PBRSB-eIBRS Not affected
Vulnerability Srbds:                Mitigation; Microcode
Vulnerability Tsx async abort:      Not affected

Versions of relevant libraries:
[pip3] numpy==1.25.2
[pip3] open-clip-torch==2.20.0
[pip3] torch==2.0.1
[pip3] torchaudio==2.0.2
[pip3] torchvision==0.15.2
[conda] blas                      1.0                         mkl  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] mkl                       2023.1.0         h213fc3f_46343  
[conda] mkl-service               2.4.0           py310h5eee18b_1  
[conda] mkl_fft                   1.3.6           py310h1128e8f_1  
[conda] mkl_random                1.2.2           py310h1128e8f_1  
[conda] numpy                     1.25.2          py310h5f9d8c6_0  
[conda] numpy-base                1.25.2          py310hb5e798b_0  
[conda] open-clip-torch           2.20.0                   pypi_0    pypi
[conda] pytorch                   2.0.1           py3.10_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchaudio                2.0.2               py310_cu117    pytorch
[conda] torchtriton               2.0.0                     py310    pytorch
[conda] torchvision               0.15.2              py310_cu117    pytorch
        Pillow (9.4.0)

Loading trainer: CoOp
Loading dataset: Caltech101
Reading split from /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data/caltech-101/split_fewshot/shot_1-seed_2.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  100
# train_x  100
# val      100
# test     2,465
---------  ----------
Loading CLIP (backbone: ViT-B/16)
CLIP(
  (visual): VisionTransformer(
    (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (transformer): Transformer(
    (resblocks): Sequential(
      (0): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (6): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (7): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (8): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (9): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (10): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (11): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (token_embedding): Embedding(49408, 512)
  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
)
Building custom CLIP
Initializing a generic context
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Turning off gradients in both the image and the text encoder
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/Caltech/1/2/tensorboard)
epoch [1/200] batch [1/3] time 1.727 (1.727) data 0.284 (0.284) loss 2.1387 (2.1387) acc 59.3750 (59.3750) lr 1.0000e-05 eta 0:17:14
epoch [1/200] batch [2/3] time 1.413 (1.570) data 0.000 (0.142) loss 2.2617 (2.2002) acc 50.0000 (54.6875) lr 1.0000e-05 eta 0:15:38
epoch [1/200] batch [3/3] time 1.417 (1.519) data 0.000 (0.095) loss 2.2676 (2.2227) acc 62.5000 (57.2917) lr 2.0000e-03 eta 0:15:06
epoch [2/200] batch [1/3] time 1.692 (1.692) data 0.270 (0.270) loss 2.3398 (2.3398) acc 59.3750 (59.3750) lr 2.0000e-03 eta 0:16:48
epoch [2/200] batch [2/3] time 1.424 (1.558) data 0.000 (0.135) loss 1.5850 (1.9624) acc 53.1250 (56.2500) lr 2.0000e-03 eta 0:15:27
epoch [2/200] batch [3/3] time 1.417 (1.511) data 0.000 (0.090) loss 1.3467 (1.7572) acc 65.6250 (59.3750) lr 1.9999e-03 eta 0:14:57
epoch [3/200] batch [1/3] time 1.678 (1.678) data 0.262 (0.262) loss 0.6499 (0.6499) acc 81.2500 (81.2500) lr 1.9999e-03 eta 0:16:35
epoch [3/200] batch [2/3] time 1.420 (1.549) data 0.000 (0.131) loss 0.8320 (0.7410) acc 81.2500 (81.2500) lr 1.9999e-03 eta 0:15:17
epoch [3/200] batch [3/3] time 1.415 (1.505) data 0.000 (0.087) loss 0.5698 (0.6839) acc 78.1250 (80.2083) lr 1.9995e-03 eta 0:14:49
epoch [4/200] batch [1/3] time 1.687 (1.687) data 0.269 (0.269) loss 0.7354 (0.7354) acc 75.0000 (75.0000) lr 1.9995e-03 eta 0:16:35
epoch [4/200] batch [2/3] time 1.414 (1.551) data 0.000 (0.134) loss 0.6333 (0.6843) acc 81.2500 (78.1250) lr 1.9995e-03 eta 0:15:13
epoch [4/200] batch [3/3] time 1.421 (1.508) data 0.000 (0.090) loss 0.7285 (0.6991) acc 81.2500 (79.1667) lr 1.9989e-03 eta 0:14:46
epoch [5/200] batch [1/3] time 1.694 (1.694) data 0.276 (0.276) loss 0.9321 (0.9321) acc 65.6250 (65.6250) lr 1.9989e-03 eta 0:16:34
epoch [5/200] batch [2/3] time 1.425 (1.560) data 0.000 (0.138) loss 0.9854 (0.9587) acc 71.8750 (68.7500) lr 1.9989e-03 eta 0:15:13
epoch [5/200] batch [3/3] time 1.417 (1.512) data 0.000 (0.092) loss 0.8979 (0.9385) acc 78.1250 (71.8750) lr 1.9980e-03 eta 0:14:44
epoch [6/200] batch [1/3] time 1.688 (1.688) data 0.263 (0.263) loss 0.7822 (0.7822) acc 84.3750 (84.3750) lr 1.9980e-03 eta 0:16:25
epoch [6/200] batch [2/3] time 1.418 (1.553) data 0.000 (0.132) loss 0.6499 (0.7161) acc 81.2500 (82.8125) lr 1.9980e-03 eta 0:15:05
epoch [6/200] batch [3/3] time 1.418 (1.508) data 0.000 (0.088) loss 0.5942 (0.6755) acc 78.1250 (81.2500) lr 1.9969e-03 eta 0:14:37
epoch [7/200] batch [1/3] time 1.698 (1.698) data 0.275 (0.275) loss 0.9258 (0.9258) acc 78.1250 (78.1250) lr 1.9969e-03 eta 0:16:26
epoch [7/200] batch [2/3] time 1.418 (1.558) data 0.000 (0.138) loss 0.7456 (0.8357) acc 84.3750 (81.2500) lr 1.9969e-03 eta 0:15:03
epoch [7/200] batch [3/3] time 1.415 (1.510) data 0.000 (0.092) loss 0.7930 (0.8215) acc 75.0000 (79.1667) lr 1.9956e-03 eta 0:14:34
epoch [8/200] batch [1/3] time 1.686 (1.686) data 0.263 (0.263) loss 0.9429 (0.9429) acc 71.8750 (71.8750) lr 1.9956e-03 eta 0:16:14
epoch [8/200] batch [2/3] time 1.418 (1.552) data 0.000 (0.131) loss 0.9624 (0.9526) acc 75.0000 (73.4375) lr 1.9956e-03 eta 0:14:55
epoch [8/200] batch [3/3] time 1.418 (1.507) data 0.000 (0.088) loss 1.2109 (1.0387) acc 68.7500 (71.8750) lr 1.9940e-03 eta 0:14:28
epoch [9/200] batch [1/3] time 1.694 (1.694) data 0.271 (0.271) loss 0.5264 (0.5264) acc 84.3750 (84.3750) lr 1.9940e-03 eta 0:16:14
epoch [9/200] batch [2/3] time 1.418 (1.556) data 0.000 (0.135) loss 0.8423 (0.6843) acc 78.1250 (81.2500) lr 1.9940e-03 eta 0:14:53
epoch [9/200] batch [3/3] time 1.424 (1.512) data 0.000 (0.090) loss 1.0859 (0.8182) acc 65.6250 (76.0417) lr 1.9921e-03 eta 0:14:26
epoch [10/200] batch [1/3] time 1.687 (1.687) data 0.263 (0.263) loss 0.6118 (0.6118) acc 78.1250 (78.1250) lr 1.9921e-03 eta 0:16:04
epoch [10/200] batch [2/3] time 1.410 (1.548) data 0.000 (0.131) loss 0.7803 (0.6960) acc 84.3750 (81.2500) lr 1.9921e-03 eta 0:14:44
epoch [10/200] batch [3/3] time 1.421 (1.506) data 0.000 (0.088) loss 0.6543 (0.6821) acc 75.0000 (79.1667) lr 1.9900e-03 eta 0:14:18
epoch [11/200] batch [1/3] time 1.682 (1.682) data 0.262 (0.262) loss 1.0820 (1.0820) acc 75.0000 (75.0000) lr 1.9900e-03 eta 0:15:56
epoch [11/200] batch [2/3] time 1.417 (1.550) data 0.000 (0.131) loss 0.7881 (0.9351) acc 78.1250 (76.5625) lr 1.9900e-03 eta 0:14:40
epoch [11/200] batch [3/3] time 1.425 (1.508) data 0.000 (0.087) loss 0.7935 (0.8879) acc 78.1250 (77.0833) lr 1.9877e-03 eta 0:14:14
epoch [12/200] batch [1/3] time 1.694 (1.694) data 0.280 (0.280) loss 0.7686 (0.7686) acc 81.2500 (81.2500) lr 1.9877e-03 eta 0:15:58
epoch [12/200] batch [2/3] time 1.417 (1.556) data 0.000 (0.140) loss 0.6128 (0.6907) acc 81.2500 (81.2500) lr 1.9877e-03 eta 0:14:38
epoch [12/200] batch [3/3] time 1.425 (1.512) data 0.000 (0.093) loss 0.6401 (0.6738) acc 84.3750 (82.2917) lr 1.9851e-03 eta 0:14:12
epoch [13/200] batch [1/3] time 1.690 (1.690) data 0.277 (0.277) loss 0.6187 (0.6187) acc 87.5000 (87.5000) lr 1.9851e-03 eta 0:15:51
epoch [13/200] batch [2/3] time 1.410 (1.550) data 0.000 (0.138) loss 0.6943 (0.6565) acc 78.1250 (82.8125) lr 1.9851e-03 eta 0:14:31
epoch [13/200] batch [3/3] time 1.419 (1.506) data 0.000 (0.092) loss 0.4785 (0.5972) acc 90.6250 (85.4167) lr 1.9823e-03 eta 0:14:04
epoch [14/200] batch [1/3] time 1.690 (1.690) data 0.270 (0.270) loss 0.7930 (0.7930) acc 78.1250 (78.1250) lr 1.9823e-03 eta 0:15:46
epoch [14/200] batch [2/3] time 1.415 (1.553) data 0.000 (0.135) loss 0.5005 (0.6467) acc 84.3750 (81.2500) lr 1.9823e-03 eta 0:14:27
epoch [14/200] batch [3/3] time 1.412 (1.506) data 0.000 (0.090) loss 0.4656 (0.5863) acc 84.3750 (82.2917) lr 1.9792e-03 eta 0:14:00
epoch [15/200] batch [1/3] time 1.681 (1.681) data 0.263 (0.263) loss 0.6255 (0.6255) acc 81.2500 (81.2500) lr 1.9792e-03 eta 0:15:36
epoch [15/200] batch [2/3] time 1.416 (1.548) data 0.000 (0.132) loss 0.6279 (0.6267) acc 84.3750 (82.8125) lr 1.9792e-03 eta 0:14:20
epoch [15/200] batch [3/3] time 1.414 (1.503) data 0.000 (0.088) loss 0.9507 (0.7347) acc 68.7500 (78.1250) lr 1.9759e-03 eta 0:13:54
epoch [16/200] batch [1/3] time 1.683 (1.683) data 0.259 (0.259) loss 0.9253 (0.9253) acc 71.8750 (71.8750) lr 1.9759e-03 eta 0:15:32
epoch [16/200] batch [2/3] time 1.418 (1.551) data 0.000 (0.130) loss 0.5679 (0.7466) acc 81.2500 (76.5625) lr 1.9759e-03 eta 0:14:17
epoch [16/200] batch [3/3] time 1.424 (1.508) data 0.000 (0.087) loss 0.7070 (0.7334) acc 81.2500 (78.1250) lr 1.9724e-03 eta 0:13:52
epoch [17/200] batch [1/3] time 1.674 (1.674) data 0.261 (0.261) loss 0.8613 (0.8613) acc 78.1250 (78.1250) lr 1.9724e-03 eta 0:15:22
epoch [17/200] batch [2/3] time 1.418 (1.546) data 0.000 (0.131) loss 0.4700 (0.6656) acc 87.5000 (82.8125) lr 1.9724e-03 eta 0:14:10
epoch [17/200] batch [3/3] time 1.421 (1.504) data 0.000 (0.087) loss 0.5854 (0.6389) acc 84.3750 (83.3333) lr 1.9686e-03 eta 0:13:45
epoch [18/200] batch [1/3] time 1.676 (1.676) data 0.262 (0.262) loss 0.6851 (0.6851) acc 84.3750 (84.3750) lr 1.9686e-03 eta 0:15:18
epoch [18/200] batch [2/3] time 1.423 (1.550) data 0.000 (0.131) loss 0.6460 (0.6655) acc 81.2500 (82.8125) lr 1.9686e-03 eta 0:14:07
epoch [18/200] batch [3/3] time 1.415 (1.505) data 0.000 (0.087) loss 0.5073 (0.6128) acc 71.8750 (79.1667) lr 1.9646e-03 eta 0:13:41
epoch [19/200] batch [1/3] time 1.686 (1.686) data 0.266 (0.266) loss 0.9077 (0.9077) acc 81.2500 (81.2500) lr 1.9646e-03 eta 0:15:18
epoch [19/200] batch [2/3] time 1.422 (1.554) data 0.000 (0.133) loss 0.6641 (0.7859) acc 81.2500 (81.2500) lr 1.9646e-03 eta 0:14:05
epoch [19/200] batch [3/3] time 1.425 (1.511) data 0.000 (0.089) loss 0.3938 (0.6552) acc 87.5000 (83.3333) lr 1.9603e-03 eta 0:13:40
epoch [20/200] batch [1/3] time 1.671 (1.671) data 0.260 (0.260) loss 0.3816 (0.3816) acc 81.2500 (81.2500) lr 1.9603e-03 eta 0:15:05
epoch [20/200] batch [2/3] time 1.420 (1.546) data 0.000 (0.130) loss 0.6816 (0.5316) acc 78.1250 (79.6875) lr 1.9603e-03 eta 0:13:56
epoch [20/200] batch [3/3] time 1.416 (1.503) data 0.000 (0.087) loss 0.4431 (0.5021) acc 87.5000 (82.2917) lr 1.9558e-03 eta 0:13:31
epoch [21/200] batch [1/3] time 1.696 (1.696) data 0.278 (0.278) loss 0.7021 (0.7021) acc 84.3750 (84.3750) lr 1.9558e-03 eta 0:15:14
epoch [21/200] batch [2/3] time 1.420 (1.558) data 0.000 (0.139) loss 0.9917 (0.8469) acc 71.8750 (78.1250) lr 1.9558e-03 eta 0:13:58
epoch [21/200] batch [3/3] time 1.415 (1.510) data 0.000 (0.093) loss 0.5894 (0.7611) acc 87.5000 (81.2500) lr 1.9511e-03 eta 0:13:31
epoch [22/200] batch [1/3] time 1.679 (1.679) data 0.260 (0.260) loss 0.4297 (0.4297) acc 87.5000 (87.5000) lr 1.9511e-03 eta 0:14:59
epoch [22/200] batch [2/3] time 1.417 (1.548) data 0.000 (0.130) loss 0.6587 (0.5442) acc 78.1250 (82.8125) lr 1.9511e-03 eta 0:13:48
epoch [22/200] batch [3/3] time 1.423 (1.506) data 0.000 (0.087) loss 0.4031 (0.4972) acc 90.6250 (85.4167) lr 1.9461e-03 eta 0:13:24
epoch [23/200] batch [1/3] time 1.683 (1.683) data 0.260 (0.260) loss 0.4746 (0.4746) acc 81.2500 (81.2500) lr 1.9461e-03 eta 0:14:57
epoch [23/200] batch [2/3] time 1.414 (1.549) data 0.000 (0.130) loss 0.6064 (0.5405) acc 90.6250 (85.9375) lr 1.9461e-03 eta 0:13:43
epoch [23/200] batch [3/3] time 1.424 (1.507) data 0.000 (0.087) loss 0.3074 (0.4628) acc 90.6250 (87.5000) lr 1.9409e-03 eta 0:13:20
epoch [24/200] batch [1/3] time 1.680 (1.680) data 0.263 (0.263) loss 0.5479 (0.5479) acc 87.5000 (87.5000) lr 1.9409e-03 eta 0:14:50
epoch [24/200] batch [2/3] time 1.420 (1.550) data 0.000 (0.132) loss 0.7241 (0.6360) acc 78.1250 (82.8125) lr 1.9409e-03 eta 0:13:40
epoch [24/200] batch [3/3] time 1.417 (1.506) data 0.000 (0.088) loss 0.4814 (0.5845) acc 93.7500 (86.4583) lr 1.9354e-03 eta 0:13:15
epoch [25/200] batch [1/3] time 1.688 (1.688) data 0.277 (0.277) loss 0.4944 (0.4944) acc 84.3750 (84.3750) lr 1.9354e-03 eta 0:14:49
epoch [25/200] batch [2/3] time 1.426 (1.557) data 0.000 (0.139) loss 0.5669 (0.5306) acc 81.2500 (82.8125) lr 1.9354e-03 eta 0:13:38
epoch [25/200] batch [3/3] time 1.417 (1.510) data 0.000 (0.093) loss 0.3789 (0.4801) acc 90.6250 (85.4167) lr 1.9298e-03 eta 0:13:12
epoch [26/200] batch [1/3] time 1.702 (1.702) data 0.284 (0.284) loss 0.6958 (0.6958) acc 81.2500 (81.2500) lr 1.9298e-03 eta 0:14:52
epoch [26/200] batch [2/3] time 1.424 (1.563) data 0.000 (0.142) loss 0.2408 (0.4683) acc 93.7500 (87.5000) lr 1.9298e-03 eta 0:13:37
epoch [26/200] batch [3/3] time 1.421 (1.516) data 0.000 (0.095) loss 0.4248 (0.4538) acc 93.7500 (89.5833) lr 1.9239e-03 eta 0:13:11
epoch [27/200] batch [1/3] time 1.689 (1.689) data 0.273 (0.273) loss 0.9746 (0.9746) acc 78.1250 (78.1250) lr 1.9239e-03 eta 0:14:39
epoch [27/200] batch [2/3] time 1.415 (1.552) data 0.000 (0.137) loss 0.4705 (0.7225) acc 87.5000 (82.8125) lr 1.9239e-03 eta 0:13:27
epoch [27/200] batch [3/3] time 1.417 (1.507) data 0.000 (0.091) loss 0.6338 (0.6930) acc 81.2500 (82.2917) lr 1.9178e-03 eta 0:13:02
epoch [28/200] batch [1/3] time 1.681 (1.681) data 0.262 (0.262) loss 0.6523 (0.6523) acc 84.3750 (84.3750) lr 1.9178e-03 eta 0:14:30
epoch [28/200] batch [2/3] time 1.417 (1.549) data 0.000 (0.131) loss 0.6138 (0.6331) acc 84.3750 (84.3750) lr 1.9178e-03 eta 0:13:20
epoch [28/200] batch [3/3] time 1.415 (1.505) data 0.000 (0.087) loss 0.7778 (0.6813) acc 81.2500 (83.3333) lr 1.9114e-03 eta 0:12:56
epoch [29/200] batch [1/3] time 1.692 (1.692) data 0.269 (0.269) loss 0.6045 (0.6045) acc 81.2500 (81.2500) lr 1.9114e-03 eta 0:14:31
epoch [29/200] batch [2/3] time 1.419 (1.556) data 0.000 (0.134) loss 0.7744 (0.6895) acc 78.1250 (79.6875) lr 1.9114e-03 eta 0:13:19
epoch [29/200] batch [3/3] time 1.423 (1.511) data 0.000 (0.090) loss 0.3362 (0.5717) acc 87.5000 (82.2917) lr 1.9048e-03 eta 0:12:55
epoch [30/200] batch [1/3] time 1.684 (1.684) data 0.277 (0.277) loss 0.5112 (0.5112) acc 87.5000 (87.5000) lr 1.9048e-03 eta 0:14:22
epoch [30/200] batch [2/3] time 1.419 (1.552) data 0.000 (0.139) loss 0.5542 (0.5327) acc 87.5000 (87.5000) lr 1.9048e-03 eta 0:13:12
epoch [30/200] batch [3/3] time 1.421 (1.508) data 0.000 (0.092) loss 0.4629 (0.5094) acc 90.6250 (88.5417) lr 1.8980e-03 eta 0:12:49
epoch [31/200] batch [1/3] time 1.675 (1.675) data 0.262 (0.262) loss 0.2881 (0.2881) acc 93.7500 (93.7500) lr 1.8980e-03 eta 0:14:12
epoch [31/200] batch [2/3] time 1.420 (1.548) data 0.000 (0.131) loss 0.8052 (0.5466) acc 81.2500 (87.5000) lr 1.8980e-03 eta 0:13:06
epoch [31/200] batch [3/3] time 1.422 (1.506) data 0.000 (0.087) loss 0.3293 (0.4742) acc 93.7500 (89.5833) lr 1.8910e-03 eta 0:12:43
epoch [32/200] batch [1/3] time 1.700 (1.700) data 0.277 (0.277) loss 0.4424 (0.4424) acc 84.3750 (84.3750) lr 1.8910e-03 eta 0:14:20
epoch [32/200] batch [2/3] time 1.419 (1.559) data 0.000 (0.139) loss 0.3555 (0.3989) acc 93.7500 (89.0625) lr 1.8910e-03 eta 0:13:07
epoch [32/200] batch [3/3] time 1.421 (1.513) data 0.000 (0.093) loss 0.5376 (0.4451) acc 84.3750 (87.5000) lr 1.8838e-03 eta 0:12:42
epoch [33/200] batch [1/3] time 1.688 (1.688) data 0.278 (0.278) loss 0.5078 (0.5078) acc 87.5000 (87.5000) lr 1.8838e-03 eta 0:14:09
epoch [33/200] batch [2/3] time 1.417 (1.553) data 0.000 (0.139) loss 0.9565 (0.7322) acc 65.6250 (76.5625) lr 1.8838e-03 eta 0:12:59
epoch [33/200] batch [3/3] time 1.424 (1.510) data 0.000 (0.093) loss 0.6050 (0.6898) acc 81.2500 (78.1250) lr 1.8763e-03 eta 0:12:36
epoch [34/200] batch [1/3] time 1.682 (1.682) data 0.262 (0.262) loss 0.5430 (0.5430) acc 81.2500 (81.2500) lr 1.8763e-03 eta 0:14:01
epoch [34/200] batch [2/3] time 1.415 (1.549) data 0.000 (0.131) loss 0.4165 (0.4797) acc 90.6250 (85.9375) lr 1.8763e-03 eta 0:12:52
epoch [34/200] batch [3/3] time 1.423 (1.507) data 0.000 (0.087) loss 0.8716 (0.6104) acc 78.1250 (83.3333) lr 1.8686e-03 eta 0:12:30
epoch [35/200] batch [1/3] time 1.674 (1.674) data 0.260 (0.260) loss 0.5312 (0.5312) acc 87.5000 (87.5000) lr 1.8686e-03 eta 0:13:52
epoch [35/200] batch [2/3] time 1.424 (1.549) data 0.000 (0.130) loss 0.5015 (0.5164) acc 84.3750 (85.9375) lr 1.8686e-03 eta 0:12:48
epoch [35/200] batch [3/3] time 1.423 (1.507) data 0.000 (0.087) loss 0.6187 (0.5505) acc 81.2500 (84.3750) lr 1.8607e-03 eta 0:12:26
epoch [36/200] batch [1/3] time 1.698 (1.698) data 0.280 (0.280) loss 0.2842 (0.2842) acc 93.7500 (93.7500) lr 1.8607e-03 eta 0:13:58
epoch [36/200] batch [2/3] time 1.422 (1.560) data 0.000 (0.140) loss 0.3972 (0.3407) acc 90.6250 (92.1875) lr 1.8607e-03 eta 0:12:49
epoch [36/200] batch [3/3] time 1.426 (1.515) data 0.000 (0.093) loss 0.5195 (0.4003) acc 90.6250 (91.6667) lr 1.8526e-03 eta 0:12:25
epoch [37/200] batch [1/3] time 1.697 (1.697) data 0.280 (0.280) loss 0.2703 (0.2703) acc 93.7500 (93.7500) lr 1.8526e-03 eta 0:13:53
epoch [37/200] batch [2/3] time 1.414 (1.556) data 0.000 (0.140) loss 0.4841 (0.3772) acc 87.5000 (90.6250) lr 1.8526e-03 eta 0:12:42
epoch [37/200] batch [3/3] time 1.425 (1.512) data 0.000 (0.093) loss 0.5791 (0.4445) acc 87.5000 (89.5833) lr 1.8443e-03 eta 0:12:19
epoch [38/200] batch [1/3] time 1.685 (1.685) data 0.263 (0.263) loss 0.6187 (0.6187) acc 84.3750 (84.3750) lr 1.8443e-03 eta 0:13:42
epoch [38/200] batch [2/3] time 1.423 (1.554) data 0.000 (0.131) loss 0.3625 (0.4906) acc 93.7500 (89.0625) lr 1.8443e-03 eta 0:12:36
epoch [38/200] batch [3/3] time 1.418 (1.508) data 0.000 (0.088) loss 0.7104 (0.5639) acc 78.1250 (85.4167) lr 1.8358e-03 eta 0:12:13
epoch [39/200] batch [1/3] time 1.691 (1.691) data 0.272 (0.272) loss 0.2413 (0.2413) acc 96.8750 (96.8750) lr 1.8358e-03 eta 0:13:40
epoch [39/200] batch [2/3] time 1.422 (1.557) data 0.000 (0.136) loss 0.4553 (0.3483) acc 84.3750 (90.6250) lr 1.8358e-03 eta 0:12:33
epoch [39/200] batch [3/3] time 1.427 (1.514) data 0.000 (0.091) loss 0.4043 (0.3670) acc 87.5000 (89.5833) lr 1.8271e-03 eta 0:12:11
epoch [40/200] batch [1/3] time 1.691 (1.691) data 0.278 (0.278) loss 0.6670 (0.6670) acc 84.3750 (84.3750) lr 1.8271e-03 eta 0:13:35
epoch [40/200] batch [2/3] time 1.428 (1.559) data 0.000 (0.139) loss 0.4788 (0.5729) acc 87.5000 (85.9375) lr 1.8271e-03 eta 0:12:30
epoch [40/200] batch [3/3] time 1.425 (1.515) data 0.000 (0.093) loss 0.5259 (0.5572) acc 93.7500 (88.5417) lr 1.8181e-03 eta 0:12:07
epoch [41/200] batch [1/3] time 1.694 (1.694) data 0.278 (0.278) loss 0.4026 (0.4026) acc 87.5000 (87.5000) lr 1.8181e-03 eta 0:13:31
epoch [41/200] batch [2/3] time 1.413 (1.554) data 0.000 (0.139) loss 0.3662 (0.3844) acc 93.7500 (90.6250) lr 1.8181e-03 eta 0:12:22
epoch [41/200] batch [3/3] time 1.425 (1.511) data 0.000 (0.093) loss 0.8306 (0.5331) acc 81.2500 (87.5000) lr 1.8090e-03 eta 0:12:00
epoch [42/200] batch [1/3] time 1.676 (1.676) data 0.261 (0.261) loss 0.3638 (0.3638) acc 84.3750 (84.3750) lr 1.8090e-03 eta 0:13:17
epoch [42/200] batch [2/3] time 1.419 (1.548) data 0.000 (0.131) loss 0.6191 (0.4915) acc 81.2500 (82.8125) lr 1.8090e-03 eta 0:12:15
epoch [42/200] batch [3/3] time 1.422 (1.506) data 0.000 (0.087) loss 0.4561 (0.4797) acc 87.5000 (84.3750) lr 1.7997e-03 eta 0:11:53
epoch [43/200] batch [1/3] time 1.680 (1.680) data 0.262 (0.262) loss 0.3831 (0.3831) acc 84.3750 (84.3750) lr 1.7997e-03 eta 0:13:14
epoch [43/200] batch [2/3] time 1.426 (1.553) data 0.000 (0.131) loss 0.2573 (0.3202) acc 96.8750 (90.6250) lr 1.7997e-03 eta 0:12:12
epoch [43/200] batch [3/3] time 1.425 (1.510) data 0.000 (0.088) loss 0.2335 (0.2913) acc 93.7500 (91.6667) lr 1.7902e-03 eta 0:11:51
epoch [44/200] batch [1/3] time 1.681 (1.681) data 0.261 (0.261) loss 0.5117 (0.5117) acc 87.5000 (87.5000) lr 1.7902e-03 eta 0:13:09
epoch [44/200] batch [2/3] time 1.414 (1.547) data 0.000 (0.131) loss 0.5703 (0.5410) acc 84.3750 (85.9375) lr 1.7902e-03 eta 0:12:05
epoch [44/200] batch [3/3] time 1.409 (1.501) data 0.000 (0.087) loss 0.5957 (0.5592) acc 84.3750 (85.4167) lr 1.7804e-03 eta 0:11:42
epoch [45/200] batch [1/3] time 1.687 (1.687) data 0.261 (0.261) loss 0.6631 (0.6631) acc 84.3750 (84.3750) lr 1.7804e-03 eta 0:13:07
epoch [45/200] batch [2/3] time 1.419 (1.553) data 0.000 (0.131) loss 0.3613 (0.5122) acc 96.8750 (90.6250) lr 1.7804e-03 eta 0:12:03
epoch [45/200] batch [3/3] time 1.419 (1.508) data 0.000 (0.087) loss 0.6709 (0.5651) acc 75.0000 (85.4167) lr 1.7705e-03 eta 0:11:41
epoch [46/200] batch [1/3] time 1.702 (1.702) data 0.280 (0.280) loss 0.5952 (0.5952) acc 90.6250 (90.6250) lr 1.7705e-03 eta 0:13:09
epoch [46/200] batch [2/3] time 1.422 (1.562) data 0.000 (0.140) loss 0.1385 (0.3669) acc 96.8750 (93.7500) lr 1.7705e-03 eta 0:12:03
epoch [46/200] batch [3/3] time 1.417 (1.513) data 0.000 (0.093) loss 0.2258 (0.3199) acc 93.7500 (93.7500) lr 1.7604e-03 eta 0:11:39
epoch [47/200] batch [1/3] time 1.680 (1.680) data 0.262 (0.262) loss 0.6606 (0.6606) acc 84.3750 (84.3750) lr 1.7604e-03 eta 0:12:54
epoch [47/200] batch [2/3] time 1.419 (1.549) data 0.000 (0.131) loss 0.5220 (0.5913) acc 87.5000 (85.9375) lr 1.7604e-03 eta 0:11:52
epoch [47/200] batch [3/3] time 1.417 (1.505) data 0.000 (0.087) loss 0.5327 (0.5718) acc 84.3750 (85.4167) lr 1.7501e-03 eta 0:11:30
epoch [48/200] batch [1/3] time 1.683 (1.683) data 0.261 (0.261) loss 0.3171 (0.3171) acc 93.7500 (93.7500) lr 1.7501e-03 eta 0:12:50
epoch [48/200] batch [2/3] time 1.418 (1.551) data 0.000 (0.130) loss 0.5234 (0.4203) acc 93.7500 (93.7500) lr 1.7501e-03 eta 0:11:48
epoch [48/200] batch [3/3] time 1.417 (1.506) data 0.000 (0.087) loss 0.4312 (0.4239) acc 87.5000 (91.6667) lr 1.7396e-03 eta 0:11:26
epoch [49/200] batch [1/3] time 1.677 (1.677) data 0.261 (0.261) loss 0.3933 (0.3933) acc 87.5000 (87.5000) lr 1.7396e-03 eta 0:12:43
epoch [49/200] batch [2/3] time 1.416 (1.547) data 0.000 (0.130) loss 0.6855 (0.5394) acc 78.1250 (82.8125) lr 1.7396e-03 eta 0:11:42
epoch [49/200] batch [3/3] time 1.418 (1.504) data 0.000 (0.087) loss 0.2805 (0.4531) acc 90.6250 (85.4167) lr 1.7290e-03 eta 0:11:21
epoch [50/200] batch [1/3] time 1.676 (1.676) data 0.260 (0.260) loss 0.4275 (0.4275) acc 87.5000 (87.5000) lr 1.7290e-03 eta 0:12:37
epoch [50/200] batch [2/3] time 1.425 (1.551) data 0.000 (0.130) loss 0.5181 (0.4728) acc 87.5000 (87.5000) lr 1.7290e-03 eta 0:11:39
epoch [50/200] batch [3/3] time 1.420 (1.507) data 0.000 (0.087) loss 0.5791 (0.5082) acc 87.5000 (87.5000) lr 1.7181e-03 eta 0:11:18
epoch [51/200] batch [1/3] time 1.717 (1.717) data 0.290 (0.290) loss 0.3420 (0.3420) acc 93.7500 (93.7500) lr 1.7181e-03 eta 0:12:50
epoch [51/200] batch [2/3] time 1.421 (1.569) data 0.000 (0.145) loss 0.5396 (0.4408) acc 87.5000 (90.6250) lr 1.7181e-03 eta 0:11:42
epoch [51/200] batch [3/3] time 1.426 (1.521) data 0.000 (0.097) loss 0.6299 (0.5038) acc 84.3750 (88.5417) lr 1.7071e-03 eta 0:11:20
epoch [52/200] batch [1/3] time 1.679 (1.679) data 0.261 (0.261) loss 0.2598 (0.2598) acc 93.7500 (93.7500) lr 1.7071e-03 eta 0:12:28
epoch [52/200] batch [2/3] time 1.420 (1.549) data 0.000 (0.130) loss 0.4392 (0.3495) acc 93.7500 (93.7500) lr 1.7071e-03 eta 0:11:29
epoch [52/200] batch [3/3] time 1.424 (1.508) data 0.000 (0.087) loss 0.2681 (0.3223) acc 93.7500 (93.7500) lr 1.6959e-03 eta 0:11:09
epoch [53/200] batch [1/3] time 1.682 (1.682) data 0.259 (0.259) loss 0.6362 (0.6362) acc 81.2500 (81.2500) lr 1.6959e-03 eta 0:12:25
epoch [53/200] batch [2/3] time 1.421 (1.551) data 0.000 (0.130) loss 0.9077 (0.7720) acc 81.2500 (81.2500) lr 1.6959e-03 eta 0:11:25
epoch [53/200] batch [3/3] time 1.414 (1.506) data 0.000 (0.087) loss 0.8052 (0.7830) acc 81.2500 (81.2500) lr 1.6845e-03 eta 0:11:04
epoch [54/200] batch [1/3] time 1.688 (1.688) data 0.268 (0.268) loss 0.1974 (0.1974) acc 93.7500 (93.7500) lr 1.6845e-03 eta 0:12:22
epoch [54/200] batch [2/3] time 1.415 (1.552) data 0.000 (0.134) loss 0.4834 (0.3404) acc 90.6250 (92.1875) lr 1.6845e-03 eta 0:11:21
epoch [54/200] batch [3/3] time 1.414 (1.506) data 0.000 (0.089) loss 0.3567 (0.3458) acc 90.6250 (91.6667) lr 1.6730e-03 eta 0:10:59
epoch [55/200] batch [1/3] time 1.693 (1.693) data 0.272 (0.272) loss 0.5234 (0.5234) acc 90.6250 (90.6250) lr 1.6730e-03 eta 0:12:20
epoch [55/200] batch [2/3] time 1.420 (1.557) data 0.000 (0.136) loss 0.4260 (0.4747) acc 87.5000 (89.0625) lr 1.6730e-03 eta 0:11:18
epoch [55/200] batch [3/3] time 1.413 (1.509) data 0.000 (0.091) loss 0.4390 (0.4628) acc 93.7500 (90.6250) lr 1.6613e-03 eta 0:10:56
epoch [56/200] batch [1/3] time 1.685 (1.685) data 0.268 (0.268) loss 0.1730 (0.1730) acc 93.7500 (93.7500) lr 1.6613e-03 eta 0:12:11
epoch [56/200] batch [2/3] time 1.424 (1.555) data 0.000 (0.134) loss 0.5288 (0.3509) acc 84.3750 (89.0625) lr 1.6613e-03 eta 0:11:13
epoch [56/200] batch [3/3] time 1.419 (1.509) data 0.000 (0.089) loss 0.4363 (0.3794) acc 90.6250 (89.5833) lr 1.6494e-03 eta 0:10:52
epoch [57/200] batch [1/3] time 1.680 (1.680) data 0.263 (0.263) loss 0.3357 (0.3357) acc 96.8750 (96.8750) lr 1.6494e-03 eta 0:12:04
epoch [57/200] batch [2/3] time 1.416 (1.548) data 0.000 (0.132) loss 0.4075 (0.3716) acc 90.6250 (93.7500) lr 1.6494e-03 eta 0:11:05
epoch [57/200] batch [3/3] time 1.414 (1.504) data 0.000 (0.088) loss 0.5029 (0.4154) acc 90.6250 (92.7083) lr 1.6374e-03 eta 0:10:45
epoch [58/200] batch [1/3] time 1.680 (1.680) data 0.259 (0.259) loss 0.6045 (0.6045) acc 87.5000 (87.5000) lr 1.6374e-03 eta 0:11:59
epoch [58/200] batch [2/3] time 1.424 (1.552) data 0.000 (0.130) loss 0.3240 (0.4642) acc 87.5000 (87.5000) lr 1.6374e-03 eta 0:11:02
epoch [58/200] batch [3/3] time 1.421 (1.509) data 0.000 (0.086) loss 0.3391 (0.4225) acc 87.5000 (87.5000) lr 1.6252e-03 eta 0:10:42
epoch [59/200] batch [1/3] time 1.673 (1.673) data 0.258 (0.258) loss 0.8081 (0.8081) acc 71.8750 (71.8750) lr 1.6252e-03 eta 0:11:51
epoch [59/200] batch [2/3] time 1.412 (1.543) data 0.000 (0.129) loss 0.5737 (0.6909) acc 87.5000 (79.6875) lr 1.6252e-03 eta 0:10:54
epoch [59/200] batch [3/3] time 1.416 (1.501) data 0.000 (0.086) loss 0.6421 (0.6746) acc 87.5000 (82.2917) lr 1.6129e-03 eta 0:10:34
epoch [60/200] batch [1/3] time 1.690 (1.690) data 0.268 (0.268) loss 0.4241 (0.4241) acc 87.5000 (87.5000) lr 1.6129e-03 eta 0:11:52
epoch [60/200] batch [2/3] time 1.420 (1.555) data 0.000 (0.134) loss 0.3284 (0.3762) acc 87.5000 (87.5000) lr 1.6129e-03 eta 0:10:54
epoch [60/200] batch [3/3] time 1.416 (1.509) data 0.000 (0.090) loss 0.6201 (0.4575) acc 84.3750 (86.4583) lr 1.6004e-03 eta 0:10:33
epoch [61/200] batch [1/3] time 1.687 (1.687) data 0.269 (0.269) loss 0.5278 (0.5278) acc 84.3750 (84.3750) lr 1.6004e-03 eta 0:11:46
epoch [61/200] batch [2/3] time 1.422 (1.555) data 0.000 (0.134) loss 0.2708 (0.3993) acc 96.8750 (90.6250) lr 1.6004e-03 eta 0:10:49
epoch [61/200] batch [3/3] time 1.423 (1.511) data 0.000 (0.090) loss 0.6045 (0.4677) acc 90.6250 (90.6250) lr 1.5878e-03 eta 0:10:29
epoch [62/200] batch [1/3] time 1.694 (1.694) data 0.270 (0.270) loss 0.4587 (0.4587) acc 90.6250 (90.6250) lr 1.5878e-03 eta 0:11:44
epoch [62/200] batch [2/3] time 1.418 (1.556) data 0.000 (0.135) loss 0.3347 (0.3967) acc 93.7500 (92.1875) lr 1.5878e-03 eta 0:10:45
epoch [62/200] batch [3/3] time 1.419 (1.510) data 0.000 (0.090) loss 0.4280 (0.4071) acc 87.5000 (90.6250) lr 1.5750e-03 eta 0:10:25
epoch [63/200] batch [1/3] time 1.691 (1.691) data 0.268 (0.268) loss 0.6704 (0.6704) acc 81.2500 (81.2500) lr 1.5750e-03 eta 0:11:38
epoch [63/200] batch [2/3] time 1.422 (1.557) data 0.000 (0.134) loss 0.5024 (0.5864) acc 93.7500 (87.5000) lr 1.5750e-03 eta 0:10:41
epoch [63/200] batch [3/3] time 1.420 (1.511) data 0.000 (0.089) loss 0.3738 (0.5155) acc 96.8750 (90.6250) lr 1.5621e-03 eta 0:10:21
epoch [64/200] batch [1/3] time 1.673 (1.673) data 0.260 (0.260) loss 0.4070 (0.4070) acc 90.6250 (90.6250) lr 1.5621e-03 eta 0:11:26
epoch [64/200] batch [2/3] time 1.421 (1.547) data 0.000 (0.130) loss 0.0565 (0.2318) acc 100.0000 (95.3125) lr 1.5621e-03 eta 0:10:32
epoch [64/200] batch [3/3] time 1.424 (1.506) data 0.000 (0.087) loss 0.7598 (0.4078) acc 81.2500 (90.6250) lr 1.5490e-03 eta 0:10:14
epoch [65/200] batch [1/3] time 1.690 (1.690) data 0.276 (0.276) loss 0.5464 (0.5464) acc 87.5000 (87.5000) lr 1.5490e-03 eta 0:11:27
epoch [65/200] batch [2/3] time 1.422 (1.556) data 0.000 (0.138) loss 0.5464 (0.5464) acc 81.2500 (84.3750) lr 1.5490e-03 eta 0:10:31
epoch [65/200] batch [3/3] time 1.426 (1.513) data 0.000 (0.092) loss 0.4331 (0.5086) acc 90.6250 (86.4583) lr 1.5358e-03 eta 0:10:12
epoch [66/200] batch [1/3] time 1.686 (1.686) data 0.269 (0.269) loss 0.2031 (0.2031) acc 90.6250 (90.6250) lr 1.5358e-03 eta 0:11:21
epoch [66/200] batch [2/3] time 1.417 (1.552) data 0.000 (0.134) loss 0.5371 (0.3701) acc 90.6250 (90.6250) lr 1.5358e-03 eta 0:10:25
epoch [66/200] batch [3/3] time 1.426 (1.510) data 0.000 (0.090) loss 0.5293 (0.4232) acc 90.6250 (90.6250) lr 1.5225e-03 eta 0:10:06
epoch [67/200] batch [1/3] time 1.688 (1.688) data 0.260 (0.260) loss 0.7314 (0.7314) acc 81.2500 (81.2500) lr 1.5225e-03 eta 0:11:16
epoch [67/200] batch [2/3] time 1.420 (1.554) data 0.000 (0.130) loss 0.3672 (0.5493) acc 96.8750 (89.0625) lr 1.5225e-03 eta 0:10:21
epoch [67/200] batch [3/3] time 1.419 (1.509) data 0.000 (0.087) loss 0.4380 (0.5122) acc 90.6250 (89.5833) lr 1.5090e-03 eta 0:10:02
epoch [68/200] batch [1/3] time 1.683 (1.683) data 0.260 (0.260) loss 0.2847 (0.2847) acc 87.5000 (87.5000) lr 1.5090e-03 eta 0:11:09
epoch [68/200] batch [2/3] time 1.410 (1.546) data 0.000 (0.130) loss 0.1586 (0.2216) acc 96.8750 (92.1875) lr 1.5090e-03 eta 0:10:13
epoch [68/200] batch [3/3] time 1.420 (1.504) data 0.000 (0.087) loss 0.2239 (0.2224) acc 93.7500 (92.7083) lr 1.4955e-03 eta 0:09:55
epoch [69/200] batch [1/3] time 1.683 (1.683) data 0.270 (0.270) loss 0.2302 (0.2302) acc 93.7500 (93.7500) lr 1.4955e-03 eta 0:11:04
epoch [69/200] batch [2/3] time 1.423 (1.553) data 0.000 (0.135) loss 0.5713 (0.4008) acc 75.0000 (84.3750) lr 1.4955e-03 eta 0:10:11
epoch [69/200] batch [3/3] time 1.420 (1.509) data 0.000 (0.090) loss 0.5811 (0.4609) acc 81.2500 (83.3333) lr 1.4818e-03 eta 0:09:52
epoch [70/200] batch [1/3] time 1.699 (1.699) data 0.276 (0.276) loss 0.5986 (0.5986) acc 81.2500 (81.2500) lr 1.4818e-03 eta 0:11:05
epoch [70/200] batch [2/3] time 1.421 (1.560) data 0.000 (0.138) loss 0.5278 (0.5632) acc 78.1250 (79.6875) lr 1.4818e-03 eta 0:10:09
epoch [70/200] batch [3/3] time 1.414 (1.511) data 0.000 (0.092) loss 0.2283 (0.4516) acc 90.6250 (83.3333) lr 1.4679e-03 eta 0:09:49
epoch [71/200] batch [1/3] time 1.689 (1.689) data 0.278 (0.278) loss 0.4797 (0.4797) acc 87.5000 (87.5000) lr 1.4679e-03 eta 0:10:57
epoch [71/200] batch [2/3] time 1.424 (1.557) data 0.000 (0.139) loss 0.3240 (0.4019) acc 87.5000 (87.5000) lr 1.4679e-03 eta 0:10:03
epoch [71/200] batch [3/3] time 1.415 (1.509) data 0.000 (0.093) loss 0.3621 (0.3886) acc 84.3750 (86.4583) lr 1.4540e-03 eta 0:09:44
epoch [72/200] batch [1/3] time 1.681 (1.681) data 0.260 (0.260) loss 1.0215 (1.0215) acc 78.1250 (78.1250) lr 1.4540e-03 eta 0:10:48
epoch [72/200] batch [2/3] time 1.421 (1.551) data 0.000 (0.130) loss 0.4221 (0.7218) acc 87.5000 (82.8125) lr 1.4540e-03 eta 0:09:57
epoch [72/200] batch [3/3] time 1.422 (1.508) data 0.000 (0.087) loss 0.3806 (0.6081) acc 93.7500 (86.4583) lr 1.4399e-03 eta 0:09:39
epoch [73/200] batch [1/3] time 1.698 (1.698) data 0.279 (0.279) loss 0.2952 (0.2952) acc 96.8750 (96.8750) lr 1.4399e-03 eta 0:10:50
epoch [73/200] batch [2/3] time 1.412 (1.555) data 0.000 (0.140) loss 0.3232 (0.3092) acc 90.6250 (93.7500) lr 1.4399e-03 eta 0:09:54
epoch [73/200] batch [3/3] time 1.419 (1.510) data 0.000 (0.093) loss 0.5156 (0.3780) acc 81.2500 (89.5833) lr 1.4258e-03 eta 0:09:35
epoch [74/200] batch [1/3] time 1.674 (1.674) data 0.260 (0.260) loss 0.2678 (0.2678) acc 90.6250 (90.6250) lr 1.4258e-03 eta 0:10:36
epoch [74/200] batch [2/3] time 1.423 (1.549) data 0.000 (0.130) loss 0.2998 (0.2838) acc 93.7500 (92.1875) lr 1.4258e-03 eta 0:09:46
epoch [74/200] batch [3/3] time 1.419 (1.505) data 0.000 (0.087) loss 0.5483 (0.3720) acc 84.3750 (89.5833) lr 1.4115e-03 eta 0:09:29
epoch [75/200] batch [1/3] time 1.681 (1.681) data 0.262 (0.262) loss 0.3083 (0.3083) acc 93.7500 (93.7500) lr 1.4115e-03 eta 0:10:33
epoch [75/200] batch [2/3] time 1.422 (1.552) data 0.000 (0.131) loss 0.7139 (0.5111) acc 81.2500 (87.5000) lr 1.4115e-03 eta 0:09:43
epoch [75/200] batch [3/3] time 1.418 (1.507) data 0.000 (0.087) loss 0.8403 (0.6208) acc 81.2500 (85.4167) lr 1.3971e-03 eta 0:09:25
epoch [76/200] batch [1/3] time 1.684 (1.684) data 0.267 (0.267) loss 0.3325 (0.3325) acc 90.6250 (90.6250) lr 1.3971e-03 eta 0:10:29
epoch [76/200] batch [2/3] time 1.422 (1.553) data 0.000 (0.134) loss 0.7529 (0.5427) acc 84.3750 (87.5000) lr 1.3971e-03 eta 0:09:39
epoch [76/200] batch [3/3] time 1.425 (1.510) data 0.000 (0.089) loss 0.0959 (0.3938) acc 100.0000 (91.6667) lr 1.3827e-03 eta 0:09:21
epoch [77/200] batch [1/3] time 1.683 (1.683) data 0.264 (0.264) loss 0.5063 (0.5063) acc 87.5000 (87.5000) lr 1.3827e-03 eta 0:10:24
epoch [77/200] batch [2/3] time 1.415 (1.549) data 0.000 (0.132) loss 0.3164 (0.4114) acc 96.8750 (92.1875) lr 1.3827e-03 eta 0:09:33
epoch [77/200] batch [3/3] time 1.425 (1.508) data 0.000 (0.088) loss 0.1896 (0.3374) acc 93.7500 (92.7083) lr 1.3681e-03 eta 0:09:16
epoch [78/200] batch [1/3] time 1.676 (1.676) data 0.259 (0.259) loss 0.3220 (0.3220) acc 93.7500 (93.7500) lr 1.3681e-03 eta 0:10:16
epoch [78/200] batch [2/3] time 1.413 (1.544) data 0.000 (0.130) loss 0.9531 (0.6376) acc 71.8750 (82.8125) lr 1.3681e-03 eta 0:09:26
epoch [78/200] batch [3/3] time 1.426 (1.505) data 0.000 (0.086) loss 0.2238 (0.4996) acc 93.7500 (86.4583) lr 1.3535e-03 eta 0:09:10
epoch [79/200] batch [1/3] time 1.682 (1.682) data 0.260 (0.260) loss 0.3340 (0.3340) acc 90.6250 (90.6250) lr 1.3535e-03 eta 0:10:13
epoch [79/200] batch [2/3] time 1.415 (1.548) data 0.000 (0.130) loss 0.4573 (0.3956) acc 87.5000 (89.0625) lr 1.3535e-03 eta 0:09:23
epoch [79/200] batch [3/3] time 1.411 (1.503) data 0.000 (0.087) loss 0.7476 (0.5129) acc 84.3750 (87.5000) lr 1.3387e-03 eta 0:09:05
epoch [80/200] batch [1/3] time 1.683 (1.683) data 0.261 (0.261) loss 0.5098 (0.5098) acc 87.5000 (87.5000) lr 1.3387e-03 eta 0:10:09
epoch [80/200] batch [2/3] time 1.422 (1.553) data 0.000 (0.130) loss 0.3220 (0.4159) acc 90.6250 (89.0625) lr 1.3387e-03 eta 0:09:20
epoch [80/200] batch [3/3] time 1.409 (1.505) data 0.000 (0.087) loss 0.8433 (0.5583) acc 78.1250 (85.4167) lr 1.3239e-03 eta 0:09:01
epoch [81/200] batch [1/3] time 1.687 (1.687) data 0.261 (0.261) loss 0.6074 (0.6074) acc 87.5000 (87.5000) lr 1.3239e-03 eta 0:10:05
epoch [81/200] batch [2/3] time 1.423 (1.555) data 0.000 (0.131) loss 0.1881 (0.3978) acc 93.7500 (90.6250) lr 1.3239e-03 eta 0:09:16
epoch [81/200] batch [3/3] time 1.423 (1.511) data 0.000 (0.087) loss 0.1641 (0.3199) acc 96.8750 (92.7083) lr 1.3090e-03 eta 0:08:59
epoch [82/200] batch [1/3] time 1.680 (1.680) data 0.259 (0.259) loss 0.4727 (0.4727) acc 90.6250 (90.6250) lr 1.3090e-03 eta 0:09:58
epoch [82/200] batch [2/3] time 1.416 (1.548) data 0.000 (0.130) loss 0.1731 (0.3229) acc 96.8750 (93.7500) lr 1.3090e-03 eta 0:09:09
epoch [82/200] batch [3/3] time 1.418 (1.504) data 0.000 (0.086) loss 0.3586 (0.3348) acc 90.6250 (92.7083) lr 1.2940e-03 eta 0:08:52
epoch [83/200] batch [1/3] time 1.701 (1.701) data 0.280 (0.280) loss 0.5039 (0.5039) acc 90.6250 (90.6250) lr 1.2940e-03 eta 0:10:00
epoch [83/200] batch [2/3] time 1.415 (1.558) data 0.000 (0.140) loss 0.4146 (0.4592) acc 93.7500 (92.1875) lr 1.2940e-03 eta 0:09:08
epoch [83/200] batch [3/3] time 1.422 (1.513) data 0.000 (0.094) loss 0.4836 (0.4674) acc 81.2500 (88.5417) lr 1.2790e-03 eta 0:08:50
epoch [84/200] batch [1/3] time 1.694 (1.694) data 0.278 (0.278) loss 0.3186 (0.3186) acc 90.6250 (90.6250) lr 1.2790e-03 eta 0:09:52
epoch [84/200] batch [2/3] time 1.427 (1.561) data 0.000 (0.139) loss 0.2937 (0.3062) acc 90.6250 (90.6250) lr 1.2790e-03 eta 0:09:04
epoch [84/200] batch [3/3] time 1.426 (1.516) data 0.000 (0.093) loss 0.6021 (0.4048) acc 84.3750 (88.5417) lr 1.2639e-03 eta 0:08:47
epoch [85/200] batch [1/3] time 1.689 (1.689) data 0.268 (0.268) loss 0.1218 (0.1218) acc 96.8750 (96.8750) lr 1.2639e-03 eta 0:09:46
epoch [85/200] batch [2/3] time 1.419 (1.554) data 0.000 (0.134) loss 0.1343 (0.1281) acc 96.8750 (96.8750) lr 1.2639e-03 eta 0:08:57
epoch [85/200] batch [3/3] time 1.420 (1.510) data 0.000 (0.089) loss 0.1973 (0.1511) acc 93.7500 (95.8333) lr 1.2487e-03 eta 0:08:40
epoch [86/200] batch [1/3] time 1.692 (1.692) data 0.276 (0.276) loss 0.5464 (0.5464) acc 78.1250 (78.1250) lr 1.2487e-03 eta 0:09:42
epoch [86/200] batch [2/3] time 1.417 (1.555) data 0.000 (0.138) loss 0.1935 (0.3699) acc 96.8750 (87.5000) lr 1.2487e-03 eta 0:08:53
epoch [86/200] batch [3/3] time 1.419 (1.509) data 0.000 (0.092) loss 0.3184 (0.3527) acc 93.7500 (89.5833) lr 1.2334e-03 eta 0:08:36
epoch [87/200] batch [1/3] time 1.682 (1.682) data 0.261 (0.261) loss 0.3855 (0.3855) acc 90.6250 (90.6250) lr 1.2334e-03 eta 0:09:33
epoch [87/200] batch [2/3] time 1.418 (1.550) data 0.000 (0.131) loss 0.1857 (0.2856) acc 96.8750 (93.7500) lr 1.2334e-03 eta 0:08:46
epoch [87/200] batch [3/3] time 1.420 (1.507) data 0.000 (0.087) loss 0.2649 (0.2787) acc 90.6250 (92.7083) lr 1.2181e-03 eta 0:08:30
epoch [88/200] batch [1/3] time 1.700 (1.700) data 0.277 (0.277) loss 0.6587 (0.6587) acc 71.8750 (71.8750) lr 1.2181e-03 eta 0:09:34
epoch [88/200] batch [2/3] time 1.415 (1.558) data 0.000 (0.138) loss 0.3279 (0.4933) acc 87.5000 (79.6875) lr 1.2181e-03 eta 0:08:44
epoch [88/200] batch [3/3] time 1.418 (1.511) data 0.000 (0.092) loss 0.3376 (0.4414) acc 93.7500 (84.3750) lr 1.2028e-03 eta 0:08:27
epoch [89/200] batch [1/3] time 1.671 (1.671) data 0.261 (0.261) loss 0.3958 (0.3958) acc 90.6250 (90.6250) lr 1.2028e-03 eta 0:09:19
epoch [89/200] batch [2/3] time 1.422 (1.547) data 0.000 (0.131) loss 0.7915 (0.5936) acc 81.2500 (85.9375) lr 1.2028e-03 eta 0:08:36
epoch [89/200] batch [3/3] time 1.422 (1.505) data 0.000 (0.087) loss 0.4395 (0.5422) acc 93.7500 (88.5417) lr 1.1874e-03 eta 0:08:21
epoch [90/200] batch [1/3] time 1.681 (1.681) data 0.265 (0.265) loss 0.3557 (0.3557) acc 87.5000 (87.5000) lr 1.1874e-03 eta 0:09:18
epoch [90/200] batch [2/3] time 1.418 (1.550) data 0.000 (0.133) loss 0.3723 (0.3640) acc 87.5000 (87.5000) lr 1.1874e-03 eta 0:08:32
epoch [90/200] batch [3/3] time 1.424 (1.508) data 0.000 (0.088) loss 0.2400 (0.3227) acc 93.7500 (89.5833) lr 1.1719e-03 eta 0:08:17
epoch [91/200] batch [1/3] time 1.694 (1.694) data 0.270 (0.270) loss 0.2539 (0.2539) acc 90.6250 (90.6250) lr 1.1719e-03 eta 0:09:17
epoch [91/200] batch [2/3] time 1.423 (1.558) data 0.000 (0.135) loss 0.2615 (0.2577) acc 90.6250 (90.6250) lr 1.1719e-03 eta 0:08:31
epoch [91/200] batch [3/3] time 1.411 (1.509) data 0.000 (0.090) loss 0.2207 (0.2454) acc 93.7500 (91.6667) lr 1.1564e-03 eta 0:08:13
epoch [92/200] batch [1/3] time 1.678 (1.678) data 0.262 (0.262) loss 0.1004 (0.1004) acc 100.0000 (100.0000) lr 1.1564e-03 eta 0:09:07
epoch [92/200] batch [2/3] time 1.412 (1.545) data 0.000 (0.131) loss 0.2253 (0.1629) acc 93.7500 (96.8750) lr 1.1564e-03 eta 0:08:22
epoch [92/200] batch [3/3] time 1.418 (1.503) data 0.000 (0.087) loss 0.3169 (0.2142) acc 90.6250 (94.7917) lr 1.1409e-03 eta 0:08:06
epoch [93/200] batch [1/3] time 1.683 (1.683) data 0.267 (0.267) loss 0.3250 (0.3250) acc 90.6250 (90.6250) lr 1.1409e-03 eta 0:09:03
epoch [93/200] batch [2/3] time 1.418 (1.551) data 0.000 (0.134) loss 0.6641 (0.4945) acc 81.2500 (85.9375) lr 1.1409e-03 eta 0:08:19
epoch [93/200] batch [3/3] time 1.418 (1.506) data 0.000 (0.089) loss 0.4751 (0.4880) acc 90.6250 (87.5000) lr 1.1253e-03 eta 0:08:03
epoch [94/200] batch [1/3] time 1.672 (1.672) data 0.260 (0.260) loss 0.3088 (0.3088) acc 96.8750 (96.8750) lr 1.1253e-03 eta 0:08:55
epoch [94/200] batch [2/3] time 1.417 (1.544) data 0.000 (0.130) loss 0.3491 (0.3290) acc 93.7500 (95.3125) lr 1.1253e-03 eta 0:08:12
epoch [94/200] batch [3/3] time 1.420 (1.503) data 0.000 (0.087) loss 0.2886 (0.3155) acc 93.7500 (94.7917) lr 1.1097e-03 eta 0:07:57
epoch [95/200] batch [1/3] time 1.695 (1.695) data 0.275 (0.275) loss 0.4392 (0.4392) acc 87.5000 (87.5000) lr 1.1097e-03 eta 0:08:57
epoch [95/200] batch [2/3] time 1.410 (1.553) data 0.000 (0.137) loss 0.3113 (0.3752) acc 93.7500 (90.6250) lr 1.1097e-03 eta 0:08:10
epoch [95/200] batch [3/3] time 1.415 (1.507) data 0.000 (0.092) loss 0.3162 (0.3556) acc 93.7500 (91.6667) lr 1.0941e-03 eta 0:07:54
epoch [96/200] batch [1/3] time 1.690 (1.690) data 0.277 (0.277) loss 0.7217 (0.7217) acc 87.5000 (87.5000) lr 1.0941e-03 eta 0:08:50
epoch [96/200] batch [2/3] time 1.417 (1.553) data 0.000 (0.138) loss 0.2681 (0.4949) acc 93.7500 (90.6250) lr 1.0941e-03 eta 0:08:06
epoch [96/200] batch [3/3] time 1.414 (1.507) data 0.000 (0.092) loss 0.4915 (0.4937) acc 87.5000 (89.5833) lr 1.0785e-03 eta 0:07:50
epoch [97/200] batch [1/3] time 1.682 (1.682) data 0.265 (0.265) loss 0.3879 (0.3879) acc 87.5000 (87.5000) lr 1.0785e-03 eta 0:08:43
epoch [97/200] batch [2/3] time 1.426 (1.554) data 0.000 (0.132) loss 0.1707 (0.2793) acc 93.7500 (90.6250) lr 1.0785e-03 eta 0:08:01
epoch [97/200] batch [3/3] time 1.413 (1.507) data 0.000 (0.088) loss 0.1787 (0.2458) acc 96.8750 (92.7083) lr 1.0628e-03 eta 0:07:45
epoch [98/200] batch [1/3] time 1.685 (1.685) data 0.260 (0.260) loss 0.5371 (0.5371) acc 81.2500 (81.2500) lr 1.0628e-03 eta 0:08:39
epoch [98/200] batch [2/3] time 1.416 (1.551) data 0.000 (0.130) loss 0.7637 (0.6504) acc 81.2500 (81.2500) lr 1.0628e-03 eta 0:07:56
epoch [98/200] batch [3/3] time 1.421 (1.508) data 0.000 (0.087) loss 0.3484 (0.5497) acc 90.6250 (84.3750) lr 1.0471e-03 eta 0:07:41
epoch [99/200] batch [1/3] time 1.672 (1.672) data 0.261 (0.261) loss 0.3525 (0.3525) acc 93.7500 (93.7500) lr 1.0471e-03 eta 0:08:29
epoch [99/200] batch [2/3] time 1.417 (1.544) data 0.000 (0.130) loss 0.3755 (0.3640) acc 90.6250 (92.1875) lr 1.0471e-03 eta 0:07:49
epoch [99/200] batch [3/3] time 1.415 (1.501) data 0.000 (0.087) loss 0.2646 (0.3309) acc 90.6250 (91.6667) lr 1.0314e-03 eta 0:07:34
epoch [100/200] batch [1/3] time 1.696 (1.696) data 0.282 (0.282) loss 0.4446 (0.4446) acc 87.5000 (87.5000) lr 1.0314e-03 eta 0:08:32
epoch [100/200] batch [2/3] time 1.425 (1.561) data 0.000 (0.141) loss 0.2925 (0.3685) acc 87.5000 (87.5000) lr 1.0314e-03 eta 0:07:49
epoch [100/200] batch [3/3] time 1.423 (1.515) data 0.000 (0.094) loss 0.5098 (0.4156) acc 84.3750 (86.4583) lr 1.0157e-03 eta 0:07:34
epoch [101/200] batch [1/3] time 1.681 (1.681) data 0.261 (0.261) loss 0.2615 (0.2615) acc 93.7500 (93.7500) lr 1.0157e-03 eta 0:08:22
epoch [101/200] batch [2/3] time 1.418 (1.549) data 0.000 (0.131) loss 0.2037 (0.2326) acc 96.8750 (95.3125) lr 1.0157e-03 eta 0:07:41
epoch [101/200] batch [3/3] time 1.424 (1.508) data 0.000 (0.087) loss 0.2410 (0.2354) acc 96.8750 (95.8333) lr 1.0000e-03 eta 0:07:27
epoch [102/200] batch [1/3] time 1.693 (1.693) data 0.269 (0.269) loss 0.2651 (0.2651) acc 93.7500 (93.7500) lr 1.0000e-03 eta 0:08:21
epoch [102/200] batch [2/3] time 1.424 (1.558) data 0.000 (0.134) loss 0.3376 (0.3014) acc 84.3750 (89.0625) lr 1.0000e-03 eta 0:07:39
epoch [102/200] batch [3/3] time 1.423 (1.513) data 0.000 (0.090) loss 0.2365 (0.2797) acc 90.6250 (89.5833) lr 9.8429e-04 eta 0:07:24
epoch [103/200] batch [1/3] time 1.676 (1.676) data 0.259 (0.259) loss 0.1479 (0.1479) acc 100.0000 (100.0000) lr 9.8429e-04 eta 0:08:11
epoch [103/200] batch [2/3] time 1.426 (1.551) data 0.000 (0.129) loss 0.3523 (0.2501) acc 90.6250 (95.3125) lr 9.8429e-04 eta 0:07:33
epoch [103/200] batch [3/3] time 1.412 (1.505) data 0.000 (0.086) loss 0.3928 (0.2977) acc 90.6250 (93.7500) lr 9.6859e-04 eta 0:07:17
epoch [104/200] batch [1/3] time 1.700 (1.700) data 0.277 (0.277) loss 0.3369 (0.3369) acc 93.7500 (93.7500) lr 9.6859e-04 eta 0:08:12
epoch [104/200] batch [2/3] time 1.421 (1.560) data 0.000 (0.139) loss 0.2280 (0.2825) acc 93.7500 (93.7500) lr 9.6859e-04 eta 0:07:30
epoch [104/200] batch [3/3] time 1.420 (1.513) data 0.000 (0.092) loss 0.3188 (0.2946) acc 90.6250 (92.7083) lr 9.5289e-04 eta 0:07:15
epoch [105/200] batch [1/3] time 1.697 (1.697) data 0.277 (0.277) loss 0.1987 (0.1987) acc 90.6250 (90.6250) lr 9.5289e-04 eta 0:08:07
epoch [105/200] batch [2/3] time 1.416 (1.557) data 0.000 (0.139) loss 0.1970 (0.1979) acc 93.7500 (92.1875) lr 9.5289e-04 eta 0:07:25
epoch [105/200] batch [3/3] time 1.418 (1.511) data 0.000 (0.093) loss 0.0560 (0.1506) acc 100.0000 (94.7917) lr 9.3721e-04 eta 0:07:10
epoch [106/200] batch [1/3] time 1.698 (1.698) data 0.275 (0.275) loss 0.5220 (0.5220) acc 84.3750 (84.3750) lr 9.3721e-04 eta 0:08:02
epoch [106/200] batch [2/3] time 1.427 (1.563) data 0.000 (0.138) loss 0.4519 (0.4869) acc 87.5000 (85.9375) lr 9.3721e-04 eta 0:07:22
epoch [106/200] batch [3/3] time 1.419 (1.515) data 0.000 (0.092) loss 0.2393 (0.4044) acc 93.7500 (88.5417) lr 9.2154e-04 eta 0:07:07
epoch [107/200] batch [1/3] time 1.677 (1.677) data 0.262 (0.262) loss 0.3647 (0.3647) acc 87.5000 (87.5000) lr 9.2154e-04 eta 0:07:51
epoch [107/200] batch [2/3] time 1.414 (1.545) data 0.000 (0.131) loss 0.1804 (0.2726) acc 96.8750 (92.1875) lr 9.2154e-04 eta 0:07:12
epoch [107/200] batch [3/3] time 1.416 (1.502) data 0.000 (0.087) loss 0.2374 (0.2609) acc 93.7500 (92.7083) lr 9.0589e-04 eta 0:06:59
epoch [108/200] batch [1/3] time 1.695 (1.695) data 0.276 (0.276) loss 0.2465 (0.2465) acc 96.8750 (96.8750) lr 9.0589e-04 eta 0:07:51
epoch [108/200] batch [2/3] time 1.418 (1.556) data 0.000 (0.138) loss 0.5684 (0.4074) acc 90.6250 (93.7500) lr 9.0589e-04 eta 0:07:11
epoch [108/200] batch [3/3] time 1.422 (1.511) data 0.000 (0.092) loss 0.1801 (0.3316) acc 96.8750 (94.7917) lr 8.9027e-04 eta 0:06:57
epoch [109/200] batch [1/3] time 1.698 (1.698) data 0.278 (0.278) loss 0.1279 (0.1279) acc 96.8750 (96.8750) lr 8.9027e-04 eta 0:07:46
epoch [109/200] batch [2/3] time 1.423 (1.560) data 0.000 (0.139) loss 0.2235 (0.1757) acc 93.7500 (95.3125) lr 8.9027e-04 eta 0:07:07
epoch [109/200] batch [3/3] time 1.417 (1.513) data 0.000 (0.093) loss 0.3533 (0.2349) acc 93.7500 (94.7917) lr 8.7467e-04 eta 0:06:52
epoch [110/200] batch [1/3] time 1.681 (1.681) data 0.258 (0.258) loss 0.5850 (0.5850) acc 78.1250 (78.1250) lr 8.7467e-04 eta 0:07:37
epoch [110/200] batch [2/3] time 1.416 (1.548) data 0.000 (0.129) loss 0.1005 (0.3427) acc 100.0000 (89.0625) lr 8.7467e-04 eta 0:06:59
epoch [110/200] batch [3/3] time 1.419 (1.505) data 0.000 (0.086) loss 0.2800 (0.3218) acc 90.6250 (89.5833) lr 8.5910e-04 eta 0:06:46
epoch [111/200] batch [1/3] time 1.696 (1.696) data 0.280 (0.280) loss 0.3362 (0.3362) acc 90.6250 (90.6250) lr 8.5910e-04 eta 0:07:36
epoch [111/200] batch [2/3] time 1.423 (1.559) data 0.000 (0.140) loss 0.1613 (0.2487) acc 93.7500 (92.1875) lr 8.5910e-04 eta 0:06:57
epoch [111/200] batch [3/3] time 1.421 (1.513) data 0.000 (0.093) loss 0.6001 (0.3658) acc 90.6250 (91.6667) lr 8.4357e-04 eta 0:06:44
epoch [112/200] batch [1/3] time 1.691 (1.691) data 0.271 (0.271) loss 0.2074 (0.2074) acc 96.8750 (96.8750) lr 8.4357e-04 eta 0:07:29
epoch [112/200] batch [2/3] time 1.417 (1.554) data 0.000 (0.136) loss 0.2820 (0.2447) acc 93.7500 (95.3125) lr 8.4357e-04 eta 0:06:51
epoch [112/200] batch [3/3] time 1.412 (1.507) data 0.000 (0.090) loss 0.2695 (0.2530) acc 90.6250 (93.7500) lr 8.2807e-04 eta 0:06:37
epoch [113/200] batch [1/3] time 1.688 (1.688) data 0.269 (0.269) loss 0.4692 (0.4692) acc 90.6250 (90.6250) lr 8.2807e-04 eta 0:07:23
epoch [113/200] batch [2/3] time 1.426 (1.557) data 0.000 (0.135) loss 0.8203 (0.6448) acc 75.0000 (82.8125) lr 8.2807e-04 eta 0:06:47
epoch [113/200] batch [3/3] time 1.428 (1.514) data 0.000 (0.090) loss 0.1501 (0.4799) acc 96.8750 (87.5000) lr 8.1262e-04 eta 0:06:35
epoch [114/200] batch [1/3] time 1.681 (1.681) data 0.259 (0.259) loss 0.1057 (0.1057) acc 100.0000 (100.0000) lr 8.1262e-04 eta 0:07:17
epoch [114/200] batch [2/3] time 1.422 (1.552) data 0.000 (0.130) loss 0.1288 (0.1172) acc 96.8750 (98.4375) lr 8.1262e-04 eta 0:06:41
epoch [114/200] batch [3/3] time 1.425 (1.510) data 0.000 (0.087) loss 0.3538 (0.1961) acc 90.6250 (95.8333) lr 7.9721e-04 eta 0:06:29
epoch [115/200] batch [1/3] time 1.684 (1.684) data 0.269 (0.269) loss 0.2878 (0.2878) acc 90.6250 (90.6250) lr 7.9721e-04 eta 0:07:12
epoch [115/200] batch [2/3] time 1.418 (1.551) data 0.000 (0.135) loss 0.1610 (0.2244) acc 93.7500 (92.1875) lr 7.9721e-04 eta 0:06:36
epoch [115/200] batch [3/3] time 1.421 (1.507) data 0.000 (0.090) loss 0.3618 (0.2702) acc 87.5000 (90.6250) lr 7.8186e-04 eta 0:06:24
epoch [116/200] batch [1/3] time 1.680 (1.680) data 0.257 (0.257) loss 0.3762 (0.3762) acc 90.6250 (90.6250) lr 7.8186e-04 eta 0:07:06
epoch [116/200] batch [2/3] time 1.421 (1.550) data 0.000 (0.129) loss 0.3467 (0.3615) acc 90.6250 (90.6250) lr 7.8186e-04 eta 0:06:32
epoch [116/200] batch [3/3] time 1.417 (1.506) data 0.000 (0.086) loss 0.2620 (0.3283) acc 96.8750 (92.7083) lr 7.6655e-04 eta 0:06:19
epoch [117/200] batch [1/3] time 1.684 (1.684) data 0.261 (0.261) loss 0.3696 (0.3696) acc 90.6250 (90.6250) lr 7.6655e-04 eta 0:07:02
epoch [117/200] batch [2/3] time 1.424 (1.554) data 0.000 (0.130) loss 0.7300 (0.5498) acc 84.3750 (87.5000) lr 7.6655e-04 eta 0:06:28
epoch [117/200] batch [3/3] time 1.416 (1.508) data 0.000 (0.087) loss 0.0653 (0.3883) acc 100.0000 (91.6667) lr 7.5131e-04 eta 0:06:15
epoch [118/200] batch [1/3] time 1.692 (1.692) data 0.270 (0.270) loss 0.2236 (0.2236) acc 90.6250 (90.6250) lr 7.5131e-04 eta 0:06:59
epoch [118/200] batch [2/3] time 1.419 (1.555) data 0.000 (0.135) loss 0.3311 (0.2773) acc 93.7500 (92.1875) lr 7.5131e-04 eta 0:06:24
epoch [118/200] batch [3/3] time 1.416 (1.509) data 0.000 (0.090) loss 0.0914 (0.2154) acc 100.0000 (94.7917) lr 7.3613e-04 eta 0:06:11
epoch [119/200] batch [1/3] time 1.699 (1.699) data 0.278 (0.278) loss 0.2759 (0.2759) acc 90.6250 (90.6250) lr 7.3613e-04 eta 0:06:56
epoch [119/200] batch [2/3] time 1.419 (1.559) data 0.000 (0.139) loss 0.2600 (0.2679) acc 90.6250 (90.6250) lr 7.3613e-04 eta 0:06:20
epoch [119/200] batch [3/3] time 1.415 (1.511) data 0.000 (0.093) loss 0.2878 (0.2746) acc 93.7500 (91.6667) lr 7.2101e-04 eta 0:06:07
epoch [120/200] batch [1/3] time 1.698 (1.698) data 0.276 (0.276) loss 0.1522 (0.1522) acc 96.8750 (96.8750) lr 7.2101e-04 eta 0:06:50
epoch [120/200] batch [2/3] time 1.416 (1.557) data 0.000 (0.138) loss 0.2817 (0.2170) acc 90.6250 (93.7500) lr 7.2101e-04 eta 0:06:15
epoch [120/200] batch [3/3] time 1.414 (1.510) data 0.000 (0.092) loss 0.2834 (0.2391) acc 93.7500 (93.7500) lr 7.0596e-04 eta 0:06:02
epoch [121/200] batch [1/3] time 1.670 (1.670) data 0.262 (0.262) loss 0.1159 (0.1159) acc 96.8750 (96.8750) lr 7.0596e-04 eta 0:06:39
epoch [121/200] batch [2/3] time 1.418 (1.544) data 0.000 (0.131) loss 0.5654 (0.3407) acc 87.5000 (92.1875) lr 7.0596e-04 eta 0:06:07
epoch [121/200] batch [3/3] time 1.419 (1.502) data 0.000 (0.087) loss 0.5659 (0.4158) acc 90.6250 (91.6667) lr 6.9098e-04 eta 0:05:56
epoch [122/200] batch [1/3] time 1.685 (1.685) data 0.269 (0.269) loss 0.4797 (0.4797) acc 90.6250 (90.6250) lr 6.9098e-04 eta 0:06:37
epoch [122/200] batch [2/3] time 1.416 (1.550) data 0.000 (0.134) loss 0.1866 (0.3332) acc 96.8750 (93.7500) lr 6.9098e-04 eta 0:06:04
epoch [122/200] batch [3/3] time 1.413 (1.505) data 0.000 (0.090) loss 0.1858 (0.2841) acc 93.7500 (93.7500) lr 6.7608e-04 eta 0:05:52
epoch [123/200] batch [1/3] time 1.696 (1.696) data 0.279 (0.279) loss 0.3381 (0.3381) acc 90.6250 (90.6250) lr 6.7608e-04 eta 0:06:35
epoch [123/200] batch [2/3] time 1.425 (1.560) data 0.000 (0.140) loss 0.1412 (0.2397) acc 96.8750 (93.7500) lr 6.7608e-04 eta 0:06:02
epoch [123/200] batch [3/3] time 1.419 (1.513) data 0.000 (0.093) loss 0.4258 (0.3017) acc 84.3750 (90.6250) lr 6.6126e-04 eta 0:05:49
epoch [124/200] batch [1/3] time 1.681 (1.681) data 0.260 (0.260) loss 0.5703 (0.5703) acc 87.5000 (87.5000) lr 6.6126e-04 eta 0:06:26
epoch [124/200] batch [2/3] time 1.424 (1.552) data 0.000 (0.130) loss 0.1116 (0.3409) acc 100.0000 (93.7500) lr 6.6126e-04 eta 0:05:55
epoch [124/200] batch [3/3] time 1.418 (1.507) data 0.000 (0.087) loss 0.1445 (0.2755) acc 96.8750 (94.7917) lr 6.4653e-04 eta 0:05:43
epoch [125/200] batch [1/3] time 1.678 (1.678) data 0.260 (0.260) loss 0.2155 (0.2155) acc 93.7500 (93.7500) lr 6.4653e-04 eta 0:06:20
epoch [125/200] batch [2/3] time 1.426 (1.552) data 0.000 (0.130) loss 0.6460 (0.4307) acc 84.3750 (89.0625) lr 6.4653e-04 eta 0:05:50
epoch [125/200] batch [3/3] time 1.425 (1.510) data 0.000 (0.087) loss 0.0953 (0.3189) acc 96.8750 (91.6667) lr 6.3188e-04 eta 0:05:39
epoch [126/200] batch [1/3] time 1.683 (1.683) data 0.261 (0.261) loss 0.1637 (0.1637) acc 96.8750 (96.8750) lr 6.3188e-04 eta 0:06:16
epoch [126/200] batch [2/3] time 1.419 (1.551) data 0.000 (0.131) loss 0.4019 (0.2828) acc 90.6250 (93.7500) lr 6.3188e-04 eta 0:05:45
epoch [126/200] batch [3/3] time 1.417 (1.506) data 0.000 (0.087) loss 0.2595 (0.2750) acc 90.6250 (92.7083) lr 6.1732e-04 eta 0:05:34
epoch [127/200] batch [1/3] time 1.670 (1.670) data 0.261 (0.261) loss 0.4302 (0.4302) acc 84.3750 (84.3750) lr 6.1732e-04 eta 0:06:08
epoch [127/200] batch [2/3] time 1.416 (1.543) data 0.000 (0.131) loss 0.5254 (0.4778) acc 84.3750 (84.3750) lr 6.1732e-04 eta 0:05:39
epoch [127/200] batch [3/3] time 1.416 (1.500) data 0.000 (0.087) loss 0.3184 (0.4246) acc 93.7500 (87.5000) lr 6.0285e-04 eta 0:05:28
epoch [128/200] batch [1/3] time 1.686 (1.686) data 0.266 (0.266) loss 0.1458 (0.1458) acc 96.8750 (96.8750) lr 6.0285e-04 eta 0:06:07
epoch [128/200] batch [2/3] time 1.420 (1.553) data 0.000 (0.133) loss 0.3481 (0.2469) acc 87.5000 (92.1875) lr 6.0285e-04 eta 0:05:37
epoch [128/200] batch [3/3] time 1.420 (1.509) data 0.000 (0.089) loss 0.2549 (0.2496) acc 90.6250 (91.6667) lr 5.8849e-04 eta 0:05:25
epoch [129/200] batch [1/3] time 1.685 (1.685) data 0.263 (0.263) loss 0.4465 (0.4465) acc 87.5000 (87.5000) lr 5.8849e-04 eta 0:06:02
epoch [129/200] batch [2/3] time 1.425 (1.555) data 0.000 (0.132) loss 0.3694 (0.4080) acc 93.7500 (90.6250) lr 5.8849e-04 eta 0:05:32
epoch [129/200] batch [3/3] time 1.422 (1.510) data 0.000 (0.088) loss 0.1964 (0.3374) acc 96.8750 (92.7083) lr 5.7422e-04 eta 0:05:21
epoch [130/200] batch [1/3] time 1.683 (1.683) data 0.259 (0.259) loss 0.0795 (0.0795) acc 100.0000 (100.0000) lr 5.7422e-04 eta 0:05:56
epoch [130/200] batch [2/3] time 1.418 (1.551) data 0.000 (0.130) loss 0.5024 (0.2910) acc 84.3750 (92.1875) lr 5.7422e-04 eta 0:05:27
epoch [130/200] batch [3/3] time 1.425 (1.509) data 0.000 (0.087) loss 0.3533 (0.3117) acc 93.7500 (92.7083) lr 5.6006e-04 eta 0:05:16
epoch [131/200] batch [1/3] time 1.677 (1.677) data 0.258 (0.258) loss 0.4512 (0.4512) acc 90.6250 (90.6250) lr 5.6006e-04 eta 0:05:50
epoch [131/200] batch [2/3] time 1.426 (1.552) data 0.000 (0.129) loss 0.2795 (0.3654) acc 93.7500 (92.1875) lr 5.6006e-04 eta 0:05:22
epoch [131/200] batch [3/3] time 1.414 (1.506) data 0.000 (0.086) loss 0.2454 (0.3254) acc 90.6250 (91.6667) lr 5.4601e-04 eta 0:05:11
epoch [132/200] batch [1/3] time 1.695 (1.695) data 0.277 (0.277) loss 0.1511 (0.1511) acc 96.8750 (96.8750) lr 5.4601e-04 eta 0:05:49
epoch [132/200] batch [2/3] time 1.423 (1.559) data 0.000 (0.138) loss 0.3835 (0.2673) acc 90.6250 (93.7500) lr 5.4601e-04 eta 0:05:19
epoch [132/200] batch [3/3] time 1.411 (1.510) data 0.000 (0.092) loss 0.1165 (0.2170) acc 96.8750 (94.7917) lr 5.3207e-04 eta 0:05:07
epoch [133/200] batch [1/3] time 1.678 (1.678) data 0.262 (0.262) loss 0.1376 (0.1376) acc 96.8750 (96.8750) lr 5.3207e-04 eta 0:05:40
epoch [133/200] batch [2/3] time 1.420 (1.549) data 0.000 (0.131) loss 0.2786 (0.2081) acc 93.7500 (95.3125) lr 5.3207e-04 eta 0:05:12
epoch [133/200] batch [3/3] time 1.417 (1.505) data 0.000 (0.087) loss 0.4050 (0.2737) acc 93.7500 (94.7917) lr 5.1825e-04 eta 0:05:02
epoch [134/200] batch [1/3] time 1.693 (1.693) data 0.270 (0.270) loss 0.1505 (0.1505) acc 96.8750 (96.8750) lr 5.1825e-04 eta 0:05:38
epoch [134/200] batch [2/3] time 1.414 (1.553) data 0.000 (0.135) loss 0.1277 (0.1391) acc 93.7500 (95.3125) lr 5.1825e-04 eta 0:05:09
epoch [134/200] batch [3/3] time 1.420 (1.509) data 0.000 (0.090) loss 0.2242 (0.1675) acc 96.8750 (95.8333) lr 5.0454e-04 eta 0:04:58
epoch [135/200] batch [1/3] time 1.676 (1.676) data 0.258 (0.258) loss 0.4087 (0.4087) acc 90.6250 (90.6250) lr 5.0454e-04 eta 0:05:30
epoch [135/200] batch [2/3] time 1.416 (1.546) data 0.000 (0.129) loss 0.2384 (0.3235) acc 96.8750 (93.7500) lr 5.0454e-04 eta 0:05:03
epoch [135/200] batch [3/3] time 1.420 (1.504) data 0.000 (0.086) loss 0.4561 (0.3677) acc 90.6250 (92.7083) lr 4.9096e-04 eta 0:04:53
epoch [136/200] batch [1/3] time 1.684 (1.684) data 0.260 (0.260) loss 0.2139 (0.2139) acc 96.8750 (96.8750) lr 4.9096e-04 eta 0:05:26
epoch [136/200] batch [2/3] time 1.415 (1.549) data 0.000 (0.130) loss 0.1602 (0.1870) acc 96.8750 (96.8750) lr 4.9096e-04 eta 0:04:58
epoch [136/200] batch [3/3] time 1.418 (1.505) data 0.000 (0.087) loss 0.5049 (0.2930) acc 87.5000 (93.7500) lr 4.7750e-04 eta 0:04:49
epoch [137/200] batch [1/3] time 1.682 (1.682) data 0.268 (0.268) loss 0.2581 (0.2581) acc 93.7500 (93.7500) lr 4.7750e-04 eta 0:05:21
epoch [137/200] batch [2/3] time 1.412 (1.547) data 0.000 (0.134) loss 0.1675 (0.2128) acc 96.8750 (95.3125) lr 4.7750e-04 eta 0:04:53
epoch [137/200] batch [3/3] time 1.421 (1.505) data 0.000 (0.089) loss 0.3940 (0.2732) acc 87.5000 (92.7083) lr 4.6417e-04 eta 0:04:44
epoch [138/200] batch [1/3] time 1.706 (1.706) data 0.285 (0.285) loss 0.3052 (0.3052) acc 87.5000 (87.5000) lr 4.6417e-04 eta 0:05:20
epoch [138/200] batch [2/3] time 1.419 (1.562) data 0.000 (0.143) loss 0.1022 (0.2037) acc 96.8750 (92.1875) lr 4.6417e-04 eta 0:04:52
epoch [138/200] batch [3/3] time 1.415 (1.513) data 0.000 (0.095) loss 0.6685 (0.3586) acc 81.2500 (88.5417) lr 4.5098e-04 eta 0:04:41
epoch [139/200] batch [1/3] time 1.676 (1.676) data 0.260 (0.260) loss 0.2749 (0.2749) acc 90.6250 (90.6250) lr 4.5098e-04 eta 0:05:10
epoch [139/200] batch [2/3] time 1.417 (1.547) data 0.000 (0.130) loss 0.3652 (0.3201) acc 87.5000 (89.0625) lr 4.5098e-04 eta 0:04:44
epoch [139/200] batch [3/3] time 1.420 (1.504) data 0.000 (0.087) loss 0.3525 (0.3309) acc 96.8750 (91.6667) lr 4.3792e-04 eta 0:04:35
epoch [140/200] batch [1/3] time 1.683 (1.683) data 0.276 (0.276) loss 0.3235 (0.3235) acc 90.6250 (90.6250) lr 4.3792e-04 eta 0:05:06
epoch [140/200] batch [2/3] time 1.413 (1.548) data 0.000 (0.138) loss 0.3269 (0.3252) acc 93.7500 (92.1875) lr 4.3792e-04 eta 0:04:40
epoch [140/200] batch [3/3] time 1.416 (1.504) data 0.000 (0.092) loss 0.3401 (0.3302) acc 93.7500 (92.7083) lr 4.2499e-04 eta 0:04:30
epoch [141/200] batch [1/3] time 1.678 (1.678) data 0.259 (0.259) loss 0.6489 (0.6489) acc 87.5000 (87.5000) lr 4.2499e-04 eta 0:05:00
epoch [141/200] batch [2/3] time 1.421 (1.549) data 0.000 (0.130) loss 0.4006 (0.5248) acc 90.6250 (89.0625) lr 4.2499e-04 eta 0:04:35
epoch [141/200] batch [3/3] time 1.412 (1.504) data 0.000 (0.087) loss 0.0622 (0.3706) acc 100.0000 (92.7083) lr 4.1221e-04 eta 0:04:26
epoch [142/200] batch [1/3] time 1.677 (1.677) data 0.260 (0.260) loss 0.4971 (0.4971) acc 90.6250 (90.6250) lr 4.1221e-04 eta 0:04:55
epoch [142/200] batch [2/3] time 1.416 (1.547) data 0.000 (0.130) loss 0.3098 (0.4034) acc 90.6250 (90.6250) lr 4.1221e-04 eta 0:04:30
epoch [142/200] batch [3/3] time 1.419 (1.504) data 0.000 (0.087) loss 0.2332 (0.3467) acc 93.7500 (91.6667) lr 3.9958e-04 eta 0:04:21
epoch [143/200] batch [1/3] time 1.689 (1.689) data 0.268 (0.268) loss 0.1497 (0.1497) acc 100.0000 (100.0000) lr 3.9958e-04 eta 0:04:52
epoch [143/200] batch [2/3] time 1.419 (1.554) data 0.000 (0.134) loss 0.1073 (0.1285) acc 100.0000 (100.0000) lr 3.9958e-04 eta 0:04:27
epoch [143/200] batch [3/3] time 1.426 (1.511) data 0.000 (0.089) loss 0.1089 (0.1220) acc 96.8750 (98.9583) lr 3.8709e-04 eta 0:04:18
epoch [144/200] batch [1/3] time 1.680 (1.680) data 0.259 (0.259) loss 0.2922 (0.2922) acc 96.8750 (96.8750) lr 3.8709e-04 eta 0:04:45
epoch [144/200] batch [2/3] time 1.429 (1.554) data 0.000 (0.130) loss 0.2893 (0.2908) acc 93.7500 (95.3125) lr 3.8709e-04 eta 0:04:22
epoch [144/200] batch [3/3] time 1.421 (1.510) data 0.000 (0.087) loss 0.1689 (0.2502) acc 96.8750 (95.8333) lr 3.7476e-04 eta 0:04:13
epoch [145/200] batch [1/3] time 1.675 (1.675) data 0.259 (0.259) loss 0.2529 (0.2529) acc 93.7500 (93.7500) lr 3.7476e-04 eta 0:04:39
epoch [145/200] batch [2/3] time 1.414 (1.545) data 0.000 (0.130) loss 0.4436 (0.3483) acc 90.6250 (92.1875) lr 3.7476e-04 eta 0:04:16
epoch [145/200] batch [3/3] time 1.425 (1.505) data 0.000 (0.086) loss 0.4167 (0.3711) acc 90.6250 (91.6667) lr 3.6258e-04 eta 0:04:08
epoch [146/200] batch [1/3] time 1.683 (1.683) data 0.258 (0.258) loss 0.0845 (0.0845) acc 100.0000 (100.0000) lr 3.6258e-04 eta 0:04:36
epoch [146/200] batch [2/3] time 1.414 (1.549) data 0.000 (0.129) loss 0.1187 (0.1016) acc 96.8750 (98.4375) lr 3.6258e-04 eta 0:04:12
epoch [146/200] batch [3/3] time 1.417 (1.505) data 0.000 (0.086) loss 0.7012 (0.3015) acc 84.3750 (93.7500) lr 3.5055e-04 eta 0:04:03
epoch [147/200] batch [1/3] time 1.684 (1.684) data 0.268 (0.268) loss 0.2142 (0.2142) acc 93.7500 (93.7500) lr 3.5055e-04 eta 0:04:31
epoch [147/200] batch [2/3] time 1.426 (1.555) data 0.000 (0.134) loss 0.5981 (0.4062) acc 90.6250 (92.1875) lr 3.5055e-04 eta 0:04:08
epoch [147/200] batch [3/3] time 1.421 (1.510) data 0.000 (0.089) loss 0.5010 (0.4378) acc 87.5000 (90.6250) lr 3.3869e-04 eta 0:04:00
epoch [148/200] batch [1/3] time 1.695 (1.695) data 0.269 (0.269) loss 0.4902 (0.4902) acc 87.5000 (87.5000) lr 3.3869e-04 eta 0:04:27
epoch [148/200] batch [2/3] time 1.417 (1.556) data 0.000 (0.134) loss 0.2578 (0.3740) acc 93.7500 (90.6250) lr 3.3869e-04 eta 0:04:04
epoch [148/200] batch [3/3] time 1.414 (1.509) data 0.000 (0.090) loss 0.4048 (0.3843) acc 90.6250 (90.6250) lr 3.2699e-04 eta 0:03:55
epoch [149/200] batch [1/3] time 1.695 (1.695) data 0.275 (0.275) loss 0.0751 (0.0751) acc 100.0000 (100.0000) lr 3.2699e-04 eta 0:04:22
epoch [149/200] batch [2/3] time 1.415 (1.555) data 0.000 (0.137) loss 0.3198 (0.1974) acc 93.7500 (96.8750) lr 3.2699e-04 eta 0:03:59
epoch [149/200] batch [3/3] time 1.410 (1.507) data 0.000 (0.092) loss 0.2832 (0.2260) acc 90.6250 (94.7917) lr 3.1545e-04 eta 0:03:50
epoch [150/200] batch [1/3] time 1.700 (1.700) data 0.277 (0.277) loss 0.1140 (0.1140) acc 100.0000 (100.0000) lr 3.1545e-04 eta 0:04:18
epoch [150/200] batch [2/3] time 1.422 (1.561) data 0.000 (0.139) loss 0.1763 (0.1451) acc 90.6250 (95.3125) lr 3.1545e-04 eta 0:03:55
epoch [150/200] batch [3/3] time 1.424 (1.515) data 0.000 (0.092) loss 0.4136 (0.2346) acc 84.3750 (91.6667) lr 3.0409e-04 eta 0:03:47
epoch [151/200] batch [1/3] time 1.699 (1.699) data 0.277 (0.277) loss 0.4971 (0.4971) acc 87.5000 (87.5000) lr 3.0409e-04 eta 0:04:13
epoch [151/200] batch [2/3] time 1.423 (1.561) data 0.000 (0.138) loss 0.3870 (0.4420) acc 87.5000 (87.5000) lr 3.0409e-04 eta 0:03:51
epoch [151/200] batch [3/3] time 1.422 (1.515) data 0.000 (0.092) loss 0.4307 (0.4382) acc 90.6250 (88.5417) lr 2.9289e-04 eta 0:03:42
epoch [152/200] batch [1/3] time 1.681 (1.681) data 0.263 (0.263) loss 0.0552 (0.0552) acc 96.8750 (96.8750) lr 2.9289e-04 eta 0:04:05
epoch [152/200] batch [2/3] time 1.417 (1.549) data 0.000 (0.132) loss 0.4827 (0.2690) acc 90.6250 (93.7500) lr 2.9289e-04 eta 0:03:44
epoch [152/200] batch [3/3] time 1.425 (1.508) data 0.000 (0.088) loss 0.4509 (0.3296) acc 90.6250 (92.7083) lr 2.8187e-04 eta 0:03:37
epoch [153/200] batch [1/3] time 1.677 (1.677) data 0.261 (0.261) loss 0.1747 (0.1747) acc 93.7500 (93.7500) lr 2.8187e-04 eta 0:03:59
epoch [153/200] batch [2/3] time 1.423 (1.550) data 0.000 (0.131) loss 0.1255 (0.1501) acc 100.0000 (96.8750) lr 2.8187e-04 eta 0:03:40
epoch [153/200] batch [3/3] time 1.422 (1.507) data 0.000 (0.087) loss 0.2671 (0.1891) acc 93.7500 (95.8333) lr 2.7103e-04 eta 0:03:32
epoch [154/200] batch [1/3] time 1.681 (1.681) data 0.261 (0.261) loss 0.4109 (0.4109) acc 93.7500 (93.7500) lr 2.7103e-04 eta 0:03:55
epoch [154/200] batch [2/3] time 1.421 (1.551) data 0.000 (0.130) loss 0.1561 (0.2835) acc 100.0000 (96.8750) lr 2.7103e-04 eta 0:03:35
epoch [154/200] batch [3/3] time 1.423 (1.508) data 0.000 (0.087) loss 0.3970 (0.3213) acc 90.6250 (94.7917) lr 2.6037e-04 eta 0:03:28
epoch [155/200] batch [1/3] time 1.680 (1.680) data 0.262 (0.262) loss 0.2717 (0.2717) acc 90.6250 (90.6250) lr 2.6037e-04 eta 0:03:50
epoch [155/200] batch [2/3] time 1.414 (1.547) data 0.000 (0.131) loss 0.7285 (0.5001) acc 84.3750 (87.5000) lr 2.6037e-04 eta 0:03:30
epoch [155/200] batch [3/3] time 1.417 (1.504) data 0.000 (0.087) loss 0.1917 (0.3973) acc 96.8750 (90.6250) lr 2.4989e-04 eta 0:03:23
epoch [156/200] batch [1/3] time 1.692 (1.692) data 0.262 (0.262) loss 0.1924 (0.1924) acc 96.8750 (96.8750) lr 2.4989e-04 eta 0:03:46
epoch [156/200] batch [2/3] time 1.429 (1.560) data 0.000 (0.131) loss 0.3584 (0.2754) acc 90.6250 (93.7500) lr 2.4989e-04 eta 0:03:27
epoch [156/200] batch [3/3] time 1.420 (1.513) data 0.000 (0.087) loss 0.3022 (0.2843) acc 87.5000 (91.6667) lr 2.3959e-04 eta 0:03:19
epoch [157/200] batch [1/3] time 1.694 (1.694) data 0.268 (0.268) loss 0.0851 (0.0851) acc 96.8750 (96.8750) lr 2.3959e-04 eta 0:03:41
epoch [157/200] batch [2/3] time 1.429 (1.562) data 0.000 (0.134) loss 0.0296 (0.0574) acc 100.0000 (98.4375) lr 2.3959e-04 eta 0:03:23
epoch [157/200] batch [3/3] time 1.425 (1.516) data 0.000 (0.090) loss 0.5825 (0.2324) acc 84.3750 (93.7500) lr 2.2949e-04 eta 0:03:15
epoch [158/200] batch [1/3] time 1.683 (1.683) data 0.259 (0.259) loss 0.5127 (0.5127) acc 90.6250 (90.6250) lr 2.2949e-04 eta 0:03:35
epoch [158/200] batch [2/3] time 1.425 (1.554) data 0.000 (0.130) loss 0.0741 (0.2934) acc 100.0000 (95.3125) lr 2.2949e-04 eta 0:03:17
epoch [158/200] batch [3/3] time 1.421 (1.510) data 0.000 (0.086) loss 0.5864 (0.3911) acc 84.3750 (91.6667) lr 2.1957e-04 eta 0:03:10
epoch [159/200] batch [1/3] time 1.699 (1.699) data 0.278 (0.278) loss 0.2842 (0.2842) acc 93.7500 (93.7500) lr 2.1957e-04 eta 0:03:32
epoch [159/200] batch [2/3] time 1.419 (1.559) data 0.000 (0.139) loss 0.2781 (0.2811) acc 96.8750 (95.3125) lr 2.1957e-04 eta 0:03:13
epoch [159/200] batch [3/3] time 1.419 (1.512) data 0.000 (0.093) loss 0.1659 (0.2427) acc 96.8750 (95.8333) lr 2.0984e-04 eta 0:03:05
epoch [160/200] batch [1/3] time 1.683 (1.683) data 0.263 (0.263) loss 0.3101 (0.3101) acc 90.6250 (90.6250) lr 2.0984e-04 eta 0:03:25
epoch [160/200] batch [2/3] time 1.418 (1.550) data 0.000 (0.132) loss 0.3010 (0.3055) acc 93.7500 (92.1875) lr 2.0984e-04 eta 0:03:07
epoch [160/200] batch [3/3] time 1.415 (1.505) data 0.000 (0.088) loss 0.3853 (0.3321) acc 90.6250 (91.6667) lr 2.0032e-04 eta 0:03:00
epoch [161/200] batch [1/3] time 1.706 (1.706) data 0.278 (0.278) loss 0.2175 (0.2175) acc 90.6250 (90.6250) lr 2.0032e-04 eta 0:03:23
epoch [161/200] batch [2/3] time 1.418 (1.562) data 0.000 (0.139) loss 0.1186 (0.1681) acc 93.7500 (92.1875) lr 2.0032e-04 eta 0:03:04
epoch [161/200] batch [3/3] time 1.461 (1.529) data 0.000 (0.093) loss 0.2277 (0.1879) acc 96.8750 (93.7500) lr 1.9098e-04 eta 0:02:58
epoch [162/200] batch [1/3] time 1.759 (1.759) data 0.289 (0.289) loss 0.3513 (0.3513) acc 93.7500 (93.7500) lr 1.9098e-04 eta 0:03:24
epoch [162/200] batch [2/3] time 1.471 (1.615) data 0.000 (0.145) loss 0.1069 (0.2291) acc 100.0000 (96.8750) lr 1.9098e-04 eta 0:03:05
epoch [162/200] batch [3/3] time 1.452 (1.561) data 0.000 (0.096) loss 0.1555 (0.2046) acc 96.8750 (96.8750) lr 1.8185e-04 eta 0:02:57
epoch [163/200] batch [1/3] time 1.702 (1.702) data 0.267 (0.267) loss 0.0814 (0.0814) acc 96.8750 (96.8750) lr 1.8185e-04 eta 0:03:12
epoch [163/200] batch [2/3] time 1.435 (1.569) data 0.000 (0.134) loss 0.2267 (0.1541) acc 96.8750 (96.8750) lr 1.8185e-04 eta 0:02:55
epoch [163/200] batch [3/3] time 1.438 (1.525) data 0.000 (0.089) loss 0.1871 (0.1651) acc 90.6250 (94.7917) lr 1.7292e-04 eta 0:02:49
epoch [164/200] batch [1/3] time 1.709 (1.709) data 0.275 (0.275) loss 0.1338 (0.1338) acc 96.8750 (96.8750) lr 1.7292e-04 eta 0:03:08
epoch [164/200] batch [2/3] time 1.437 (1.573) data 0.000 (0.137) loss 0.1876 (0.1607) acc 90.6250 (93.7500) lr 1.7292e-04 eta 0:02:51
epoch [164/200] batch [3/3] time 1.438 (1.528) data 0.000 (0.092) loss 0.2832 (0.2015) acc 93.7500 (93.7500) lr 1.6419e-04 eta 0:02:45
epoch [165/200] batch [1/3] time 1.705 (1.705) data 0.277 (0.277) loss 0.5449 (0.5449) acc 84.3750 (84.3750) lr 1.6419e-04 eta 0:03:02
epoch [165/200] batch [2/3] time 1.417 (1.561) data 0.000 (0.139) loss 0.3618 (0.4534) acc 93.7500 (89.0625) lr 1.6419e-04 eta 0:02:45
epoch [165/200] batch [3/3] time 1.422 (1.515) data 0.000 (0.093) loss 0.6035 (0.5034) acc 87.5000 (88.5417) lr 1.5567e-04 eta 0:02:39
epoch [166/200] batch [1/3] time 1.679 (1.679) data 0.261 (0.261) loss 0.4143 (0.4143) acc 93.7500 (93.7500) lr 1.5567e-04 eta 0:02:54
epoch [166/200] batch [2/3] time 1.429 (1.554) data 0.000 (0.130) loss 0.2507 (0.3325) acc 96.8750 (95.3125) lr 1.5567e-04 eta 0:02:40
epoch [166/200] batch [3/3] time 1.423 (1.510) data 0.000 (0.087) loss 0.3994 (0.3548) acc 87.5000 (92.7083) lr 1.4736e-04 eta 0:02:34
epoch [167/200] batch [1/3] time 1.679 (1.679) data 0.259 (0.259) loss 0.4392 (0.4392) acc 87.5000 (87.5000) lr 1.4736e-04 eta 0:02:49
epoch [167/200] batch [2/3] time 1.423 (1.551) data 0.000 (0.129) loss 0.2324 (0.3358) acc 93.7500 (90.6250) lr 1.4736e-04 eta 0:02:35
epoch [167/200] batch [3/3] time 1.421 (1.507) data 0.000 (0.086) loss 0.2496 (0.3071) acc 93.7500 (91.6667) lr 1.3926e-04 eta 0:02:29
epoch [168/200] batch [1/3] time 1.681 (1.681) data 0.261 (0.261) loss 0.3860 (0.3860) acc 90.6250 (90.6250) lr 1.3926e-04 eta 0:02:44
epoch [168/200] batch [2/3] time 1.421 (1.551) data 0.000 (0.130) loss 0.1709 (0.2784) acc 93.7500 (92.1875) lr 1.3926e-04 eta 0:02:30
epoch [168/200] batch [3/3] time 1.424 (1.509) data 0.000 (0.087) loss 0.3831 (0.3133) acc 87.5000 (90.6250) lr 1.3137e-04 eta 0:02:24
epoch [169/200] batch [1/3] time 1.701 (1.701) data 0.279 (0.279) loss 0.2515 (0.2515) acc 96.8750 (96.8750) lr 1.3137e-04 eta 0:02:41
epoch [169/200] batch [2/3] time 1.418 (1.560) data 0.000 (0.140) loss 0.1792 (0.2153) acc 93.7500 (95.3125) lr 1.3137e-04 eta 0:02:26
epoch [169/200] batch [3/3] time 1.418 (1.512) data 0.000 (0.093) loss 0.2247 (0.2185) acc 93.7500 (94.7917) lr 1.2369e-04 eta 0:02:20
epoch [170/200] batch [1/3] time 1.680 (1.680) data 0.262 (0.262) loss 0.5952 (0.5952) acc 81.2500 (81.2500) lr 1.2369e-04 eta 0:02:34
epoch [170/200] batch [2/3] time 1.415 (1.547) data 0.000 (0.131) loss 0.3621 (0.4786) acc 90.6250 (85.9375) lr 1.2369e-04 eta 0:02:20
epoch [170/200] batch [3/3] time 1.420 (1.505) data 0.000 (0.087) loss 0.2327 (0.3966) acc 93.7500 (88.5417) lr 1.1623e-04 eta 0:02:15
epoch [171/200] batch [1/3] time 1.706 (1.706) data 0.278 (0.278) loss 0.3821 (0.3821) acc 87.5000 (87.5000) lr 1.1623e-04 eta 0:02:31
epoch [171/200] batch [2/3] time 1.423 (1.564) data 0.000 (0.139) loss 0.6206 (0.5013) acc 84.3750 (85.9375) lr 1.1623e-04 eta 0:02:17
epoch [171/200] batch [3/3] time 1.425 (1.518) data 0.000 (0.093) loss 0.1154 (0.3727) acc 96.8750 (89.5833) lr 1.0899e-04 eta 0:02:12
epoch [172/200] batch [1/3] time 1.671 (1.671) data 0.263 (0.263) loss 0.4360 (0.4360) acc 90.6250 (90.6250) lr 1.0899e-04 eta 0:02:23
epoch [172/200] batch [2/3] time 1.418 (1.545) data 0.000 (0.132) loss 0.3503 (0.3932) acc 90.6250 (90.6250) lr 1.0899e-04 eta 0:02:11
epoch [172/200] batch [3/3] time 1.425 (1.505) data 0.000 (0.088) loss 0.3557 (0.3807) acc 87.5000 (89.5833) lr 1.0197e-04 eta 0:02:06
epoch [173/200] batch [1/3] time 1.675 (1.675) data 0.262 (0.262) loss 0.2612 (0.2612) acc 93.7500 (93.7500) lr 1.0197e-04 eta 0:02:19
epoch [173/200] batch [2/3] time 1.423 (1.549) data 0.000 (0.131) loss 0.3665 (0.3138) acc 90.6250 (92.1875) lr 1.0197e-04 eta 0:02:07
epoch [173/200] batch [3/3] time 1.416 (1.505) data 0.000 (0.088) loss 0.2991 (0.3089) acc 96.8750 (93.7500) lr 9.5173e-05 eta 0:02:01
epoch [174/200] batch [1/3] time 1.686 (1.686) data 0.263 (0.263) loss 0.2432 (0.2432) acc 96.8750 (96.8750) lr 9.5173e-05 eta 0:02:14
epoch [174/200] batch [2/3] time 1.423 (1.554) data 0.000 (0.131) loss 0.4167 (0.3300) acc 87.5000 (92.1875) lr 9.5173e-05 eta 0:02:02
epoch [174/200] batch [3/3] time 1.417 (1.509) data 0.000 (0.088) loss 0.2817 (0.3139) acc 93.7500 (92.7083) lr 8.8597e-05 eta 0:01:57
epoch [175/200] batch [1/3] time 1.691 (1.691) data 0.270 (0.270) loss 0.2498 (0.2498) acc 93.7500 (93.7500) lr 8.8597e-05 eta 0:02:10
epoch [175/200] batch [2/3] time 1.420 (1.556) data 0.000 (0.135) loss 0.1881 (0.2189) acc 96.8750 (95.3125) lr 8.8597e-05 eta 0:01:58
epoch [175/200] batch [3/3] time 1.420 (1.511) data 0.000 (0.090) loss 0.0981 (0.1786) acc 100.0000 (96.8750) lr 8.2245e-05 eta 0:01:53
epoch [176/200] batch [1/3] time 1.683 (1.683) data 0.269 (0.269) loss 0.2084 (0.2084) acc 93.7500 (93.7500) lr 8.2245e-05 eta 0:02:04
epoch [176/200] batch [2/3] time 1.429 (1.556) data 0.000 (0.135) loss 0.2058 (0.2071) acc 96.8750 (95.3125) lr 8.2245e-05 eta 0:01:53
epoch [176/200] batch [3/3] time 1.420 (1.511) data 0.000 (0.090) loss 0.6030 (0.3391) acc 84.3750 (91.6667) lr 7.6120e-05 eta 0:01:48
epoch [177/200] batch [1/3] time 1.676 (1.676) data 0.259 (0.259) loss 0.4023 (0.4023) acc 87.5000 (87.5000) lr 7.6120e-05 eta 0:01:59
epoch [177/200] batch [2/3] time 1.421 (1.549) data 0.000 (0.129) loss 0.2440 (0.3232) acc 96.8750 (92.1875) lr 7.6120e-05 eta 0:01:48
epoch [177/200] batch [3/3] time 1.425 (1.508) data 0.000 (0.086) loss 0.0409 (0.2291) acc 100.0000 (94.7917) lr 7.0224e-05 eta 0:01:44
epoch [178/200] batch [1/3] time 1.667 (1.667) data 0.261 (0.261) loss 0.4258 (0.4258) acc 87.5000 (87.5000) lr 7.0224e-05 eta 0:01:53
epoch [178/200] batch [2/3] time 1.413 (1.540) data 0.000 (0.131) loss 0.2406 (0.3332) acc 96.8750 (92.1875) lr 7.0224e-05 eta 0:01:43
epoch [178/200] batch [3/3] time 1.421 (1.500) data 0.000 (0.087) loss 0.3948 (0.3537) acc 90.6250 (91.6667) lr 6.4556e-05 eta 0:01:39
epoch [179/200] batch [1/3] time 1.677 (1.677) data 0.261 (0.261) loss 0.3491 (0.3491) acc 90.6250 (90.6250) lr 6.4556e-05 eta 0:01:48
epoch [179/200] batch [2/3] time 1.424 (1.550) data 0.000 (0.131) loss 0.1802 (0.2646) acc 96.8750 (93.7500) lr 6.4556e-05 eta 0:01:39
epoch [179/200] batch [3/3] time 1.425 (1.509) data 0.000 (0.087) loss 0.2898 (0.2730) acc 93.7500 (93.7500) lr 5.9119e-05 eta 0:01:35
epoch [180/200] batch [1/3] time 1.694 (1.694) data 0.270 (0.270) loss 0.3838 (0.3838) acc 90.6250 (90.6250) lr 5.9119e-05 eta 0:01:45
epoch [180/200] batch [2/3] time 1.423 (1.558) data 0.000 (0.135) loss 0.1603 (0.2720) acc 93.7500 (92.1875) lr 5.9119e-05 eta 0:01:35
epoch [180/200] batch [3/3] time 1.411 (1.509) data 0.000 (0.090) loss 0.2632 (0.2691) acc 96.8750 (93.7500) lr 5.3915e-05 eta 0:01:30
epoch [181/200] batch [1/3] time 1.699 (1.699) data 0.277 (0.277) loss 0.1882 (0.1882) acc 93.7500 (93.7500) lr 5.3915e-05 eta 0:01:40
epoch [181/200] batch [2/3] time 1.428 (1.563) data 0.000 (0.139) loss 0.3230 (0.2556) acc 90.6250 (92.1875) lr 5.3915e-05 eta 0:01:30
epoch [181/200] batch [3/3] time 1.423 (1.516) data 0.000 (0.092) loss 0.1890 (0.2334) acc 100.0000 (94.7917) lr 4.8943e-05 eta 0:01:26
epoch [182/200] batch [1/3] time 1.690 (1.690) data 0.269 (0.269) loss 0.2377 (0.2377) acc 96.8750 (96.8750) lr 4.8943e-05 eta 0:01:34
epoch [182/200] batch [2/3] time 1.408 (1.549) data 0.000 (0.134) loss 0.3232 (0.2805) acc 93.7500 (95.3125) lr 4.8943e-05 eta 0:01:25
epoch [182/200] batch [3/3] time 1.422 (1.507) data 0.000 (0.090) loss 0.4053 (0.3221) acc 87.5000 (92.7083) lr 4.4207e-05 eta 0:01:21
epoch [183/200] batch [1/3] time 1.691 (1.691) data 0.276 (0.276) loss 0.1909 (0.1909) acc 96.8750 (96.8750) lr 4.4207e-05 eta 0:01:29
epoch [183/200] batch [2/3] time 1.418 (1.554) data 0.000 (0.138) loss 0.3005 (0.2457) acc 93.7500 (95.3125) lr 4.4207e-05 eta 0:01:20
epoch [183/200] batch [3/3] time 1.419 (1.509) data 0.000 (0.092) loss 0.1324 (0.2080) acc 96.8750 (95.8333) lr 3.9706e-05 eta 0:01:16
epoch [184/200] batch [1/3] time 1.682 (1.682) data 0.268 (0.268) loss 0.0579 (0.0579) acc 100.0000 (100.0000) lr 3.9706e-05 eta 0:01:24
epoch [184/200] batch [2/3] time 1.420 (1.551) data 0.000 (0.134) loss 0.5146 (0.2863) acc 87.5000 (93.7500) lr 3.9706e-05 eta 0:01:15
epoch [184/200] batch [3/3] time 1.414 (1.505) data 0.000 (0.089) loss 0.2710 (0.2812) acc 93.7500 (93.7500) lr 3.5443e-05 eta 0:01:12
epoch [185/200] batch [1/3] time 1.700 (1.700) data 0.278 (0.278) loss 0.3552 (0.3552) acc 90.6250 (90.6250) lr 3.5443e-05 eta 0:01:19
epoch [185/200] batch [2/3] time 1.420 (1.560) data 0.000 (0.139) loss 0.3928 (0.3740) acc 90.6250 (90.6250) lr 3.5443e-05 eta 0:01:11
epoch [185/200] batch [3/3] time 1.419 (1.513) data 0.000 (0.093) loss 0.3628 (0.3703) acc 93.7500 (91.6667) lr 3.1417e-05 eta 0:01:08
epoch [186/200] batch [1/3] time 1.684 (1.684) data 0.261 (0.261) loss 0.2952 (0.2952) acc 90.6250 (90.6250) lr 3.1417e-05 eta 0:01:14
epoch [186/200] batch [2/3] time 1.422 (1.553) data 0.000 (0.130) loss 0.1331 (0.2141) acc 93.7500 (92.1875) lr 3.1417e-05 eta 0:01:06
epoch [186/200] batch [3/3] time 1.415 (1.507) data 0.000 (0.087) loss 0.2489 (0.2257) acc 93.7500 (92.7083) lr 2.7630e-05 eta 0:01:03
epoch [187/200] batch [1/3] time 1.671 (1.671) data 0.260 (0.260) loss 0.3459 (0.3459) acc 87.5000 (87.5000) lr 2.7630e-05 eta 0:01:08
epoch [187/200] batch [2/3] time 1.416 (1.544) data 0.000 (0.130) loss 0.2617 (0.3038) acc 93.7500 (90.6250) lr 2.7630e-05 eta 0:01:01
epoch [187/200] batch [3/3] time 1.420 (1.502) data 0.000 (0.087) loss 0.1040 (0.2372) acc 100.0000 (93.7500) lr 2.4083e-05 eta 0:00:58
epoch [188/200] batch [1/3] time 1.680 (1.680) data 0.259 (0.259) loss 0.5635 (0.5635) acc 87.5000 (87.5000) lr 2.4083e-05 eta 0:01:03
epoch [188/200] batch [2/3] time 1.421 (1.550) data 0.000 (0.129) loss 0.3616 (0.4625) acc 93.7500 (90.6250) lr 2.4083e-05 eta 0:00:57
epoch [188/200] batch [3/3] time 1.416 (1.506) data 0.000 (0.086) loss 0.4465 (0.4572) acc 93.7500 (91.6667) lr 2.0777e-05 eta 0:00:54
epoch [189/200] batch [1/3] time 1.681 (1.681) data 0.261 (0.261) loss 0.3020 (0.3020) acc 93.7500 (93.7500) lr 2.0777e-05 eta 0:00:58
epoch [189/200] batch [2/3] time 1.420 (1.551) data 0.000 (0.130) loss 0.2338 (0.2679) acc 90.6250 (92.1875) lr 2.0777e-05 eta 0:00:52
epoch [189/200] batch [3/3] time 1.420 (1.507) data 0.000 (0.087) loss 0.4771 (0.3376) acc 90.6250 (91.6667) lr 1.7713e-05 eta 0:00:49
epoch [190/200] batch [1/3] time 1.672 (1.672) data 0.259 (0.259) loss 0.5161 (0.5161) acc 84.3750 (84.3750) lr 1.7713e-05 eta 0:00:53
epoch [190/200] batch [2/3] time 1.425 (1.548) data 0.000 (0.129) loss 0.1844 (0.3503) acc 93.7500 (89.0625) lr 1.7713e-05 eta 0:00:47
epoch [190/200] batch [3/3] time 1.422 (1.506) data 0.000 (0.086) loss 0.1881 (0.2962) acc 93.7500 (90.6250) lr 1.4891e-05 eta 0:00:45
epoch [191/200] batch [1/3] time 1.678 (1.678) data 0.260 (0.260) loss 0.3745 (0.3745) acc 87.5000 (87.5000) lr 1.4891e-05 eta 0:00:48
epoch [191/200] batch [2/3] time 1.420 (1.549) data 0.000 (0.130) loss 0.1471 (0.2608) acc 100.0000 (93.7500) lr 1.4891e-05 eta 0:00:43
epoch [191/200] batch [3/3] time 1.417 (1.505) data 0.000 (0.087) loss 0.3323 (0.2846) acc 96.8750 (94.7917) lr 1.2312e-05 eta 0:00:40
epoch [192/200] batch [1/3] time 1.676 (1.676) data 0.259 (0.259) loss 0.5215 (0.5215) acc 90.6250 (90.6250) lr 1.2312e-05 eta 0:00:43
epoch [192/200] batch [2/3] time 1.420 (1.548) data 0.000 (0.130) loss 0.4749 (0.4982) acc 87.5000 (89.0625) lr 1.2312e-05 eta 0:00:38
epoch [192/200] batch [3/3] time 1.425 (1.507) data 0.000 (0.086) loss 0.4597 (0.4854) acc 90.6250 (89.5833) lr 9.9763e-06 eta 0:00:36
epoch [193/200] batch [1/3] time 1.683 (1.683) data 0.260 (0.260) loss 0.3208 (0.3208) acc 93.7500 (93.7500) lr 9.9763e-06 eta 0:00:38
epoch [193/200] batch [2/3] time 1.412 (1.547) data 0.000 (0.130) loss 0.6226 (0.4717) acc 84.3750 (89.0625) lr 9.9763e-06 eta 0:00:34
epoch [193/200] batch [3/3] time 1.413 (1.503) data 0.000 (0.087) loss 0.4758 (0.4731) acc 84.3750 (87.5000) lr 7.8853e-06 eta 0:00:31
epoch [194/200] batch [1/3] time 1.685 (1.685) data 0.263 (0.263) loss 0.2803 (0.2803) acc 93.7500 (93.7500) lr 7.8853e-06 eta 0:00:33
epoch [194/200] batch [2/3] time 1.414 (1.549) data 0.000 (0.132) loss 0.1343 (0.2073) acc 96.8750 (95.3125) lr 7.8853e-06 eta 0:00:29
epoch [194/200] batch [3/3] time 1.419 (1.506) data 0.000 (0.088) loss 0.2290 (0.2145) acc 90.6250 (93.7500) lr 6.0390e-06 eta 0:00:27
epoch [195/200] batch [1/3] time 1.693 (1.693) data 0.276 (0.276) loss 0.3936 (0.3936) acc 90.6250 (90.6250) lr 6.0390e-06 eta 0:00:28
epoch [195/200] batch [2/3] time 1.421 (1.557) data 0.000 (0.138) loss 0.4380 (0.4158) acc 90.6250 (90.6250) lr 6.0390e-06 eta 0:00:24
epoch [195/200] batch [3/3] time 1.412 (1.509) data 0.000 (0.092) loss 0.3589 (0.3968) acc 93.7500 (91.6667) lr 4.4380e-06 eta 0:00:22
epoch [196/200] batch [1/3] time 1.686 (1.686) data 0.262 (0.262) loss 0.0885 (0.0885) acc 96.8750 (96.8750) lr 4.4380e-06 eta 0:00:23
epoch [196/200] batch [2/3] time 1.421 (1.554) data 0.000 (0.131) loss 0.1035 (0.0960) acc 100.0000 (98.4375) lr 4.4380e-06 eta 0:00:20
epoch [196/200] batch [3/3] time 1.425 (1.511) data 0.000 (0.087) loss 0.2810 (0.1577) acc 93.7500 (96.8750) lr 3.0827e-06 eta 0:00:18
epoch [197/200] batch [1/3] time 1.676 (1.676) data 0.262 (0.262) loss 0.1232 (0.1232) acc 96.8750 (96.8750) lr 3.0827e-06 eta 0:00:18
epoch [197/200] batch [2/3] time 1.423 (1.549) data 0.000 (0.131) loss 0.1030 (0.1131) acc 100.0000 (98.4375) lr 3.0827e-06 eta 0:00:15
epoch [197/200] batch [3/3] time 1.417 (1.505) data 0.000 (0.087) loss 0.4402 (0.2221) acc 84.3750 (93.7500) lr 1.9733e-06 eta 0:00:13
epoch [198/200] batch [1/3] time 1.690 (1.690) data 0.271 (0.271) loss 0.1636 (0.1636) acc 93.7500 (93.7500) lr 1.9733e-06 eta 0:00:13
epoch [198/200] batch [2/3] time 1.415 (1.553) data 0.000 (0.135) loss 0.2451 (0.2043) acc 93.7500 (93.7500) lr 1.9733e-06 eta 0:00:10
epoch [198/200] batch [3/3] time 1.417 (1.507) data 0.000 (0.090) loss 0.4768 (0.2952) acc 87.5000 (91.6667) lr 1.1101e-06 eta 0:00:09
epoch [199/200] batch [1/3] time 1.688 (1.688) data 0.269 (0.269) loss 0.1329 (0.1329) acc 96.8750 (96.8750) lr 1.1101e-06 eta 0:00:08
epoch [199/200] batch [2/3] time 1.421 (1.554) data 0.000 (0.135) loss 0.2318 (0.1824) acc 93.7500 (95.3125) lr 1.1101e-06 eta 0:00:06
epoch [199/200] batch [3/3] time 1.423 (1.510) data 0.000 (0.090) loss 0.1508 (0.1718) acc 96.8750 (95.8333) lr 4.9344e-07 eta 0:00:04
epoch [200/200] batch [1/3] time 1.688 (1.688) data 0.269 (0.269) loss 0.4509 (0.4509) acc 87.5000 (87.5000) lr 4.9344e-07 eta 0:00:03
epoch [200/200] batch [2/3] time 1.414 (1.551) data 0.000 (0.135) loss 0.0459 (0.2484) acc 100.0000 (93.7500) lr 4.9344e-07 eta 0:00:01
epoch [200/200] batch [3/3] time 1.422 (1.508) data 0.000 (0.090) loss 0.2522 (0.2497) acc 93.7500 (93.7500) lr 1.2337e-07 eta 0:00:00
Checkpoint saved to output/Caltech/1/2/prompt_learner/model.pth.tar-200
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
=> result
* total: 2,465
* correct: 2,224
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 86.1%
Elapsed: 0:17:47
args2: backbone=, config_file=configs/trainers/CoOp/vit_b16.yaml, dataset_config_file=configs/datasets/caltech101.yaml, eval_only=False, head=, load_epoch=None, model_dir=, no_train=False,  opts: ['TRAINER.COOP.N_CTX', '16', 'TRAINER.COOP.CSC', 'False', 'TRAINER.COOP.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '1'], output_dir=output/Caltech/1/2/3, resume=, root=/home/brandnerkasper/Uni/MP/MP_CustomCoOp/data, seed=3, source_domains=None, target_domains=None, trainer=CoOp, transforms=None
Setting fixed seed: 3
***************
** Arguments **
***************
config_file: configs/trainers/CoOp/vit_b16.yaml
csc: False
ctp: end
dataset_config_file: configs/datasets/caltech101.yaml
n_ctx: 16
opts: ['TRAINER.COOP.N_CTX', '16', 'TRAINER.COOP.CSC', 'False', 'TRAINER.COOP.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '1']
output_dir: output/Caltech/1/2/3
root: /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data
seed: 3
shots: 1
trainer: CoOp
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 4
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 1
  ROOT: /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/Caltech/1/2/3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 2.0.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 22.04.3 LTS (x86_64)
GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.35

Python version: 3.10.12 (main, Jul  5 2023, 18:54:27) [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-6.2.0-32-generic-x86_64-with-glibc2.35
Is CUDA available: True
CUDA runtime version: 11.5.119
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce GTX 970
Nvidia driver version: 525.125.06
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                       x86_64
CPU op-mode(s):                     32-bit, 64-bit
Address sizes:                      39 bits physical, 48 bits virtual
Byte Order:                         Little Endian
CPU(s):                             4
On-line CPU(s) list:                0-3
Vendor ID:                          GenuineIntel
Model name:                         Intel(R) Xeon(R) CPU E3-1225 v3 @ 3.20GHz
CPU family:                         6
Model:                              60
Thread(s) per core:                 1
Core(s) per socket:                 4
Socket(s):                          1
Stepping:                           3
CPU max MHz:                        3600,0000
CPU min MHz:                        800,0000
BogoMIPS:                           6397.95
Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt dtherm ida arat pln pts md_clear flush_l1d
Virtualization:                     VT-x
L1d cache:                          128 KiB (4 instances)
L1i cache:                          128 KiB (4 instances)
L2 cache:                           1 MiB (4 instances)
L3 cache:                           8 MiB (1 instance)
NUMA node(s):                       1
NUMA node0 CPU(s):                  0-3
Vulnerability Gather data sampling: Not affected
Vulnerability Itlb multihit:        KVM: Mitigation: VMX disabled
Vulnerability L1tf:                 Mitigation; PTE Inversion; VMX conditional cache flushes, SMT disabled
Vulnerability Mds:                  Mitigation; Clear CPU buffers; SMT disabled
Vulnerability Meltdown:             Mitigation; PTI
Vulnerability Mmio stale data:      Unknown: No mitigations
Vulnerability Retbleed:             Not affected
Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl
Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:           Mitigation; Retpolines, IBPB conditional, IBRS_FW, STIBP disabled, RSB filling, PBRSB-eIBRS Not affected
Vulnerability Srbds:                Mitigation; Microcode
Vulnerability Tsx async abort:      Not affected

Versions of relevant libraries:
[pip3] numpy==1.25.2
[pip3] open-clip-torch==2.20.0
[pip3] torch==2.0.1
[pip3] torchaudio==2.0.2
[pip3] torchvision==0.15.2
[conda] blas                      1.0                         mkl  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] mkl                       2023.1.0         h213fc3f_46343  
[conda] mkl-service               2.4.0           py310h5eee18b_1  
[conda] mkl_fft                   1.3.6           py310h1128e8f_1  
[conda] mkl_random                1.2.2           py310h1128e8f_1  
[conda] numpy                     1.25.2          py310h5f9d8c6_0  
[conda] numpy-base                1.25.2          py310hb5e798b_0  
[conda] open-clip-torch           2.20.0                   pypi_0    pypi
[conda] pytorch                   2.0.1           py3.10_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchaudio                2.0.2               py310_cu117    pytorch
[conda] torchtriton               2.0.0                     py310    pytorch
[conda] torchvision               0.15.2              py310_cu117    pytorch
        Pillow (9.4.0)

Loading trainer: CoOp
Loading dataset: Caltech101
Reading split from /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data/caltech-101/split_fewshot/shot_1-seed_3.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  100
# train_x  100
# val      100
# test     2,465
---------  ----------
Loading CLIP (backbone: ViT-B/16)
CLIP(
  (visual): VisionTransformer(
    (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (transformer): Transformer(
    (resblocks): Sequential(
      (0): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (6): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (7): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (8): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (9): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (10): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (11): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (token_embedding): Embedding(49408, 512)
  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
)
Building custom CLIP
Initializing a generic context
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Turning off gradients in both the image and the text encoder
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/Caltech/1/2/3/tensorboard)
epoch [1/200] batch [1/3] time 1.744 (1.744) data 0.290 (0.290) loss 2.0078 (2.0078) acc 65.6250 (65.6250) lr 1.0000e-05 eta 0:17:24
epoch [1/200] batch [2/3] time 1.426 (1.585) data 0.000 (0.145) loss 1.9160 (1.9619) acc 53.1250 (59.3750) lr 1.0000e-05 eta 0:15:47
epoch [1/200] batch [3/3] time 1.426 (1.532) data 0.000 (0.097) loss 2.3223 (2.0820) acc 59.3750 (59.3750) lr 2.0000e-03 eta 0:15:14
epoch [2/200] batch [1/3] time 1.707 (1.707) data 0.293 (0.293) loss 1.8389 (1.8389) acc 53.1250 (53.1250) lr 2.0000e-03 eta 0:16:57
epoch [2/200] batch [2/3] time 1.422 (1.564) data 0.000 (0.146) loss 0.8096 (1.3242) acc 68.7500 (60.9375) lr 2.0000e-03 eta 0:15:30
epoch [2/200] batch [3/3] time 1.415 (1.515) data 0.000 (0.098) loss 0.6514 (1.0999) acc 81.2500 (67.7083) lr 1.9999e-03 eta 0:14:59
epoch [3/200] batch [1/3] time 1.707 (1.707) data 0.283 (0.283) loss 0.5625 (0.5625) acc 87.5000 (87.5000) lr 1.9999e-03 eta 0:16:51
epoch [3/200] batch [2/3] time 1.416 (1.561) data 0.000 (0.142) loss 1.0176 (0.7900) acc 75.0000 (81.2500) lr 1.9999e-03 eta 0:15:24
epoch [3/200] batch [3/3] time 1.420 (1.514) data 0.000 (0.094) loss 1.0830 (0.8877) acc 75.0000 (79.1667) lr 1.9995e-03 eta 0:14:55
epoch [4/200] batch [1/3] time 1.705 (1.705) data 0.284 (0.284) loss 1.0654 (1.0654) acc 71.8750 (71.8750) lr 1.9995e-03 eta 0:16:46
epoch [4/200] batch [2/3] time 1.427 (1.566) data 0.000 (0.142) loss 0.9253 (0.9954) acc 81.2500 (76.5625) lr 1.9995e-03 eta 0:15:22
epoch [4/200] batch [3/3] time 1.426 (1.519) data 0.000 (0.095) loss 1.0576 (1.0161) acc 68.7500 (73.9583) lr 1.9989e-03 eta 0:14:53
epoch [5/200] batch [1/3] time 1.707 (1.707) data 0.277 (0.277) loss 0.4636 (0.4636) acc 87.5000 (87.5000) lr 1.9989e-03 eta 0:16:41
epoch [5/200] batch [2/3] time 1.426 (1.566) data 0.000 (0.138) loss 0.8296 (0.6466) acc 71.8750 (79.6875) lr 1.9989e-03 eta 0:15:17
epoch [5/200] batch [3/3] time 1.426 (1.520) data 0.000 (0.092) loss 0.4648 (0.5860) acc 84.3750 (81.2500) lr 1.9980e-03 eta 0:14:48
epoch [6/200] batch [1/3] time 1.697 (1.697) data 0.275 (0.275) loss 0.8281 (0.8281) acc 75.0000 (75.0000) lr 1.9980e-03 eta 0:16:31
epoch [6/200] batch [2/3] time 1.425 (1.561) data 0.000 (0.137) loss 0.6616 (0.7449) acc 75.0000 (75.0000) lr 1.9980e-03 eta 0:15:10
epoch [6/200] batch [3/3] time 1.421 (1.514) data 0.000 (0.092) loss 0.4441 (0.6446) acc 84.3750 (78.1250) lr 1.9969e-03 eta 0:14:41
epoch [7/200] batch [1/3] time 1.701 (1.701) data 0.283 (0.283) loss 0.6274 (0.6274) acc 78.1250 (78.1250) lr 1.9969e-03 eta 0:16:28
epoch [7/200] batch [2/3] time 1.425 (1.563) data 0.000 (0.141) loss 0.6118 (0.6196) acc 81.2500 (79.6875) lr 1.9969e-03 eta 0:15:06
epoch [7/200] batch [3/3] time 1.430 (1.519) data 0.000 (0.094) loss 0.9463 (0.7285) acc 75.0000 (78.1250) lr 1.9956e-03 eta 0:14:39
epoch [8/200] batch [1/3] time 1.700 (1.700) data 0.284 (0.284) loss 0.4324 (0.4324) acc 90.6250 (90.6250) lr 1.9956e-03 eta 0:16:22
epoch [8/200] batch [2/3] time 1.422 (1.561) data 0.000 (0.142) loss 0.6538 (0.5431) acc 78.1250 (84.3750) lr 1.9956e-03 eta 0:15:00
epoch [8/200] batch [3/3] time 1.421 (1.515) data 0.000 (0.095) loss 0.6904 (0.5922) acc 84.3750 (84.3750) lr 1.9940e-03 eta 0:14:32
epoch [9/200] batch [1/3] time 1.699 (1.699) data 0.279 (0.279) loss 0.4407 (0.4407) acc 87.5000 (87.5000) lr 1.9940e-03 eta 0:16:16
epoch [9/200] batch [2/3] time 1.424 (1.561) data 0.000 (0.140) loss 0.4060 (0.4233) acc 84.3750 (85.9375) lr 1.9940e-03 eta 0:14:56
epoch [9/200] batch [3/3] time 1.423 (1.515) data 0.000 (0.093) loss 0.7246 (0.5238) acc 84.3750 (85.4167) lr 1.9921e-03 eta 0:14:28
epoch [10/200] batch [1/3] time 1.713 (1.713) data 0.283 (0.283) loss 0.1703 (0.1703) acc 93.7500 (93.7500) lr 1.9921e-03 eta 0:16:20
epoch [10/200] batch [2/3] time 1.423 (1.568) data 0.000 (0.142) loss 0.3306 (0.2504) acc 87.5000 (90.6250) lr 1.9921e-03 eta 0:14:55
epoch [10/200] batch [3/3] time 1.429 (1.522) data 0.000 (0.095) loss 0.6035 (0.3681) acc 81.2500 (87.5000) lr 1.9900e-03 eta 0:14:27
epoch [11/200] batch [1/3] time 1.704 (1.704) data 0.279 (0.279) loss 0.6104 (0.6104) acc 81.2500 (81.2500) lr 1.9900e-03 eta 0:16:09
epoch [11/200] batch [2/3] time 1.430 (1.567) data 0.000 (0.139) loss 0.6489 (0.6296) acc 78.1250 (79.6875) lr 1.9900e-03 eta 0:14:50
epoch [11/200] batch [3/3] time 1.426 (1.520) data 0.000 (0.093) loss 0.2236 (0.4943) acc 96.8750 (85.4167) lr 1.9877e-03 eta 0:14:21
epoch [12/200] batch [1/3] time 1.695 (1.695) data 0.277 (0.277) loss 0.4683 (0.4683) acc 84.3750 (84.3750) lr 1.9877e-03 eta 0:15:59
epoch [12/200] batch [2/3] time 1.425 (1.560) data 0.000 (0.138) loss 0.5737 (0.5210) acc 84.3750 (84.3750) lr 1.9877e-03 eta 0:14:41
epoch [12/200] batch [3/3] time 1.424 (1.515) data 0.000 (0.092) loss 0.6826 (0.5749) acc 81.2500 (83.3333) lr 1.9851e-03 eta 0:14:14
epoch [13/200] batch [1/3] time 1.704 (1.704) data 0.283 (0.283) loss 0.5547 (0.5547) acc 81.2500 (81.2500) lr 1.9851e-03 eta 0:15:59
epoch [13/200] batch [2/3] time 1.420 (1.562) data 0.000 (0.142) loss 0.3774 (0.4661) acc 93.7500 (87.5000) lr 1.9851e-03 eta 0:14:37
epoch [13/200] batch [3/3] time 1.426 (1.516) data 0.000 (0.094) loss 0.4314 (0.4545) acc 87.5000 (87.5000) lr 1.9823e-03 eta 0:14:10
epoch [14/200] batch [1/3] time 1.711 (1.711) data 0.286 (0.286) loss 0.5093 (0.5093) acc 84.3750 (84.3750) lr 1.9823e-03 eta 0:15:58
epoch [14/200] batch [2/3] time 1.432 (1.572) data 0.000 (0.143) loss 0.5801 (0.5447) acc 87.5000 (85.9375) lr 1.9823e-03 eta 0:14:38
epoch [14/200] batch [3/3] time 1.427 (1.523) data 0.000 (0.095) loss 0.4536 (0.5143) acc 87.5000 (86.4583) lr 1.9792e-03 eta 0:14:10
epoch [15/200] batch [1/3] time 1.704 (1.704) data 0.275 (0.275) loss 0.7544 (0.7544) acc 78.1250 (78.1250) lr 1.9792e-03 eta 0:15:49
epoch [15/200] batch [2/3] time 1.428 (1.566) data 0.000 (0.138) loss 0.5508 (0.6526) acc 87.5000 (82.8125) lr 1.9792e-03 eta 0:14:30
epoch [15/200] batch [3/3] time 1.421 (1.518) data 0.000 (0.092) loss 0.8022 (0.7025) acc 81.2500 (82.2917) lr 1.9759e-03 eta 0:14:02
epoch [16/200] batch [1/3] time 1.702 (1.702) data 0.287 (0.287) loss 0.5020 (0.5020) acc 90.6250 (90.6250) lr 1.9759e-03 eta 0:15:42
epoch [16/200] batch [2/3] time 1.422 (1.562) data 0.000 (0.144) loss 0.2202 (0.3611) acc 93.7500 (92.1875) lr 1.9759e-03 eta 0:14:23
epoch [16/200] batch [3/3] time 1.432 (1.518) data 0.000 (0.096) loss 0.2224 (0.3149) acc 90.6250 (91.6667) lr 1.9724e-03 eta 0:13:58
epoch [17/200] batch [1/3] time 1.716 (1.716) data 0.294 (0.294) loss 0.4854 (0.4854) acc 90.6250 (90.6250) lr 1.9724e-03 eta 0:15:45
epoch [17/200] batch [2/3] time 1.425 (1.570) data 0.000 (0.147) loss 0.8071 (0.6462) acc 78.1250 (84.3750) lr 1.9724e-03 eta 0:14:23
epoch [17/200] batch [3/3] time 1.429 (1.523) data 0.000 (0.098) loss 0.2416 (0.5114) acc 90.6250 (86.4583) lr 1.9686e-03 eta 0:13:56
epoch [18/200] batch [1/3] time 1.701 (1.701) data 0.277 (0.277) loss 0.4446 (0.4446) acc 84.3750 (84.3750) lr 1.9686e-03 eta 0:15:32
epoch [18/200] batch [2/3] time 1.429 (1.565) data 0.000 (0.139) loss 0.8003 (0.6224) acc 84.3750 (84.3750) lr 1.9686e-03 eta 0:14:16
epoch [18/200] batch [3/3] time 1.422 (1.518) data 0.000 (0.093) loss 0.7729 (0.6726) acc 75.0000 (81.2500) lr 1.9646e-03 eta 0:13:48
epoch [19/200] batch [1/3] time 1.707 (1.707) data 0.277 (0.277) loss 0.5181 (0.5181) acc 81.2500 (81.2500) lr 1.9646e-03 eta 0:15:30
epoch [19/200] batch [2/3] time 1.423 (1.565) data 0.000 (0.138) loss 0.3918 (0.4550) acc 87.5000 (84.3750) lr 1.9646e-03 eta 0:14:11
epoch [19/200] batch [3/3] time 1.432 (1.521) data 0.000 (0.092) loss 0.3015 (0.4038) acc 90.6250 (86.4583) lr 1.9603e-03 eta 0:13:45
epoch [20/200] batch [1/3] time 1.701 (1.701) data 0.276 (0.276) loss 0.7017 (0.7017) acc 78.1250 (78.1250) lr 1.9603e-03 eta 0:15:22
epoch [20/200] batch [2/3] time 1.426 (1.564) data 0.000 (0.138) loss 0.4045 (0.5531) acc 90.6250 (84.3750) lr 1.9603e-03 eta 0:14:05
epoch [20/200] batch [3/3] time 1.420 (1.516) data 0.000 (0.092) loss 0.6460 (0.5841) acc 81.2500 (83.3333) lr 1.9558e-03 eta 0:13:38
epoch [21/200] batch [1/3] time 1.715 (1.715) data 0.293 (0.293) loss 0.3235 (0.3235) acc 93.7500 (93.7500) lr 1.9558e-03 eta 0:15:24
epoch [21/200] batch [2/3] time 1.425 (1.570) data 0.000 (0.147) loss 0.5186 (0.4210) acc 84.3750 (89.0625) lr 1.9558e-03 eta 0:14:04
epoch [21/200] batch [3/3] time 1.426 (1.522) data 0.000 (0.098) loss 0.3740 (0.4054) acc 93.7500 (90.6250) lr 1.9511e-03 eta 0:13:37
epoch [22/200] batch [1/3] time 1.714 (1.714) data 0.293 (0.293) loss 0.4482 (0.4482) acc 84.3750 (84.3750) lr 1.9511e-03 eta 0:15:18
epoch [22/200] batch [2/3] time 1.427 (1.570) data 0.000 (0.146) loss 0.5835 (0.5159) acc 90.6250 (87.5000) lr 1.9511e-03 eta 0:14:00
epoch [22/200] batch [3/3] time 1.425 (1.522) data 0.000 (0.098) loss 0.3291 (0.4536) acc 87.5000 (87.5000) lr 1.9461e-03 eta 0:13:32
epoch [23/200] batch [1/3] time 1.712 (1.712) data 0.281 (0.281) loss 0.4060 (0.4060) acc 90.6250 (90.6250) lr 1.9461e-03 eta 0:15:12
epoch [23/200] batch [2/3] time 1.426 (1.569) data 0.000 (0.141) loss 0.3643 (0.3851) acc 87.5000 (89.0625) lr 1.9461e-03 eta 0:13:54
epoch [23/200] batch [3/3] time 1.432 (1.523) data 0.000 (0.094) loss 0.4243 (0.3982) acc 90.6250 (89.5833) lr 1.9409e-03 eta 0:13:28
epoch [24/200] batch [1/3] time 1.720 (1.720) data 0.293 (0.293) loss 0.3955 (0.3955) acc 90.6250 (90.6250) lr 1.9409e-03 eta 0:15:11
epoch [24/200] batch [2/3] time 1.421 (1.571) data 0.000 (0.147) loss 0.2539 (0.3247) acc 93.7500 (92.1875) lr 1.9409e-03 eta 0:13:50
epoch [24/200] batch [3/3] time 1.422 (1.521) data 0.000 (0.098) loss 0.3406 (0.3300) acc 87.5000 (90.6250) lr 1.9354e-03 eta 0:13:23
epoch [25/200] batch [1/3] time 1.701 (1.701) data 0.275 (0.275) loss 0.6343 (0.6343) acc 84.3750 (84.3750) lr 1.9354e-03 eta 0:14:56
epoch [25/200] batch [2/3] time 1.421 (1.561) data 0.000 (0.138) loss 0.3176 (0.4760) acc 93.7500 (89.0625) lr 1.9354e-03 eta 0:13:41
epoch [25/200] batch [3/3] time 1.425 (1.516) data 0.000 (0.092) loss 0.7324 (0.5614) acc 81.2500 (86.4583) lr 1.9298e-03 eta 0:13:15
epoch [26/200] batch [1/3] time 1.713 (1.713) data 0.293 (0.293) loss 0.5215 (0.5215) acc 84.3750 (84.3750) lr 1.9298e-03 eta 0:14:57
epoch [26/200] batch [2/3] time 1.428 (1.570) data 0.000 (0.146) loss 0.3542 (0.4379) acc 90.6250 (87.5000) lr 1.9298e-03 eta 0:13:41
epoch [26/200] batch [3/3] time 1.428 (1.523) data 0.000 (0.098) loss 0.3176 (0.3978) acc 93.7500 (89.5833) lr 1.9239e-03 eta 0:13:14
epoch [27/200] batch [1/3] time 1.694 (1.694) data 0.276 (0.276) loss 0.4683 (0.4683) acc 87.5000 (87.5000) lr 1.9239e-03 eta 0:14:42
epoch [27/200] batch [2/3] time 1.423 (1.558) data 0.000 (0.138) loss 0.3013 (0.3848) acc 93.7500 (90.6250) lr 1.9239e-03 eta 0:13:30
epoch [27/200] batch [3/3] time 1.422 (1.513) data 0.000 (0.092) loss 0.4026 (0.3907) acc 87.5000 (89.5833) lr 1.9178e-03 eta 0:13:05
epoch [28/200] batch [1/3] time 1.711 (1.711) data 0.284 (0.284) loss 0.3733 (0.3733) acc 93.7500 (93.7500) lr 1.9178e-03 eta 0:14:46
epoch [28/200] batch [2/3] time 1.422 (1.567) data 0.000 (0.142) loss 0.4204 (0.3969) acc 87.5000 (90.6250) lr 1.9178e-03 eta 0:13:29
epoch [28/200] batch [3/3] time 1.429 (1.521) data 0.000 (0.095) loss 0.3079 (0.3672) acc 90.6250 (90.6250) lr 1.9114e-03 eta 0:13:04
epoch [29/200] batch [1/3] time 1.701 (1.701) data 0.278 (0.278) loss 0.7456 (0.7456) acc 78.1250 (78.1250) lr 1.9114e-03 eta 0:14:35
epoch [29/200] batch [2/3] time 1.424 (1.562) data 0.000 (0.139) loss 0.6240 (0.6848) acc 81.2500 (79.6875) lr 1.9114e-03 eta 0:13:22
epoch [29/200] batch [3/3] time 1.423 (1.516) data 0.000 (0.093) loss 0.3787 (0.5828) acc 93.7500 (84.3750) lr 1.9048e-03 eta 0:12:57
epoch [30/200] batch [1/3] time 1.711 (1.711) data 0.292 (0.292) loss 0.4531 (0.4531) acc 90.6250 (90.6250) lr 1.9048e-03 eta 0:14:35
epoch [30/200] batch [2/3] time 1.424 (1.567) data 0.000 (0.146) loss 0.4224 (0.4377) acc 90.6250 (90.6250) lr 1.9048e-03 eta 0:13:20
epoch [30/200] batch [3/3] time 1.425 (1.520) data 0.000 (0.098) loss 0.6396 (0.5050) acc 81.2500 (87.5000) lr 1.8980e-03 eta 0:12:55
epoch [31/200] batch [1/3] time 1.705 (1.705) data 0.278 (0.278) loss 0.7236 (0.7236) acc 87.5000 (87.5000) lr 1.8980e-03 eta 0:14:27
epoch [31/200] batch [2/3] time 1.426 (1.566) data 0.000 (0.139) loss 0.3267 (0.5251) acc 90.6250 (89.0625) lr 1.8980e-03 eta 0:13:15
epoch [31/200] batch [3/3] time 1.431 (1.521) data 0.000 (0.093) loss 0.4148 (0.4884) acc 87.5000 (88.5417) lr 1.8910e-03 eta 0:12:50
epoch [32/200] batch [1/3] time 1.692 (1.692) data 0.276 (0.276) loss 0.2847 (0.2847) acc 93.7500 (93.7500) lr 1.8910e-03 eta 0:14:16
epoch [32/200] batch [2/3] time 1.426 (1.559) data 0.000 (0.138) loss 0.1832 (0.2339) acc 93.7500 (93.7500) lr 1.8910e-03 eta 0:13:07
epoch [32/200] batch [3/3] time 1.427 (1.515) data 0.000 (0.092) loss 0.8091 (0.4257) acc 75.0000 (87.5000) lr 1.8838e-03 eta 0:12:43
epoch [33/200] batch [1/3] time 1.713 (1.713) data 0.292 (0.292) loss 0.4800 (0.4800) acc 84.3750 (84.3750) lr 1.8838e-03 eta 0:14:21
epoch [33/200] batch [2/3] time 1.422 (1.568) data 0.000 (0.146) loss 0.3665 (0.4232) acc 87.5000 (85.9375) lr 1.8838e-03 eta 0:13:06
epoch [33/200] batch [3/3] time 1.411 (1.515) data 0.000 (0.097) loss 0.4934 (0.4466) acc 90.6250 (87.5000) lr 1.8763e-03 eta 0:12:39
epoch [34/200] batch [1/3] time 1.691 (1.691) data 0.278 (0.278) loss 0.1094 (0.1094) acc 96.8750 (96.8750) lr 1.8763e-03 eta 0:14:05
epoch [34/200] batch [2/3] time 1.415 (1.553) data 0.000 (0.139) loss 0.4448 (0.2771) acc 90.6250 (93.7500) lr 1.8763e-03 eta 0:12:54
epoch [34/200] batch [3/3] time 1.421 (1.509) data 0.000 (0.093) loss 0.4458 (0.3334) acc 90.6250 (92.7083) lr 1.8686e-03 eta 0:12:31
epoch [35/200] batch [1/3] time 1.705 (1.705) data 0.281 (0.281) loss 0.3953 (0.3953) acc 87.5000 (87.5000) lr 1.8686e-03 eta 0:14:07
epoch [35/200] batch [2/3] time 1.423 (1.564) data 0.000 (0.141) loss 0.4243 (0.4098) acc 90.6250 (89.0625) lr 1.8686e-03 eta 0:12:55
epoch [35/200] batch [3/3] time 1.423 (1.517) data 0.000 (0.094) loss 0.3335 (0.3844) acc 87.5000 (88.5417) lr 1.8607e-03 eta 0:12:30
epoch [36/200] batch [1/3] time 1.698 (1.698) data 0.281 (0.281) loss 0.2419 (0.2419) acc 96.8750 (96.8750) lr 1.8607e-03 eta 0:13:58
epoch [36/200] batch [2/3] time 1.421 (1.560) data 0.000 (0.141) loss 0.3376 (0.2898) acc 90.6250 (93.7500) lr 1.8607e-03 eta 0:12:48
epoch [36/200] batch [3/3] time 1.422 (1.514) data 0.000 (0.094) loss 0.6152 (0.3983) acc 84.3750 (90.6250) lr 1.8526e-03 eta 0:12:24
epoch [37/200] batch [1/3] time 1.721 (1.721) data 0.293 (0.293) loss 0.4915 (0.4915) acc 87.5000 (87.5000) lr 1.8526e-03 eta 0:14:05
epoch [37/200] batch [2/3] time 1.426 (1.574) data 0.000 (0.146) loss 0.4438 (0.4677) acc 87.5000 (87.5000) lr 1.8526e-03 eta 0:12:51
epoch [37/200] batch [3/3] time 1.422 (1.523) data 0.000 (0.098) loss 0.5366 (0.4906) acc 90.6250 (88.5417) lr 1.8443e-03 eta 0:12:24
epoch [38/200] batch [1/3] time 1.706 (1.706) data 0.278 (0.278) loss 0.2367 (0.2367) acc 87.5000 (87.5000) lr 1.8443e-03 eta 0:13:52
epoch [38/200] batch [2/3] time 1.427 (1.566) data 0.000 (0.139) loss 0.4485 (0.3426) acc 93.7500 (90.6250) lr 1.8443e-03 eta 0:12:42
epoch [38/200] batch [3/3] time 1.426 (1.519) data 0.000 (0.093) loss 0.9150 (0.5334) acc 78.1250 (86.4583) lr 1.8358e-03 eta 0:12:18
epoch [39/200] batch [1/3] time 1.705 (1.705) data 0.284 (0.284) loss 0.8057 (0.8057) acc 75.0000 (75.0000) lr 1.8358e-03 eta 0:13:46
epoch [39/200] batch [2/3] time 1.428 (1.566) data 0.000 (0.142) loss 0.6455 (0.7256) acc 87.5000 (81.2500) lr 1.8358e-03 eta 0:12:38
epoch [39/200] batch [3/3] time 1.419 (1.517) data 0.000 (0.095) loss 0.2197 (0.5570) acc 93.7500 (85.4167) lr 1.8271e-03 eta 0:12:12
epoch [40/200] batch [1/3] time 1.730 (1.730) data 0.298 (0.298) loss 0.2571 (0.2571) acc 93.7500 (93.7500) lr 1.8271e-03 eta 0:13:54
epoch [40/200] batch [2/3] time 1.430 (1.580) data 0.000 (0.149) loss 0.5718 (0.4144) acc 81.2500 (87.5000) lr 1.8271e-03 eta 0:12:39
epoch [40/200] batch [3/3] time 1.419 (1.526) data 0.000 (0.099) loss 0.1621 (0.3303) acc 96.8750 (90.6250) lr 1.8181e-03 eta 0:12:12
epoch [41/200] batch [1/3] time 1.722 (1.722) data 0.295 (0.295) loss 0.1682 (0.1682) acc 90.6250 (90.6250) lr 1.8181e-03 eta 0:13:45
epoch [41/200] batch [2/3] time 1.423 (1.572) data 0.000 (0.147) loss 0.5005 (0.3344) acc 87.5000 (89.0625) lr 1.8181e-03 eta 0:12:31
epoch [41/200] batch [3/3] time 1.421 (1.522) data 0.000 (0.098) loss 0.1991 (0.2893) acc 90.6250 (89.5833) lr 1.8090e-03 eta 0:12:06
epoch [42/200] batch [1/3] time 1.710 (1.710) data 0.287 (0.287) loss 0.3931 (0.3931) acc 87.5000 (87.5000) lr 1.8090e-03 eta 0:13:34
epoch [42/200] batch [2/3] time 1.423 (1.566) data 0.000 (0.144) loss 0.2147 (0.3039) acc 93.7500 (90.6250) lr 1.8090e-03 eta 0:12:24
epoch [42/200] batch [3/3] time 1.420 (1.518) data 0.000 (0.096) loss 0.4731 (0.3603) acc 87.5000 (89.5833) lr 1.7997e-03 eta 0:11:59
epoch [43/200] batch [1/3] time 1.712 (1.712) data 0.292 (0.292) loss 0.2380 (0.2380) acc 90.6250 (90.6250) lr 1.7997e-03 eta 0:13:30
epoch [43/200] batch [2/3] time 1.425 (1.569) data 0.000 (0.146) loss 0.1792 (0.2086) acc 93.7500 (92.1875) lr 1.7997e-03 eta 0:12:20
epoch [43/200] batch [3/3] time 1.433 (1.523) data 0.000 (0.098) loss 0.5146 (0.3106) acc 90.6250 (91.6667) lr 1.7902e-03 eta 0:11:57
epoch [44/200] batch [1/3] time 1.697 (1.697) data 0.277 (0.277) loss 0.2800 (0.2800) acc 90.6250 (90.6250) lr 1.7902e-03 eta 0:13:17
epoch [44/200] batch [2/3] time 1.429 (1.563) data 0.000 (0.138) loss 0.3899 (0.3350) acc 87.5000 (89.0625) lr 1.7902e-03 eta 0:12:13
epoch [44/200] batch [3/3] time 1.424 (1.517) data 0.000 (0.092) loss 0.4194 (0.3631) acc 87.5000 (88.5417) lr 1.7804e-03 eta 0:11:49
epoch [45/200] batch [1/3] time 1.704 (1.704) data 0.280 (0.280) loss 0.3132 (0.3132) acc 90.6250 (90.6250) lr 1.7804e-03 eta 0:13:15
epoch [45/200] batch [2/3] time 1.414 (1.559) data 0.000 (0.140) loss 0.3921 (0.3527) acc 90.6250 (90.6250) lr 1.7804e-03 eta 0:12:06
epoch [45/200] batch [3/3] time 1.419 (1.512) data 0.000 (0.093) loss 0.4414 (0.3822) acc 90.6250 (90.6250) lr 1.7705e-03 eta 0:11:43
epoch [46/200] batch [1/3] time 1.711 (1.711) data 0.284 (0.284) loss 0.4536 (0.4536) acc 87.5000 (87.5000) lr 1.7705e-03 eta 0:13:13
epoch [46/200] batch [2/3] time 1.423 (1.567) data 0.000 (0.142) loss 0.3394 (0.3965) acc 87.5000 (87.5000) lr 1.7705e-03 eta 0:12:05
epoch [46/200] batch [3/3] time 1.429 (1.521) data 0.000 (0.095) loss 0.2769 (0.3566) acc 90.6250 (88.5417) lr 1.7604e-03 eta 0:11:42
epoch [47/200] batch [1/3] time 1.710 (1.710) data 0.293 (0.293) loss 0.1787 (0.1787) acc 96.8750 (96.8750) lr 1.7604e-03 eta 0:13:08
epoch [47/200] batch [2/3] time 1.422 (1.566) data 0.000 (0.147) loss 0.2910 (0.2349) acc 90.6250 (93.7500) lr 1.7604e-03 eta 0:12:00
epoch [47/200] batch [3/3] time 1.429 (1.520) data 0.000 (0.098) loss 0.5044 (0.3247) acc 84.3750 (90.6250) lr 1.7501e-03 eta 0:11:37
epoch [48/200] batch [1/3] time 1.707 (1.707) data 0.293 (0.293) loss 0.2384 (0.2384) acc 100.0000 (100.0000) lr 1.7501e-03 eta 0:13:01
epoch [48/200] batch [2/3] time 1.426 (1.567) data 0.000 (0.147) loss 0.0610 (0.1497) acc 100.0000 (100.0000) lr 1.7501e-03 eta 0:11:55
epoch [48/200] batch [3/3] time 1.430 (1.521) data 0.000 (0.098) loss 0.4619 (0.2538) acc 81.2500 (93.7500) lr 1.7396e-03 eta 0:11:33
epoch [49/200] batch [1/3] time 1.707 (1.707) data 0.284 (0.284) loss 0.3418 (0.3418) acc 93.7500 (93.7500) lr 1.7396e-03 eta 0:12:56
epoch [49/200] batch [2/3] time 1.435 (1.571) data 0.000 (0.142) loss 0.4048 (0.3733) acc 87.5000 (90.6250) lr 1.7396e-03 eta 0:11:53
epoch [49/200] batch [3/3] time 1.424 (1.522) data 0.000 (0.095) loss 0.8364 (0.5277) acc 78.1250 (86.4583) lr 1.7290e-03 eta 0:11:29
epoch [50/200] batch [1/3] time 1.712 (1.712) data 0.285 (0.285) loss 0.3052 (0.3052) acc 96.8750 (96.8750) lr 1.7290e-03 eta 0:12:53
epoch [50/200] batch [2/3] time 1.421 (1.566) data 0.000 (0.143) loss 0.4373 (0.3712) acc 87.5000 (92.1875) lr 1.7290e-03 eta 0:11:46
epoch [50/200] batch [3/3] time 1.421 (1.518) data 0.000 (0.095) loss 0.4917 (0.4114) acc 84.3750 (89.5833) lr 1.7181e-03 eta 0:11:23
epoch [51/200] batch [1/3] time 1.711 (1.711) data 0.291 (0.291) loss 0.3501 (0.3501) acc 90.6250 (90.6250) lr 1.7181e-03 eta 0:12:48
epoch [51/200] batch [2/3] time 1.421 (1.566) data 0.000 (0.146) loss 0.2776 (0.3138) acc 96.8750 (93.7500) lr 1.7181e-03 eta 0:11:41
epoch [51/200] batch [3/3] time 1.421 (1.518) data 0.000 (0.097) loss 0.4893 (0.3723) acc 87.5000 (91.6667) lr 1.7071e-03 eta 0:11:18
epoch [52/200] batch [1/3] time 1.713 (1.713) data 0.295 (0.295) loss 0.1967 (0.1967) acc 90.6250 (90.6250) lr 1.7071e-03 eta 0:12:44
epoch [52/200] batch [2/3] time 1.428 (1.571) data 0.000 (0.147) loss 0.3699 (0.2833) acc 90.6250 (90.6250) lr 1.7071e-03 eta 0:11:38
epoch [52/200] batch [3/3] time 1.427 (1.523) data 0.000 (0.098) loss 0.5361 (0.3676) acc 90.6250 (90.6250) lr 1.6959e-03 eta 0:11:16
epoch [53/200] batch [1/3] time 1.699 (1.699) data 0.275 (0.275) loss 0.6665 (0.6665) acc 78.1250 (78.1250) lr 1.6959e-03 eta 0:12:32
epoch [53/200] batch [2/3] time 1.422 (1.561) data 0.000 (0.138) loss 0.3845 (0.5255) acc 90.6250 (84.3750) lr 1.6959e-03 eta 0:11:29
epoch [53/200] batch [3/3] time 1.425 (1.516) data 0.000 (0.092) loss 0.4209 (0.4906) acc 90.6250 (86.4583) lr 1.6845e-03 eta 0:11:08
epoch [54/200] batch [1/3] time 1.716 (1.716) data 0.293 (0.293) loss 0.2935 (0.2935) acc 93.7500 (93.7500) lr 1.6845e-03 eta 0:12:35
epoch [54/200] batch [2/3] time 1.419 (1.568) data 0.000 (0.146) loss 0.2964 (0.2949) acc 96.8750 (95.3125) lr 1.6845e-03 eta 0:11:28
epoch [54/200] batch [3/3] time 1.419 (1.518) data 0.000 (0.098) loss 0.7554 (0.4484) acc 75.0000 (88.5417) lr 1.6730e-03 eta 0:11:05
epoch [55/200] batch [1/3] time 1.722 (1.722) data 0.294 (0.294) loss 0.4915 (0.4915) acc 84.3750 (84.3750) lr 1.6730e-03 eta 0:12:32
epoch [55/200] batch [2/3] time 1.422 (1.572) data 0.000 (0.147) loss 0.6509 (0.5712) acc 87.5000 (85.9375) lr 1.6730e-03 eta 0:11:25
epoch [55/200] batch [3/3] time 1.428 (1.524) data 0.000 (0.098) loss 0.4246 (0.5223) acc 90.6250 (87.5000) lr 1.6613e-03 eta 0:11:02
epoch [56/200] batch [1/3] time 1.701 (1.701) data 0.285 (0.285) loss 0.4993 (0.4993) acc 90.6250 (90.6250) lr 1.6613e-03 eta 0:12:18
epoch [56/200] batch [2/3] time 1.432 (1.566) data 0.000 (0.142) loss 0.4888 (0.4940) acc 90.6250 (90.6250) lr 1.6613e-03 eta 0:11:18
epoch [56/200] batch [3/3] time 1.428 (1.520) data 0.000 (0.095) loss 0.2262 (0.4047) acc 93.7500 (91.6667) lr 1.6494e-03 eta 0:10:56
epoch [57/200] batch [1/3] time 1.703 (1.703) data 0.286 (0.286) loss 0.4463 (0.4463) acc 84.3750 (84.3750) lr 1.6494e-03 eta 0:12:14
epoch [57/200] batch [2/3] time 1.423 (1.563) data 0.000 (0.143) loss 0.1182 (0.2823) acc 100.0000 (92.1875) lr 1.6494e-03 eta 0:11:12
epoch [57/200] batch [3/3] time 1.433 (1.520) data 0.000 (0.095) loss 0.2500 (0.2715) acc 96.8750 (93.7500) lr 1.6374e-03 eta 0:10:52
epoch [58/200] batch [1/3] time 1.697 (1.697) data 0.274 (0.274) loss 0.3210 (0.3210) acc 90.6250 (90.6250) lr 1.6374e-03 eta 0:12:06
epoch [58/200] batch [2/3] time 1.425 (1.561) data 0.000 (0.137) loss 0.1150 (0.2180) acc 100.0000 (95.3125) lr 1.6374e-03 eta 0:11:06
epoch [58/200] batch [3/3] time 1.429 (1.517) data 0.000 (0.091) loss 0.1552 (0.1971) acc 96.8750 (95.8333) lr 1.6252e-03 eta 0:10:46
epoch [59/200] batch [1/3] time 1.718 (1.718) data 0.292 (0.292) loss 0.3364 (0.3364) acc 90.6250 (90.6250) lr 1.6252e-03 eta 0:12:10
epoch [59/200] batch [2/3] time 1.421 (1.570) data 0.000 (0.146) loss 0.3340 (0.3352) acc 90.6250 (90.6250) lr 1.6252e-03 eta 0:11:05
epoch [59/200] batch [3/3] time 1.427 (1.522) data 0.000 (0.097) loss 0.3022 (0.3242) acc 93.7500 (91.6667) lr 1.6129e-03 eta 0:10:43
epoch [60/200] batch [1/3] time 1.707 (1.707) data 0.279 (0.279) loss 0.0259 (0.0259) acc 100.0000 (100.0000) lr 1.6129e-03 eta 0:12:00
epoch [60/200] batch [2/3] time 1.416 (1.561) data 0.000 (0.140) loss 0.4385 (0.2322) acc 87.5000 (93.7500) lr 1.6129e-03 eta 0:10:57
epoch [60/200] batch [3/3] time 1.420 (1.514) data 0.000 (0.093) loss 0.2507 (0.2384) acc 93.7500 (93.7500) lr 1.6004e-03 eta 0:10:36
epoch [61/200] batch [1/3] time 1.711 (1.711) data 0.285 (0.285) loss 0.3484 (0.3484) acc 93.7500 (93.7500) lr 1.6004e-03 eta 0:11:57
epoch [61/200] batch [2/3] time 1.421 (1.566) data 0.000 (0.143) loss 0.4141 (0.3812) acc 87.5000 (90.6250) lr 1.6004e-03 eta 0:10:54
epoch [61/200] batch [3/3] time 1.428 (1.520) data 0.000 (0.095) loss 0.1814 (0.3146) acc 93.7500 (91.6667) lr 1.5878e-03 eta 0:10:33
epoch [62/200] batch [1/3] time 1.709 (1.709) data 0.283 (0.283) loss 0.2115 (0.2115) acc 93.7500 (93.7500) lr 1.5878e-03 eta 0:11:50
epoch [62/200] batch [2/3] time 1.427 (1.568) data 0.000 (0.142) loss 0.2920 (0.2518) acc 93.7500 (93.7500) lr 1.5878e-03 eta 0:10:50
epoch [62/200] batch [3/3] time 1.430 (1.522) data 0.000 (0.095) loss 0.2817 (0.2618) acc 96.8750 (94.7917) lr 1.5750e-03 eta 0:10:30
epoch [63/200] batch [1/3] time 1.705 (1.705) data 0.284 (0.284) loss 0.1665 (0.1665) acc 96.8750 (96.8750) lr 1.5750e-03 eta 0:11:44
epoch [63/200] batch [2/3] time 1.431 (1.568) data 0.000 (0.142) loss 0.2627 (0.2146) acc 90.6250 (93.7500) lr 1.5750e-03 eta 0:10:46
epoch [63/200] batch [3/3] time 1.479 (1.538) data 0.000 (0.095) loss 0.2852 (0.2381) acc 87.5000 (91.6667) lr 1.5621e-03 eta 0:10:32
epoch [64/200] batch [1/3] time 1.761 (1.761) data 0.290 (0.290) loss 0.1111 (0.1111) acc 100.0000 (100.0000) lr 1.5621e-03 eta 0:12:01
epoch [64/200] batch [2/3] time 1.448 (1.604) data 0.000 (0.145) loss 0.5024 (0.3068) acc 87.5000 (93.7500) lr 1.5621e-03 eta 0:10:56
epoch [64/200] batch [3/3] time 1.447 (1.552) data 0.000 (0.097) loss 0.3523 (0.3219) acc 93.7500 (93.7500) lr 1.5490e-03 eta 0:10:33
epoch [65/200] batch [1/3] time 1.722 (1.722) data 0.276 (0.276) loss 0.4502 (0.4502) acc 90.6250 (90.6250) lr 1.5490e-03 eta 0:11:41
epoch [65/200] batch [2/3] time 1.450 (1.586) data 0.000 (0.138) loss 0.4871 (0.4686) acc 81.2500 (85.9375) lr 1.5490e-03 eta 0:10:44
epoch [65/200] batch [3/3] time 1.449 (1.541) data 0.000 (0.092) loss 0.4270 (0.4548) acc 90.6250 (87.5000) lr 1.5358e-03 eta 0:10:23
epoch [66/200] batch [1/3] time 1.732 (1.732) data 0.291 (0.291) loss 0.3794 (0.3794) acc 90.6250 (90.6250) lr 1.5358e-03 eta 0:11:39
epoch [66/200] batch [2/3] time 1.450 (1.591) data 0.000 (0.145) loss 0.2396 (0.3095) acc 93.7500 (92.1875) lr 1.5358e-03 eta 0:10:41
epoch [66/200] batch [3/3] time 1.435 (1.539) data 0.000 (0.097) loss 0.2866 (0.3019) acc 93.7500 (92.7083) lr 1.5225e-03 eta 0:10:18
epoch [67/200] batch [1/3] time 1.705 (1.705) data 0.275 (0.275) loss 0.3696 (0.3696) acc 87.5000 (87.5000) lr 1.5225e-03 eta 0:11:23
epoch [67/200] batch [2/3] time 1.421 (1.563) data 0.000 (0.138) loss 0.3340 (0.3518) acc 93.7500 (90.6250) lr 1.5225e-03 eta 0:10:25
epoch [67/200] batch [3/3] time 1.430 (1.519) data 0.000 (0.092) loss 0.1486 (0.2841) acc 90.6250 (90.6250) lr 1.5090e-03 eta 0:10:05
epoch [68/200] batch [1/3] time 1.720 (1.720) data 0.292 (0.292) loss 0.2155 (0.2155) acc 93.7500 (93.7500) lr 1.5090e-03 eta 0:11:24
epoch [68/200] batch [2/3] time 1.428 (1.574) data 0.000 (0.146) loss 0.3027 (0.2591) acc 93.7500 (93.7500) lr 1.5090e-03 eta 0:10:24
epoch [68/200] batch [3/3] time 1.425 (1.525) data 0.000 (0.097) loss 0.2162 (0.2448) acc 96.8750 (94.7917) lr 1.4955e-03 eta 0:10:03
epoch [69/200] batch [1/3] time 1.701 (1.701) data 0.285 (0.285) loss 0.3726 (0.3726) acc 93.7500 (93.7500) lr 1.4955e-03 eta 0:11:12
epoch [69/200] batch [2/3] time 1.415 (1.558) data 0.000 (0.142) loss 0.1329 (0.2527) acc 100.0000 (96.8750) lr 1.4955e-03 eta 0:10:13
epoch [69/200] batch [3/3] time 1.431 (1.516) data 0.000 (0.095) loss 0.1930 (0.2328) acc 96.8750 (96.8750) lr 1.4818e-03 eta 0:09:55
epoch [70/200] batch [1/3] time 1.700 (1.700) data 0.274 (0.274) loss 0.1225 (0.1225) acc 96.8750 (96.8750) lr 1.4818e-03 eta 0:11:06
epoch [70/200] batch [2/3] time 1.424 (1.562) data 0.000 (0.137) loss 0.2384 (0.1805) acc 93.7500 (95.3125) lr 1.4818e-03 eta 0:10:10
epoch [70/200] batch [3/3] time 1.427 (1.517) data 0.000 (0.091) loss 0.2754 (0.2121) acc 87.5000 (92.7083) lr 1.4679e-03 eta 0:09:51
epoch [71/200] batch [1/3] time 1.702 (1.702) data 0.281 (0.281) loss 0.5806 (0.5806) acc 87.5000 (87.5000) lr 1.4679e-03 eta 0:11:02
epoch [71/200] batch [2/3] time 1.420 (1.561) data 0.000 (0.141) loss 0.4187 (0.4996) acc 90.6250 (89.0625) lr 1.4679e-03 eta 0:10:05
epoch [71/200] batch [3/3] time 1.419 (1.514) data 0.000 (0.094) loss 0.0765 (0.3586) acc 96.8750 (91.6667) lr 1.4540e-03 eta 0:09:45
epoch [72/200] batch [1/3] time 1.711 (1.711) data 0.285 (0.285) loss 0.1449 (0.1449) acc 96.8750 (96.8750) lr 1.4540e-03 eta 0:11:00
epoch [72/200] batch [2/3] time 1.425 (1.568) data 0.000 (0.143) loss 0.2238 (0.1843) acc 93.7500 (95.3125) lr 1.4540e-03 eta 0:10:03
epoch [72/200] batch [3/3] time 1.429 (1.522) data 0.000 (0.095) loss 0.1006 (0.1564) acc 96.8750 (95.8333) lr 1.4399e-03 eta 0:09:44
epoch [73/200] batch [1/3] time 1.716 (1.716) data 0.291 (0.291) loss 0.4849 (0.4849) acc 90.6250 (90.6250) lr 1.4399e-03 eta 0:10:57
epoch [73/200] batch [2/3] time 1.424 (1.570) data 0.000 (0.146) loss 0.1833 (0.3341) acc 96.8750 (93.7500) lr 1.4399e-03 eta 0:09:59
epoch [73/200] batch [3/3] time 1.428 (1.523) data 0.000 (0.097) loss 0.2152 (0.2945) acc 93.7500 (93.7500) lr 1.4258e-03 eta 0:09:40
epoch [74/200] batch [1/3] time 1.704 (1.704) data 0.283 (0.283) loss 0.0855 (0.0855) acc 100.0000 (100.0000) lr 1.4258e-03 eta 0:10:47
epoch [74/200] batch [2/3] time 1.421 (1.562) data 0.000 (0.142) loss 0.4004 (0.2430) acc 90.6250 (95.3125) lr 1.4258e-03 eta 0:09:52
epoch [74/200] batch [3/3] time 1.427 (1.517) data 0.000 (0.094) loss 0.1688 (0.2182) acc 93.7500 (94.7917) lr 1.4115e-03 eta 0:09:33
epoch [75/200] batch [1/3] time 1.713 (1.713) data 0.285 (0.285) loss 0.0510 (0.0510) acc 100.0000 (100.0000) lr 1.4115e-03 eta 0:10:45
epoch [75/200] batch [2/3] time 1.428 (1.571) data 0.000 (0.143) loss 0.2515 (0.1512) acc 93.7500 (96.8750) lr 1.4115e-03 eta 0:09:50
epoch [75/200] batch [3/3] time 1.428 (1.523) data 0.000 (0.095) loss 0.2686 (0.1903) acc 93.7500 (95.8333) lr 1.3971e-03 eta 0:09:31
epoch [76/200] batch [1/3] time 1.703 (1.703) data 0.278 (0.278) loss 0.2443 (0.2443) acc 93.7500 (93.7500) lr 1.3971e-03 eta 0:10:36
epoch [76/200] batch [2/3] time 1.424 (1.564) data 0.000 (0.139) loss 0.2949 (0.2696) acc 90.6250 (92.1875) lr 1.3971e-03 eta 0:09:43
epoch [76/200] batch [3/3] time 1.416 (1.514) data 0.000 (0.093) loss 0.5381 (0.3591) acc 84.3750 (89.5833) lr 1.3827e-03 eta 0:09:23
epoch [77/200] batch [1/3] time 1.714 (1.714) data 0.281 (0.281) loss 0.0588 (0.0588) acc 100.0000 (100.0000) lr 1.3827e-03 eta 0:10:35
epoch [77/200] batch [2/3] time 1.429 (1.572) data 0.000 (0.140) loss 0.1998 (0.1293) acc 93.7500 (96.8750) lr 1.3827e-03 eta 0:09:41
epoch [77/200] batch [3/3] time 1.421 (1.522) data 0.000 (0.094) loss 0.4858 (0.2482) acc 87.5000 (93.7500) lr 1.3681e-03 eta 0:09:21
epoch [78/200] batch [1/3] time 1.717 (1.717) data 0.291 (0.291) loss 0.3711 (0.3711) acc 90.6250 (90.6250) lr 1.3681e-03 eta 0:10:31
epoch [78/200] batch [2/3] time 1.433 (1.575) data 0.000 (0.146) loss 0.1846 (0.2778) acc 93.7500 (92.1875) lr 1.3681e-03 eta 0:09:38
epoch [78/200] batch [3/3] time 1.423 (1.525) data 0.000 (0.097) loss 0.3962 (0.3173) acc 90.6250 (91.6667) lr 1.3535e-03 eta 0:09:18
epoch [79/200] batch [1/3] time 1.718 (1.718) data 0.300 (0.300) loss 0.4685 (0.4685) acc 84.3750 (84.3750) lr 1.3535e-03 eta 0:10:27
epoch [79/200] batch [2/3] time 1.429 (1.574) data 0.000 (0.150) loss 0.0861 (0.2773) acc 96.8750 (90.6250) lr 1.3535e-03 eta 0:09:32
epoch [79/200] batch [3/3] time 1.431 (1.526) data 0.000 (0.100) loss 0.1296 (0.2281) acc 96.8750 (92.7083) lr 1.3387e-03 eta 0:09:13
epoch [80/200] batch [1/3] time 1.704 (1.704) data 0.275 (0.275) loss 0.6758 (0.6758) acc 84.3750 (84.3750) lr 1.3387e-03 eta 0:10:16
epoch [80/200] batch [2/3] time 1.430 (1.567) data 0.000 (0.138) loss 0.2407 (0.4583) acc 93.7500 (89.0625) lr 1.3387e-03 eta 0:09:25
epoch [80/200] batch [3/3] time 1.423 (1.519) data 0.000 (0.092) loss 0.1260 (0.3475) acc 100.0000 (92.7083) lr 1.3239e-03 eta 0:09:06
epoch [81/200] batch [1/3] time 1.718 (1.718) data 0.287 (0.287) loss 0.0822 (0.0822) acc 100.0000 (100.0000) lr 1.3239e-03 eta 0:10:16
epoch [81/200] batch [2/3] time 1.428 (1.573) data 0.000 (0.144) loss 0.4551 (0.2686) acc 90.6250 (95.3125) lr 1.3239e-03 eta 0:09:22
epoch [81/200] batch [3/3] time 1.424 (1.523) data 0.000 (0.096) loss 0.3083 (0.2819) acc 93.7500 (94.7917) lr 1.3090e-03 eta 0:09:03
epoch [82/200] batch [1/3] time 1.718 (1.718) data 0.293 (0.293) loss 0.1450 (0.1450) acc 93.7500 (93.7500) lr 1.3090e-03 eta 0:10:11
epoch [82/200] batch [2/3] time 1.425 (1.571) data 0.000 (0.146) loss 0.3533 (0.2491) acc 90.6250 (92.1875) lr 1.3090e-03 eta 0:09:17
epoch [82/200] batch [3/3] time 1.427 (1.523) data 0.000 (0.098) loss 0.3257 (0.2747) acc 93.7500 (92.7083) lr 1.2940e-03 eta 0:08:59
epoch [83/200] batch [1/3] time 1.698 (1.698) data 0.274 (0.274) loss 0.3989 (0.3989) acc 87.5000 (87.5000) lr 1.2940e-03 eta 0:09:59
epoch [83/200] batch [2/3] time 1.430 (1.564) data 0.000 (0.137) loss 0.2678 (0.3334) acc 93.7500 (90.6250) lr 1.2940e-03 eta 0:09:10
epoch [83/200] batch [3/3] time 1.425 (1.518) data 0.000 (0.091) loss 0.3760 (0.3476) acc 87.5000 (89.5833) lr 1.2790e-03 eta 0:08:52
epoch [84/200] batch [1/3] time 1.704 (1.704) data 0.281 (0.281) loss 0.0521 (0.0521) acc 96.8750 (96.8750) lr 1.2790e-03 eta 0:09:56
epoch [84/200] batch [2/3] time 1.425 (1.565) data 0.000 (0.141) loss 0.0912 (0.0717) acc 100.0000 (98.4375) lr 1.2790e-03 eta 0:09:06
epoch [84/200] batch [3/3] time 1.422 (1.517) data 0.000 (0.094) loss 0.4209 (0.1881) acc 87.5000 (94.7917) lr 1.2639e-03 eta 0:08:48
epoch [85/200] batch [1/3] time 1.713 (1.713) data 0.284 (0.284) loss 0.2903 (0.2903) acc 90.6250 (90.6250) lr 1.2639e-03 eta 0:09:54
epoch [85/200] batch [2/3] time 1.425 (1.569) data 0.000 (0.142) loss 0.2388 (0.2645) acc 93.7500 (92.1875) lr 1.2639e-03 eta 0:09:02
epoch [85/200] batch [3/3] time 1.424 (1.520) data 0.000 (0.095) loss 0.4858 (0.3383) acc 84.3750 (89.5833) lr 1.2487e-03 eta 0:08:44
epoch [86/200] batch [1/3] time 1.700 (1.700) data 0.277 (0.277) loss 0.6714 (0.6714) acc 87.5000 (87.5000) lr 1.2487e-03 eta 0:09:44
epoch [86/200] batch [2/3] time 1.429 (1.565) data 0.000 (0.138) loss 0.3218 (0.4966) acc 93.7500 (90.6250) lr 1.2487e-03 eta 0:08:56
epoch [86/200] batch [3/3] time 1.427 (1.519) data 0.000 (0.092) loss 0.5112 (0.5015) acc 84.3750 (88.5417) lr 1.2334e-03 eta 0:08:39
epoch [87/200] batch [1/3] time 1.717 (1.717) data 0.290 (0.290) loss 0.5093 (0.5093) acc 90.6250 (90.6250) lr 1.2334e-03 eta 0:09:45
epoch [87/200] batch [2/3] time 1.427 (1.572) data 0.000 (0.145) loss 0.5581 (0.5337) acc 81.2500 (85.9375) lr 1.2334e-03 eta 0:08:54
epoch [87/200] batch [3/3] time 1.426 (1.523) data 0.000 (0.097) loss 0.5356 (0.5343) acc 81.2500 (84.3750) lr 1.2181e-03 eta 0:08:36
epoch [88/200] batch [1/3] time 1.692 (1.692) data 0.276 (0.276) loss 0.3755 (0.3755) acc 87.5000 (87.5000) lr 1.2181e-03 eta 0:09:31
epoch [88/200] batch [2/3] time 1.429 (1.560) data 0.000 (0.138) loss 0.2622 (0.3188) acc 93.7500 (90.6250) lr 1.2181e-03 eta 0:08:45
epoch [88/200] batch [3/3] time 1.426 (1.516) data 0.000 (0.092) loss 0.3027 (0.3135) acc 87.5000 (89.5833) lr 1.2028e-03 eta 0:08:29
epoch [89/200] batch [1/3] time 1.717 (1.717) data 0.290 (0.290) loss 0.3130 (0.3130) acc 96.8750 (96.8750) lr 1.2028e-03 eta 0:09:35
epoch [89/200] batch [2/3] time 1.429 (1.573) data 0.000 (0.145) loss 0.3855 (0.3492) acc 93.7500 (95.3125) lr 1.2028e-03 eta 0:08:45
epoch [89/200] batch [3/3] time 1.421 (1.522) data 0.000 (0.097) loss 0.2289 (0.3091) acc 93.7500 (94.7917) lr 1.1874e-03 eta 0:08:26
epoch [90/200] batch [1/3] time 1.714 (1.714) data 0.284 (0.284) loss 0.3579 (0.3579) acc 93.7500 (93.7500) lr 1.1874e-03 eta 0:09:28
epoch [90/200] batch [2/3] time 1.422 (1.568) data 0.000 (0.142) loss 0.2316 (0.2947) acc 93.7500 (93.7500) lr 1.1874e-03 eta 0:08:38
epoch [90/200] batch [3/3] time 1.428 (1.521) data 0.000 (0.095) loss 0.4167 (0.3354) acc 84.3750 (90.6250) lr 1.1719e-03 eta 0:08:21
epoch [91/200] batch [1/3] time 1.717 (1.717) data 0.292 (0.292) loss 0.2339 (0.2339) acc 93.7500 (93.7500) lr 1.1719e-03 eta 0:09:25
epoch [91/200] batch [2/3] time 1.418 (1.568) data 0.000 (0.146) loss 0.2744 (0.2542) acc 96.8750 (95.3125) lr 1.1719e-03 eta 0:08:34
epoch [91/200] batch [3/3] time 1.423 (1.520) data 0.000 (0.097) loss 0.2646 (0.2576) acc 93.7500 (94.7917) lr 1.1564e-03 eta 0:08:16
epoch [92/200] batch [1/3] time 1.708 (1.708) data 0.284 (0.284) loss 0.2969 (0.2969) acc 90.6250 (90.6250) lr 1.1564e-03 eta 0:09:16
epoch [92/200] batch [2/3] time 1.428 (1.568) data 0.000 (0.142) loss 0.2452 (0.2711) acc 93.7500 (92.1875) lr 1.1564e-03 eta 0:08:29
epoch [92/200] batch [3/3] time 1.428 (1.521) data 0.000 (0.095) loss 0.3733 (0.3051) acc 90.6250 (91.6667) lr 1.1409e-03 eta 0:08:12
epoch [93/200] batch [1/3] time 1.720 (1.720) data 0.292 (0.292) loss 0.2878 (0.2878) acc 93.7500 (93.7500) lr 1.1409e-03 eta 0:09:15
epoch [93/200] batch [2/3] time 1.424 (1.572) data 0.000 (0.146) loss 0.2549 (0.2714) acc 93.7500 (93.7500) lr 1.1409e-03 eta 0:08:26
epoch [93/200] batch [3/3] time 1.431 (1.525) data 0.000 (0.097) loss 0.3489 (0.2972) acc 93.7500 (93.7500) lr 1.1253e-03 eta 0:08:09
epoch [94/200] batch [1/3] time 1.735 (1.735) data 0.315 (0.315) loss 0.2296 (0.2296) acc 100.0000 (100.0000) lr 1.1253e-03 eta 0:09:15
epoch [94/200] batch [2/3] time 1.427 (1.581) data 0.000 (0.157) loss 0.3684 (0.2990) acc 93.7500 (96.8750) lr 1.1253e-03 eta 0:08:24
epoch [94/200] batch [3/3] time 1.423 (1.528) data 0.000 (0.105) loss 0.4275 (0.3418) acc 90.6250 (94.7917) lr 1.1097e-03 eta 0:08:05
epoch [95/200] batch [1/3] time 1.711 (1.711) data 0.285 (0.285) loss 0.5010 (0.5010) acc 90.6250 (90.6250) lr 1.1097e-03 eta 0:09:02
epoch [95/200] batch [2/3] time 1.420 (1.566) data 0.000 (0.143) loss 0.2976 (0.3993) acc 96.8750 (93.7500) lr 1.1097e-03 eta 0:08:14
epoch [95/200] batch [3/3] time 1.430 (1.521) data 0.000 (0.095) loss 0.5303 (0.4430) acc 81.2500 (89.5833) lr 1.0941e-03 eta 0:07:58
epoch [96/200] batch [1/3] time 1.719 (1.719) data 0.293 (0.293) loss 0.2754 (0.2754) acc 93.7500 (93.7500) lr 1.0941e-03 eta 0:08:59
epoch [96/200] batch [2/3] time 1.428 (1.574) data 0.000 (0.147) loss 0.2107 (0.2430) acc 93.7500 (93.7500) lr 1.0941e-03 eta 0:08:12
epoch [96/200] batch [3/3] time 1.423 (1.523) data 0.000 (0.098) loss 0.2014 (0.2292) acc 96.8750 (94.7917) lr 1.0785e-03 eta 0:07:55
epoch [97/200] batch [1/3] time 1.698 (1.698) data 0.277 (0.277) loss 0.1059 (0.1059) acc 96.8750 (96.8750) lr 1.0785e-03 eta 0:08:48
epoch [97/200] batch [2/3] time 1.422 (1.560) data 0.000 (0.138) loss 0.1552 (0.1305) acc 93.7500 (95.3125) lr 1.0785e-03 eta 0:08:03
epoch [97/200] batch [3/3] time 1.428 (1.516) data 0.000 (0.092) loss 0.2708 (0.1773) acc 90.6250 (93.7500) lr 1.0628e-03 eta 0:07:48
epoch [98/200] batch [1/3] time 1.707 (1.707) data 0.280 (0.280) loss 0.5996 (0.5996) acc 81.2500 (81.2500) lr 1.0628e-03 eta 0:08:45
epoch [98/200] batch [2/3] time 1.428 (1.568) data 0.000 (0.140) loss 0.2734 (0.4365) acc 96.8750 (89.0625) lr 1.0628e-03 eta 0:08:01
epoch [98/200] batch [3/3] time 1.430 (1.522) data 0.000 (0.093) loss 0.2949 (0.3893) acc 93.7500 (90.6250) lr 1.0471e-03 eta 0:07:45
epoch [99/200] batch [1/3] time 1.699 (1.699) data 0.280 (0.280) loss 0.1218 (0.1218) acc 100.0000 (100.0000) lr 1.0471e-03 eta 0:08:38
epoch [99/200] batch [2/3] time 1.425 (1.562) data 0.000 (0.140) loss 0.2290 (0.1754) acc 93.7500 (96.8750) lr 1.0471e-03 eta 0:07:54
epoch [99/200] batch [3/3] time 1.429 (1.518) data 0.000 (0.093) loss 0.3604 (0.2371) acc 90.6250 (94.7917) lr 1.0314e-03 eta 0:07:39
epoch [100/200] batch [1/3] time 1.695 (1.695) data 0.274 (0.274) loss 0.0815 (0.0815) acc 100.0000 (100.0000) lr 1.0314e-03 eta 0:08:31
epoch [100/200] batch [2/3] time 1.426 (1.561) data 0.000 (0.137) loss 0.0782 (0.0799) acc 100.0000 (100.0000) lr 1.0314e-03 eta 0:07:49
epoch [100/200] batch [3/3] time 1.429 (1.517) data 0.000 (0.092) loss 0.8770 (0.3456) acc 75.0000 (91.6667) lr 1.0157e-03 eta 0:07:35
epoch [101/200] batch [1/3] time 1.711 (1.711) data 0.285 (0.285) loss 0.1350 (0.1350) acc 93.7500 (93.7500) lr 1.0157e-03 eta 0:08:31
epoch [101/200] batch [2/3] time 1.425 (1.568) data 0.000 (0.143) loss 0.4883 (0.3116) acc 84.3750 (89.0625) lr 1.0157e-03 eta 0:07:47
epoch [101/200] batch [3/3] time 1.426 (1.521) data 0.000 (0.095) loss 0.0599 (0.2277) acc 100.0000 (92.7083) lr 1.0000e-03 eta 0:07:31
epoch [102/200] batch [1/3] time 1.701 (1.701) data 0.277 (0.277) loss 0.3206 (0.3206) acc 90.6250 (90.6250) lr 1.0000e-03 eta 0:08:23
epoch [102/200] batch [2/3] time 1.422 (1.561) data 0.000 (0.139) loss 0.4685 (0.3945) acc 90.6250 (90.6250) lr 1.0000e-03 eta 0:07:40
epoch [102/200] batch [3/3] time 1.420 (1.514) data 0.000 (0.093) loss 0.1768 (0.3219) acc 96.8750 (92.7083) lr 9.8429e-04 eta 0:07:25
epoch [103/200] batch [1/3] time 1.702 (1.702) data 0.284 (0.284) loss 0.2783 (0.2783) acc 90.6250 (90.6250) lr 9.8429e-04 eta 0:08:18
epoch [103/200] batch [2/3] time 1.424 (1.563) data 0.000 (0.142) loss 0.3691 (0.3237) acc 87.5000 (89.0625) lr 9.8429e-04 eta 0:07:36
epoch [103/200] batch [3/3] time 1.427 (1.518) data 0.000 (0.095) loss 0.0784 (0.2419) acc 100.0000 (92.7083) lr 9.6859e-04 eta 0:07:21
epoch [104/200] batch [1/3] time 1.699 (1.699) data 0.274 (0.274) loss 0.5068 (0.5068) acc 90.6250 (90.6250) lr 9.6859e-04 eta 0:08:12
epoch [104/200] batch [2/3] time 1.420 (1.560) data 0.000 (0.137) loss 0.3623 (0.4346) acc 90.6250 (90.6250) lr 9.6859e-04 eta 0:07:30
epoch [104/200] batch [3/3] time 1.431 (1.517) data 0.000 (0.092) loss 0.2646 (0.3779) acc 90.6250 (90.6250) lr 9.5289e-04 eta 0:07:16
epoch [105/200] batch [1/3] time 1.718 (1.718) data 0.291 (0.291) loss 0.3125 (0.3125) acc 93.7500 (93.7500) lr 9.5289e-04 eta 0:08:13
epoch [105/200] batch [2/3] time 1.426 (1.572) data 0.000 (0.146) loss 0.1100 (0.2113) acc 96.8750 (95.3125) lr 9.5289e-04 eta 0:07:29
epoch [105/200] batch [3/3] time 1.428 (1.524) data 0.000 (0.097) loss 0.2959 (0.2395) acc 87.5000 (92.7083) lr 9.3721e-04 eta 0:07:14
epoch [106/200] batch [1/3] time 1.709 (1.709) data 0.283 (0.283) loss 0.4966 (0.4966) acc 93.7500 (93.7500) lr 9.3721e-04 eta 0:08:05
epoch [106/200] batch [2/3] time 1.429 (1.569) data 0.000 (0.142) loss 0.2205 (0.3585) acc 96.8750 (95.3125) lr 9.3721e-04 eta 0:07:24
epoch [106/200] batch [3/3] time 1.423 (1.520) data 0.000 (0.095) loss 0.2035 (0.3068) acc 96.8750 (95.8333) lr 9.2154e-04 eta 0:07:08
epoch [107/200] batch [1/3] time 1.713 (1.713) data 0.291 (0.291) loss 0.0793 (0.0793) acc 100.0000 (100.0000) lr 9.2154e-04 eta 0:08:01
epoch [107/200] batch [2/3] time 1.422 (1.567) data 0.000 (0.146) loss 0.3945 (0.2369) acc 93.7500 (96.8750) lr 9.2154e-04 eta 0:07:18
epoch [107/200] batch [3/3] time 1.427 (1.521) data 0.000 (0.097) loss 0.2057 (0.2265) acc 96.8750 (96.8750) lr 9.0589e-04 eta 0:07:04
epoch [108/200] batch [1/3] time 1.711 (1.711) data 0.286 (0.286) loss 0.4639 (0.4639) acc 87.5000 (87.5000) lr 9.0589e-04 eta 0:07:55
epoch [108/200] batch [2/3] time 1.421 (1.566) data 0.000 (0.143) loss 0.2354 (0.3496) acc 96.8750 (92.1875) lr 9.0589e-04 eta 0:07:13
epoch [108/200] batch [3/3] time 1.422 (1.518) data 0.000 (0.095) loss 0.0549 (0.2514) acc 100.0000 (94.7917) lr 8.9027e-04 eta 0:06:59
epoch [109/200] batch [1/3] time 1.705 (1.705) data 0.282 (0.282) loss 0.2593 (0.2593) acc 93.7500 (93.7500) lr 8.9027e-04 eta 0:07:48
epoch [109/200] batch [2/3] time 1.422 (1.563) data 0.000 (0.141) loss 0.3677 (0.3135) acc 87.5000 (90.6250) lr 8.9027e-04 eta 0:07:08
epoch [109/200] batch [3/3] time 1.420 (1.516) data 0.000 (0.094) loss 0.7026 (0.4432) acc 87.5000 (89.5833) lr 8.7467e-04 eta 0:06:53
epoch [110/200] batch [1/3] time 1.714 (1.714) data 0.284 (0.284) loss 0.3350 (0.3350) acc 93.7500 (93.7500) lr 8.7467e-04 eta 0:07:46
epoch [110/200] batch [2/3] time 1.425 (1.570) data 0.000 (0.142) loss 0.3481 (0.3416) acc 93.7500 (93.7500) lr 8.7467e-04 eta 0:07:05
epoch [110/200] batch [3/3] time 1.437 (1.526) data 0.000 (0.095) loss 0.4504 (0.3778) acc 90.6250 (92.7083) lr 8.5910e-04 eta 0:06:51
epoch [111/200] batch [1/3] time 1.715 (1.715) data 0.292 (0.292) loss 0.0938 (0.0938) acc 96.8750 (96.8750) lr 8.5910e-04 eta 0:07:41
epoch [111/200] batch [2/3] time 1.427 (1.571) data 0.000 (0.146) loss 0.4443 (0.2690) acc 87.5000 (92.1875) lr 8.5910e-04 eta 0:07:01
epoch [111/200] batch [3/3] time 1.427 (1.523) data 0.000 (0.097) loss 0.0747 (0.2043) acc 96.8750 (93.7500) lr 8.4357e-04 eta 0:06:46
epoch [112/200] batch [1/3] time 1.701 (1.701) data 0.278 (0.278) loss 0.2600 (0.2600) acc 93.7500 (93.7500) lr 8.4357e-04 eta 0:07:32
epoch [112/200] batch [2/3] time 1.425 (1.563) data 0.000 (0.139) loss 0.1807 (0.2203) acc 93.7500 (93.7500) lr 8.4357e-04 eta 0:06:54
epoch [112/200] batch [3/3] time 1.426 (1.518) data 0.000 (0.093) loss 0.0674 (0.1694) acc 100.0000 (95.8333) lr 8.2807e-04 eta 0:06:40
epoch [113/200] batch [1/3] time 1.704 (1.704) data 0.283 (0.283) loss 0.2378 (0.2378) acc 90.6250 (90.6250) lr 8.2807e-04 eta 0:07:28
epoch [113/200] batch [2/3] time 1.427 (1.565) data 0.000 (0.142) loss 0.1891 (0.2134) acc 96.8750 (93.7500) lr 8.2807e-04 eta 0:06:50
epoch [113/200] batch [3/3] time 1.424 (1.518) data 0.000 (0.094) loss 0.4585 (0.2951) acc 87.5000 (91.6667) lr 8.1262e-04 eta 0:06:36
epoch [114/200] batch [1/3] time 1.717 (1.717) data 0.286 (0.286) loss 0.4343 (0.4343) acc 90.6250 (90.6250) lr 8.1262e-04 eta 0:07:26
epoch [114/200] batch [2/3] time 1.422 (1.569) data 0.000 (0.143) loss 0.1471 (0.2907) acc 96.8750 (93.7500) lr 8.1262e-04 eta 0:06:46
epoch [114/200] batch [3/3] time 1.422 (1.520) data 0.000 (0.095) loss 0.1442 (0.2419) acc 96.8750 (94.7917) lr 7.9721e-04 eta 0:06:32
epoch [115/200] batch [1/3] time 1.698 (1.698) data 0.275 (0.275) loss 0.1353 (0.1353) acc 100.0000 (100.0000) lr 7.9721e-04 eta 0:07:16
epoch [115/200] batch [2/3] time 1.429 (1.563) data 0.000 (0.138) loss 0.0689 (0.1021) acc 100.0000 (100.0000) lr 7.9721e-04 eta 0:06:40
epoch [115/200] batch [3/3] time 1.426 (1.518) data 0.000 (0.092) loss 0.2480 (0.1507) acc 93.7500 (97.9167) lr 7.8186e-04 eta 0:06:27
epoch [116/200] batch [1/3] time 1.695 (1.695) data 0.277 (0.277) loss 0.1458 (0.1458) acc 96.8750 (96.8750) lr 7.8186e-04 eta 0:07:10
epoch [116/200] batch [2/3] time 1.423 (1.559) data 0.000 (0.138) loss 0.3853 (0.2655) acc 90.6250 (93.7500) lr 7.8186e-04 eta 0:06:34
epoch [116/200] batch [3/3] time 1.430 (1.516) data 0.000 (0.092) loss 0.1146 (0.2152) acc 96.8750 (94.7917) lr 7.6655e-04 eta 0:06:22
epoch [117/200] batch [1/3] time 1.729 (1.729) data 0.294 (0.294) loss 0.2046 (0.2046) acc 96.8750 (96.8750) lr 7.6655e-04 eta 0:07:14
epoch [117/200] batch [2/3] time 1.421 (1.575) data 0.000 (0.147) loss 0.2952 (0.2499) acc 90.6250 (93.7500) lr 7.6655e-04 eta 0:06:33
epoch [117/200] batch [3/3] time 1.424 (1.525) data 0.000 (0.098) loss 0.3394 (0.2797) acc 93.7500 (93.7500) lr 7.5131e-04 eta 0:06:19
epoch [118/200] batch [1/3] time 1.695 (1.695) data 0.276 (0.276) loss 0.4888 (0.4888) acc 81.2500 (81.2500) lr 7.5131e-04 eta 0:07:00
epoch [118/200] batch [2/3] time 1.423 (1.559) data 0.000 (0.138) loss 0.3252 (0.4070) acc 90.6250 (85.9375) lr 7.5131e-04 eta 0:06:25
epoch [118/200] batch [3/3] time 1.423 (1.514) data 0.000 (0.092) loss 0.0367 (0.2836) acc 100.0000 (90.6250) lr 7.3613e-04 eta 0:06:12
epoch [119/200] batch [1/3] time 1.708 (1.708) data 0.283 (0.283) loss 0.2240 (0.2240) acc 90.6250 (90.6250) lr 7.3613e-04 eta 0:06:58
epoch [119/200] batch [2/3] time 1.424 (1.566) data 0.000 (0.142) loss 0.4653 (0.3447) acc 84.3750 (87.5000) lr 7.3613e-04 eta 0:06:22
epoch [119/200] batch [3/3] time 1.417 (1.517) data 0.000 (0.095) loss 0.1020 (0.2638) acc 100.0000 (91.6667) lr 7.2101e-04 eta 0:06:08
epoch [120/200] batch [1/3] time 1.699 (1.699) data 0.275 (0.275) loss 0.1604 (0.1604) acc 93.7500 (93.7500) lr 7.2101e-04 eta 0:06:51
epoch [120/200] batch [2/3] time 1.429 (1.564) data 0.000 (0.138) loss 0.0682 (0.1143) acc 100.0000 (96.8750) lr 7.2101e-04 eta 0:06:16
epoch [120/200] batch [3/3] time 1.421 (1.516) data 0.000 (0.092) loss 0.5117 (0.2468) acc 90.6250 (94.7917) lr 7.0596e-04 eta 0:06:03
epoch [121/200] batch [1/3] time 1.711 (1.711) data 0.284 (0.284) loss 0.1866 (0.1866) acc 93.7500 (93.7500) lr 7.0596e-04 eta 0:06:48
epoch [121/200] batch [2/3] time 1.419 (1.565) data 0.000 (0.142) loss 0.0242 (0.1054) acc 100.0000 (96.8750) lr 7.0596e-04 eta 0:06:12
epoch [121/200] batch [3/3] time 1.416 (1.515) data 0.000 (0.095) loss 0.5962 (0.2690) acc 87.5000 (93.7500) lr 6.9098e-04 eta 0:05:59
epoch [122/200] batch [1/3] time 1.713 (1.713) data 0.284 (0.284) loss 0.2224 (0.2224) acc 96.8750 (96.8750) lr 6.9098e-04 eta 0:06:44
epoch [122/200] batch [2/3] time 1.430 (1.572) data 0.000 (0.142) loss 0.1588 (0.1906) acc 96.8750 (96.8750) lr 6.9098e-04 eta 0:06:09
epoch [122/200] batch [3/3] time 1.423 (1.522) data 0.000 (0.095) loss 0.1550 (0.1788) acc 93.7500 (95.8333) lr 6.7608e-04 eta 0:05:56
epoch [123/200] batch [1/3] time 1.717 (1.717) data 0.290 (0.290) loss 0.7217 (0.7217) acc 81.2500 (81.2500) lr 6.7608e-04 eta 0:06:39
epoch [123/200] batch [2/3] time 1.427 (1.572) data 0.000 (0.145) loss 0.1459 (0.4338) acc 96.8750 (89.0625) lr 6.7608e-04 eta 0:06:04
epoch [123/200] batch [3/3] time 1.427 (1.523) data 0.000 (0.097) loss 0.1927 (0.3534) acc 96.8750 (91.6667) lr 6.6126e-04 eta 0:05:51
epoch [124/200] batch [1/3] time 1.708 (1.708) data 0.284 (0.284) loss 0.4397 (0.4397) acc 84.3750 (84.3750) lr 6.6126e-04 eta 0:06:32
epoch [124/200] batch [2/3] time 1.424 (1.566) data 0.000 (0.142) loss 0.1630 (0.3013) acc 96.8750 (90.6250) lr 6.6126e-04 eta 0:05:58
epoch [124/200] batch [3/3] time 1.428 (1.520) data 0.000 (0.095) loss 0.1710 (0.2579) acc 96.8750 (92.7083) lr 6.4653e-04 eta 0:05:46
epoch [125/200] batch [1/3] time 1.711 (1.711) data 0.291 (0.291) loss 0.4443 (0.4443) acc 84.3750 (84.3750) lr 6.4653e-04 eta 0:06:28
epoch [125/200] batch [2/3] time 1.431 (1.571) data 0.000 (0.146) loss 0.3425 (0.3934) acc 93.7500 (89.0625) lr 6.4653e-04 eta 0:05:55
epoch [125/200] batch [3/3] time 1.431 (1.524) data 0.000 (0.097) loss 0.2090 (0.3319) acc 96.8750 (91.6667) lr 6.3188e-04 eta 0:05:42
epoch [126/200] batch [1/3] time 1.712 (1.712) data 0.285 (0.285) loss 0.0592 (0.0592) acc 100.0000 (100.0000) lr 6.3188e-04 eta 0:06:23
epoch [126/200] batch [2/3] time 1.431 (1.571) data 0.000 (0.143) loss 0.1455 (0.1024) acc 96.8750 (98.4375) lr 6.3188e-04 eta 0:05:50
epoch [126/200] batch [3/3] time 1.424 (1.522) data 0.000 (0.095) loss 0.3040 (0.1696) acc 93.7500 (96.8750) lr 6.1732e-04 eta 0:05:37
epoch [127/200] batch [1/3] time 1.714 (1.714) data 0.285 (0.285) loss 0.2534 (0.2534) acc 90.6250 (90.6250) lr 6.1732e-04 eta 0:06:18
epoch [127/200] batch [2/3] time 1.431 (1.572) data 0.000 (0.143) loss 0.1753 (0.2144) acc 93.7500 (92.1875) lr 6.1732e-04 eta 0:05:45
epoch [127/200] batch [3/3] time 1.421 (1.522) data 0.000 (0.095) loss 0.2913 (0.2400) acc 90.6250 (91.6667) lr 6.0285e-04 eta 0:05:33
epoch [128/200] batch [1/3] time 1.704 (1.704) data 0.284 (0.284) loss 0.1530 (0.1530) acc 100.0000 (100.0000) lr 6.0285e-04 eta 0:06:11
epoch [128/200] batch [2/3] time 1.430 (1.567) data 0.000 (0.142) loss 0.3086 (0.2308) acc 96.8750 (98.4375) lr 6.0285e-04 eta 0:05:39
epoch [128/200] batch [3/3] time 1.419 (1.517) data 0.000 (0.095) loss 0.1730 (0.2115) acc 93.7500 (96.8750) lr 5.8849e-04 eta 0:05:27
epoch [129/200] batch [1/3] time 1.696 (1.696) data 0.274 (0.274) loss 0.1906 (0.1906) acc 93.7500 (93.7500) lr 5.8849e-04 eta 0:06:04
epoch [129/200] batch [2/3] time 1.431 (1.564) data 0.000 (0.137) loss 0.0514 (0.1210) acc 100.0000 (96.8750) lr 5.8849e-04 eta 0:05:34
epoch [129/200] batch [3/3] time 1.429 (1.519) data 0.000 (0.091) loss 0.1404 (0.1275) acc 96.8750 (96.8750) lr 5.7422e-04 eta 0:05:23
epoch [130/200] batch [1/3] time 1.713 (1.713) data 0.284 (0.284) loss 0.0864 (0.0864) acc 100.0000 (100.0000) lr 5.7422e-04 eta 0:06:03
epoch [130/200] batch [2/3] time 1.430 (1.571) data 0.000 (0.142) loss 0.1477 (0.1170) acc 96.8750 (98.4375) lr 5.7422e-04 eta 0:05:31
epoch [130/200] batch [3/3] time 1.421 (1.521) data 0.000 (0.095) loss 0.3418 (0.1920) acc 90.6250 (95.8333) lr 5.6006e-04 eta 0:05:19
epoch [131/200] batch [1/3] time 1.709 (1.709) data 0.284 (0.284) loss 0.1604 (0.1604) acc 93.7500 (93.7500) lr 5.6006e-04 eta 0:05:57
epoch [131/200] batch [2/3] time 1.431 (1.570) data 0.000 (0.142) loss 0.1558 (0.1581) acc 93.7500 (93.7500) lr 5.6006e-04 eta 0:05:26
epoch [131/200] batch [3/3] time 1.425 (1.522) data 0.000 (0.095) loss 0.3447 (0.2203) acc 90.6250 (92.7083) lr 5.4601e-04 eta 0:05:14
epoch [132/200] batch [1/3] time 1.703 (1.703) data 0.283 (0.283) loss 0.0890 (0.0890) acc 96.8750 (96.8750) lr 5.4601e-04 eta 0:05:50
epoch [132/200] batch [2/3] time 1.421 (1.562) data 0.000 (0.142) loss 0.3281 (0.2086) acc 90.6250 (93.7500) lr 5.4601e-04 eta 0:05:20
epoch [132/200] batch [3/3] time 1.430 (1.518) data 0.000 (0.094) loss 0.0366 (0.1512) acc 100.0000 (95.8333) lr 5.3207e-04 eta 0:05:09
epoch [133/200] batch [1/3] time 1.711 (1.711) data 0.283 (0.283) loss 0.2808 (0.2808) acc 90.6250 (90.6250) lr 5.3207e-04 eta 0:05:47
epoch [133/200] batch [2/3] time 1.431 (1.571) data 0.000 (0.142) loss 0.4114 (0.3461) acc 87.5000 (89.0625) lr 5.3207e-04 eta 0:05:17
epoch [133/200] batch [3/3] time 1.426 (1.522) data 0.000 (0.095) loss 0.0423 (0.2448) acc 100.0000 (92.7083) lr 5.1825e-04 eta 0:05:06
epoch [134/200] batch [1/3] time 1.703 (1.703) data 0.284 (0.284) loss 0.0784 (0.0784) acc 100.0000 (100.0000) lr 5.1825e-04 eta 0:05:40
epoch [134/200] batch [2/3] time 1.424 (1.563) data 0.000 (0.142) loss 0.3577 (0.2180) acc 90.6250 (95.3125) lr 5.1825e-04 eta 0:05:11
epoch [134/200] batch [3/3] time 1.428 (1.518) data 0.000 (0.095) loss 0.1157 (0.1839) acc 96.8750 (95.8333) lr 5.0454e-04 eta 0:05:00
epoch [135/200] batch [1/3] time 1.707 (1.707) data 0.286 (0.286) loss 0.2169 (0.2169) acc 96.8750 (96.8750) lr 5.0454e-04 eta 0:05:36
epoch [135/200] batch [2/3] time 1.419 (1.563) data 0.000 (0.143) loss 0.1148 (0.1659) acc 96.8750 (96.8750) lr 5.0454e-04 eta 0:05:06
epoch [135/200] batch [3/3] time 1.426 (1.517) data 0.000 (0.096) loss 0.2585 (0.1968) acc 93.7500 (95.8333) lr 4.9096e-04 eta 0:04:55
epoch [136/200] batch [1/3] time 1.698 (1.698) data 0.278 (0.278) loss 0.3123 (0.3123) acc 87.5000 (87.5000) lr 4.9096e-04 eta 0:05:29
epoch [136/200] batch [2/3] time 1.425 (1.562) data 0.000 (0.139) loss 0.3279 (0.3201) acc 90.6250 (89.0625) lr 4.9096e-04 eta 0:05:01
epoch [136/200] batch [3/3] time 1.427 (1.517) data 0.000 (0.093) loss 0.2007 (0.2803) acc 93.7500 (90.6250) lr 4.7750e-04 eta 0:04:51
epoch [137/200] batch [1/3] time 1.703 (1.703) data 0.277 (0.277) loss 0.2087 (0.2087) acc 93.7500 (93.7500) lr 4.7750e-04 eta 0:05:25
epoch [137/200] batch [2/3] time 1.430 (1.566) data 0.000 (0.138) loss 0.1825 (0.1956) acc 96.8750 (95.3125) lr 4.7750e-04 eta 0:04:57
epoch [137/200] batch [3/3] time 1.429 (1.521) data 0.000 (0.092) loss 0.1434 (0.1782) acc 96.8750 (95.8333) lr 4.6417e-04 eta 0:04:47
epoch [138/200] batch [1/3] time 1.706 (1.706) data 0.276 (0.276) loss 0.2466 (0.2466) acc 93.7500 (93.7500) lr 4.6417e-04 eta 0:05:20
epoch [138/200] batch [2/3] time 1.425 (1.566) data 0.000 (0.138) loss 0.1761 (0.2114) acc 96.8750 (95.3125) lr 4.6417e-04 eta 0:04:52
epoch [138/200] batch [3/3] time 1.421 (1.518) data 0.000 (0.092) loss 0.2913 (0.2380) acc 90.6250 (93.7500) lr 4.5098e-04 eta 0:04:42
epoch [139/200] batch [1/3] time 1.704 (1.704) data 0.276 (0.276) loss 0.0779 (0.0779) acc 96.8750 (96.8750) lr 4.5098e-04 eta 0:05:15
epoch [139/200] batch [2/3] time 1.428 (1.566) data 0.000 (0.138) loss 0.2542 (0.1660) acc 93.7500 (95.3125) lr 4.5098e-04 eta 0:04:48
epoch [139/200] batch [3/3] time 1.427 (1.520) data 0.000 (0.092) loss 0.4998 (0.2773) acc 90.6250 (93.7500) lr 4.3792e-04 eta 0:04:38
epoch [140/200] batch [1/3] time 1.697 (1.697) data 0.275 (0.275) loss 0.0691 (0.0691) acc 96.8750 (96.8750) lr 4.3792e-04 eta 0:05:08
epoch [140/200] batch [2/3] time 1.419 (1.558) data 0.000 (0.138) loss 0.2693 (0.1692) acc 90.6250 (93.7500) lr 4.3792e-04 eta 0:04:41
epoch [140/200] batch [3/3] time 1.425 (1.514) data 0.000 (0.092) loss 0.3572 (0.2319) acc 93.7500 (93.7500) lr 4.2499e-04 eta 0:04:32
epoch [141/200] batch [1/3] time 1.710 (1.710) data 0.284 (0.284) loss 0.4587 (0.4587) acc 87.5000 (87.5000) lr 4.2499e-04 eta 0:05:06
epoch [141/200] batch [2/3] time 1.424 (1.567) data 0.000 (0.142) loss 0.0843 (0.2715) acc 96.8750 (92.1875) lr 4.2499e-04 eta 0:04:38
epoch [141/200] batch [3/3] time 1.423 (1.519) data 0.000 (0.095) loss 0.2930 (0.2787) acc 90.6250 (91.6667) lr 4.1221e-04 eta 0:04:28
epoch [142/200] batch [1/3] time 1.703 (1.703) data 0.275 (0.275) loss 0.2018 (0.2018) acc 96.8750 (96.8750) lr 4.1221e-04 eta 0:04:59
epoch [142/200] batch [2/3] time 1.423 (1.563) data 0.000 (0.138) loss 0.1583 (0.1801) acc 96.8750 (96.8750) lr 4.1221e-04 eta 0:04:33
epoch [142/200] batch [3/3] time 1.414 (1.513) data 0.000 (0.092) loss 0.3149 (0.2250) acc 93.7500 (95.8333) lr 3.9958e-04 eta 0:04:23
epoch [143/200] batch [1/3] time 1.699 (1.699) data 0.274 (0.274) loss 0.2390 (0.2390) acc 93.7500 (93.7500) lr 3.9958e-04 eta 0:04:53
epoch [143/200] batch [2/3] time 1.428 (1.563) data 0.000 (0.137) loss 0.3716 (0.3053) acc 93.7500 (93.7500) lr 3.9958e-04 eta 0:04:28
epoch [143/200] batch [3/3] time 1.425 (1.517) data 0.000 (0.092) loss 0.2937 (0.3014) acc 90.6250 (92.7083) lr 3.8709e-04 eta 0:04:19
epoch [144/200] batch [1/3] time 1.715 (1.715) data 0.287 (0.287) loss 0.1957 (0.1957) acc 96.8750 (96.8750) lr 3.8709e-04 eta 0:04:51
epoch [144/200] batch [2/3] time 1.425 (1.570) data 0.000 (0.144) loss 0.2468 (0.2213) acc 93.7500 (95.3125) lr 3.8709e-04 eta 0:04:25
epoch [144/200] batch [3/3] time 1.424 (1.521) data 0.000 (0.096) loss 0.4082 (0.2836) acc 84.3750 (91.6667) lr 3.7476e-04 eta 0:04:15
epoch [145/200] batch [1/3] time 1.716 (1.716) data 0.297 (0.297) loss 0.0818 (0.0818) acc 100.0000 (100.0000) lr 3.7476e-04 eta 0:04:46
epoch [145/200] batch [2/3] time 1.424 (1.570) data 0.000 (0.148) loss 0.2358 (0.1588) acc 90.6250 (95.3125) lr 3.7476e-04 eta 0:04:20
epoch [145/200] batch [3/3] time 1.422 (1.521) data 0.000 (0.099) loss 0.0854 (0.1343) acc 96.8750 (95.8333) lr 3.6258e-04 eta 0:04:10
epoch [146/200] batch [1/3] time 1.708 (1.708) data 0.291 (0.291) loss 0.1147 (0.1147) acc 100.0000 (100.0000) lr 3.6258e-04 eta 0:04:40
epoch [146/200] batch [2/3] time 1.432 (1.570) data 0.000 (0.146) loss 0.2549 (0.1848) acc 93.7500 (96.8750) lr 3.6258e-04 eta 0:04:15
epoch [146/200] batch [3/3] time 1.433 (1.524) data 0.000 (0.097) loss 0.2050 (0.1915) acc 96.8750 (96.8750) lr 3.5055e-04 eta 0:04:06
epoch [147/200] batch [1/3] time 1.696 (1.696) data 0.276 (0.276) loss 0.2069 (0.2069) acc 90.6250 (90.6250) lr 3.5055e-04 eta 0:04:33
epoch [147/200] batch [2/3] time 1.427 (1.562) data 0.000 (0.138) loss 0.4175 (0.3122) acc 90.6250 (90.6250) lr 3.5055e-04 eta 0:04:09
epoch [147/200] batch [3/3] time 1.425 (1.516) data 0.000 (0.092) loss 0.0444 (0.2229) acc 100.0000 (93.7500) lr 3.3869e-04 eta 0:04:01
epoch [148/200] batch [1/3] time 1.697 (1.697) data 0.276 (0.276) loss 0.1233 (0.1233) acc 96.8750 (96.8750) lr 3.3869e-04 eta 0:04:28
epoch [148/200] batch [2/3] time 1.419 (1.558) data 0.000 (0.138) loss 0.4053 (0.2643) acc 87.5000 (92.1875) lr 3.3869e-04 eta 0:04:04
epoch [148/200] batch [3/3] time 1.424 (1.513) data 0.000 (0.092) loss 0.0667 (0.1984) acc 96.8750 (93.7500) lr 3.2699e-04 eta 0:03:56
epoch [149/200] batch [1/3] time 1.708 (1.708) data 0.290 (0.290) loss 0.2068 (0.2068) acc 96.8750 (96.8750) lr 3.2699e-04 eta 0:04:24
epoch [149/200] batch [2/3] time 1.424 (1.566) data 0.000 (0.145) loss 0.0378 (0.1223) acc 100.0000 (98.4375) lr 3.2699e-04 eta 0:04:01
epoch [149/200] batch [3/3] time 1.429 (1.520) data 0.000 (0.097) loss 0.4404 (0.2283) acc 90.6250 (95.8333) lr 3.1545e-04 eta 0:03:52
epoch [150/200] batch [1/3] time 1.700 (1.700) data 0.276 (0.276) loss 0.3018 (0.3018) acc 96.8750 (96.8750) lr 3.1545e-04 eta 0:04:18
epoch [150/200] batch [2/3] time 1.428 (1.564) data 0.000 (0.138) loss 0.2092 (0.2555) acc 96.8750 (96.8750) lr 3.1545e-04 eta 0:03:56
epoch [150/200] batch [3/3] time 1.428 (1.519) data 0.000 (0.092) loss 0.1294 (0.2135) acc 96.8750 (96.8750) lr 3.0409e-04 eta 0:03:47
epoch [151/200] batch [1/3] time 1.709 (1.709) data 0.282 (0.282) loss 0.1302 (0.1302) acc 93.7500 (93.7500) lr 3.0409e-04 eta 0:04:14
epoch [151/200] batch [2/3] time 1.422 (1.566) data 0.000 (0.141) loss 0.3259 (0.2281) acc 93.7500 (93.7500) lr 3.0409e-04 eta 0:03:51
epoch [151/200] batch [3/3] time 1.430 (1.520) data 0.000 (0.094) loss 0.4609 (0.3057) acc 87.5000 (91.6667) lr 2.9289e-04 eta 0:03:43
epoch [152/200] batch [1/3] time 1.706 (1.706) data 0.276 (0.276) loss 0.1936 (0.1936) acc 96.8750 (96.8750) lr 2.9289e-04 eta 0:04:09
epoch [152/200] batch [2/3] time 1.426 (1.566) data 0.000 (0.138) loss 0.2769 (0.2352) acc 93.7500 (95.3125) lr 2.9289e-04 eta 0:03:47
epoch [152/200] batch [3/3] time 1.425 (1.519) data 0.000 (0.092) loss 0.1279 (0.1995) acc 96.8750 (95.8333) lr 2.8187e-04 eta 0:03:38
epoch [153/200] batch [1/3] time 1.696 (1.696) data 0.277 (0.277) loss 0.2390 (0.2390) acc 96.8750 (96.8750) lr 2.8187e-04 eta 0:04:02
epoch [153/200] batch [2/3] time 1.422 (1.559) data 0.000 (0.139) loss 0.1615 (0.2003) acc 96.8750 (96.8750) lr 2.8187e-04 eta 0:03:41
epoch [153/200] batch [3/3] time 1.421 (1.513) data 0.000 (0.093) loss 0.2120 (0.2042) acc 96.8750 (96.8750) lr 2.7103e-04 eta 0:03:33
epoch [154/200] batch [1/3] time 1.714 (1.714) data 0.292 (0.292) loss 0.2498 (0.2498) acc 96.8750 (96.8750) lr 2.7103e-04 eta 0:03:59
epoch [154/200] batch [2/3] time 1.425 (1.569) data 0.000 (0.146) loss 0.0573 (0.1535) acc 100.0000 (98.4375) lr 2.7103e-04 eta 0:03:38
epoch [154/200] batch [3/3] time 1.426 (1.522) data 0.000 (0.097) loss 0.1970 (0.1680) acc 93.7500 (96.8750) lr 2.6037e-04 eta 0:03:29
epoch [155/200] batch [1/3] time 1.707 (1.707) data 0.286 (0.286) loss 0.2064 (0.2064) acc 93.7500 (93.7500) lr 2.6037e-04 eta 0:03:53
epoch [155/200] batch [2/3] time 1.420 (1.564) data 0.000 (0.143) loss 0.3264 (0.2664) acc 93.7500 (93.7500) lr 2.6037e-04 eta 0:03:32
epoch [155/200] batch [3/3] time 1.426 (1.518) data 0.000 (0.095) loss 0.3379 (0.2902) acc 93.7500 (93.7500) lr 2.4989e-04 eta 0:03:24
epoch [156/200] batch [1/3] time 1.711 (1.711) data 0.284 (0.284) loss 0.1174 (0.1174) acc 100.0000 (100.0000) lr 2.4989e-04 eta 0:03:49
epoch [156/200] batch [2/3] time 1.423 (1.567) data 0.000 (0.142) loss 0.2810 (0.1992) acc 96.8750 (98.4375) lr 2.4989e-04 eta 0:03:28
epoch [156/200] batch [3/3] time 1.423 (1.519) data 0.000 (0.095) loss 0.1698 (0.1894) acc 96.8750 (97.9167) lr 2.3959e-04 eta 0:03:20
epoch [157/200] batch [1/3] time 1.706 (1.706) data 0.284 (0.284) loss 0.1182 (0.1182) acc 96.8750 (96.8750) lr 2.3959e-04 eta 0:03:43
epoch [157/200] batch [2/3] time 1.429 (1.567) data 0.000 (0.142) loss 0.4614 (0.2898) acc 87.5000 (92.1875) lr 2.3959e-04 eta 0:03:23
epoch [157/200] batch [3/3] time 1.429 (1.521) data 0.000 (0.095) loss 0.0403 (0.2066) acc 100.0000 (94.7917) lr 2.2949e-04 eta 0:03:16
epoch [158/200] batch [1/3] time 1.709 (1.709) data 0.284 (0.284) loss 0.0700 (0.0700) acc 100.0000 (100.0000) lr 2.2949e-04 eta 0:03:38
epoch [158/200] batch [2/3] time 1.423 (1.566) data 0.000 (0.142) loss 0.1587 (0.1143) acc 93.7500 (96.8750) lr 2.2949e-04 eta 0:03:18
epoch [158/200] batch [3/3] time 1.423 (1.518) data 0.000 (0.095) loss 0.1268 (0.1185) acc 93.7500 (95.8333) lr 2.1957e-04 eta 0:03:11
epoch [159/200] batch [1/3] time 1.702 (1.702) data 0.285 (0.285) loss 0.2472 (0.2472) acc 93.7500 (93.7500) lr 2.1957e-04 eta 0:03:32
epoch [159/200] batch [2/3] time 1.428 (1.565) data 0.000 (0.143) loss 0.2454 (0.2463) acc 93.7500 (93.7500) lr 2.1957e-04 eta 0:03:14
epoch [159/200] batch [3/3] time 1.416 (1.515) data 0.000 (0.095) loss 0.1367 (0.2098) acc 96.8750 (94.7917) lr 2.0984e-04 eta 0:03:06
epoch [160/200] batch [1/3] time 1.712 (1.712) data 0.283 (0.283) loss 0.0669 (0.0669) acc 100.0000 (100.0000) lr 2.0984e-04 eta 0:03:28
epoch [160/200] batch [2/3] time 1.424 (1.568) data 0.000 (0.142) loss 0.2452 (0.1561) acc 93.7500 (96.8750) lr 2.0984e-04 eta 0:03:09
epoch [160/200] batch [3/3] time 1.435 (1.524) data 0.000 (0.094) loss 0.0577 (0.1233) acc 100.0000 (97.9167) lr 2.0032e-04 eta 0:03:02
epoch [161/200] batch [1/3] time 1.712 (1.712) data 0.284 (0.284) loss 0.1464 (0.1464) acc 96.8750 (96.8750) lr 2.0032e-04 eta 0:03:23
epoch [161/200] batch [2/3] time 1.432 (1.572) data 0.000 (0.142) loss 0.2393 (0.1928) acc 93.7500 (95.3125) lr 2.0032e-04 eta 0:03:05
epoch [161/200] batch [3/3] time 1.422 (1.522) data 0.000 (0.095) loss 0.2781 (0.2212) acc 96.8750 (95.8333) lr 1.9098e-04 eta 0:02:58
epoch [162/200] batch [1/3] time 1.711 (1.711) data 0.293 (0.293) loss 0.0931 (0.0931) acc 96.8750 (96.8750) lr 1.9098e-04 eta 0:03:18
epoch [162/200] batch [2/3] time 1.424 (1.568) data 0.000 (0.147) loss 0.2971 (0.1951) acc 93.7500 (95.3125) lr 1.9098e-04 eta 0:03:00
epoch [162/200] batch [3/3] time 1.421 (1.519) data 0.000 (0.098) loss 0.1842 (0.1915) acc 96.8750 (95.8333) lr 1.8185e-04 eta 0:02:53
epoch [163/200] batch [1/3] time 1.716 (1.716) data 0.292 (0.292) loss 0.3276 (0.3276) acc 93.7500 (93.7500) lr 1.8185e-04 eta 0:03:13
epoch [163/200] batch [2/3] time 1.421 (1.569) data 0.000 (0.146) loss 0.1620 (0.2448) acc 93.7500 (93.7500) lr 1.8185e-04 eta 0:02:55
epoch [163/200] batch [3/3] time 1.426 (1.521) data 0.000 (0.097) loss 0.0908 (0.1935) acc 96.8750 (94.7917) lr 1.7292e-04 eta 0:02:48
epoch [164/200] batch [1/3] time 1.694 (1.694) data 0.274 (0.274) loss 0.3542 (0.3542) acc 90.6250 (90.6250) lr 1.7292e-04 eta 0:03:06
epoch [164/200] batch [2/3] time 1.421 (1.558) data 0.000 (0.137) loss 0.6265 (0.4904) acc 84.3750 (87.5000) lr 1.7292e-04 eta 0:02:49
epoch [164/200] batch [3/3] time 1.420 (1.512) data 0.000 (0.091) loss 0.2007 (0.3938) acc 96.8750 (90.6250) lr 1.6419e-04 eta 0:02:43
epoch [165/200] batch [1/3] time 1.712 (1.712) data 0.284 (0.284) loss 0.3774 (0.3774) acc 93.7500 (93.7500) lr 1.6419e-04 eta 0:03:03
epoch [165/200] batch [2/3] time 1.425 (1.569) data 0.000 (0.142) loss 0.1151 (0.2462) acc 96.8750 (95.3125) lr 1.6419e-04 eta 0:02:46
epoch [165/200] batch [3/3] time 1.429 (1.522) data 0.000 (0.095) loss 0.4268 (0.3064) acc 87.5000 (92.7083) lr 1.5567e-04 eta 0:02:39
epoch [166/200] batch [1/3] time 1.717 (1.717) data 0.296 (0.296) loss 0.0312 (0.0312) acc 100.0000 (100.0000) lr 1.5567e-04 eta 0:02:58
epoch [166/200] batch [2/3] time 1.428 (1.572) data 0.000 (0.148) loss 0.1565 (0.0938) acc 93.7500 (96.8750) lr 1.5567e-04 eta 0:02:41
epoch [166/200] batch [3/3] time 1.430 (1.525) data 0.000 (0.099) loss 0.1793 (0.1223) acc 96.8750 (96.8750) lr 1.4736e-04 eta 0:02:35
epoch [167/200] batch [1/3] time 1.710 (1.710) data 0.285 (0.285) loss 0.1459 (0.1459) acc 96.8750 (96.8750) lr 1.4736e-04 eta 0:02:52
epoch [167/200] batch [2/3] time 1.424 (1.567) data 0.000 (0.143) loss 0.3320 (0.2390) acc 96.8750 (96.8750) lr 1.4736e-04 eta 0:02:36
epoch [167/200] batch [3/3] time 1.423 (1.519) data 0.000 (0.095) loss 0.0318 (0.1699) acc 100.0000 (97.9167) lr 1.3926e-04 eta 0:02:30
epoch [168/200] batch [1/3] time 1.717 (1.717) data 0.291 (0.291) loss 0.5225 (0.5225) acc 90.6250 (90.6250) lr 1.3926e-04 eta 0:02:48
epoch [168/200] batch [2/3] time 1.429 (1.573) data 0.000 (0.146) loss 0.1583 (0.3404) acc 96.8750 (93.7500) lr 1.3926e-04 eta 0:02:32
epoch [168/200] batch [3/3] time 1.423 (1.523) data 0.000 (0.097) loss 0.1818 (0.2875) acc 96.8750 (94.7917) lr 1.3137e-04 eta 0:02:26
epoch [169/200] batch [1/3] time 1.713 (1.713) data 0.285 (0.285) loss 0.1210 (0.1210) acc 96.8750 (96.8750) lr 1.3137e-04 eta 0:02:42
epoch [169/200] batch [2/3] time 1.419 (1.566) data 0.000 (0.143) loss 0.2433 (0.1822) acc 96.8750 (96.8750) lr 1.3137e-04 eta 0:02:27
epoch [169/200] batch [3/3] time 1.425 (1.519) data 0.000 (0.095) loss 0.1812 (0.1818) acc 93.7500 (95.8333) lr 1.2369e-04 eta 0:02:21
epoch [170/200] batch [1/3] time 1.710 (1.710) data 0.293 (0.293) loss 0.0101 (0.0101) acc 100.0000 (100.0000) lr 1.2369e-04 eta 0:02:37
epoch [170/200] batch [2/3] time 1.428 (1.569) data 0.000 (0.147) loss 0.0433 (0.0267) acc 100.0000 (100.0000) lr 1.2369e-04 eta 0:02:22
epoch [170/200] batch [3/3] time 1.428 (1.522) data 0.000 (0.098) loss 0.1077 (0.0537) acc 100.0000 (100.0000) lr 1.1623e-04 eta 0:02:16
epoch [171/200] batch [1/3] time 1.700 (1.700) data 0.276 (0.276) loss 0.1515 (0.1515) acc 96.8750 (96.8750) lr 1.1623e-04 eta 0:02:31
epoch [171/200] batch [2/3] time 1.424 (1.562) data 0.000 (0.138) loss 0.0596 (0.1056) acc 100.0000 (98.4375) lr 1.1623e-04 eta 0:02:17
epoch [171/200] batch [3/3] time 1.430 (1.518) data 0.000 (0.092) loss 0.2220 (0.1444) acc 93.7500 (96.8750) lr 1.0899e-04 eta 0:02:12
epoch [172/200] batch [1/3] time 1.711 (1.711) data 0.286 (0.286) loss 0.3328 (0.3328) acc 90.6250 (90.6250) lr 1.0899e-04 eta 0:02:27
epoch [172/200] batch [2/3] time 1.431 (1.571) data 0.000 (0.143) loss 0.1775 (0.2551) acc 93.7500 (92.1875) lr 1.0899e-04 eta 0:02:13
epoch [172/200] batch [3/3] time 1.422 (1.521) data 0.000 (0.095) loss 0.0609 (0.1904) acc 100.0000 (94.7917) lr 1.0197e-04 eta 0:02:07
epoch [173/200] batch [1/3] time 1.709 (1.709) data 0.283 (0.283) loss 0.0941 (0.0941) acc 100.0000 (100.0000) lr 1.0197e-04 eta 0:02:21
epoch [173/200] batch [2/3] time 1.435 (1.572) data 0.000 (0.141) loss 0.0876 (0.0909) acc 96.8750 (98.4375) lr 1.0197e-04 eta 0:02:08
epoch [173/200] batch [3/3] time 1.430 (1.525) data 0.000 (0.094) loss 0.1342 (0.1053) acc 96.8750 (97.9167) lr 9.5173e-05 eta 0:02:03
epoch [174/200] batch [1/3] time 1.703 (1.703) data 0.277 (0.277) loss 0.1038 (0.1038) acc 93.7500 (93.7500) lr 9.5173e-05 eta 0:02:16
epoch [174/200] batch [2/3] time 1.430 (1.566) data 0.000 (0.139) loss 0.1802 (0.1420) acc 93.7500 (93.7500) lr 9.5173e-05 eta 0:02:03
epoch [174/200] batch [3/3] time 1.428 (1.520) data 0.000 (0.093) loss 0.0475 (0.1105) acc 100.0000 (95.8333) lr 8.8597e-05 eta 0:01:58
epoch [175/200] batch [1/3] time 1.704 (1.704) data 0.275 (0.275) loss 0.2732 (0.2732) acc 90.6250 (90.6250) lr 8.8597e-05 eta 0:02:11
epoch [175/200] batch [2/3] time 1.429 (1.566) data 0.000 (0.138) loss 0.0623 (0.1677) acc 100.0000 (95.3125) lr 8.8597e-05 eta 0:01:59
epoch [175/200] batch [3/3] time 1.424 (1.519) data 0.000 (0.092) loss 0.0577 (0.1311) acc 100.0000 (96.8750) lr 8.2245e-05 eta 0:01:53
epoch [176/200] batch [1/3] time 1.699 (1.699) data 0.275 (0.275) loss 0.1949 (0.1949) acc 96.8750 (96.8750) lr 8.2245e-05 eta 0:02:05
epoch [176/200] batch [2/3] time 1.427 (1.563) data 0.000 (0.137) loss 0.2761 (0.2355) acc 90.6250 (93.7500) lr 8.2245e-05 eta 0:01:54
epoch [176/200] batch [3/3] time 1.427 (1.518) data 0.000 (0.092) loss 0.0609 (0.1773) acc 96.8750 (94.7917) lr 7.6120e-05 eta 0:01:49
epoch [177/200] batch [1/3] time 1.706 (1.706) data 0.284 (0.284) loss 0.1796 (0.1796) acc 96.8750 (96.8750) lr 7.6120e-05 eta 0:02:01
epoch [177/200] batch [2/3] time 1.422 (1.564) data 0.000 (0.142) loss 0.2556 (0.2176) acc 93.7500 (95.3125) lr 7.6120e-05 eta 0:01:49
epoch [177/200] batch [3/3] time 1.429 (1.519) data 0.000 (0.095) loss 0.0903 (0.1752) acc 100.0000 (96.8750) lr 7.0224e-05 eta 0:01:44
epoch [178/200] batch [1/3] time 1.698 (1.698) data 0.276 (0.276) loss 0.2368 (0.2368) acc 96.8750 (96.8750) lr 7.0224e-05 eta 0:01:55
epoch [178/200] batch [2/3] time 1.424 (1.561) data 0.000 (0.138) loss 0.1661 (0.2015) acc 96.8750 (96.8750) lr 7.0224e-05 eta 0:01:44
epoch [178/200] batch [3/3] time 1.428 (1.517) data 0.000 (0.092) loss 0.1066 (0.1698) acc 96.8750 (96.8750) lr 6.4556e-05 eta 0:01:40
epoch [179/200] batch [1/3] time 1.702 (1.702) data 0.285 (0.285) loss 0.1956 (0.1956) acc 96.8750 (96.8750) lr 6.4556e-05 eta 0:01:50
epoch [179/200] batch [2/3] time 1.432 (1.567) data 0.000 (0.143) loss 0.2262 (0.2109) acc 90.6250 (93.7500) lr 6.4556e-05 eta 0:01:40
epoch [179/200] batch [3/3] time 1.432 (1.522) data 0.000 (0.095) loss 0.1819 (0.2012) acc 90.6250 (92.7083) lr 5.9119e-05 eta 0:01:35
epoch [180/200] batch [1/3] time 1.718 (1.718) data 0.293 (0.293) loss 0.0717 (0.0717) acc 96.8750 (96.8750) lr 5.9119e-05 eta 0:01:46
epoch [180/200] batch [2/3] time 1.426 (1.572) data 0.000 (0.147) loss 0.1289 (0.1003) acc 96.8750 (96.8750) lr 5.9119e-05 eta 0:01:35
epoch [180/200] batch [3/3] time 1.424 (1.523) data 0.000 (0.098) loss 0.0186 (0.0731) acc 100.0000 (97.9167) lr 5.3915e-05 eta 0:01:31
epoch [181/200] batch [1/3] time 1.719 (1.719) data 0.292 (0.292) loss 0.3438 (0.3438) acc 90.6250 (90.6250) lr 5.3915e-05 eta 0:01:41
epoch [181/200] batch [2/3] time 1.425 (1.572) data 0.000 (0.146) loss 0.0632 (0.2035) acc 96.8750 (93.7500) lr 5.3915e-05 eta 0:01:31
epoch [181/200] batch [3/3] time 1.421 (1.522) data 0.000 (0.097) loss 0.4824 (0.2964) acc 90.6250 (92.7083) lr 4.8943e-05 eta 0:01:26
epoch [182/200] batch [1/3] time 1.721 (1.721) data 0.291 (0.291) loss 0.3174 (0.3174) acc 93.7500 (93.7500) lr 4.8943e-05 eta 0:01:36
epoch [182/200] batch [2/3] time 1.425 (1.573) data 0.000 (0.146) loss 0.1108 (0.2141) acc 93.7500 (93.7500) lr 4.8943e-05 eta 0:01:26
epoch [182/200] batch [3/3] time 1.423 (1.523) data 0.000 (0.097) loss 0.3630 (0.2637) acc 93.7500 (93.7500) lr 4.4207e-05 eta 0:01:22
epoch [183/200] batch [1/3] time 1.711 (1.711) data 0.292 (0.292) loss 0.0569 (0.0569) acc 100.0000 (100.0000) lr 4.4207e-05 eta 0:01:30
epoch [183/200] batch [2/3] time 1.427 (1.569) data 0.000 (0.146) loss 0.3713 (0.2141) acc 93.7500 (96.8750) lr 4.4207e-05 eta 0:01:21
epoch [183/200] batch [3/3] time 1.426 (1.521) data 0.000 (0.097) loss 0.2825 (0.2369) acc 90.6250 (94.7917) lr 3.9706e-05 eta 0:01:17
epoch [184/200] batch [1/3] time 1.712 (1.712) data 0.291 (0.291) loss 0.3450 (0.3450) acc 87.5000 (87.5000) lr 3.9706e-05 eta 0:01:25
epoch [184/200] batch [2/3] time 1.421 (1.566) data 0.000 (0.146) loss 0.2380 (0.2915) acc 90.6250 (89.0625) lr 3.9706e-05 eta 0:01:16
epoch [184/200] batch [3/3] time 1.432 (1.521) data 0.000 (0.097) loss 0.0207 (0.2012) acc 100.0000 (92.7083) lr 3.5443e-05 eta 0:01:13
epoch [185/200] batch [1/3] time 1.720 (1.720) data 0.285 (0.285) loss 0.3235 (0.3235) acc 93.7500 (93.7500) lr 3.5443e-05 eta 0:01:20
epoch [185/200] batch [2/3] time 1.423 (1.571) data 0.000 (0.142) loss 0.1819 (0.2527) acc 93.7500 (93.7500) lr 3.5443e-05 eta 0:01:12
epoch [185/200] batch [3/3] time 1.425 (1.523) data 0.000 (0.095) loss 0.3386 (0.2813) acc 90.6250 (92.7083) lr 3.1417e-05 eta 0:01:08
epoch [186/200] batch [1/3] time 1.712 (1.712) data 0.285 (0.285) loss 0.2622 (0.2622) acc 90.6250 (90.6250) lr 3.1417e-05 eta 0:01:15
epoch [186/200] batch [2/3] time 1.427 (1.569) data 0.000 (0.142) loss 0.3550 (0.3086) acc 96.8750 (93.7500) lr 3.1417e-05 eta 0:01:07
epoch [186/200] batch [3/3] time 1.426 (1.521) data 0.000 (0.095) loss 0.1305 (0.2492) acc 96.8750 (94.7917) lr 2.7630e-05 eta 0:01:03
epoch [187/200] batch [1/3] time 1.708 (1.708) data 0.284 (0.284) loss 0.1558 (0.1558) acc 96.8750 (96.8750) lr 2.7630e-05 eta 0:01:10
epoch [187/200] batch [2/3] time 1.424 (1.566) data 0.000 (0.142) loss 0.0863 (0.1210) acc 100.0000 (98.4375) lr 2.7630e-05 eta 0:01:02
epoch [187/200] batch [3/3] time 1.424 (1.519) data 0.000 (0.095) loss 0.1622 (0.1348) acc 96.8750 (97.9167) lr 2.4083e-05 eta 0:00:59
epoch [188/200] batch [1/3] time 1.701 (1.701) data 0.277 (0.277) loss 0.3042 (0.3042) acc 93.7500 (93.7500) lr 2.4083e-05 eta 0:01:04
epoch [188/200] batch [2/3] time 1.427 (1.564) data 0.000 (0.139) loss 0.4138 (0.3590) acc 90.6250 (92.1875) lr 2.4083e-05 eta 0:00:57
epoch [188/200] batch [3/3] time 1.422 (1.517) data 0.000 (0.092) loss 0.1338 (0.2839) acc 96.8750 (93.7500) lr 2.0777e-05 eta 0:00:54
epoch [189/200] batch [1/3] time 1.717 (1.717) data 0.292 (0.292) loss 0.5488 (0.5488) acc 87.5000 (87.5000) lr 2.0777e-05 eta 0:01:00
epoch [189/200] batch [2/3] time 1.420 (1.569) data 0.000 (0.146) loss 0.0403 (0.2946) acc 100.0000 (93.7500) lr 2.0777e-05 eta 0:00:53
epoch [189/200] batch [3/3] time 1.423 (1.520) data 0.000 (0.097) loss 0.2815 (0.2902) acc 93.7500 (93.7500) lr 1.7713e-05 eta 0:00:50
epoch [190/200] batch [1/3] time 1.720 (1.720) data 0.293 (0.293) loss 0.3264 (0.3264) acc 87.5000 (87.5000) lr 1.7713e-05 eta 0:00:55
epoch [190/200] batch [2/3] time 1.429 (1.575) data 0.000 (0.146) loss 0.1214 (0.2239) acc 100.0000 (93.7500) lr 1.7713e-05 eta 0:00:48
epoch [190/200] batch [3/3] time 1.433 (1.527) data 0.000 (0.098) loss 0.0800 (0.1759) acc 100.0000 (95.8333) lr 1.4891e-05 eta 0:00:45
epoch [191/200] batch [1/3] time 1.695 (1.695) data 0.274 (0.274) loss 0.1379 (0.1379) acc 96.8750 (96.8750) lr 1.4891e-05 eta 0:00:49
epoch [191/200] batch [2/3] time 1.429 (1.562) data 0.000 (0.137) loss 0.1312 (0.1346) acc 96.8750 (96.8750) lr 1.4891e-05 eta 0:00:43
epoch [191/200] batch [3/3] time 1.424 (1.516) data 0.000 (0.092) loss 0.3704 (0.2132) acc 90.6250 (94.7917) lr 1.2312e-05 eta 0:00:40
epoch [192/200] batch [1/3] time 1.696 (1.696) data 0.276 (0.276) loss 0.3694 (0.3694) acc 93.7500 (93.7500) lr 1.2312e-05 eta 0:00:44
epoch [192/200] batch [2/3] time 1.421 (1.558) data 0.000 (0.138) loss 0.7827 (0.5760) acc 81.2500 (87.5000) lr 1.2312e-05 eta 0:00:38
epoch [192/200] batch [3/3] time 1.433 (1.517) data 0.000 (0.092) loss 0.2690 (0.4737) acc 93.7500 (89.5833) lr 9.9763e-06 eta 0:00:36
epoch [193/200] batch [1/3] time 1.694 (1.694) data 0.275 (0.275) loss 0.4185 (0.4185) acc 93.7500 (93.7500) lr 9.9763e-06 eta 0:00:38
epoch [193/200] batch [2/3] time 1.421 (1.558) data 0.000 (0.137) loss 0.1931 (0.3058) acc 93.7500 (93.7500) lr 9.9763e-06 eta 0:00:34
epoch [193/200] batch [3/3] time 1.424 (1.513) data 0.000 (0.092) loss 0.3875 (0.3330) acc 90.6250 (92.7083) lr 7.8853e-06 eta 0:00:31
epoch [194/200] batch [1/3] time 1.703 (1.703) data 0.275 (0.275) loss 0.2029 (0.2029) acc 93.7500 (93.7500) lr 7.8853e-06 eta 0:00:34
epoch [194/200] batch [2/3] time 1.432 (1.568) data 0.000 (0.138) loss 0.0411 (0.1220) acc 100.0000 (96.8750) lr 7.8853e-06 eta 0:00:29
epoch [194/200] batch [3/3] time 1.425 (1.520) data 0.000 (0.092) loss 0.1062 (0.1167) acc 96.8750 (96.8750) lr 6.0390e-06 eta 0:00:27
epoch [195/200] batch [1/3] time 1.720 (1.720) data 0.285 (0.285) loss 0.1510 (0.1510) acc 96.8750 (96.8750) lr 6.0390e-06 eta 0:00:29
epoch [195/200] batch [2/3] time 1.424 (1.572) data 0.000 (0.143) loss 0.0351 (0.0930) acc 100.0000 (98.4375) lr 6.0390e-06 eta 0:00:25
epoch [195/200] batch [3/3] time 1.425 (1.523) data 0.000 (0.095) loss 0.1960 (0.1274) acc 96.8750 (97.9167) lr 4.4380e-06 eta 0:00:22
epoch [196/200] batch [1/3] time 1.712 (1.712) data 0.292 (0.292) loss 0.0984 (0.0984) acc 96.8750 (96.8750) lr 4.4380e-06 eta 0:00:23
epoch [196/200] batch [2/3] time 1.418 (1.565) data 0.000 (0.146) loss 0.1541 (0.1263) acc 96.8750 (96.8750) lr 4.4380e-06 eta 0:00:20
epoch [196/200] batch [3/3] time 1.424 (1.518) data 0.000 (0.097) loss 0.0760 (0.1095) acc 100.0000 (97.9167) lr 3.0827e-06 eta 0:00:18
epoch [197/200] batch [1/3] time 1.704 (1.704) data 0.283 (0.283) loss 0.1028 (0.1028) acc 96.8750 (96.8750) lr 3.0827e-06 eta 0:00:18
epoch [197/200] batch [2/3] time 1.421 (1.562) data 0.000 (0.141) loss 0.2744 (0.1886) acc 93.7500 (95.3125) lr 3.0827e-06 eta 0:00:15
epoch [197/200] batch [3/3] time 1.419 (1.514) data 0.000 (0.094) loss 0.2084 (0.1952) acc 96.8750 (95.8333) lr 1.9733e-06 eta 0:00:13
epoch [198/200] batch [1/3] time 1.704 (1.704) data 0.278 (0.278) loss 0.0588 (0.0588) acc 100.0000 (100.0000) lr 1.9733e-06 eta 0:00:13
epoch [198/200] batch [2/3] time 1.424 (1.564) data 0.000 (0.139) loss 0.2200 (0.1394) acc 93.7500 (96.8750) lr 1.9733e-06 eta 0:00:10
epoch [198/200] batch [3/3] time 1.428 (1.519) data 0.000 (0.093) loss 0.2502 (0.1764) acc 93.7500 (95.8333) lr 1.1101e-06 eta 0:00:09
epoch [199/200] batch [1/3] time 1.715 (1.715) data 0.289 (0.289) loss 0.0335 (0.0335) acc 100.0000 (100.0000) lr 1.1101e-06 eta 0:00:08
epoch [199/200] batch [2/3] time 1.424 (1.569) data 0.000 (0.145) loss 0.4233 (0.2284) acc 93.7500 (96.8750) lr 1.1101e-06 eta 0:00:06
epoch [199/200] batch [3/3] time 1.424 (1.521) data 0.000 (0.097) loss 0.1340 (0.1970) acc 96.8750 (96.8750) lr 4.9344e-07 eta 0:00:04
epoch [200/200] batch [1/3] time 1.695 (1.695) data 0.276 (0.276) loss 0.2920 (0.2920) acc 93.7500 (93.7500) lr 4.9344e-07 eta 0:00:03
epoch [200/200] batch [2/3] time 1.426 (1.560) data 0.000 (0.138) loss 0.1086 (0.2003) acc 96.8750 (95.3125) lr 4.9344e-07 eta 0:00:01
epoch [200/200] batch [3/3] time 1.422 (1.514) data 0.000 (0.092) loss 0.0690 (0.1565) acc 100.0000 (96.8750) lr 1.2337e-07 eta 0:00:00
Checkpoint saved to output/Caltech/1/2/3/prompt_learner/model.pth.tar-200
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
=> result
* total: 2,465
* correct: 2,258
* accuracy: 91.6%
* error: 8.4%
* macro_f1: 87.3%
Elapsed: 0:17:54
