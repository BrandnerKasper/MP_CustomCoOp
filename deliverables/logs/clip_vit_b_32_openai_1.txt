args2: backbone=, config_file=configs/trainers/CoOp/vit_b32.yaml, dataset_config_file=configs/datasets/caltech101.yaml, eval_only=False, head=, load_epoch=None, model_dir=, no_train=False,  opts: ['TRAINER.COOP.N_CTX', '16', 'TRAINER.COOP.CSC', 'False', 'TRAINER.COOP.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '1'], output_dir=output/Caltech/1, resume=, root=/home/brandnerkasper/Uni/MP/MP_CustomCoOp/data, seed=1, source_domains=None, target_domains=None, trainer=CoOp, transforms=None
Setting fixed seed: 1
***************
** Arguments **
***************
config_file: configs/trainers/CoOp/vit_b32.yaml
csc: False
ctp: end
dataset_config_file: configs/datasets/caltech101.yaml
n_ctx: 16
opts: ['TRAINER.COOP.N_CTX', '16', 'TRAINER.COOP.CSC', 'False', 'TRAINER.COOP.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '1']
output_dir: output/Caltech/1
root: /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data
seed: 1
shots: 1
trainer: CoOp
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 0
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 1
  ROOT: /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/32
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/Caltech/1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 2.0.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 22.04.3 LTS (x86_64)
GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.35

Python version: 3.10.12 (main, Jul  5 2023, 18:54:27) [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-6.2.0-32-generic-x86_64-with-glibc2.35
Is CUDA available: True
CUDA runtime version: 11.5.119
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce GTX 970
Nvidia driver version: 525.125.06
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                       x86_64
CPU op-mode(s):                     32-bit, 64-bit
Address sizes:                      39 bits physical, 48 bits virtual
Byte Order:                         Little Endian
CPU(s):                             4
On-line CPU(s) list:                0-3
Vendor ID:                          GenuineIntel
Model name:                         Intel(R) Xeon(R) CPU E3-1225 v3 @ 3.20GHz
CPU family:                         6
Model:                              60
Thread(s) per core:                 1
Core(s) per socket:                 4
Socket(s):                          1
Stepping:                           3
CPU max MHz:                        3600,0000
CPU min MHz:                        800,0000
BogoMIPS:                           6397.79
Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt dtherm ida arat pln pts md_clear flush_l1d
Virtualization:                     VT-x
L1d cache:                          128 KiB (4 instances)
L1i cache:                          128 KiB (4 instances)
L2 cache:                           1 MiB (4 instances)
L3 cache:                           8 MiB (1 instance)
NUMA node(s):                       1
NUMA node0 CPU(s):                  0-3
Vulnerability Gather data sampling: Not affected
Vulnerability Itlb multihit:        KVM: Mitigation: VMX disabled
Vulnerability L1tf:                 Mitigation; PTE Inversion; VMX conditional cache flushes, SMT disabled
Vulnerability Mds:                  Mitigation; Clear CPU buffers; SMT disabled
Vulnerability Meltdown:             Mitigation; PTI
Vulnerability Mmio stale data:      Unknown: No mitigations
Vulnerability Retbleed:             Not affected
Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl
Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:           Mitigation; Retpolines, IBPB conditional, IBRS_FW, STIBP disabled, RSB filling, PBRSB-eIBRS Not affected
Vulnerability Srbds:                Mitigation; Microcode
Vulnerability Tsx async abort:      Not affected

Versions of relevant libraries:
[pip3] numpy==1.25.2
[pip3] open-clip-torch==2.20.0
[pip3] torch==2.0.1
[pip3] torchaudio==2.0.2
[pip3] torchvision==0.15.2
[conda] blas                      1.0                         mkl  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] mkl                       2023.1.0         h213fc3f_46343  
[conda] mkl-service               2.4.0           py310h5eee18b_1  
[conda] mkl_fft                   1.3.6           py310h1128e8f_1  
[conda] mkl_random                1.2.2           py310h1128e8f_1  
[conda] numpy                     1.25.2          py310h5f9d8c6_0  
[conda] numpy-base                1.25.2          py310hb5e798b_0  
[conda] open-clip-torch           2.20.0                   pypi_0    pypi
[conda] pytorch                   2.0.1           py3.10_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchaudio                2.0.2               py310_cu117    pytorch
[conda] torchtriton               2.0.0                     py310    pytorch
[conda] torchvision               0.15.2              py310_cu117    pytorch
        Pillow (9.4.0)

Loading trainer: CoOp
Loading dataset: Caltech101
Reading split from /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data/caltech-101/split_zhou_Caltech101.json
Creating a 1-shot dataset
Creating a 1-shot dataset
Saving preprocessed few-shot data to /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data/caltech-101/split_fewshot/shot_1-seed_1.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  100
# train_x  100
# val      100
# test     2,465
---------  ----------
Loading CLIP (backbone: ViT-B/32)
CLIP(
  (visual): VisionTransformer(
    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (transformer): Transformer(
    (resblocks): Sequential(
      (0): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (6): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (7): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (8): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (9): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (10): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (11): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (token_embedding): Embedding(49408, 512)
  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
)
Building custom CLIP
Initializing a generic context
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Turning off gradients in both the image and the text encoder
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/Caltech/1/tensorboard)
epoch [1/200] batch [1/3] time 3.073 (3.073) data 0.426 (0.426) loss 3.1797 (3.1797) acc 28.1250 (28.1250) lr 1.0000e-05 eta 0:30:40
epoch [1/200] batch [2/3] time 0.824 (1.948) data 0.122 (0.274) loss 3.3906 (3.2852) acc 28.1250 (28.1250) lr 1.0000e-05 eta 0:19:25
epoch [1/200] batch [3/3] time 0.803 (1.567) data 0.098 (0.215) loss 2.5957 (3.0553) acc 50.0000 (35.4167) lr 2.0000e-03 eta 0:15:35
epoch [2/200] batch [1/3] time 0.795 (0.795) data 0.092 (0.092) loss 3.2168 (3.2168) acc 34.3750 (34.3750) lr 2.0000e-03 eta 0:07:54
epoch [2/200] batch [2/3] time 0.809 (0.802) data 0.105 (0.099) loss 1.8242 (2.5205) acc 59.3750 (46.8750) lr 2.0000e-03 eta 0:07:57
epoch [2/200] batch [3/3] time 0.812 (0.805) data 0.107 (0.102) loss 2.1055 (2.3822) acc 59.3750 (51.0417) lr 1.9999e-03 eta 0:07:58
epoch [3/200] batch [1/3] time 0.794 (0.794) data 0.090 (0.090) loss 1.4150 (1.4150) acc 71.8750 (71.8750) lr 1.9999e-03 eta 0:07:50
epoch [3/200] batch [2/3] time 0.791 (0.792) data 0.086 (0.088) loss 1.1572 (1.2861) acc 75.0000 (73.4375) lr 1.9999e-03 eta 0:07:49
epoch [3/200] batch [3/3] time 0.799 (0.795) data 0.095 (0.091) loss 1.3125 (1.2949) acc 65.6250 (70.8333) lr 1.9995e-03 eta 0:07:49
epoch [4/200] batch [1/3] time 0.801 (0.801) data 0.094 (0.094) loss 1.2148 (1.2148) acc 65.6250 (65.6250) lr 1.9995e-03 eta 0:07:52
epoch [4/200] batch [2/3] time 0.793 (0.797) data 0.086 (0.090) loss 1.3750 (1.2949) acc 65.6250 (65.6250) lr 1.9995e-03 eta 0:07:49
epoch [4/200] batch [3/3] time 0.870 (0.821) data 0.166 (0.115) loss 0.7192 (1.1030) acc 75.0000 (68.7500) lr 1.9989e-03 eta 0:08:03
epoch [5/200] batch [1/3] time 0.794 (0.794) data 0.087 (0.087) loss 0.9517 (0.9517) acc 78.1250 (78.1250) lr 1.9989e-03 eta 0:07:46
epoch [5/200] batch [2/3] time 0.827 (0.811) data 0.121 (0.104) loss 1.4521 (1.2019) acc 62.5000 (70.3125) lr 1.9989e-03 eta 0:07:55
epoch [5/200] batch [3/3] time 0.829 (0.817) data 0.118 (0.109) loss 1.0908 (1.1649) acc 68.7500 (69.7917) lr 1.9980e-03 eta 0:07:57
epoch [6/200] batch [1/3] time 0.800 (0.800) data 0.089 (0.089) loss 0.9927 (0.9927) acc 71.8750 (71.8750) lr 1.9980e-03 eta 0:07:46
epoch [6/200] batch [2/3] time 0.999 (0.899) data 0.285 (0.187) loss 0.9976 (0.9951) acc 71.8750 (71.8750) lr 1.9980e-03 eta 0:08:44
epoch [6/200] batch [3/3] time 0.798 (0.865) data 0.092 (0.155) loss 0.9785 (0.9896) acc 71.8750 (71.8750) lr 1.9969e-03 eta 0:08:23
epoch [7/200] batch [1/3] time 1.036 (1.036) data 0.221 (0.221) loss 0.7847 (0.7847) acc 78.1250 (78.1250) lr 1.9969e-03 eta 0:10:02
epoch [7/200] batch [2/3] time 1.206 (1.121) data 0.471 (0.346) loss 0.8784 (0.8315) acc 71.8750 (75.0000) lr 1.9969e-03 eta 0:10:50
epoch [7/200] batch [3/3] time 1.099 (1.114) data 0.367 (0.353) loss 0.9634 (0.8755) acc 65.6250 (71.8750) lr 1.9956e-03 eta 0:10:44
epoch [8/200] batch [1/3] time 0.863 (0.863) data 0.130 (0.130) loss 1.5117 (1.5117) acc 59.3750 (59.3750) lr 1.9956e-03 eta 0:08:18
epoch [8/200] batch [2/3] time 0.854 (0.858) data 0.123 (0.127) loss 1.1309 (1.3213) acc 65.6250 (62.5000) lr 1.9956e-03 eta 0:08:15
epoch [8/200] batch [3/3] time 0.837 (0.851) data 0.107 (0.120) loss 1.0166 (1.2197) acc 65.6250 (63.5417) lr 1.9940e-03 eta 0:08:10
epoch [9/200] batch [1/3] time 0.841 (0.841) data 0.107 (0.107) loss 1.0586 (1.0586) acc 71.8750 (71.8750) lr 1.9940e-03 eta 0:08:03
epoch [9/200] batch [2/3] time 0.869 (0.855) data 0.135 (0.121) loss 0.9736 (1.0161) acc 71.8750 (71.8750) lr 1.9940e-03 eta 0:08:10
epoch [9/200] batch [3/3] time 0.844 (0.851) data 0.111 (0.118) loss 0.5337 (0.8553) acc 87.5000 (77.0833) lr 1.9921e-03 eta 0:08:07
epoch [10/200] batch [1/3] time 0.846 (0.846) data 0.115 (0.115) loss 1.0928 (1.0928) acc 71.8750 (71.8750) lr 1.9921e-03 eta 0:08:04
epoch [10/200] batch [2/3] time 0.848 (0.847) data 0.109 (0.112) loss 0.7612 (0.9270) acc 78.1250 (75.0000) lr 1.9921e-03 eta 0:08:03
epoch [10/200] batch [3/3] time 0.849 (0.848) data 0.114 (0.113) loss 1.0254 (0.9598) acc 71.8750 (73.9583) lr 1.9900e-03 eta 0:08:03
epoch [11/200] batch [1/3] time 0.840 (0.840) data 0.103 (0.103) loss 0.3228 (0.3228) acc 96.8750 (96.8750) lr 1.9900e-03 eta 0:07:58
epoch [11/200] batch [2/3] time 0.877 (0.859) data 0.144 (0.124) loss 0.5327 (0.4277) acc 84.3750 (90.6250) lr 1.9900e-03 eta 0:08:07
epoch [11/200] batch [3/3] time 0.843 (0.853) data 0.109 (0.119) loss 0.9297 (0.5951) acc 78.1250 (86.4583) lr 1.9877e-03 eta 0:08:03
epoch [12/200] batch [1/3] time 0.839 (0.839) data 0.105 (0.105) loss 0.7363 (0.7363) acc 81.2500 (81.2500) lr 1.9877e-03 eta 0:07:54
epoch [12/200] batch [2/3] time 0.846 (0.842) data 0.115 (0.110) loss 0.6621 (0.6992) acc 84.3750 (82.8125) lr 1.9877e-03 eta 0:07:55
epoch [12/200] batch [3/3] time 0.849 (0.845) data 0.118 (0.113) loss 1.0254 (0.8079) acc 68.7500 (78.1250) lr 1.9851e-03 eta 0:07:56
epoch [13/200] batch [1/3] time 0.857 (0.857) data 0.125 (0.125) loss 0.8599 (0.8599) acc 71.8750 (71.8750) lr 1.9851e-03 eta 0:08:02
epoch [13/200] batch [2/3] time 0.838 (0.848) data 0.104 (0.114) loss 1.0625 (0.9612) acc 78.1250 (75.0000) lr 1.9851e-03 eta 0:07:56
epoch [13/200] batch [3/3] time 0.851 (0.849) data 0.110 (0.113) loss 0.4556 (0.7926) acc 84.3750 (78.1250) lr 1.9823e-03 eta 0:07:56
epoch [14/200] batch [1/3] time 0.841 (0.841) data 0.106 (0.106) loss 0.7544 (0.7544) acc 78.1250 (78.1250) lr 1.9823e-03 eta 0:07:51
epoch [14/200] batch [2/3] time 0.845 (0.843) data 0.111 (0.109) loss 0.6450 (0.6997) acc 84.3750 (81.2500) lr 1.9823e-03 eta 0:07:51
epoch [14/200] batch [3/3] time 0.841 (0.843) data 0.105 (0.108) loss 0.5605 (0.6533) acc 90.6250 (84.3750) lr 1.9792e-03 eta 0:07:50
epoch [15/200] batch [1/3] time 0.845 (0.845) data 0.110 (0.110) loss 0.6333 (0.6333) acc 84.3750 (84.3750) lr 1.9792e-03 eta 0:07:50
epoch [15/200] batch [2/3] time 0.874 (0.859) data 0.116 (0.113) loss 0.4883 (0.5608) acc 87.5000 (85.9375) lr 1.9792e-03 eta 0:07:57
epoch [15/200] batch [3/3] time 0.899 (0.872) data 0.138 (0.121) loss 0.6284 (0.5833) acc 81.2500 (84.3750) lr 1.9759e-03 eta 0:08:04
epoch [16/200] batch [1/3] time 0.891 (0.891) data 0.120 (0.120) loss 0.9404 (0.9404) acc 75.0000 (75.0000) lr 1.9759e-03 eta 0:08:13
epoch [16/200] batch [2/3] time 1.045 (0.968) data 0.324 (0.222) loss 0.6836 (0.8120) acc 81.2500 (78.1250) lr 1.9759e-03 eta 0:08:55
epoch [16/200] batch [3/3] time 0.810 (0.916) data 0.102 (0.182) loss 0.5298 (0.7179) acc 84.3750 (80.2083) lr 1.9724e-03 eta 0:08:25
epoch [17/200] batch [1/3] time 0.806 (0.806) data 0.092 (0.092) loss 0.6138 (0.6138) acc 84.3750 (84.3750) lr 1.9724e-03 eta 0:07:24
epoch [17/200] batch [2/3] time 0.831 (0.819) data 0.120 (0.106) loss 0.5591 (0.5864) acc 84.3750 (84.3750) lr 1.9724e-03 eta 0:07:30
epoch [17/200] batch [3/3] time 0.840 (0.826) data 0.095 (0.103) loss 0.6377 (0.6035) acc 84.3750 (84.3750) lr 1.9686e-03 eta 0:07:33
epoch [18/200] batch [1/3] time 0.858 (0.858) data 0.115 (0.115) loss 0.6963 (0.6963) acc 81.2500 (81.2500) lr 1.9686e-03 eta 0:07:50
epoch [18/200] batch [2/3] time 1.146 (1.002) data 0.356 (0.236) loss 0.7915 (0.7439) acc 78.1250 (79.6875) lr 1.9686e-03 eta 0:09:08
epoch [18/200] batch [3/3] time 0.938 (0.981) data 0.120 (0.197) loss 0.4534 (0.6471) acc 81.2500 (80.2083) lr 1.9646e-03 eta 0:08:55
epoch [19/200] batch [1/3] time 1.154 (1.154) data 0.319 (0.319) loss 0.9624 (0.9624) acc 68.7500 (68.7500) lr 1.9646e-03 eta 0:10:29
epoch [19/200] batch [2/3] time 1.323 (1.239) data 0.550 (0.435) loss 0.5308 (0.7466) acc 84.3750 (76.5625) lr 1.9646e-03 eta 0:11:13
epoch [19/200] batch [3/3] time 1.201 (1.226) data 0.378 (0.416) loss 0.6421 (0.7118) acc 84.3750 (79.1667) lr 1.9603e-03 eta 0:11:05
epoch [20/200] batch [1/3] time 0.884 (0.884) data 0.109 (0.109) loss 0.4907 (0.4907) acc 84.3750 (84.3750) lr 1.9603e-03 eta 0:07:58
epoch [20/200] batch [2/3] time 0.902 (0.893) data 0.104 (0.107) loss 1.2002 (0.8455) acc 68.7500 (76.5625) lr 1.9603e-03 eta 0:08:02
epoch [20/200] batch [3/3] time 1.161 (0.982) data 0.333 (0.182) loss 0.7876 (0.8262) acc 81.2500 (78.1250) lr 1.9558e-03 eta 0:08:50
epoch [21/200] batch [1/3] time 1.117 (1.117) data 0.317 (0.317) loss 0.6187 (0.6187) acc 81.2500 (81.2500) lr 1.9558e-03 eta 0:10:02
epoch [21/200] batch [2/3] time 1.654 (1.385) data 0.828 (0.572) loss 0.7290 (0.6738) acc 78.1250 (79.6875) lr 1.9558e-03 eta 0:12:25
epoch [21/200] batch [3/3] time 1.411 (1.394) data 0.664 (0.603) loss 0.4058 (0.5845) acc 90.6250 (83.3333) lr 1.9511e-03 eta 0:12:28
epoch [22/200] batch [1/3] time 1.028 (1.028) data 0.197 (0.197) loss 0.6914 (0.6914) acc 75.0000 (75.0000) lr 1.9511e-03 eta 0:09:10
epoch [22/200] batch [2/3] time 1.365 (1.197) data 0.574 (0.386) loss 0.9453 (0.8184) acc 75.0000 (75.0000) lr 1.9511e-03 eta 0:10:40
epoch [22/200] batch [3/3] time 1.490 (1.294) data 0.690 (0.487) loss 0.5435 (0.7267) acc 90.6250 (80.2083) lr 1.9461e-03 eta 0:11:31
epoch [23/200] batch [1/3] time 1.421 (1.421) data 0.613 (0.613) loss 0.6523 (0.6523) acc 84.3750 (84.3750) lr 1.9461e-03 eta 0:12:37
epoch [23/200] batch [2/3] time 1.321 (1.371) data 0.577 (0.595) loss 0.7812 (0.7168) acc 78.1250 (81.2500) lr 1.9461e-03 eta 0:12:09
epoch [23/200] batch [3/3] time 0.939 (1.227) data 0.225 (0.472) loss 0.4519 (0.6285) acc 84.3750 (82.2917) lr 1.9409e-03 eta 0:10:51
epoch [24/200] batch [1/3] time 0.802 (0.802) data 0.094 (0.094) loss 0.7734 (0.7734) acc 75.0000 (75.0000) lr 1.9409e-03 eta 0:07:05
epoch [24/200] batch [2/3] time 0.812 (0.807) data 0.092 (0.093) loss 0.2832 (0.5283) acc 90.6250 (82.8125) lr 1.9409e-03 eta 0:07:06
epoch [24/200] batch [3/3] time 0.854 (0.822) data 0.119 (0.102) loss 0.5806 (0.5457) acc 84.3750 (83.3333) lr 1.9354e-03 eta 0:07:14
epoch [25/200] batch [1/3] time 0.912 (0.912) data 0.194 (0.194) loss 0.7339 (0.7339) acc 71.8750 (71.8750) lr 1.9354e-03 eta 0:08:00
epoch [25/200] batch [2/3] time 0.811 (0.861) data 0.104 (0.149) loss 0.6611 (0.6975) acc 84.3750 (78.1250) lr 1.9354e-03 eta 0:07:33
epoch [25/200] batch [3/3] time 0.822 (0.848) data 0.092 (0.130) loss 0.2568 (0.5506) acc 96.8750 (84.3750) lr 1.9298e-03 eta 0:07:25
epoch [26/200] batch [1/3] time 0.855 (0.855) data 0.132 (0.132) loss 0.4712 (0.4712) acc 81.2500 (81.2500) lr 1.9298e-03 eta 0:07:27
epoch [26/200] batch [2/3] time 0.958 (0.906) data 0.123 (0.128) loss 0.9878 (0.7295) acc 78.1250 (79.6875) lr 1.9298e-03 eta 0:07:53
epoch [26/200] batch [3/3] time 0.967 (0.927) data 0.176 (0.144) loss 0.5894 (0.6828) acc 84.3750 (81.2500) lr 1.9239e-03 eta 0:08:03
epoch [27/200] batch [1/3] time 0.862 (0.862) data 0.109 (0.109) loss 0.3015 (0.3015) acc 90.6250 (90.6250) lr 1.9239e-03 eta 0:07:29
epoch [27/200] batch [2/3] time 0.886 (0.874) data 0.101 (0.105) loss 0.7520 (0.5267) acc 75.0000 (82.8125) lr 1.9239e-03 eta 0:07:34
epoch [27/200] batch [3/3] time 0.899 (0.883) data 0.104 (0.105) loss 1.0469 (0.7001) acc 75.0000 (80.2083) lr 1.9178e-03 eta 0:07:38
epoch [28/200] batch [1/3] time 0.939 (0.939) data 0.217 (0.217) loss 0.5898 (0.5898) acc 87.5000 (87.5000) lr 1.9178e-03 eta 0:08:06
epoch [28/200] batch [2/3] time 0.955 (0.947) data 0.132 (0.174) loss 0.8911 (0.7405) acc 75.0000 (81.2500) lr 1.9178e-03 eta 0:08:09
epoch [28/200] batch [3/3] time 0.954 (0.949) data 0.246 (0.198) loss 0.7529 (0.7446) acc 78.1250 (80.2083) lr 1.9114e-03 eta 0:08:09
epoch [29/200] batch [1/3] time 0.912 (0.912) data 0.101 (0.101) loss 0.7134 (0.7134) acc 87.5000 (87.5000) lr 1.9114e-03 eta 0:07:49
epoch [29/200] batch [2/3] time 1.059 (0.986) data 0.292 (0.197) loss 0.9092 (0.8113) acc 78.1250 (82.8125) lr 1.9114e-03 eta 0:08:26
epoch [29/200] batch [3/3] time 0.953 (0.975) data 0.243 (0.212) loss 0.4731 (0.6986) acc 87.5000 (84.3750) lr 1.9048e-03 eta 0:08:20
epoch [30/200] batch [1/3] time 0.863 (0.863) data 0.133 (0.133) loss 1.0449 (1.0449) acc 75.0000 (75.0000) lr 1.9048e-03 eta 0:07:22
epoch [30/200] batch [2/3] time 0.825 (0.844) data 0.094 (0.114) loss 0.4407 (0.7428) acc 84.3750 (79.6875) lr 1.9048e-03 eta 0:07:11
epoch [30/200] batch [3/3] time 1.024 (0.904) data 0.262 (0.163) loss 0.8511 (0.7789) acc 75.0000 (78.1250) lr 1.8980e-03 eta 0:07:41
epoch [31/200] batch [1/3] time 0.883 (0.883) data 0.144 (0.144) loss 0.5332 (0.5332) acc 84.3750 (84.3750) lr 1.8980e-03 eta 0:07:29
epoch [31/200] batch [2/3] time 0.839 (0.861) data 0.128 (0.136) loss 0.4233 (0.4783) acc 87.5000 (85.9375) lr 1.8980e-03 eta 0:07:17
epoch [31/200] batch [3/3] time 1.072 (0.931) data 0.206 (0.159) loss 0.2581 (0.4049) acc 93.7500 (88.5417) lr 1.8910e-03 eta 0:07:52
epoch [32/200] batch [1/3] time 0.934 (0.934) data 0.153 (0.153) loss 0.6470 (0.6470) acc 90.6250 (90.6250) lr 1.8910e-03 eta 0:07:52
epoch [32/200] batch [2/3] time 0.975 (0.955) data 0.153 (0.153) loss 0.7983 (0.7227) acc 81.2500 (85.9375) lr 1.8910e-03 eta 0:08:02
epoch [32/200] batch [3/3] time 0.985 (0.965) data 0.148 (0.151) loss 0.7539 (0.7331) acc 84.3750 (85.4167) lr 1.8838e-03 eta 0:08:06
epoch [33/200] batch [1/3] time 1.177 (1.177) data 0.316 (0.316) loss 0.3621 (0.3621) acc 87.5000 (87.5000) lr 1.8838e-03 eta 0:09:51
epoch [33/200] batch [2/3] time 0.905 (1.041) data 0.146 (0.231) loss 0.9189 (0.6405) acc 78.1250 (82.8125) lr 1.8838e-03 eta 0:08:42
epoch [33/200] batch [3/3] time 0.991 (1.024) data 0.272 (0.245) loss 0.6089 (0.6300) acc 87.5000 (84.3750) lr 1.8763e-03 eta 0:08:33
epoch [34/200] batch [1/3] time 0.888 (0.888) data 0.124 (0.124) loss 0.3860 (0.3860) acc 90.6250 (90.6250) lr 1.8763e-03 eta 0:07:24
epoch [34/200] batch [2/3] time 1.123 (1.006) data 0.298 (0.211) loss 0.7520 (0.5690) acc 78.1250 (84.3750) lr 1.8763e-03 eta 0:08:21
epoch [34/200] batch [3/3] time 0.982 (0.998) data 0.217 (0.213) loss 0.3894 (0.5091) acc 90.6250 (86.4583) lr 1.8686e-03 eta 0:08:16
epoch [35/200] batch [1/3] time 0.821 (0.821) data 0.094 (0.094) loss 0.1957 (0.1957) acc 93.7500 (93.7500) lr 1.8686e-03 eta 0:06:47
epoch [35/200] batch [2/3] time 0.844 (0.832) data 0.108 (0.101) loss 0.5010 (0.3483) acc 87.5000 (90.6250) lr 1.8686e-03 eta 0:06:52
epoch [35/200] batch [3/3] time 1.147 (0.937) data 0.388 (0.196) loss 1.0029 (0.5665) acc 78.1250 (86.4583) lr 1.8607e-03 eta 0:07:44
epoch [36/200] batch [1/3] time 0.993 (0.993) data 0.248 (0.248) loss 0.7251 (0.7251) acc 81.2500 (81.2500) lr 1.8607e-03 eta 0:08:10
epoch [36/200] batch [2/3] time 0.828 (0.910) data 0.114 (0.181) loss 0.5107 (0.6179) acc 87.5000 (84.3750) lr 1.8607e-03 eta 0:07:28
epoch [36/200] batch [3/3] time 1.042 (0.954) data 0.187 (0.183) loss 0.3350 (0.5236) acc 87.5000 (85.4167) lr 1.8526e-03 eta 0:07:49
epoch [37/200] batch [1/3] time 0.923 (0.923) data 0.187 (0.187) loss 0.6685 (0.6685) acc 84.3750 (84.3750) lr 1.8526e-03 eta 0:07:33
epoch [37/200] batch [2/3] time 0.855 (0.889) data 0.134 (0.161) loss 0.6431 (0.6558) acc 87.5000 (85.9375) lr 1.8526e-03 eta 0:07:15
epoch [37/200] batch [3/3] time 0.909 (0.896) data 0.134 (0.152) loss 0.2686 (0.5267) acc 90.6250 (87.5000) lr 1.8443e-03 eta 0:07:18
epoch [38/200] batch [1/3] time 0.903 (0.903) data 0.163 (0.163) loss 0.3706 (0.3706) acc 93.7500 (93.7500) lr 1.8443e-03 eta 0:07:20
epoch [38/200] batch [2/3] time 0.892 (0.898) data 0.173 (0.168) loss 0.2046 (0.2876) acc 96.8750 (95.3125) lr 1.8443e-03 eta 0:07:17
epoch [38/200] batch [3/3] time 1.067 (0.954) data 0.245 (0.194) loss 0.3745 (0.3166) acc 87.5000 (92.7083) lr 1.8358e-03 eta 0:07:43
epoch [39/200] batch [1/3] time 0.939 (0.939) data 0.160 (0.160) loss 0.7998 (0.7998) acc 81.2500 (81.2500) lr 1.8358e-03 eta 0:07:35
epoch [39/200] batch [2/3] time 0.820 (0.879) data 0.108 (0.134) loss 0.5747 (0.6873) acc 81.2500 (81.2500) lr 1.8358e-03 eta 0:07:05
epoch [39/200] batch [3/3] time 0.916 (0.892) data 0.093 (0.120) loss 0.1760 (0.5168) acc 96.8750 (86.4583) lr 1.8271e-03 eta 0:07:10
epoch [40/200] batch [1/3] time 0.893 (0.893) data 0.156 (0.156) loss 0.4231 (0.4231) acc 87.5000 (87.5000) lr 1.8271e-03 eta 0:07:10
epoch [40/200] batch [2/3] time 1.118 (1.006) data 0.285 (0.221) loss 0.5239 (0.4735) acc 90.6250 (89.0625) lr 1.8271e-03 eta 0:08:03
epoch [40/200] batch [3/3] time 1.310 (1.107) data 0.509 (0.317) loss 0.6973 (0.5481) acc 84.3750 (87.5000) lr 1.8181e-03 eta 0:08:51
epoch [41/200] batch [1/3] time 0.877 (0.877) data 0.097 (0.097) loss 0.5376 (0.5376) acc 90.6250 (90.6250) lr 1.8181e-03 eta 0:07:00
epoch [41/200] batch [2/3] time 0.823 (0.850) data 0.108 (0.103) loss 0.3831 (0.4603) acc 90.6250 (90.6250) lr 1.8181e-03 eta 0:06:46
epoch [41/200] batch [3/3] time 0.803 (0.834) data 0.093 (0.099) loss 0.8325 (0.5844) acc 78.1250 (86.4583) lr 1.8090e-03 eta 0:06:37
epoch [42/200] batch [1/3] time 0.821 (0.821) data 0.101 (0.101) loss 0.6499 (0.6499) acc 78.1250 (78.1250) lr 1.8090e-03 eta 0:06:30
epoch [42/200] batch [2/3] time 0.807 (0.814) data 0.092 (0.096) loss 0.8726 (0.7612) acc 71.8750 (75.0000) lr 1.8090e-03 eta 0:06:26
epoch [42/200] batch [3/3] time 0.849 (0.825) data 0.134 (0.109) loss 0.6094 (0.7106) acc 87.5000 (79.1667) lr 1.7997e-03 eta 0:06:31
epoch [43/200] batch [1/3] time 0.975 (0.975) data 0.268 (0.268) loss 0.2888 (0.2888) acc 87.5000 (87.5000) lr 1.7997e-03 eta 0:07:41
epoch [43/200] batch [2/3] time 0.811 (0.893) data 0.102 (0.185) loss 0.6562 (0.4725) acc 84.3750 (85.9375) lr 1.7997e-03 eta 0:07:01
epoch [43/200] batch [3/3] time 0.802 (0.863) data 0.093 (0.154) loss 0.4658 (0.4703) acc 93.7500 (88.5417) lr 1.7902e-03 eta 0:06:46
epoch [44/200] batch [1/3] time 0.825 (0.825) data 0.116 (0.116) loss 0.7593 (0.7593) acc 78.1250 (78.1250) lr 1.7902e-03 eta 0:06:27
epoch [44/200] batch [2/3] time 0.804 (0.814) data 0.096 (0.106) loss 0.7119 (0.7356) acc 87.5000 (82.8125) lr 1.7902e-03 eta 0:06:21
epoch [44/200] batch [3/3] time 0.796 (0.808) data 0.087 (0.099) loss 0.2291 (0.5668) acc 93.7500 (86.4583) lr 1.7804e-03 eta 0:06:18
epoch [45/200] batch [1/3] time 0.911 (0.911) data 0.191 (0.191) loss 0.6123 (0.6123) acc 81.2500 (81.2500) lr 1.7804e-03 eta 0:07:05
epoch [45/200] batch [2/3] time 0.821 (0.866) data 0.106 (0.148) loss 0.3542 (0.4833) acc 93.7500 (87.5000) lr 1.7804e-03 eta 0:06:43
epoch [45/200] batch [3/3] time 0.809 (0.847) data 0.097 (0.131) loss 0.3096 (0.4254) acc 90.6250 (88.5417) lr 1.7705e-03 eta 0:06:33
epoch [46/200] batch [1/3] time 0.830 (0.830) data 0.091 (0.091) loss 0.3169 (0.3169) acc 87.5000 (87.5000) lr 1.7705e-03 eta 0:06:24
epoch [46/200] batch [2/3] time 1.032 (0.931) data 0.177 (0.134) loss 0.2664 (0.2916) acc 96.8750 (92.1875) lr 1.7705e-03 eta 0:07:10
epoch [46/200] batch [3/3] time 0.884 (0.915) data 0.150 (0.139) loss 0.8862 (0.4898) acc 81.2500 (88.5417) lr 1.7604e-03 eta 0:07:02
epoch [47/200] batch [1/3] time 0.897 (0.897) data 0.091 (0.091) loss 0.6587 (0.6587) acc 87.5000 (87.5000) lr 1.7604e-03 eta 0:06:53
epoch [47/200] batch [2/3] time 0.796 (0.847) data 0.089 (0.090) loss 0.8633 (0.7610) acc 71.8750 (79.6875) lr 1.7604e-03 eta 0:06:29
epoch [47/200] batch [3/3] time 0.807 (0.833) data 0.098 (0.092) loss 0.7144 (0.7454) acc 84.3750 (81.2500) lr 1.7501e-03 eta 0:06:22
epoch [48/200] batch [1/3] time 1.246 (1.246) data 0.415 (0.415) loss 0.6265 (0.6265) acc 84.3750 (84.3750) lr 1.7501e-03 eta 0:09:30
epoch [48/200] batch [2/3] time 1.049 (1.148) data 0.201 (0.308) loss 0.1758 (0.4011) acc 96.8750 (90.6250) lr 1.7501e-03 eta 0:08:44
epoch [48/200] batch [3/3] time 0.891 (1.062) data 0.125 (0.247) loss 0.7256 (0.5093) acc 84.3750 (88.5417) lr 1.7396e-03 eta 0:08:04
epoch [49/200] batch [1/3] time 0.912 (0.912) data 0.171 (0.171) loss 0.6221 (0.6221) acc 87.5000 (87.5000) lr 1.7396e-03 eta 0:06:55
epoch [49/200] batch [2/3] time 1.049 (0.980) data 0.261 (0.216) loss 0.9131 (0.7676) acc 84.3750 (85.9375) lr 1.7396e-03 eta 0:07:25
epoch [49/200] batch [3/3] time 0.905 (0.955) data 0.095 (0.176) loss 0.6489 (0.7280) acc 81.2500 (84.3750) lr 1.7290e-03 eta 0:07:12
epoch [50/200] batch [1/3] time 0.902 (0.902) data 0.179 (0.179) loss 0.4141 (0.4141) acc 87.5000 (87.5000) lr 1.7290e-03 eta 0:06:47
epoch [50/200] batch [2/3] time 0.949 (0.926) data 0.234 (0.206) loss 0.2452 (0.3297) acc 96.8750 (92.1875) lr 1.7290e-03 eta 0:06:57
epoch [50/200] batch [3/3] time 0.866 (0.906) data 0.153 (0.189) loss 1.1992 (0.6195) acc 81.2500 (88.5417) lr 1.7181e-03 eta 0:06:47
epoch [51/200] batch [1/3] time 0.828 (0.828) data 0.107 (0.107) loss 0.3970 (0.3970) acc 96.8750 (96.8750) lr 1.7181e-03 eta 0:06:11
epoch [51/200] batch [2/3] time 0.828 (0.828) data 0.113 (0.110) loss 0.4829 (0.4399) acc 84.3750 (90.6250) lr 1.7181e-03 eta 0:06:10
epoch [51/200] batch [3/3] time 0.807 (0.821) data 0.095 (0.105) loss 0.4238 (0.4346) acc 87.5000 (89.5833) lr 1.7071e-03 eta 0:06:07
epoch [52/200] batch [1/3] time 0.806 (0.806) data 0.091 (0.091) loss 0.4236 (0.4236) acc 87.5000 (87.5000) lr 1.7071e-03 eta 0:05:59
epoch [52/200] batch [2/3] time 0.823 (0.814) data 0.105 (0.098) loss 0.1665 (0.2950) acc 96.8750 (92.1875) lr 1.7071e-03 eta 0:06:02
epoch [52/200] batch [3/3] time 0.880 (0.836) data 0.099 (0.099) loss 0.2637 (0.2846) acc 90.6250 (91.6667) lr 1.6959e-03 eta 0:06:11
epoch [53/200] batch [1/3] time 0.879 (0.879) data 0.107 (0.107) loss 0.3557 (0.3557) acc 90.6250 (90.6250) lr 1.6959e-03 eta 0:06:29
epoch [53/200] batch [2/3] time 1.039 (0.959) data 0.259 (0.183) loss 0.6753 (0.5155) acc 84.3750 (87.5000) lr 1.6959e-03 eta 0:07:03
epoch [53/200] batch [3/3] time 1.067 (0.995) data 0.244 (0.203) loss 0.4468 (0.4926) acc 90.6250 (88.5417) lr 1.6845e-03 eta 0:07:18
epoch [54/200] batch [1/3] time 0.906 (0.906) data 0.153 (0.153) loss 0.6812 (0.6812) acc 90.6250 (90.6250) lr 1.6845e-03 eta 0:06:38
epoch [54/200] batch [2/3] time 1.082 (0.994) data 0.335 (0.244) loss 0.4221 (0.5516) acc 93.7500 (92.1875) lr 1.6845e-03 eta 0:07:16
epoch [54/200] batch [3/3] time 0.876 (0.955) data 0.096 (0.195) loss 0.4814 (0.5282) acc 90.6250 (91.6667) lr 1.6730e-03 eta 0:06:58
epoch [55/200] batch [1/3] time 0.819 (0.819) data 0.100 (0.100) loss 0.6216 (0.6216) acc 84.3750 (84.3750) lr 1.6730e-03 eta 0:05:57
epoch [55/200] batch [2/3] time 0.843 (0.831) data 0.103 (0.102) loss 1.3467 (0.9841) acc 71.8750 (78.1250) lr 1.6730e-03 eta 0:06:02
epoch [55/200] batch [3/3] time 1.022 (0.895) data 0.176 (0.126) loss 0.3435 (0.7706) acc 93.7500 (83.3333) lr 1.6613e-03 eta 0:06:29
epoch [56/200] batch [1/3] time 1.119 (1.119) data 0.390 (0.390) loss 0.2136 (0.2136) acc 96.8750 (96.8750) lr 1.6613e-03 eta 0:08:05
epoch [56/200] batch [2/3] time 0.875 (0.997) data 0.098 (0.244) loss 0.9243 (0.5690) acc 84.3750 (90.6250) lr 1.6613e-03 eta 0:07:11
epoch [56/200] batch [3/3] time 1.092 (1.029) data 0.331 (0.273) loss 0.4163 (0.5181) acc 87.5000 (89.5833) lr 1.6494e-03 eta 0:07:24
epoch [57/200] batch [1/3] time 0.816 (0.816) data 0.103 (0.103) loss 0.4438 (0.4438) acc 87.5000 (87.5000) lr 1.6494e-03 eta 0:05:51
epoch [57/200] batch [2/3] time 0.850 (0.833) data 0.136 (0.120) loss 0.4580 (0.4509) acc 87.5000 (87.5000) lr 1.6494e-03 eta 0:05:58
epoch [57/200] batch [3/3] time 0.831 (0.832) data 0.120 (0.120) loss 0.3547 (0.4189) acc 90.6250 (88.5417) lr 1.6374e-03 eta 0:05:57
epoch [58/200] batch [1/3] time 0.808 (0.808) data 0.097 (0.097) loss 0.7412 (0.7412) acc 87.5000 (87.5000) lr 1.6374e-03 eta 0:05:45
epoch [58/200] batch [2/3] time 0.816 (0.812) data 0.099 (0.098) loss 0.1882 (0.4647) acc 93.7500 (90.6250) lr 1.6374e-03 eta 0:05:46
epoch [58/200] batch [3/3] time 0.819 (0.814) data 0.103 (0.100) loss 0.3440 (0.4245) acc 90.6250 (90.6250) lr 1.6252e-03 eta 0:05:46
epoch [59/200] batch [1/3] time 0.815 (0.815) data 0.100 (0.100) loss 0.2993 (0.2993) acc 93.7500 (93.7500) lr 1.6252e-03 eta 0:05:46
epoch [59/200] batch [2/3] time 0.901 (0.858) data 0.186 (0.143) loss 0.3062 (0.3027) acc 93.7500 (93.7500) lr 1.6252e-03 eta 0:06:03
epoch [59/200] batch [3/3] time 0.809 (0.842) data 0.095 (0.127) loss 0.4968 (0.3674) acc 84.3750 (90.6250) lr 1.6129e-03 eta 0:05:56
epoch [60/200] batch [1/3] time 0.818 (0.818) data 0.093 (0.093) loss 0.2766 (0.2766) acc 93.7500 (93.7500) lr 1.6129e-03 eta 0:05:45
epoch [60/200] batch [2/3] time 0.874 (0.846) data 0.114 (0.103) loss 0.5059 (0.3912) acc 87.5000 (90.6250) lr 1.6129e-03 eta 0:05:56
epoch [60/200] batch [3/3] time 0.867 (0.853) data 0.092 (0.099) loss 0.1588 (0.3138) acc 93.7500 (91.6667) lr 1.6004e-03 eta 0:05:58
epoch [61/200] batch [1/3] time 1.058 (1.058) data 0.297 (0.297) loss 0.4946 (0.4946) acc 90.6250 (90.6250) lr 1.6004e-03 eta 0:07:23
epoch [61/200] batch [2/3] time 0.855 (0.957) data 0.144 (0.220) loss 0.2128 (0.3537) acc 93.7500 (92.1875) lr 1.6004e-03 eta 0:06:39
epoch [61/200] batch [3/3] time 0.847 (0.920) data 0.112 (0.184) loss 0.1533 (0.2869) acc 96.8750 (93.7500) lr 1.5878e-03 eta 0:06:23
epoch [62/200] batch [1/3] time 1.184 (1.184) data 0.362 (0.362) loss 0.5254 (0.5254) acc 81.2500 (81.2500) lr 1.5878e-03 eta 0:08:12
epoch [62/200] batch [2/3] time 1.132 (1.158) data 0.357 (0.360) loss 0.5347 (0.5300) acc 90.6250 (85.9375) lr 1.5878e-03 eta 0:08:00
epoch [62/200] batch [3/3] time 0.895 (1.070) data 0.104 (0.274) loss 0.2710 (0.4437) acc 90.6250 (87.5000) lr 1.5750e-03 eta 0:07:23
epoch [63/200] batch [1/3] time 0.978 (0.978) data 0.262 (0.262) loss 0.2764 (0.2764) acc 96.8750 (96.8750) lr 1.5750e-03 eta 0:06:43
epoch [63/200] batch [2/3] time 0.947 (0.963) data 0.189 (0.225) loss 0.4080 (0.3422) acc 90.6250 (93.7500) lr 1.5750e-03 eta 0:06:36
epoch [63/200] batch [3/3] time 1.056 (0.994) data 0.293 (0.248) loss 0.7666 (0.4836) acc 78.1250 (88.5417) lr 1.5621e-03 eta 0:06:48
epoch [64/200] batch [1/3] time 0.940 (0.940) data 0.227 (0.227) loss 0.4910 (0.4910) acc 87.5000 (87.5000) lr 1.5621e-03 eta 0:06:25
epoch [64/200] batch [2/3] time 0.813 (0.877) data 0.102 (0.165) loss 0.6235 (0.5573) acc 87.5000 (87.5000) lr 1.5621e-03 eta 0:05:58
epoch [64/200] batch [3/3] time 0.904 (0.886) data 0.136 (0.155) loss 0.3308 (0.4818) acc 93.7500 (89.5833) lr 1.5490e-03 eta 0:06:01
epoch [65/200] batch [1/3] time 0.892 (0.892) data 0.099 (0.099) loss 0.2271 (0.2271) acc 93.7500 (93.7500) lr 1.5490e-03 eta 0:06:03
epoch [65/200] batch [2/3] time 0.805 (0.848) data 0.092 (0.096) loss 0.2959 (0.2615) acc 87.5000 (90.6250) lr 1.5490e-03 eta 0:05:44
epoch [65/200] batch [3/3] time 0.855 (0.850) data 0.103 (0.098) loss 0.3323 (0.2851) acc 90.6250 (90.6250) lr 1.5358e-03 eta 0:05:44
epoch [66/200] batch [1/3] time 0.839 (0.839) data 0.092 (0.092) loss 0.2476 (0.2476) acc 93.7500 (93.7500) lr 1.5358e-03 eta 0:05:39
epoch [66/200] batch [2/3] time 0.861 (0.850) data 0.104 (0.098) loss 0.5444 (0.3960) acc 87.5000 (90.6250) lr 1.5358e-03 eta 0:05:42
epoch [66/200] batch [3/3] time 0.806 (0.836) data 0.096 (0.097) loss 0.4863 (0.4261) acc 87.5000 (89.5833) lr 1.5225e-03 eta 0:05:35
epoch [67/200] batch [1/3] time 0.823 (0.823) data 0.088 (0.088) loss 0.7744 (0.7744) acc 81.2500 (81.2500) lr 1.5225e-03 eta 0:05:29
epoch [67/200] batch [2/3] time 0.879 (0.851) data 0.152 (0.120) loss 0.4475 (0.6110) acc 84.3750 (82.8125) lr 1.5225e-03 eta 0:05:40
epoch [67/200] batch [3/3] time 0.977 (0.893) data 0.155 (0.132) loss 0.2170 (0.4797) acc 93.7500 (86.4583) lr 1.5090e-03 eta 0:05:56
epoch [68/200] batch [1/3] time 0.820 (0.820) data 0.103 (0.103) loss 0.6001 (0.6001) acc 81.2500 (81.2500) lr 1.5090e-03 eta 0:05:26
epoch [68/200] batch [2/3] time 0.810 (0.815) data 0.102 (0.103) loss 0.6440 (0.6221) acc 84.3750 (82.8125) lr 1.5090e-03 eta 0:05:23
epoch [68/200] batch [3/3] time 0.923 (0.851) data 0.139 (0.115) loss 0.5225 (0.5889) acc 90.6250 (85.4167) lr 1.4955e-03 eta 0:05:36
epoch [69/200] batch [1/3] time 0.865 (0.865) data 0.112 (0.112) loss 0.1522 (0.1522) acc 96.8750 (96.8750) lr 1.4955e-03 eta 0:05:41
epoch [69/200] batch [2/3] time 0.836 (0.850) data 0.123 (0.117) loss 0.6362 (0.3942) acc 87.5000 (92.1875) lr 1.4955e-03 eta 0:05:35
epoch [69/200] batch [3/3] time 0.803 (0.835) data 0.092 (0.109) loss 0.4163 (0.4016) acc 93.7500 (92.7083) lr 1.4818e-03 eta 0:05:27
epoch [70/200] batch [1/3] time 0.802 (0.802) data 0.093 (0.093) loss 0.4336 (0.4336) acc 84.3750 (84.3750) lr 1.4818e-03 eta 0:05:14
epoch [70/200] batch [2/3] time 0.802 (0.802) data 0.093 (0.093) loss 0.4019 (0.4177) acc 87.5000 (85.9375) lr 1.4818e-03 eta 0:05:13
epoch [70/200] batch [3/3] time 0.802 (0.802) data 0.092 (0.093) loss 0.2290 (0.3548) acc 96.8750 (89.5833) lr 1.4679e-03 eta 0:05:12
epoch [71/200] batch [1/3] time 0.810 (0.810) data 0.102 (0.102) loss 0.4602 (0.4602) acc 90.6250 (90.6250) lr 1.4679e-03 eta 0:05:15
epoch [71/200] batch [2/3] time 0.805 (0.808) data 0.098 (0.100) loss 0.1710 (0.3156) acc 96.8750 (93.7500) lr 1.4679e-03 eta 0:05:13
epoch [71/200] batch [3/3] time 0.818 (0.811) data 0.096 (0.099) loss 0.4116 (0.3476) acc 87.5000 (91.6667) lr 1.4540e-03 eta 0:05:13
epoch [72/200] batch [1/3] time 0.813 (0.813) data 0.093 (0.093) loss 0.3025 (0.3025) acc 93.7500 (93.7500) lr 1.4540e-03 eta 0:05:13
epoch [72/200] batch [2/3] time 0.851 (0.832) data 0.104 (0.099) loss 0.2131 (0.2578) acc 100.0000 (96.8750) lr 1.4540e-03 eta 0:05:20
epoch [72/200] batch [3/3] time 1.432 (1.032) data 0.636 (0.278) loss 0.4026 (0.3061) acc 84.3750 (92.7083) lr 1.4399e-03 eta 0:06:36
epoch [73/200] batch [1/3] time 0.847 (0.847) data 0.112 (0.112) loss 0.1974 (0.1974) acc 96.8750 (96.8750) lr 1.4399e-03 eta 0:05:24
epoch [73/200] batch [2/3] time 0.800 (0.823) data 0.092 (0.102) loss 0.9648 (0.5811) acc 81.2500 (89.0625) lr 1.4399e-03 eta 0:05:14
epoch [73/200] batch [3/3] time 0.804 (0.817) data 0.091 (0.098) loss 0.7593 (0.6405) acc 81.2500 (86.4583) lr 1.4258e-03 eta 0:05:11
epoch [74/200] batch [1/3] time 0.795 (0.795) data 0.088 (0.088) loss 0.2544 (0.2544) acc 90.6250 (90.6250) lr 1.4258e-03 eta 0:05:02
epoch [74/200] batch [2/3] time 0.807 (0.801) data 0.092 (0.090) loss 0.3386 (0.2965) acc 84.3750 (87.5000) lr 1.4258e-03 eta 0:05:03
epoch [74/200] batch [3/3] time 1.005 (0.869) data 0.280 (0.153) loss 0.6958 (0.4296) acc 78.1250 (84.3750) lr 1.4115e-03 eta 0:05:28
epoch [75/200] batch [1/3] time 0.797 (0.797) data 0.089 (0.089) loss 0.7930 (0.7930) acc 87.5000 (87.5000) lr 1.4115e-03 eta 0:05:00
epoch [75/200] batch [2/3] time 0.802 (0.800) data 0.092 (0.090) loss 0.4854 (0.6392) acc 87.5000 (87.5000) lr 1.4115e-03 eta 0:05:00
epoch [75/200] batch [3/3] time 0.835 (0.812) data 0.093 (0.091) loss 0.2656 (0.5146) acc 90.6250 (88.5417) lr 1.3971e-03 eta 0:05:04
epoch [76/200] batch [1/3] time 0.903 (0.903) data 0.190 (0.190) loss 0.2031 (0.2031) acc 90.6250 (90.6250) lr 1.3971e-03 eta 0:05:37
epoch [76/200] batch [2/3] time 0.941 (0.922) data 0.236 (0.213) loss 0.1462 (0.1747) acc 100.0000 (95.3125) lr 1.3971e-03 eta 0:05:43
epoch [76/200] batch [3/3] time 0.871 (0.905) data 0.095 (0.173) loss 0.5698 (0.3064) acc 81.2500 (90.6250) lr 1.3827e-03 eta 0:05:36
epoch [77/200] batch [1/3] time 0.800 (0.800) data 0.092 (0.092) loss 0.2155 (0.2155) acc 93.7500 (93.7500) lr 1.3827e-03 eta 0:04:56
epoch [77/200] batch [2/3] time 0.799 (0.799) data 0.091 (0.091) loss 0.3286 (0.2720) acc 96.8750 (95.3125) lr 1.3827e-03 eta 0:04:55
epoch [77/200] batch [3/3] time 0.800 (0.800) data 0.093 (0.092) loss 0.2471 (0.2637) acc 93.7500 (94.7917) lr 1.3681e-03 eta 0:04:55
epoch [78/200] batch [1/3] time 0.798 (0.798) data 0.090 (0.090) loss 0.1855 (0.1855) acc 93.7500 (93.7500) lr 1.3681e-03 eta 0:04:53
epoch [78/200] batch [2/3] time 0.832 (0.815) data 0.092 (0.091) loss 0.2220 (0.2038) acc 96.8750 (95.3125) lr 1.3681e-03 eta 0:04:59
epoch [78/200] batch [3/3] time 0.883 (0.838) data 0.092 (0.091) loss 0.5308 (0.3128) acc 90.6250 (93.7500) lr 1.3535e-03 eta 0:05:06
epoch [79/200] batch [1/3] time 0.799 (0.799) data 0.091 (0.091) loss 0.4653 (0.4653) acc 93.7500 (93.7500) lr 1.3535e-03 eta 0:04:51
epoch [79/200] batch [2/3] time 0.932 (0.866) data 0.118 (0.105) loss 0.5361 (0.5007) acc 87.5000 (90.6250) lr 1.3535e-03 eta 0:05:15
epoch [79/200] batch [3/3] time 0.853 (0.861) data 0.145 (0.118) loss 0.2708 (0.4241) acc 96.8750 (92.7083) lr 1.3387e-03 eta 0:05:12
epoch [80/200] batch [1/3] time 0.861 (0.861) data 0.087 (0.087) loss 0.3840 (0.3840) acc 90.6250 (90.6250) lr 1.3387e-03 eta 0:05:11
epoch [80/200] batch [2/3] time 0.795 (0.828) data 0.088 (0.087) loss 0.3777 (0.3809) acc 90.6250 (90.6250) lr 1.3387e-03 eta 0:04:58
epoch [80/200] batch [3/3] time 0.798 (0.818) data 0.090 (0.088) loss 0.2725 (0.3447) acc 90.6250 (90.6250) lr 1.3239e-03 eta 0:04:54
epoch [81/200] batch [1/3] time 0.796 (0.796) data 0.087 (0.087) loss 0.7939 (0.7939) acc 84.3750 (84.3750) lr 1.3239e-03 eta 0:04:45
epoch [81/200] batch [2/3] time 0.795 (0.796) data 0.088 (0.088) loss 0.5020 (0.6479) acc 87.5000 (85.9375) lr 1.3239e-03 eta 0:04:44
epoch [81/200] batch [3/3] time 0.816 (0.802) data 0.103 (0.093) loss 0.5664 (0.6208) acc 84.3750 (85.4167) lr 1.3090e-03 eta 0:04:46
epoch [82/200] batch [1/3] time 0.800 (0.800) data 0.092 (0.092) loss 0.2549 (0.2549) acc 96.8750 (96.8750) lr 1.3090e-03 eta 0:04:44
epoch [82/200] batch [2/3] time 0.800 (0.800) data 0.092 (0.092) loss 0.5029 (0.3789) acc 93.7500 (95.3125) lr 1.3090e-03 eta 0:04:44
epoch [82/200] batch [3/3] time 0.798 (0.799) data 0.089 (0.091) loss 0.3425 (0.3668) acc 87.5000 (92.7083) lr 1.2940e-03 eta 0:04:42
epoch [83/200] batch [1/3] time 0.801 (0.801) data 0.089 (0.089) loss 0.6206 (0.6206) acc 87.5000 (87.5000) lr 1.2940e-03 eta 0:04:42
epoch [83/200] batch [2/3] time 0.801 (0.801) data 0.093 (0.091) loss 0.1219 (0.3713) acc 96.8750 (92.1875) lr 1.2940e-03 eta 0:04:41
epoch [83/200] batch [3/3] time 0.800 (0.801) data 0.092 (0.091) loss 0.4524 (0.3983) acc 87.5000 (90.6250) lr 1.2790e-03 eta 0:04:41
epoch [84/200] batch [1/3] time 0.797 (0.797) data 0.089 (0.089) loss 0.3528 (0.3528) acc 90.6250 (90.6250) lr 1.2790e-03 eta 0:04:39
epoch [84/200] batch [2/3] time 0.817 (0.807) data 0.094 (0.091) loss 0.2002 (0.2765) acc 96.8750 (93.7500) lr 1.2790e-03 eta 0:04:41
epoch [84/200] batch [3/3] time 0.860 (0.825) data 0.112 (0.098) loss 0.1114 (0.2215) acc 96.8750 (94.7917) lr 1.2639e-03 eta 0:04:46
epoch [85/200] batch [1/3] time 0.868 (0.868) data 0.090 (0.090) loss 0.5273 (0.5273) acc 84.3750 (84.3750) lr 1.2639e-03 eta 0:05:01
epoch [85/200] batch [2/3] time 0.872 (0.870) data 0.120 (0.105) loss 0.1639 (0.3456) acc 96.8750 (90.6250) lr 1.2639e-03 eta 0:05:00
epoch [85/200] batch [3/3] time 0.823 (0.854) data 0.107 (0.106) loss 0.6880 (0.4598) acc 84.3750 (88.5417) lr 1.2487e-03 eta 0:04:54
epoch [86/200] batch [1/3] time 0.849 (0.849) data 0.100 (0.100) loss 0.2485 (0.2485) acc 93.7500 (93.7500) lr 1.2487e-03 eta 0:04:52
epoch [86/200] batch [2/3] time 0.807 (0.828) data 0.090 (0.095) loss 0.4087 (0.3286) acc 87.5000 (90.6250) lr 1.2487e-03 eta 0:04:44
epoch [86/200] batch [3/3] time 0.832 (0.830) data 0.095 (0.095) loss 0.3186 (0.3253) acc 96.8750 (92.7083) lr 1.2334e-03 eta 0:04:43
epoch [87/200] batch [1/3] time 0.799 (0.799) data 0.089 (0.089) loss 0.5493 (0.5493) acc 84.3750 (84.3750) lr 1.2334e-03 eta 0:04:32
epoch [87/200] batch [2/3] time 0.803 (0.801) data 0.093 (0.091) loss 0.3367 (0.4430) acc 93.7500 (89.0625) lr 1.2334e-03 eta 0:04:32
epoch [87/200] batch [3/3] time 0.801 (0.801) data 0.092 (0.091) loss 0.1702 (0.3521) acc 100.0000 (92.7083) lr 1.2181e-03 eta 0:04:31
epoch [88/200] batch [1/3] time 0.800 (0.800) data 0.090 (0.090) loss 0.6846 (0.6846) acc 84.3750 (84.3750) lr 1.2181e-03 eta 0:04:30
epoch [88/200] batch [2/3] time 0.805 (0.803) data 0.096 (0.093) loss 0.3750 (0.5298) acc 87.5000 (85.9375) lr 1.2181e-03 eta 0:04:30
epoch [88/200] batch [3/3] time 0.802 (0.802) data 0.093 (0.093) loss 0.3342 (0.4646) acc 93.7500 (88.5417) lr 1.2028e-03 eta 0:04:29
epoch [89/200] batch [1/3] time 0.803 (0.803) data 0.094 (0.094) loss 0.1381 (0.1381) acc 100.0000 (100.0000) lr 1.2028e-03 eta 0:04:29
epoch [89/200] batch [2/3] time 0.799 (0.801) data 0.091 (0.092) loss 0.4019 (0.2700) acc 90.6250 (95.3125) lr 1.2028e-03 eta 0:04:27
epoch [89/200] batch [3/3] time 0.810 (0.804) data 0.099 (0.095) loss 0.1252 (0.2217) acc 96.8750 (95.8333) lr 1.1874e-03 eta 0:04:27
epoch [90/200] batch [1/3] time 0.800 (0.800) data 0.090 (0.090) loss 0.3440 (0.3440) acc 90.6250 (90.6250) lr 1.1874e-03 eta 0:04:25
epoch [90/200] batch [2/3] time 0.807 (0.804) data 0.098 (0.094) loss 0.2632 (0.3036) acc 93.7500 (92.1875) lr 1.1874e-03 eta 0:04:25
epoch [90/200] batch [3/3] time 0.801 (0.803) data 0.091 (0.093) loss 0.4937 (0.3669) acc 87.5000 (90.6250) lr 1.1719e-03 eta 0:04:24
epoch [91/200] batch [1/3] time 0.800 (0.800) data 0.090 (0.090) loss 0.3579 (0.3579) acc 93.7500 (93.7500) lr 1.1719e-03 eta 0:04:23
epoch [91/200] batch [2/3] time 0.801 (0.801) data 0.093 (0.091) loss 0.3044 (0.3312) acc 93.7500 (93.7500) lr 1.1719e-03 eta 0:04:22
epoch [91/200] batch [3/3] time 0.804 (0.802) data 0.093 (0.092) loss 0.2196 (0.2940) acc 93.7500 (93.7500) lr 1.1564e-03 eta 0:04:22
epoch [92/200] batch [1/3] time 0.799 (0.799) data 0.091 (0.091) loss 0.3423 (0.3423) acc 90.6250 (90.6250) lr 1.1564e-03 eta 0:04:20
epoch [92/200] batch [2/3] time 0.800 (0.799) data 0.090 (0.091) loss 0.2333 (0.2878) acc 90.6250 (90.6250) lr 1.1564e-03 eta 0:04:19
epoch [92/200] batch [3/3] time 0.800 (0.800) data 0.092 (0.091) loss 0.4741 (0.3499) acc 87.5000 (89.5833) lr 1.1409e-03 eta 0:04:19
epoch [93/200] batch [1/3] time 0.814 (0.814) data 0.105 (0.105) loss 0.0561 (0.0561) acc 100.0000 (100.0000) lr 1.1409e-03 eta 0:04:22
epoch [93/200] batch [2/3] time 0.798 (0.806) data 0.091 (0.098) loss 0.2993 (0.1777) acc 93.7500 (96.8750) lr 1.1409e-03 eta 0:04:19
epoch [93/200] batch [3/3] time 0.801 (0.804) data 0.091 (0.096) loss 0.3147 (0.2234) acc 90.6250 (94.7917) lr 1.1253e-03 eta 0:04:18
epoch [94/200] batch [1/3] time 0.806 (0.806) data 0.097 (0.097) loss 0.6362 (0.6362) acc 84.3750 (84.3750) lr 1.1253e-03 eta 0:04:17
epoch [94/200] batch [2/3] time 0.800 (0.803) data 0.091 (0.094) loss 0.1501 (0.3932) acc 96.8750 (90.6250) lr 1.1253e-03 eta 0:04:16
epoch [94/200] batch [3/3] time 0.807 (0.804) data 0.099 (0.096) loss 0.2090 (0.3318) acc 90.6250 (90.6250) lr 1.1097e-03 eta 0:04:15
epoch [95/200] batch [1/3] time 0.798 (0.798) data 0.088 (0.088) loss 0.3528 (0.3528) acc 93.7500 (93.7500) lr 1.1097e-03 eta 0:04:13
epoch [95/200] batch [2/3] time 0.800 (0.799) data 0.091 (0.090) loss 0.3701 (0.3615) acc 90.6250 (92.1875) lr 1.1097e-03 eta 0:04:12
epoch [95/200] batch [3/3] time 0.905 (0.834) data 0.188 (0.123) loss 0.3940 (0.3723) acc 84.3750 (89.5833) lr 1.0941e-03 eta 0:04:22
epoch [96/200] batch [1/3] time 1.092 (1.092) data 0.380 (0.380) loss 0.4558 (0.4558) acc 93.7500 (93.7500) lr 1.0941e-03 eta 0:05:42
epoch [96/200] batch [2/3] time 0.822 (0.957) data 0.109 (0.245) loss 0.2157 (0.3358) acc 96.8750 (95.3125) lr 1.0941e-03 eta 0:04:59
epoch [96/200] batch [3/3] time 0.830 (0.915) data 0.118 (0.202) loss 0.2220 (0.2979) acc 90.6250 (93.7500) lr 1.0785e-03 eta 0:04:45
epoch [97/200] batch [1/3] time 0.917 (0.917) data 0.110 (0.110) loss 0.1423 (0.1423) acc 93.7500 (93.7500) lr 1.0785e-03 eta 0:04:45
epoch [97/200] batch [2/3] time 1.847 (1.382) data 1.140 (0.625) loss 0.4736 (0.3080) acc 90.6250 (92.1875) lr 1.0785e-03 eta 0:07:08
epoch [97/200] batch [3/3] time 0.836 (1.200) data 0.125 (0.459) loss 0.0854 (0.2338) acc 96.8750 (93.7500) lr 1.0628e-03 eta 0:06:10
epoch [98/200] batch [1/3] time 0.817 (0.817) data 0.106 (0.106) loss 0.2515 (0.2515) acc 93.7500 (93.7500) lr 1.0628e-03 eta 0:04:11
epoch [98/200] batch [2/3] time 0.819 (0.818) data 0.108 (0.107) loss 0.5918 (0.4216) acc 87.5000 (90.6250) lr 1.0628e-03 eta 0:04:11
epoch [98/200] batch [3/3] time 0.823 (0.820) data 0.112 (0.109) loss 0.4041 (0.4158) acc 96.8750 (92.7083) lr 1.0471e-03 eta 0:04:10
epoch [99/200] batch [1/3] time 0.812 (0.812) data 0.101 (0.101) loss 0.2866 (0.2866) acc 93.7500 (93.7500) lr 1.0471e-03 eta 0:04:07
epoch [99/200] batch [2/3] time 0.803 (0.808) data 0.092 (0.097) loss 0.4082 (0.3474) acc 93.7500 (93.7500) lr 1.0471e-03 eta 0:04:05
epoch [99/200] batch [3/3] time 0.816 (0.810) data 0.100 (0.098) loss 0.9722 (0.5557) acc 71.8750 (86.4583) lr 1.0314e-03 eta 0:04:05
epoch [100/200] batch [1/3] time 0.807 (0.807) data 0.096 (0.096) loss 0.2087 (0.2087) acc 96.8750 (96.8750) lr 1.0314e-03 eta 0:04:03
epoch [100/200] batch [2/3] time 0.805 (0.806) data 0.094 (0.095) loss 0.3618 (0.2853) acc 93.7500 (95.3125) lr 1.0314e-03 eta 0:04:02
epoch [100/200] batch [3/3] time 0.833 (0.815) data 0.121 (0.104) loss 0.3826 (0.3177) acc 87.5000 (92.7083) lr 1.0157e-03 eta 0:04:04
epoch [101/200] batch [1/3] time 0.799 (0.799) data 0.089 (0.089) loss 0.1859 (0.1859) acc 93.7500 (93.7500) lr 1.0157e-03 eta 0:03:59
epoch [101/200] batch [2/3] time 0.810 (0.805) data 0.099 (0.094) loss 0.2717 (0.2288) acc 90.6250 (92.1875) lr 1.0157e-03 eta 0:03:59
epoch [101/200] batch [3/3] time 0.805 (0.805) data 0.092 (0.093) loss 0.2690 (0.2422) acc 90.6250 (91.6667) lr 1.0000e-03 eta 0:03:59
epoch [102/200] batch [1/3] time 0.942 (0.942) data 0.236 (0.236) loss 0.2468 (0.2468) acc 93.7500 (93.7500) lr 1.0000e-03 eta 0:04:38
epoch [102/200] batch [2/3] time 0.804 (0.873) data 0.093 (0.164) loss 0.1475 (0.1971) acc 96.8750 (95.3125) lr 1.0000e-03 eta 0:04:17
epoch [102/200] batch [3/3] time 0.821 (0.856) data 0.108 (0.146) loss 0.4832 (0.2925) acc 90.6250 (93.7500) lr 9.8429e-04 eta 0:04:11
epoch [103/200] batch [1/3] time 0.807 (0.807) data 0.097 (0.097) loss 0.1542 (0.1542) acc 96.8750 (96.8750) lr 9.8429e-04 eta 0:03:56
epoch [103/200] batch [2/3] time 0.833 (0.820) data 0.122 (0.110) loss 0.2067 (0.1804) acc 96.8750 (96.8750) lr 9.8429e-04 eta 0:03:59
epoch [103/200] batch [3/3] time 0.894 (0.845) data 0.183 (0.134) loss 0.3206 (0.2271) acc 93.7500 (95.8333) lr 9.6859e-04 eta 0:04:05
epoch [104/200] batch [1/3] time 0.801 (0.801) data 0.090 (0.090) loss 0.1820 (0.1820) acc 96.8750 (96.8750) lr 9.6859e-04 eta 0:03:52
epoch [104/200] batch [2/3] time 0.822 (0.811) data 0.110 (0.100) loss 0.2888 (0.2354) acc 93.7500 (95.3125) lr 9.6859e-04 eta 0:03:54
epoch [104/200] batch [3/3] time 0.805 (0.809) data 0.093 (0.098) loss 0.0453 (0.1720) acc 100.0000 (96.8750) lr 9.5289e-04 eta 0:03:53
epoch [105/200] batch [1/3] time 0.802 (0.802) data 0.090 (0.090) loss 0.1205 (0.1205) acc 96.8750 (96.8750) lr 9.5289e-04 eta 0:03:50
epoch [105/200] batch [2/3] time 0.815 (0.808) data 0.104 (0.097) loss 0.5488 (0.3347) acc 84.3750 (90.6250) lr 9.5289e-04 eta 0:03:51
epoch [105/200] batch [3/3] time 0.801 (0.806) data 0.090 (0.095) loss 0.3462 (0.3385) acc 93.7500 (91.6667) lr 9.3721e-04 eta 0:03:49
epoch [106/200] batch [1/3] time 0.803 (0.803) data 0.092 (0.092) loss 0.3887 (0.3887) acc 87.5000 (87.5000) lr 9.3721e-04 eta 0:03:48
epoch [106/200] batch [2/3] time 0.801 (0.802) data 0.088 (0.090) loss 0.1338 (0.2612) acc 96.8750 (92.1875) lr 9.3721e-04 eta 0:03:46
epoch [106/200] batch [3/3] time 0.866 (0.823) data 0.128 (0.103) loss 0.5103 (0.3442) acc 81.2500 (88.5417) lr 9.2154e-04 eta 0:03:52
epoch [107/200] batch [1/3] time 0.834 (0.834) data 0.129 (0.129) loss 0.3452 (0.3452) acc 93.7500 (93.7500) lr 9.2154e-04 eta 0:03:54
epoch [107/200] batch [2/3] time 0.796 (0.815) data 0.092 (0.111) loss 0.2644 (0.3048) acc 90.6250 (92.1875) lr 9.2154e-04 eta 0:03:48
epoch [107/200] batch [3/3] time 0.796 (0.809) data 0.092 (0.104) loss 0.3784 (0.3293) acc 90.6250 (91.6667) lr 9.0589e-04 eta 0:03:45
epoch [108/200] batch [1/3] time 0.792 (0.792) data 0.088 (0.088) loss 0.5078 (0.5078) acc 87.5000 (87.5000) lr 9.0589e-04 eta 0:03:40
epoch [108/200] batch [2/3] time 0.800 (0.796) data 0.096 (0.092) loss 0.4382 (0.4730) acc 93.7500 (90.6250) lr 9.0589e-04 eta 0:03:40
epoch [108/200] batch [3/3] time 0.802 (0.798) data 0.096 (0.094) loss 0.3589 (0.4350) acc 90.6250 (90.6250) lr 8.9027e-04 eta 0:03:40
epoch [109/200] batch [1/3] time 0.795 (0.795) data 0.091 (0.091) loss 0.6162 (0.6162) acc 81.2500 (81.2500) lr 8.9027e-04 eta 0:03:38
epoch [109/200] batch [2/3] time 0.798 (0.796) data 0.094 (0.093) loss 0.4978 (0.5570) acc 87.5000 (84.3750) lr 8.9027e-04 eta 0:03:38
epoch [109/200] batch [3/3] time 0.799 (0.797) data 0.094 (0.093) loss 0.2671 (0.4604) acc 96.8750 (88.5417) lr 8.7467e-04 eta 0:03:37
epoch [110/200] batch [1/3] time 0.800 (0.800) data 0.097 (0.097) loss 0.2964 (0.2964) acc 93.7500 (93.7500) lr 8.7467e-04 eta 0:03:37
epoch [110/200] batch [2/3] time 0.797 (0.798) data 0.094 (0.095) loss 0.3611 (0.3287) acc 90.6250 (92.1875) lr 8.7467e-04 eta 0:03:36
epoch [110/200] batch [3/3] time 0.798 (0.798) data 0.092 (0.094) loss 0.2856 (0.3144) acc 93.7500 (92.7083) lr 8.5910e-04 eta 0:03:35
epoch [111/200] batch [1/3] time 0.798 (0.798) data 0.094 (0.094) loss 0.7954 (0.7954) acc 87.5000 (87.5000) lr 8.5910e-04 eta 0:03:34
epoch [111/200] batch [2/3] time 0.801 (0.799) data 0.098 (0.096) loss 0.0645 (0.4299) acc 100.0000 (93.7500) lr 8.5910e-04 eta 0:03:34
epoch [111/200] batch [3/3] time 0.834 (0.811) data 0.129 (0.107) loss 0.0883 (0.3161) acc 100.0000 (95.8333) lr 8.4357e-04 eta 0:03:36
epoch [112/200] batch [1/3] time 0.798 (0.798) data 0.094 (0.094) loss 0.5459 (0.5459) acc 87.5000 (87.5000) lr 8.4357e-04 eta 0:03:32
epoch [112/200] batch [2/3] time 0.859 (0.828) data 0.155 (0.125) loss 0.1304 (0.3381) acc 96.8750 (92.1875) lr 8.4357e-04 eta 0:03:39
epoch [112/200] batch [3/3] time 0.797 (0.818) data 0.094 (0.114) loss 0.0975 (0.2579) acc 100.0000 (94.7917) lr 8.2807e-04 eta 0:03:35
epoch [113/200] batch [1/3] time 0.797 (0.797) data 0.093 (0.093) loss 0.1697 (0.1697) acc 96.8750 (96.8750) lr 8.2807e-04 eta 0:03:29
epoch [113/200] batch [2/3] time 0.794 (0.796) data 0.092 (0.092) loss 0.5610 (0.3654) acc 87.5000 (92.1875) lr 8.2807e-04 eta 0:03:28
epoch [113/200] batch [3/3] time 0.834 (0.809) data 0.132 (0.105) loss 0.2695 (0.3334) acc 96.8750 (93.7500) lr 8.1262e-04 eta 0:03:31
epoch [114/200] batch [1/3] time 0.800 (0.800) data 0.096 (0.096) loss 0.3674 (0.3674) acc 93.7500 (93.7500) lr 8.1262e-04 eta 0:03:27
epoch [114/200] batch [2/3] time 0.796 (0.798) data 0.093 (0.095) loss 0.2644 (0.3159) acc 96.8750 (95.3125) lr 8.1262e-04 eta 0:03:26
epoch [114/200] batch [3/3] time 0.830 (0.809) data 0.127 (0.105) loss 0.1437 (0.2585) acc 96.8750 (95.8333) lr 7.9721e-04 eta 0:03:28
epoch [115/200] batch [1/3] time 0.794 (0.794) data 0.091 (0.091) loss 0.3628 (0.3628) acc 93.7500 (93.7500) lr 7.9721e-04 eta 0:03:24
epoch [115/200] batch [2/3] time 0.794 (0.794) data 0.090 (0.090) loss 0.1339 (0.2484) acc 96.8750 (95.3125) lr 7.9721e-04 eta 0:03:23
epoch [115/200] batch [3/3] time 0.799 (0.796) data 0.095 (0.092) loss 0.1624 (0.2197) acc 96.8750 (95.8333) lr 7.8186e-04 eta 0:03:22
epoch [116/200] batch [1/3] time 0.799 (0.799) data 0.095 (0.095) loss 0.2559 (0.2559) acc 93.7500 (93.7500) lr 7.8186e-04 eta 0:03:22
epoch [116/200] batch [2/3] time 0.798 (0.799) data 0.094 (0.094) loss 0.1680 (0.2119) acc 96.8750 (95.3125) lr 7.8186e-04 eta 0:03:22
epoch [116/200] batch [3/3] time 0.796 (0.798) data 0.093 (0.094) loss 0.3623 (0.2620) acc 90.6250 (93.7500) lr 7.6655e-04 eta 0:03:21
epoch [117/200] batch [1/3] time 0.792 (0.792) data 0.089 (0.089) loss 0.1455 (0.1455) acc 96.8750 (96.8750) lr 7.6655e-04 eta 0:03:18
epoch [117/200] batch [2/3] time 0.802 (0.797) data 0.098 (0.093) loss 0.5176 (0.3315) acc 90.6250 (93.7500) lr 7.6655e-04 eta 0:03:19
epoch [117/200] batch [3/3] time 0.795 (0.796) data 0.092 (0.093) loss 0.4636 (0.3756) acc 87.5000 (91.6667) lr 7.5131e-04 eta 0:03:18
epoch [118/200] batch [1/3] time 0.797 (0.797) data 0.093 (0.093) loss 0.3801 (0.3801) acc 90.6250 (90.6250) lr 7.5131e-04 eta 0:03:17
epoch [118/200] batch [2/3] time 0.791 (0.794) data 0.086 (0.089) loss 0.3311 (0.3556) acc 90.6250 (90.6250) lr 7.5131e-04 eta 0:03:16
epoch [118/200] batch [3/3] time 0.889 (0.826) data 0.185 (0.121) loss 0.3809 (0.3640) acc 90.6250 (90.6250) lr 7.3613e-04 eta 0:03:23
epoch [119/200] batch [1/3] time 0.793 (0.793) data 0.089 (0.089) loss 0.1425 (0.1425) acc 96.8750 (96.8750) lr 7.3613e-04 eta 0:03:14
epoch [119/200] batch [2/3] time 0.794 (0.793) data 0.089 (0.089) loss 0.4170 (0.2797) acc 90.6250 (93.7500) lr 7.3613e-04 eta 0:03:13
epoch [119/200] batch [3/3] time 0.796 (0.794) data 0.093 (0.090) loss 0.2903 (0.2832) acc 96.8750 (94.7917) lr 7.2101e-04 eta 0:03:12
epoch [120/200] batch [1/3] time 0.796 (0.796) data 0.093 (0.093) loss 0.2050 (0.2050) acc 96.8750 (96.8750) lr 7.2101e-04 eta 0:03:12
epoch [120/200] batch [2/3] time 0.800 (0.798) data 0.096 (0.094) loss 0.3831 (0.2940) acc 87.5000 (92.1875) lr 7.2101e-04 eta 0:03:12
epoch [120/200] batch [3/3] time 0.791 (0.796) data 0.088 (0.092) loss 0.5137 (0.3672) acc 87.5000 (90.6250) lr 7.0596e-04 eta 0:03:10
epoch [121/200] batch [1/3] time 0.793 (0.793) data 0.089 (0.089) loss 0.4331 (0.4331) acc 87.5000 (87.5000) lr 7.0596e-04 eta 0:03:09
epoch [121/200] batch [2/3] time 0.831 (0.812) data 0.127 (0.108) loss 0.2479 (0.3405) acc 93.7500 (90.6250) lr 7.0596e-04 eta 0:03:13
epoch [121/200] batch [3/3] time 0.803 (0.809) data 0.098 (0.105) loss 0.3481 (0.3431) acc 93.7500 (91.6667) lr 6.9098e-04 eta 0:03:11
epoch [122/200] batch [1/3] time 0.794 (0.794) data 0.090 (0.090) loss 0.3137 (0.3137) acc 96.8750 (96.8750) lr 6.9098e-04 eta 0:03:07
epoch [122/200] batch [2/3] time 0.792 (0.793) data 0.089 (0.089) loss 0.3225 (0.3181) acc 90.6250 (93.7500) lr 6.9098e-04 eta 0:03:06
epoch [122/200] batch [3/3] time 0.793 (0.793) data 0.089 (0.089) loss 0.3821 (0.3394) acc 93.7500 (93.7500) lr 6.7608e-04 eta 0:03:05
epoch [123/200] batch [1/3] time 0.800 (0.800) data 0.096 (0.096) loss 0.2698 (0.2698) acc 93.7500 (93.7500) lr 6.7608e-04 eta 0:03:06
epoch [123/200] batch [2/3] time 0.807 (0.804) data 0.103 (0.099) loss 0.4900 (0.3799) acc 90.6250 (92.1875) lr 6.7608e-04 eta 0:03:06
epoch [123/200] batch [3/3] time 0.792 (0.800) data 0.089 (0.096) loss 0.2988 (0.3529) acc 93.7500 (92.7083) lr 6.6126e-04 eta 0:03:04
epoch [124/200] batch [1/3] time 0.790 (0.790) data 0.086 (0.086) loss 0.4758 (0.4758) acc 84.3750 (84.3750) lr 6.6126e-04 eta 0:03:01
epoch [124/200] batch [2/3] time 0.797 (0.793) data 0.094 (0.090) loss 0.1350 (0.3054) acc 96.8750 (90.6250) lr 6.6126e-04 eta 0:03:01
epoch [124/200] batch [3/3] time 0.794 (0.794) data 0.090 (0.090) loss 0.2866 (0.2992) acc 90.6250 (90.6250) lr 6.4653e-04 eta 0:03:00
epoch [125/200] batch [1/3] time 0.793 (0.793) data 0.089 (0.089) loss 0.2058 (0.2058) acc 93.7500 (93.7500) lr 6.4653e-04 eta 0:02:59
epoch [125/200] batch [2/3] time 0.896 (0.845) data 0.192 (0.141) loss 0.2708 (0.2383) acc 96.8750 (95.3125) lr 6.4653e-04 eta 0:03:10
epoch [125/200] batch [3/3] time 0.801 (0.830) data 0.088 (0.123) loss 0.0535 (0.1767) acc 100.0000 (96.8750) lr 6.3188e-04 eta 0:03:06
epoch [126/200] batch [1/3] time 0.802 (0.802) data 0.093 (0.093) loss 0.2007 (0.2007) acc 96.8750 (96.8750) lr 6.3188e-04 eta 0:02:59
epoch [126/200] batch [2/3] time 0.798 (0.800) data 0.090 (0.091) loss 0.2827 (0.2417) acc 96.8750 (96.8750) lr 6.3188e-04 eta 0:02:58
epoch [126/200] batch [3/3] time 0.802 (0.801) data 0.095 (0.093) loss 0.2578 (0.2471) acc 90.6250 (94.7917) lr 6.1732e-04 eta 0:02:57
epoch [127/200] batch [1/3] time 0.794 (0.794) data 0.090 (0.090) loss 0.5649 (0.5649) acc 84.3750 (84.3750) lr 6.1732e-04 eta 0:02:55
epoch [127/200] batch [2/3] time 0.922 (0.858) data 0.211 (0.150) loss 0.1512 (0.3581) acc 96.8750 (90.6250) lr 6.1732e-04 eta 0:03:08
epoch [127/200] batch [3/3] time 0.799 (0.838) data 0.089 (0.130) loss 0.3459 (0.3540) acc 90.6250 (90.6250) lr 6.0285e-04 eta 0:03:03
epoch [128/200] batch [1/3] time 0.796 (0.796) data 0.091 (0.091) loss 0.3779 (0.3779) acc 87.5000 (87.5000) lr 6.0285e-04 eta 0:02:53
epoch [128/200] batch [2/3] time 0.789 (0.793) data 0.086 (0.088) loss 0.3174 (0.3477) acc 90.6250 (89.0625) lr 6.0285e-04 eta 0:02:52
epoch [128/200] batch [3/3] time 0.798 (0.795) data 0.092 (0.090) loss 0.4153 (0.3702) acc 96.8750 (91.6667) lr 5.8849e-04 eta 0:02:51
epoch [129/200] batch [1/3] time 0.814 (0.814) data 0.106 (0.106) loss 0.3894 (0.3894) acc 90.6250 (90.6250) lr 5.8849e-04 eta 0:02:54
epoch [129/200] batch [2/3] time 0.810 (0.812) data 0.096 (0.101) loss 0.5645 (0.4769) acc 90.6250 (90.6250) lr 5.8849e-04 eta 0:02:53
epoch [129/200] batch [3/3] time 0.877 (0.834) data 0.113 (0.105) loss 0.4829 (0.4789) acc 87.5000 (89.5833) lr 5.7422e-04 eta 0:02:57
epoch [130/200] batch [1/3] time 0.798 (0.798) data 0.093 (0.093) loss 0.9277 (0.9277) acc 81.2500 (81.2500) lr 5.7422e-04 eta 0:02:49
epoch [130/200] batch [2/3] time 0.863 (0.830) data 0.096 (0.095) loss 0.2686 (0.5981) acc 90.6250 (85.9375) lr 5.7422e-04 eta 0:02:55
epoch [130/200] batch [3/3] time 0.860 (0.840) data 0.093 (0.094) loss 0.4395 (0.5452) acc 87.5000 (86.4583) lr 5.6006e-04 eta 0:02:56
epoch [131/200] batch [1/3] time 0.813 (0.813) data 0.102 (0.102) loss 0.2422 (0.2422) acc 96.8750 (96.8750) lr 5.6006e-04 eta 0:02:49
epoch [131/200] batch [2/3] time 0.813 (0.813) data 0.097 (0.100) loss 0.2771 (0.2596) acc 93.7500 (95.3125) lr 5.6006e-04 eta 0:02:49
epoch [131/200] batch [3/3] time 0.849 (0.825) data 0.138 (0.113) loss 0.2759 (0.2651) acc 93.7500 (94.7917) lr 5.4601e-04 eta 0:02:50
epoch [132/200] batch [1/3] time 0.997 (0.997) data 0.263 (0.263) loss 0.3440 (0.3440) acc 90.6250 (90.6250) lr 5.4601e-04 eta 0:03:25
epoch [132/200] batch [2/3] time 0.808 (0.903) data 0.101 (0.182) loss 0.1450 (0.2445) acc 96.8750 (93.7500) lr 5.4601e-04 eta 0:03:05
epoch [132/200] batch [3/3] time 0.990 (0.932) data 0.120 (0.161) loss 0.2172 (0.2354) acc 96.8750 (94.7917) lr 5.3207e-04 eta 0:03:10
epoch [133/200] batch [1/3] time 0.892 (0.892) data 0.104 (0.104) loss 0.3818 (0.3818) acc 90.6250 (90.6250) lr 5.3207e-04 eta 0:03:01
epoch [133/200] batch [2/3] time 0.811 (0.852) data 0.103 (0.104) loss 0.1808 (0.2813) acc 96.8750 (93.7500) lr 5.3207e-04 eta 0:02:52
epoch [133/200] batch [3/3] time 0.799 (0.834) data 0.090 (0.099) loss 0.0461 (0.2029) acc 100.0000 (95.8333) lr 5.1825e-04 eta 0:02:47
epoch [134/200] batch [1/3] time 0.886 (0.886) data 0.177 (0.177) loss 0.2185 (0.2185) acc 96.8750 (96.8750) lr 5.1825e-04 eta 0:02:57
epoch [134/200] batch [2/3] time 0.813 (0.849) data 0.106 (0.142) loss 0.3386 (0.2786) acc 90.6250 (93.7500) lr 5.1825e-04 eta 0:02:49
epoch [134/200] batch [3/3] time 0.799 (0.833) data 0.094 (0.126) loss 0.2791 (0.2787) acc 90.6250 (92.7083) lr 5.0454e-04 eta 0:02:44
epoch [135/200] batch [1/3] time 0.795 (0.795) data 0.090 (0.090) loss 0.0602 (0.0602) acc 100.0000 (100.0000) lr 5.0454e-04 eta 0:02:36
epoch [135/200] batch [2/3] time 0.791 (0.793) data 0.088 (0.089) loss 0.2722 (0.1662) acc 96.8750 (98.4375) lr 5.0454e-04 eta 0:02:35
epoch [135/200] batch [3/3] time 0.803 (0.796) data 0.098 (0.092) loss 0.2693 (0.2006) acc 90.6250 (95.8333) lr 4.9096e-04 eta 0:02:35
epoch [136/200] batch [1/3] time 0.812 (0.812) data 0.106 (0.106) loss 0.2815 (0.2815) acc 93.7500 (93.7500) lr 4.9096e-04 eta 0:02:37
epoch [136/200] batch [2/3] time 0.792 (0.802) data 0.089 (0.097) loss 0.5415 (0.4115) acc 93.7500 (93.7500) lr 4.9096e-04 eta 0:02:34
epoch [136/200] batch [3/3] time 0.798 (0.801) data 0.092 (0.095) loss 0.4836 (0.4355) acc 90.6250 (92.7083) lr 4.7750e-04 eta 0:02:33
epoch [137/200] batch [1/3] time 0.798 (0.798) data 0.093 (0.093) loss 0.4697 (0.4697) acc 93.7500 (93.7500) lr 4.7750e-04 eta 0:02:32
epoch [137/200] batch [2/3] time 0.794 (0.796) data 0.091 (0.092) loss 0.2732 (0.3715) acc 90.6250 (92.1875) lr 4.7750e-04 eta 0:02:31
epoch [137/200] batch [3/3] time 0.799 (0.797) data 0.093 (0.092) loss 0.1648 (0.3026) acc 93.7500 (92.7083) lr 4.6417e-04 eta 0:02:30
epoch [138/200] batch [1/3] time 0.805 (0.805) data 0.100 (0.100) loss 0.4119 (0.4119) acc 90.6250 (90.6250) lr 4.6417e-04 eta 0:02:31
epoch [138/200] batch [2/3] time 0.910 (0.857) data 0.196 (0.148) loss 0.5488 (0.4803) acc 84.3750 (87.5000) lr 4.6417e-04 eta 0:02:40
epoch [138/200] batch [3/3] time 0.808 (0.841) data 0.096 (0.130) loss 0.2001 (0.3869) acc 93.7500 (89.5833) lr 4.5098e-04 eta 0:02:36
epoch [139/200] batch [1/3] time 0.822 (0.822) data 0.105 (0.105) loss 0.1149 (0.1149) acc 96.8750 (96.8750) lr 4.5098e-04 eta 0:02:32
epoch [139/200] batch [2/3] time 0.795 (0.809) data 0.090 (0.097) loss 0.4558 (0.2854) acc 87.5000 (92.1875) lr 4.5098e-04 eta 0:02:28
epoch [139/200] batch [3/3] time 0.820 (0.812) data 0.110 (0.101) loss 0.6650 (0.4119) acc 81.2500 (88.5417) lr 4.3792e-04 eta 0:02:28
epoch [140/200] batch [1/3] time 0.838 (0.838) data 0.130 (0.130) loss 0.1730 (0.1730) acc 96.8750 (96.8750) lr 4.3792e-04 eta 0:02:32
epoch [140/200] batch [2/3] time 0.855 (0.847) data 0.148 (0.139) loss 0.2389 (0.2059) acc 93.7500 (95.3125) lr 4.3792e-04 eta 0:02:33
epoch [140/200] batch [3/3] time 0.814 (0.836) data 0.100 (0.126) loss 0.3157 (0.2425) acc 93.7500 (94.7917) lr 4.2499e-04 eta 0:02:30
epoch [141/200] batch [1/3] time 0.802 (0.802) data 0.092 (0.092) loss 0.5498 (0.5498) acc 90.6250 (90.6250) lr 4.2499e-04 eta 0:02:23
epoch [141/200] batch [2/3] time 0.799 (0.801) data 0.088 (0.090) loss 0.4460 (0.4979) acc 87.5000 (89.0625) lr 4.2499e-04 eta 0:02:22
epoch [141/200] batch [3/3] time 0.825 (0.809) data 0.115 (0.098) loss 0.4075 (0.4678) acc 93.7500 (90.6250) lr 4.1221e-04 eta 0:02:23
epoch [142/200] batch [1/3] time 0.803 (0.803) data 0.091 (0.091) loss 0.1981 (0.1981) acc 93.7500 (93.7500) lr 4.1221e-04 eta 0:02:21
epoch [142/200] batch [2/3] time 0.802 (0.802) data 0.090 (0.090) loss 0.3401 (0.2691) acc 93.7500 (93.7500) lr 4.1221e-04 eta 0:02:20
epoch [142/200] batch [3/3] time 0.795 (0.800) data 0.091 (0.090) loss 0.2260 (0.2547) acc 93.7500 (93.7500) lr 3.9958e-04 eta 0:02:19
epoch [143/200] batch [1/3] time 0.878 (0.878) data 0.107 (0.107) loss 0.3630 (0.3630) acc 90.6250 (90.6250) lr 3.9958e-04 eta 0:02:31
epoch [143/200] batch [2/3] time 0.850 (0.864) data 0.132 (0.120) loss 0.1302 (0.2466) acc 100.0000 (95.3125) lr 3.9958e-04 eta 0:02:28
epoch [143/200] batch [3/3] time 0.936 (0.888) data 0.106 (0.115) loss 0.3350 (0.2761) acc 93.7500 (94.7917) lr 3.8709e-04 eta 0:02:31
epoch [144/200] batch [1/3] time 0.813 (0.813) data 0.089 (0.089) loss 0.4360 (0.4360) acc 90.6250 (90.6250) lr 3.8709e-04 eta 0:02:18
epoch [144/200] batch [2/3] time 0.799 (0.806) data 0.095 (0.092) loss 0.0967 (0.2664) acc 100.0000 (95.3125) lr 3.8709e-04 eta 0:02:16
epoch [144/200] batch [3/3] time 0.870 (0.828) data 0.165 (0.117) loss 0.0260 (0.1862) acc 100.0000 (96.8750) lr 3.7476e-04 eta 0:02:19
epoch [145/200] batch [1/3] time 1.103 (1.103) data 0.335 (0.335) loss 0.1304 (0.1304) acc 96.8750 (96.8750) lr 3.7476e-04 eta 0:03:04
epoch [145/200] batch [2/3] time 0.897 (1.000) data 0.179 (0.257) loss 0.1923 (0.1613) acc 96.8750 (96.8750) lr 3.7476e-04 eta 0:02:46
epoch [145/200] batch [3/3] time 0.805 (0.935) data 0.091 (0.202) loss 0.0971 (0.1399) acc 100.0000 (97.9167) lr 3.6258e-04 eta 0:02:34
epoch [146/200] batch [1/3] time 0.808 (0.808) data 0.104 (0.104) loss 0.1635 (0.1635) acc 96.8750 (96.8750) lr 3.6258e-04 eta 0:02:12
epoch [146/200] batch [2/3] time 0.822 (0.815) data 0.115 (0.110) loss 0.2175 (0.1905) acc 93.7500 (95.3125) lr 3.6258e-04 eta 0:02:12
epoch [146/200] batch [3/3] time 0.801 (0.810) data 0.096 (0.105) loss 0.2856 (0.2222) acc 90.6250 (93.7500) lr 3.5055e-04 eta 0:02:11
epoch [147/200] batch [1/3] time 0.801 (0.801) data 0.095 (0.095) loss 0.1892 (0.1892) acc 93.7500 (93.7500) lr 3.5055e-04 eta 0:02:08
epoch [147/200] batch [2/3] time 0.796 (0.798) data 0.091 (0.093) loss 0.4382 (0.3137) acc 90.6250 (92.1875) lr 3.5055e-04 eta 0:02:07
epoch [147/200] batch [3/3] time 1.029 (0.875) data 0.323 (0.170) loss 0.2307 (0.2861) acc 96.8750 (93.7500) lr 3.3869e-04 eta 0:02:19
epoch [148/200] batch [1/3] time 0.984 (0.984) data 0.278 (0.278) loss 0.3047 (0.3047) acc 87.5000 (87.5000) lr 3.3869e-04 eta 0:02:35
epoch [148/200] batch [2/3] time 0.817 (0.900) data 0.112 (0.195) loss 0.2686 (0.2866) acc 93.7500 (90.6250) lr 3.3869e-04 eta 0:02:21
epoch [148/200] batch [3/3] time 0.875 (0.892) data 0.171 (0.187) loss 0.3372 (0.3035) acc 90.6250 (90.6250) lr 3.2699e-04 eta 0:02:19
epoch [149/200] batch [1/3] time 0.837 (0.837) data 0.132 (0.132) loss 0.2200 (0.2200) acc 93.7500 (93.7500) lr 3.2699e-04 eta 0:02:09
epoch [149/200] batch [2/3] time 0.832 (0.834) data 0.128 (0.130) loss 0.2430 (0.2315) acc 90.6250 (92.1875) lr 3.2699e-04 eta 0:02:08
epoch [149/200] batch [3/3] time 0.836 (0.835) data 0.132 (0.131) loss 0.2959 (0.2530) acc 90.6250 (91.6667) lr 3.1545e-04 eta 0:02:07
epoch [150/200] batch [1/3] time 0.828 (0.828) data 0.122 (0.122) loss 0.3015 (0.3015) acc 90.6250 (90.6250) lr 3.1545e-04 eta 0:02:05
epoch [150/200] batch [2/3] time 0.827 (0.827) data 0.121 (0.121) loss 0.4175 (0.3595) acc 93.7500 (92.1875) lr 3.1545e-04 eta 0:02:04
epoch [150/200] batch [3/3] time 0.848 (0.834) data 0.145 (0.129) loss 0.4067 (0.3752) acc 90.6250 (91.6667) lr 3.0409e-04 eta 0:02:05
epoch [151/200] batch [1/3] time 0.859 (0.859) data 0.155 (0.155) loss 0.1182 (0.1182) acc 96.8750 (96.8750) lr 3.0409e-04 eta 0:02:07
epoch [151/200] batch [2/3] time 0.814 (0.837) data 0.111 (0.133) loss 0.5928 (0.3555) acc 93.7500 (95.3125) lr 3.0409e-04 eta 0:02:03
epoch [151/200] batch [3/3] time 0.793 (0.822) data 0.090 (0.119) loss 0.2112 (0.3074) acc 100.0000 (96.8750) lr 2.9289e-04 eta 0:02:00
epoch [152/200] batch [1/3] time 0.808 (0.808) data 0.104 (0.104) loss 0.2073 (0.2073) acc 93.7500 (93.7500) lr 2.9289e-04 eta 0:01:57
epoch [152/200] batch [2/3] time 0.795 (0.802) data 0.092 (0.098) loss 0.2081 (0.2077) acc 96.8750 (95.3125) lr 2.9289e-04 eta 0:01:56
epoch [152/200] batch [3/3] time 0.793 (0.799) data 0.089 (0.095) loss 0.5190 (0.3115) acc 84.3750 (91.6667) lr 2.8187e-04 eta 0:01:55
epoch [153/200] batch [1/3] time 0.812 (0.812) data 0.108 (0.108) loss 0.0591 (0.0591) acc 100.0000 (100.0000) lr 2.8187e-04 eta 0:01:56
epoch [153/200] batch [2/3] time 0.798 (0.805) data 0.093 (0.101) loss 0.1243 (0.0917) acc 100.0000 (100.0000) lr 2.8187e-04 eta 0:01:54
epoch [153/200] batch [3/3] time 0.794 (0.801) data 0.092 (0.098) loss 0.3108 (0.1647) acc 90.6250 (96.8750) lr 2.7103e-04 eta 0:01:53
epoch [154/200] batch [1/3] time 0.813 (0.813) data 0.110 (0.110) loss 0.2930 (0.2930) acc 93.7500 (93.7500) lr 2.7103e-04 eta 0:01:53
epoch [154/200] batch [2/3] time 0.795 (0.804) data 0.091 (0.100) loss 0.5327 (0.4128) acc 84.3750 (89.0625) lr 2.7103e-04 eta 0:01:51
epoch [154/200] batch [3/3] time 0.792 (0.800) data 0.089 (0.097) loss 0.3928 (0.4062) acc 90.6250 (89.5833) lr 2.6037e-04 eta 0:01:50
epoch [155/200] batch [1/3] time 0.794 (0.794) data 0.091 (0.091) loss 0.0897 (0.0897) acc 100.0000 (100.0000) lr 2.6037e-04 eta 0:01:48
epoch [155/200] batch [2/3] time 0.797 (0.795) data 0.094 (0.092) loss 0.3518 (0.2207) acc 87.5000 (93.7500) lr 2.6037e-04 eta 0:01:48
epoch [155/200] batch [3/3] time 0.811 (0.801) data 0.107 (0.097) loss 0.2462 (0.2292) acc 93.7500 (93.7500) lr 2.4989e-04 eta 0:01:48
epoch [156/200] batch [1/3] time 0.796 (0.796) data 0.093 (0.093) loss 0.3540 (0.3540) acc 87.5000 (87.5000) lr 2.4989e-04 eta 0:01:46
epoch [156/200] batch [2/3] time 0.792 (0.794) data 0.089 (0.091) loss 0.2603 (0.3071) acc 96.8750 (92.1875) lr 2.4989e-04 eta 0:01:45
epoch [156/200] batch [3/3] time 0.797 (0.795) data 0.092 (0.092) loss 0.2930 (0.3024) acc 93.7500 (92.7083) lr 2.3959e-04 eta 0:01:44
epoch [157/200] batch [1/3] time 0.803 (0.803) data 0.098 (0.098) loss 0.1360 (0.1360) acc 96.8750 (96.8750) lr 2.3959e-04 eta 0:01:45
epoch [157/200] batch [2/3] time 0.803 (0.803) data 0.099 (0.099) loss 0.1421 (0.1390) acc 96.8750 (96.8750) lr 2.3959e-04 eta 0:01:44
epoch [157/200] batch [3/3] time 0.791 (0.799) data 0.087 (0.095) loss 0.2830 (0.1870) acc 90.6250 (94.7917) lr 2.2949e-04 eta 0:01:43
epoch [158/200] batch [1/3] time 0.808 (0.808) data 0.105 (0.105) loss 0.3767 (0.3767) acc 93.7500 (93.7500) lr 2.2949e-04 eta 0:01:43
epoch [158/200] batch [2/3] time 0.794 (0.801) data 0.091 (0.098) loss 0.2314 (0.3041) acc 96.8750 (95.3125) lr 2.2949e-04 eta 0:01:41
epoch [158/200] batch [3/3] time 0.800 (0.801) data 0.097 (0.098) loss 0.2002 (0.2694) acc 96.8750 (95.8333) lr 2.1957e-04 eta 0:01:40
epoch [159/200] batch [1/3] time 0.792 (0.792) data 0.089 (0.089) loss 0.1100 (0.1100) acc 96.8750 (96.8750) lr 2.1957e-04 eta 0:01:38
epoch [159/200] batch [2/3] time 0.794 (0.793) data 0.090 (0.089) loss 0.5293 (0.3196) acc 87.5000 (92.1875) lr 2.1957e-04 eta 0:01:38
epoch [159/200] batch [3/3] time 0.795 (0.794) data 0.092 (0.090) loss 0.3582 (0.3325) acc 90.6250 (91.6667) lr 2.0984e-04 eta 0:01:37
epoch [160/200] batch [1/3] time 0.796 (0.796) data 0.092 (0.092) loss 0.1053 (0.1053) acc 93.7500 (93.7500) lr 2.0984e-04 eta 0:01:37
epoch [160/200] batch [2/3] time 0.798 (0.797) data 0.093 (0.093) loss 0.2286 (0.1670) acc 96.8750 (95.3125) lr 2.0984e-04 eta 0:01:36
epoch [160/200] batch [3/3] time 0.789 (0.794) data 0.086 (0.090) loss 0.3013 (0.2117) acc 93.7500 (94.7917) lr 2.0032e-04 eta 0:01:35
epoch [161/200] batch [1/3] time 0.798 (0.798) data 0.094 (0.094) loss 0.3130 (0.3130) acc 90.6250 (90.6250) lr 2.0032e-04 eta 0:01:34
epoch [161/200] batch [2/3] time 0.795 (0.797) data 0.091 (0.093) loss 0.4146 (0.3638) acc 90.6250 (90.6250) lr 2.0032e-04 eta 0:01:34
epoch [161/200] batch [3/3] time 0.859 (0.818) data 0.155 (0.114) loss 0.0639 (0.2638) acc 100.0000 (93.7500) lr 1.9098e-04 eta 0:01:35
epoch [162/200] batch [1/3] time 0.793 (0.793) data 0.090 (0.090) loss 0.6582 (0.6582) acc 84.3750 (84.3750) lr 1.9098e-04 eta 0:01:32
epoch [162/200] batch [2/3] time 0.791 (0.792) data 0.088 (0.089) loss 0.1097 (0.3839) acc 96.8750 (90.6250) lr 1.9098e-04 eta 0:01:31
epoch [162/200] batch [3/3] time 0.796 (0.793) data 0.092 (0.090) loss 0.3306 (0.3661) acc 87.5000 (89.5833) lr 1.8185e-04 eta 0:01:30
epoch [163/200] batch [1/3] time 0.795 (0.795) data 0.092 (0.092) loss 0.3767 (0.3767) acc 90.6250 (90.6250) lr 1.8185e-04 eta 0:01:29
epoch [163/200] batch [2/3] time 0.798 (0.796) data 0.094 (0.093) loss 0.3271 (0.3519) acc 87.5000 (89.0625) lr 1.8185e-04 eta 0:01:29
epoch [163/200] batch [3/3] time 0.797 (0.797) data 0.095 (0.093) loss 0.0443 (0.2494) acc 100.0000 (92.7083) lr 1.7292e-04 eta 0:01:28
epoch [164/200] batch [1/3] time 0.798 (0.798) data 0.095 (0.095) loss 0.0956 (0.0956) acc 100.0000 (100.0000) lr 1.7292e-04 eta 0:01:27
epoch [164/200] batch [2/3] time 0.815 (0.807) data 0.097 (0.096) loss 0.2411 (0.1683) acc 96.8750 (98.4375) lr 1.7292e-04 eta 0:01:27
epoch [164/200] batch [3/3] time 0.807 (0.807) data 0.096 (0.096) loss 0.2578 (0.1982) acc 96.8750 (97.9167) lr 1.6419e-04 eta 0:01:27
epoch [165/200] batch [1/3] time 0.853 (0.853) data 0.139 (0.139) loss 0.1014 (0.1014) acc 96.8750 (96.8750) lr 1.6419e-04 eta 0:01:31
epoch [165/200] batch [2/3] time 0.816 (0.835) data 0.103 (0.121) loss 0.2158 (0.1586) acc 96.8750 (96.8750) lr 1.6419e-04 eta 0:01:28
epoch [165/200] batch [3/3] time 0.795 (0.821) data 0.089 (0.110) loss 0.5405 (0.2859) acc 93.7500 (95.8333) lr 1.5567e-04 eta 0:01:26
epoch [166/200] batch [1/3] time 0.796 (0.796) data 0.087 (0.087) loss 0.1159 (0.1159) acc 100.0000 (100.0000) lr 1.5567e-04 eta 0:01:22
epoch [166/200] batch [2/3] time 0.812 (0.804) data 0.091 (0.089) loss 0.4978 (0.3069) acc 90.6250 (95.3125) lr 1.5567e-04 eta 0:01:22
epoch [166/200] batch [3/3] time 0.794 (0.801) data 0.090 (0.089) loss 0.1802 (0.2646) acc 90.6250 (93.7500) lr 1.4736e-04 eta 0:01:21
epoch [167/200] batch [1/3] time 0.828 (0.828) data 0.123 (0.123) loss 0.2747 (0.2747) acc 93.7500 (93.7500) lr 1.4736e-04 eta 0:01:23
epoch [167/200] batch [2/3] time 0.805 (0.816) data 0.091 (0.107) loss 0.2279 (0.2513) acc 93.7500 (93.7500) lr 1.4736e-04 eta 0:01:21
epoch [167/200] batch [3/3] time 0.808 (0.814) data 0.098 (0.104) loss 0.0453 (0.1826) acc 100.0000 (95.8333) lr 1.3926e-04 eta 0:01:20
epoch [168/200] batch [1/3] time 0.806 (0.806) data 0.089 (0.089) loss 0.2070 (0.2070) acc 93.7500 (93.7500) lr 1.3926e-04 eta 0:01:18
epoch [168/200] batch [2/3] time 0.855 (0.831) data 0.140 (0.114) loss 0.0828 (0.1449) acc 96.8750 (95.3125) lr 1.3926e-04 eta 0:01:20
epoch [168/200] batch [3/3] time 0.801 (0.821) data 0.089 (0.106) loss 0.1135 (0.1344) acc 96.8750 (95.8333) lr 1.3137e-04 eta 0:01:18
epoch [169/200] batch [1/3] time 0.794 (0.794) data 0.088 (0.088) loss 0.3408 (0.3408) acc 93.7500 (93.7500) lr 1.3137e-04 eta 0:01:15
epoch [169/200] batch [2/3] time 0.800 (0.797) data 0.093 (0.091) loss 0.1270 (0.2339) acc 96.8750 (95.3125) lr 1.3137e-04 eta 0:01:14
epoch [169/200] batch [3/3] time 0.802 (0.798) data 0.096 (0.093) loss 0.4160 (0.2946) acc 84.3750 (91.6667) lr 1.2369e-04 eta 0:01:14
epoch [170/200] batch [1/3] time 0.797 (0.797) data 0.092 (0.092) loss 0.1250 (0.1250) acc 96.8750 (96.8750) lr 1.2369e-04 eta 0:01:13
epoch [170/200] batch [2/3] time 0.812 (0.805) data 0.106 (0.099) loss 0.0129 (0.0690) acc 100.0000 (98.4375) lr 1.2369e-04 eta 0:01:13
epoch [170/200] batch [3/3] time 0.800 (0.803) data 0.090 (0.096) loss 0.4666 (0.2015) acc 87.5000 (94.7917) lr 1.1623e-04 eta 0:01:12
epoch [171/200] batch [1/3] time 0.812 (0.812) data 0.096 (0.096) loss 0.4045 (0.4045) acc 87.5000 (87.5000) lr 1.1623e-04 eta 0:01:12
epoch [171/200] batch [2/3] time 0.810 (0.811) data 0.104 (0.100) loss 0.5083 (0.4564) acc 87.5000 (87.5000) lr 1.1623e-04 eta 0:01:11
epoch [171/200] batch [3/3] time 0.803 (0.808) data 0.091 (0.097) loss 0.5151 (0.4760) acc 90.6250 (88.5417) lr 1.0899e-04 eta 0:01:10
epoch [172/200] batch [1/3] time 0.815 (0.815) data 0.107 (0.107) loss 0.2905 (0.2905) acc 90.6250 (90.6250) lr 1.0899e-04 eta 0:01:10
epoch [172/200] batch [2/3] time 0.814 (0.814) data 0.099 (0.103) loss 0.5347 (0.4126) acc 84.3750 (87.5000) lr 1.0899e-04 eta 0:01:09
epoch [172/200] batch [3/3] time 0.852 (0.827) data 0.144 (0.117) loss 0.1826 (0.3359) acc 96.8750 (90.6250) lr 1.0197e-04 eta 0:01:09
epoch [173/200] batch [1/3] time 0.833 (0.833) data 0.124 (0.124) loss 0.4553 (0.4553) acc 87.5000 (87.5000) lr 1.0197e-04 eta 0:01:09
epoch [173/200] batch [2/3] time 0.806 (0.820) data 0.096 (0.110) loss 0.0616 (0.2585) acc 100.0000 (93.7500) lr 1.0197e-04 eta 0:01:07
epoch [173/200] batch [3/3] time 0.832 (0.824) data 0.124 (0.115) loss 0.1055 (0.2075) acc 96.8750 (94.7917) lr 9.5173e-05 eta 0:01:06
epoch [174/200] batch [1/3] time 0.889 (0.889) data 0.185 (0.185) loss 0.3801 (0.3801) acc 93.7500 (93.7500) lr 9.5173e-05 eta 0:01:11
epoch [174/200] batch [2/3] time 1.022 (0.956) data 0.253 (0.219) loss 0.2294 (0.3047) acc 93.7500 (93.7500) lr 9.5173e-05 eta 0:01:15
epoch [174/200] batch [3/3] time 0.865 (0.926) data 0.138 (0.192) loss 0.3374 (0.3156) acc 87.5000 (91.6667) lr 8.8597e-05 eta 0:01:12
epoch [175/200] batch [1/3] time 0.803 (0.803) data 0.094 (0.094) loss 0.6836 (0.6836) acc 84.3750 (84.3750) lr 8.8597e-05 eta 0:01:01
epoch [175/200] batch [2/3] time 0.873 (0.838) data 0.166 (0.130) loss 0.3369 (0.5103) acc 96.8750 (90.6250) lr 8.8597e-05 eta 0:01:03
epoch [175/200] batch [3/3] time 0.792 (0.823) data 0.087 (0.116) loss 0.2812 (0.4339) acc 90.6250 (90.6250) lr 8.2245e-05 eta 0:01:01
epoch [176/200] batch [1/3] time 0.799 (0.799) data 0.093 (0.093) loss 0.1964 (0.1964) acc 96.8750 (96.8750) lr 8.2245e-05 eta 0:00:59
epoch [176/200] batch [2/3] time 0.795 (0.797) data 0.091 (0.092) loss 0.4004 (0.2984) acc 90.6250 (93.7500) lr 8.2245e-05 eta 0:00:58
epoch [176/200] batch [3/3] time 0.809 (0.801) data 0.099 (0.094) loss 0.1610 (0.2526) acc 100.0000 (95.8333) lr 7.6120e-05 eta 0:00:57
epoch [177/200] batch [1/3] time 0.798 (0.798) data 0.092 (0.092) loss 0.2617 (0.2617) acc 93.7500 (93.7500) lr 7.6120e-05 eta 0:00:56
epoch [177/200] batch [2/3] time 0.844 (0.821) data 0.126 (0.109) loss 0.2527 (0.2572) acc 93.7500 (93.7500) lr 7.6120e-05 eta 0:00:57
epoch [177/200] batch [3/3] time 0.853 (0.832) data 0.143 (0.120) loss 0.3926 (0.3023) acc 90.6250 (92.7083) lr 7.0224e-05 eta 0:00:57
epoch [178/200] batch [1/3] time 0.813 (0.813) data 0.099 (0.099) loss 0.2468 (0.2468) acc 90.6250 (90.6250) lr 7.0224e-05 eta 0:00:55
epoch [178/200] batch [2/3] time 0.802 (0.808) data 0.099 (0.099) loss 0.1914 (0.2191) acc 93.7500 (92.1875) lr 7.0224e-05 eta 0:00:54
epoch [178/200] batch [3/3] time 0.801 (0.805) data 0.089 (0.096) loss 0.2986 (0.2456) acc 87.5000 (90.6250) lr 6.4556e-05 eta 0:00:53
epoch [179/200] batch [1/3] time 0.802 (0.802) data 0.089 (0.089) loss 0.4292 (0.4292) acc 87.5000 (87.5000) lr 6.4556e-05 eta 0:00:52
epoch [179/200] batch [2/3] time 0.831 (0.817) data 0.115 (0.102) loss 0.3833 (0.4062) acc 90.6250 (89.0625) lr 6.4556e-05 eta 0:00:52
epoch [179/200] batch [3/3] time 0.821 (0.818) data 0.109 (0.104) loss 0.0544 (0.2890) acc 100.0000 (92.7083) lr 5.9119e-05 eta 0:00:51
epoch [180/200] batch [1/3] time 0.798 (0.798) data 0.093 (0.093) loss 0.2134 (0.2134) acc 96.8750 (96.8750) lr 5.9119e-05 eta 0:00:49
epoch [180/200] batch [2/3] time 0.792 (0.795) data 0.090 (0.091) loss 0.1815 (0.1974) acc 93.7500 (95.3125) lr 5.9119e-05 eta 0:00:48
epoch [180/200] batch [3/3] time 0.795 (0.795) data 0.090 (0.091) loss 0.3662 (0.2537) acc 90.6250 (93.7500) lr 5.3915e-05 eta 0:00:47
epoch [181/200] batch [1/3] time 0.800 (0.800) data 0.094 (0.094) loss 0.3594 (0.3594) acc 96.8750 (96.8750) lr 5.3915e-05 eta 0:00:47
epoch [181/200] batch [2/3] time 0.796 (0.798) data 0.091 (0.093) loss 0.2092 (0.2843) acc 93.7500 (95.3125) lr 5.3915e-05 eta 0:00:46
epoch [181/200] batch [3/3] time 0.794 (0.797) data 0.089 (0.092) loss 0.3335 (0.3007) acc 93.7500 (94.7917) lr 4.8943e-05 eta 0:00:45
epoch [182/200] batch [1/3] time 0.797 (0.797) data 0.091 (0.091) loss 0.5137 (0.5137) acc 84.3750 (84.3750) lr 4.8943e-05 eta 0:00:44
epoch [182/200] batch [2/3] time 0.798 (0.797) data 0.095 (0.093) loss 0.2299 (0.3718) acc 93.7500 (89.0625) lr 4.8943e-05 eta 0:00:43
epoch [182/200] batch [3/3] time 0.797 (0.797) data 0.092 (0.093) loss 0.2812 (0.3416) acc 96.8750 (91.6667) lr 4.4207e-05 eta 0:00:43
epoch [183/200] batch [1/3] time 0.795 (0.795) data 0.090 (0.090) loss 0.2455 (0.2455) acc 90.6250 (90.6250) lr 4.4207e-05 eta 0:00:42
epoch [183/200] batch [2/3] time 0.809 (0.802) data 0.104 (0.097) loss 0.3232 (0.2844) acc 93.7500 (92.1875) lr 4.4207e-05 eta 0:00:41
epoch [183/200] batch [3/3] time 0.796 (0.800) data 0.091 (0.095) loss 0.3560 (0.3082) acc 90.6250 (91.6667) lr 3.9706e-05 eta 0:00:40
epoch [184/200] batch [1/3] time 0.795 (0.795) data 0.090 (0.090) loss 0.2783 (0.2783) acc 93.7500 (93.7500) lr 3.9706e-05 eta 0:00:39
epoch [184/200] batch [2/3] time 0.799 (0.797) data 0.094 (0.092) loss 0.1733 (0.2258) acc 93.7500 (93.7500) lr 3.9706e-05 eta 0:00:39
epoch [184/200] batch [3/3] time 0.799 (0.798) data 0.094 (0.093) loss 0.6265 (0.3594) acc 87.5000 (91.6667) lr 3.5443e-05 eta 0:00:38
epoch [185/200] batch [1/3] time 0.802 (0.802) data 0.100 (0.100) loss 0.2478 (0.2478) acc 93.7500 (93.7500) lr 3.5443e-05 eta 0:00:37
epoch [185/200] batch [2/3] time 0.792 (0.797) data 0.088 (0.094) loss 0.2030 (0.2254) acc 93.7500 (93.7500) lr 3.5443e-05 eta 0:00:36
epoch [185/200] batch [3/3] time 0.803 (0.799) data 0.099 (0.096) loss 0.4426 (0.2978) acc 87.5000 (91.6667) lr 3.1417e-05 eta 0:00:35
epoch [186/200] batch [1/3] time 0.792 (0.792) data 0.088 (0.088) loss 0.4143 (0.4143) acc 84.3750 (84.3750) lr 3.1417e-05 eta 0:00:34
epoch [186/200] batch [2/3] time 0.796 (0.794) data 0.091 (0.090) loss 0.2074 (0.3109) acc 93.7500 (89.0625) lr 3.1417e-05 eta 0:00:34
epoch [186/200] batch [3/3] time 0.803 (0.797) data 0.100 (0.093) loss 0.2598 (0.2938) acc 96.8750 (91.6667) lr 2.7630e-05 eta 0:00:33
epoch [187/200] batch [1/3] time 0.882 (0.882) data 0.179 (0.179) loss 0.3196 (0.3196) acc 90.6250 (90.6250) lr 2.7630e-05 eta 0:00:36
epoch [187/200] batch [2/3] time 0.797 (0.840) data 0.092 (0.136) loss 0.3508 (0.3352) acc 96.8750 (93.7500) lr 2.7630e-05 eta 0:00:33
epoch [187/200] batch [3/3] time 0.795 (0.825) data 0.091 (0.121) loss 0.4458 (0.3721) acc 87.5000 (91.6667) lr 2.4083e-05 eta 0:00:32
epoch [188/200] batch [1/3] time 0.792 (0.792) data 0.088 (0.088) loss 0.3689 (0.3689) acc 90.6250 (90.6250) lr 2.4083e-05 eta 0:00:30
epoch [188/200] batch [2/3] time 0.798 (0.795) data 0.093 (0.091) loss 0.1110 (0.2399) acc 100.0000 (95.3125) lr 2.4083e-05 eta 0:00:29
epoch [188/200] batch [3/3] time 0.830 (0.807) data 0.115 (0.099) loss 0.1591 (0.2130) acc 93.7500 (94.7917) lr 2.0777e-05 eta 0:00:29
epoch [189/200] batch [1/3] time 0.916 (0.916) data 0.113 (0.113) loss 0.1124 (0.1124) acc 96.8750 (96.8750) lr 2.0777e-05 eta 0:00:32
epoch [189/200] batch [2/3] time 1.089 (1.002) data 0.296 (0.205) loss 0.2668 (0.1896) acc 96.8750 (96.8750) lr 2.0777e-05 eta 0:00:34
epoch [189/200] batch [3/3] time 0.823 (0.942) data 0.101 (0.170) loss 0.2339 (0.2044) acc 93.7500 (95.8333) lr 1.7713e-05 eta 0:00:31
epoch [190/200] batch [1/3] time 0.982 (0.982) data 0.162 (0.162) loss 0.1287 (0.1287) acc 96.8750 (96.8750) lr 1.7713e-05 eta 0:00:31
epoch [190/200] batch [2/3] time 0.945 (0.963) data 0.242 (0.202) loss 0.2299 (0.1793) acc 93.7500 (95.3125) lr 1.7713e-05 eta 0:00:29
epoch [190/200] batch [3/3] time 0.830 (0.919) data 0.103 (0.169) loss 0.1616 (0.1734) acc 96.8750 (95.8333) lr 1.4891e-05 eta 0:00:27
epoch [191/200] batch [1/3] time 0.903 (0.903) data 0.159 (0.159) loss 0.2979 (0.2979) acc 93.7500 (93.7500) lr 1.4891e-05 eta 0:00:26
epoch [191/200] batch [2/3] time 0.883 (0.893) data 0.153 (0.156) loss 0.3293 (0.3136) acc 87.5000 (90.6250) lr 1.4891e-05 eta 0:00:24
epoch [191/200] batch [3/3] time 0.812 (0.866) data 0.100 (0.137) loss 0.2408 (0.2893) acc 93.7500 (91.6667) lr 1.2312e-05 eta 0:00:23
epoch [192/200] batch [1/3] time 0.803 (0.803) data 0.097 (0.097) loss 0.1799 (0.1799) acc 93.7500 (93.7500) lr 1.2312e-05 eta 0:00:20
epoch [192/200] batch [2/3] time 0.833 (0.818) data 0.122 (0.110) loss 0.2157 (0.1978) acc 93.7500 (93.7500) lr 1.2312e-05 eta 0:00:20
epoch [192/200] batch [3/3] time 0.876 (0.837) data 0.170 (0.130) loss 0.3623 (0.2526) acc 90.6250 (92.7083) lr 9.9763e-06 eta 0:00:20
epoch [193/200] batch [1/3] time 0.811 (0.811) data 0.106 (0.106) loss 0.2856 (0.2856) acc 93.7500 (93.7500) lr 9.9763e-06 eta 0:00:18
epoch [193/200] batch [2/3] time 0.825 (0.818) data 0.121 (0.113) loss 0.0723 (0.1790) acc 100.0000 (96.8750) lr 9.9763e-06 eta 0:00:17
epoch [193/200] batch [3/3] time 0.799 (0.812) data 0.094 (0.107) loss 0.1932 (0.1837) acc 96.8750 (96.8750) lr 7.8853e-06 eta 0:00:17
epoch [194/200] batch [1/3] time 0.817 (0.817) data 0.103 (0.103) loss 0.1394 (0.1394) acc 100.0000 (100.0000) lr 7.8853e-06 eta 0:00:16
epoch [194/200] batch [2/3] time 0.807 (0.812) data 0.090 (0.096) loss 0.1100 (0.1247) acc 93.7500 (96.8750) lr 7.8853e-06 eta 0:00:15
epoch [194/200] batch [3/3] time 0.806 (0.810) data 0.093 (0.095) loss 0.3567 (0.2020) acc 90.6250 (94.7917) lr 6.0390e-06 eta 0:00:14
epoch [195/200] batch [1/3] time 0.814 (0.814) data 0.102 (0.102) loss 0.2893 (0.2893) acc 87.5000 (87.5000) lr 6.0390e-06 eta 0:00:13
epoch [195/200] batch [2/3] time 0.801 (0.807) data 0.095 (0.098) loss 0.1077 (0.1985) acc 96.8750 (92.1875) lr 6.0390e-06 eta 0:00:12
epoch [195/200] batch [3/3] time 0.799 (0.805) data 0.094 (0.097) loss 0.1541 (0.1837) acc 96.8750 (93.7500) lr 4.4380e-06 eta 0:00:12
epoch [196/200] batch [1/3] time 0.812 (0.812) data 0.097 (0.097) loss 0.1569 (0.1569) acc 93.7500 (93.7500) lr 4.4380e-06 eta 0:00:11
epoch [196/200] batch [2/3] time 0.829 (0.820) data 0.122 (0.110) loss 0.2444 (0.2006) acc 93.7500 (93.7500) lr 4.4380e-06 eta 0:00:10
epoch [196/200] batch [3/3] time 0.929 (0.857) data 0.204 (0.141) loss 0.2930 (0.2314) acc 90.6250 (92.7083) lr 3.0827e-06 eta 0:00:10
epoch [197/200] batch [1/3] time 0.972 (0.972) data 0.106 (0.106) loss 0.0541 (0.0541) acc 100.0000 (100.0000) lr 3.0827e-06 eta 0:00:10
epoch [197/200] batch [2/3] time 0.955 (0.964) data 0.189 (0.148) loss 0.1146 (0.0843) acc 100.0000 (100.0000) lr 3.0827e-06 eta 0:00:09
epoch [197/200] batch [3/3] time 0.804 (0.911) data 0.095 (0.130) loss 0.4238 (0.1975) acc 90.6250 (96.8750) lr 1.9733e-06 eta 0:00:08
epoch [198/200] batch [1/3] time 0.806 (0.806) data 0.102 (0.102) loss 0.4033 (0.4033) acc 90.6250 (90.6250) lr 1.9733e-06 eta 0:00:06
epoch [198/200] batch [2/3] time 0.804 (0.805) data 0.101 (0.101) loss 0.2725 (0.3379) acc 93.7500 (92.1875) lr 1.9733e-06 eta 0:00:05
epoch [198/200] batch [3/3] time 0.809 (0.807) data 0.101 (0.101) loss 0.2395 (0.3051) acc 96.8750 (93.7500) lr 1.1101e-06 eta 0:00:04
epoch [199/200] batch [1/3] time 0.796 (0.796) data 0.090 (0.090) loss 0.1748 (0.1748) acc 93.7500 (93.7500) lr 1.1101e-06 eta 0:00:03
epoch [199/200] batch [2/3] time 0.798 (0.797) data 0.095 (0.093) loss 0.1830 (0.1789) acc 93.7500 (93.7500) lr 1.1101e-06 eta 0:00:03
epoch [199/200] batch [3/3] time 0.833 (0.809) data 0.127 (0.104) loss 0.2917 (0.2165) acc 93.7500 (93.7500) lr 4.9344e-07 eta 0:00:02
epoch [200/200] batch [1/3] time 0.796 (0.796) data 0.091 (0.091) loss 0.2686 (0.2686) acc 93.7500 (93.7500) lr 4.9344e-07 eta 0:00:01
epoch [200/200] batch [2/3] time 0.799 (0.798) data 0.095 (0.093) loss 0.2181 (0.2433) acc 96.8750 (95.3125) lr 4.9344e-07 eta 0:00:00
epoch [200/200] batch [3/3] time 0.795 (0.797) data 0.090 (0.092) loss 0.2834 (0.2567) acc 96.8750 (95.8333) lr 1.2337e-07 eta 0:00:00
Checkpoint saved to output/Caltech/1/prompt_learner/model.pth.tar-200
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
=> result
* total: 2,465
* correct: 2,147
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 82.1%
Elapsed: 0:09:06
args2: backbone=, config_file=configs/trainers/CoOp/vit_b32.yaml, dataset_config_file=configs/datasets/caltech101.yaml, eval_only=False, head=, load_epoch=None, model_dir=, no_train=False,  opts: ['TRAINER.COOP.N_CTX', '16', 'TRAINER.COOP.CSC', 'False', 'TRAINER.COOP.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '1'], output_dir=output/Caltech/1/2, resume=, root=/home/brandnerkasper/Uni/MP/MP_CustomCoOp/data, seed=2, source_domains=None, target_domains=None, trainer=CoOp, transforms=None
Setting fixed seed: 2
***************
** Arguments **
***************
config_file: configs/trainers/CoOp/vit_b32.yaml
csc: False
ctp: end
dataset_config_file: configs/datasets/caltech101.yaml
n_ctx: 16
opts: ['TRAINER.COOP.N_CTX', '16', 'TRAINER.COOP.CSC', 'False', 'TRAINER.COOP.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '1']
output_dir: output/Caltech/1/2
root: /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data
seed: 2
shots: 1
trainer: CoOp
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 0
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 1
  ROOT: /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/32
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/Caltech/1/2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 2.0.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 22.04.3 LTS (x86_64)
GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.35

Python version: 3.10.12 (main, Jul  5 2023, 18:54:27) [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-6.2.0-32-generic-x86_64-with-glibc2.35
Is CUDA available: True
CUDA runtime version: 11.5.119
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce GTX 970
Nvidia driver version: 525.125.06
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                       x86_64
CPU op-mode(s):                     32-bit, 64-bit
Address sizes:                      39 bits physical, 48 bits virtual
Byte Order:                         Little Endian
CPU(s):                             4
On-line CPU(s) list:                0-3
Vendor ID:                          GenuineIntel
Model name:                         Intel(R) Xeon(R) CPU E3-1225 v3 @ 3.20GHz
CPU family:                         6
Model:                              60
Thread(s) per core:                 1
Core(s) per socket:                 4
Socket(s):                          1
Stepping:                           3
CPU max MHz:                        3600,0000
CPU min MHz:                        800,0000
BogoMIPS:                           6397.79
Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt dtherm ida arat pln pts md_clear flush_l1d
Virtualization:                     VT-x
L1d cache:                          128 KiB (4 instances)
L1i cache:                          128 KiB (4 instances)
L2 cache:                           1 MiB (4 instances)
L3 cache:                           8 MiB (1 instance)
NUMA node(s):                       1
NUMA node0 CPU(s):                  0-3
Vulnerability Gather data sampling: Not affected
Vulnerability Itlb multihit:        KVM: Mitigation: VMX disabled
Vulnerability L1tf:                 Mitigation; PTE Inversion; VMX conditional cache flushes, SMT disabled
Vulnerability Mds:                  Mitigation; Clear CPU buffers; SMT disabled
Vulnerability Meltdown:             Mitigation; PTI
Vulnerability Mmio stale data:      Unknown: No mitigations
Vulnerability Retbleed:             Not affected
Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl
Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:           Mitigation; Retpolines, IBPB conditional, IBRS_FW, STIBP disabled, RSB filling, PBRSB-eIBRS Not affected
Vulnerability Srbds:                Mitigation; Microcode
Vulnerability Tsx async abort:      Not affected

Versions of relevant libraries:
[pip3] numpy==1.25.2
[pip3] open-clip-torch==2.20.0
[pip3] torch==2.0.1
[pip3] torchaudio==2.0.2
[pip3] torchvision==0.15.2
[conda] blas                      1.0                         mkl  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] mkl                       2023.1.0         h213fc3f_46343  
[conda] mkl-service               2.4.0           py310h5eee18b_1  
[conda] mkl_fft                   1.3.6           py310h1128e8f_1  
[conda] mkl_random                1.2.2           py310h1128e8f_1  
[conda] numpy                     1.25.2          py310h5f9d8c6_0  
[conda] numpy-base                1.25.2          py310hb5e798b_0  
[conda] open-clip-torch           2.20.0                   pypi_0    pypi
[conda] pytorch                   2.0.1           py3.10_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchaudio                2.0.2               py310_cu117    pytorch
[conda] torchtriton               2.0.0                     py310    pytorch
[conda] torchvision               0.15.2              py310_cu117    pytorch
        Pillow (9.4.0)

Loading trainer: CoOp
Loading dataset: Caltech101
Reading split from /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data/caltech-101/split_zhou_Caltech101.json
Creating a 1-shot dataset
Creating a 1-shot dataset
Saving preprocessed few-shot data to /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data/caltech-101/split_fewshot/shot_1-seed_2.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  100
# train_x  100
# val      100
# test     2,465
---------  ----------
Loading CLIP (backbone: ViT-B/32)
CLIP(
  (visual): VisionTransformer(
    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (transformer): Transformer(
    (resblocks): Sequential(
      (0): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (6): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (7): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (8): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (9): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (10): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (11): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (token_embedding): Embedding(49408, 512)
  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
)
Building custom CLIP
Initializing a generic context
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Turning off gradients in both the image and the text encoder
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/Caltech/1/2/tensorboard)
epoch [1/200] batch [1/3] time 0.861 (0.861) data 0.135 (0.135) loss 2.3848 (2.3848) acc 53.1250 (53.1250) lr 1.0000e-05 eta 0:08:35
epoch [1/200] batch [2/3] time 1.006 (0.934) data 0.299 (0.217) loss 2.0801 (2.2324) acc 53.1250 (53.1250) lr 1.0000e-05 eta 0:09:18
epoch [1/200] batch [3/3] time 0.871 (0.913) data 0.164 (0.199) loss 1.9395 (2.1348) acc 68.7500 (58.3333) lr 2.0000e-03 eta 0:09:05
epoch [2/200] batch [1/3] time 0.830 (0.830) data 0.122 (0.122) loss 1.6318 (1.6318) acc 68.7500 (68.7500) lr 2.0000e-03 eta 0:08:14
epoch [2/200] batch [2/3] time 0.855 (0.843) data 0.138 (0.130) loss 1.2822 (1.4570) acc 65.6250 (67.1875) lr 2.0000e-03 eta 0:08:21
epoch [2/200] batch [3/3] time 0.904 (0.863) data 0.192 (0.151) loss 0.7246 (1.2129) acc 78.1250 (70.8333) lr 1.9999e-03 eta 0:08:32
epoch [3/200] batch [1/3] time 0.835 (0.835) data 0.123 (0.123) loss 1.2451 (1.2451) acc 71.8750 (71.8750) lr 1.9999e-03 eta 0:08:15
epoch [3/200] batch [2/3] time 0.840 (0.838) data 0.128 (0.125) loss 1.0371 (1.1411) acc 75.0000 (73.4375) lr 1.9999e-03 eta 0:08:15
epoch [3/200] batch [3/3] time 0.820 (0.832) data 0.110 (0.120) loss 0.8193 (1.0339) acc 78.1250 (75.0000) lr 1.9995e-03 eta 0:08:11
epoch [4/200] batch [1/3] time 0.860 (0.860) data 0.145 (0.145) loss 1.0840 (1.0840) acc 65.6250 (65.6250) lr 1.9995e-03 eta 0:08:27
epoch [4/200] batch [2/3] time 0.828 (0.844) data 0.115 (0.130) loss 0.8672 (0.9756) acc 65.6250 (65.6250) lr 1.9995e-03 eta 0:08:17
epoch [4/200] batch [3/3] time 0.819 (0.836) data 0.105 (0.122) loss 0.5278 (0.8263) acc 81.2500 (70.8333) lr 1.9989e-03 eta 0:08:11
epoch [5/200] batch [1/3] time 0.914 (0.914) data 0.195 (0.195) loss 0.9414 (0.9414) acc 71.8750 (71.8750) lr 1.9989e-03 eta 0:08:56
epoch [5/200] batch [2/3] time 0.807 (0.861) data 0.095 (0.145) loss 1.2861 (1.1138) acc 68.7500 (70.3125) lr 1.9989e-03 eta 0:08:24
epoch [5/200] batch [3/3] time 0.803 (0.841) data 0.090 (0.127) loss 1.1670 (1.1315) acc 68.7500 (69.7917) lr 1.9980e-03 eta 0:08:12
epoch [6/200] batch [1/3] time 0.827 (0.827) data 0.105 (0.105) loss 0.7695 (0.7695) acc 81.2500 (81.2500) lr 1.9980e-03 eta 0:08:02
epoch [6/200] batch [2/3] time 0.818 (0.823) data 0.100 (0.102) loss 0.9810 (0.8752) acc 78.1250 (79.6875) lr 1.9980e-03 eta 0:07:59
epoch [6/200] batch [3/3] time 0.803 (0.816) data 0.094 (0.100) loss 1.1064 (0.9523) acc 71.8750 (77.0833) lr 1.9969e-03 eta 0:07:54
epoch [7/200] batch [1/3] time 0.809 (0.809) data 0.099 (0.099) loss 0.6411 (0.6411) acc 81.2500 (81.2500) lr 1.9969e-03 eta 0:07:50
epoch [7/200] batch [2/3] time 0.918 (0.864) data 0.199 (0.149) loss 0.8447 (0.7429) acc 75.0000 (78.1250) lr 1.9969e-03 eta 0:08:20
epoch [7/200] batch [3/3] time 0.965 (0.898) data 0.108 (0.135) loss 0.7339 (0.7399) acc 78.1250 (78.1250) lr 1.9956e-03 eta 0:08:39
epoch [8/200] batch [1/3] time 0.832 (0.832) data 0.126 (0.126) loss 0.5391 (0.5391) acc 84.3750 (84.3750) lr 1.9956e-03 eta 0:08:01
epoch [8/200] batch [2/3] time 0.814 (0.823) data 0.096 (0.111) loss 0.8999 (0.7195) acc 71.8750 (78.1250) lr 1.9956e-03 eta 0:07:54
epoch [8/200] batch [3/3] time 0.964 (0.870) data 0.117 (0.113) loss 0.9639 (0.8009) acc 71.8750 (76.0417) lr 1.9940e-03 eta 0:08:21
epoch [9/200] batch [1/3] time 0.991 (0.991) data 0.174 (0.174) loss 0.6006 (0.6006) acc 78.1250 (78.1250) lr 1.9940e-03 eta 0:09:30
epoch [9/200] batch [2/3] time 0.900 (0.946) data 0.169 (0.171) loss 0.7729 (0.6868) acc 68.7500 (73.4375) lr 1.9940e-03 eta 0:09:02
epoch [9/200] batch [3/3] time 0.800 (0.897) data 0.093 (0.145) loss 0.4192 (0.5976) acc 84.3750 (77.0833) lr 1.9921e-03 eta 0:08:33
epoch [10/200] batch [1/3] time 0.799 (0.799) data 0.093 (0.093) loss 0.4446 (0.4446) acc 87.5000 (87.5000) lr 1.9921e-03 eta 0:07:36
epoch [10/200] batch [2/3] time 0.801 (0.800) data 0.094 (0.094) loss 0.8745 (0.6595) acc 78.1250 (82.8125) lr 1.9921e-03 eta 0:07:36
epoch [10/200] batch [3/3] time 0.799 (0.799) data 0.092 (0.093) loss 0.6821 (0.6671) acc 84.3750 (83.3333) lr 1.9900e-03 eta 0:07:35
epoch [11/200] batch [1/3] time 0.840 (0.840) data 0.103 (0.103) loss 0.7725 (0.7725) acc 75.0000 (75.0000) lr 1.9900e-03 eta 0:07:57
epoch [11/200] batch [2/3] time 0.909 (0.874) data 0.126 (0.115) loss 0.7656 (0.7690) acc 78.1250 (76.5625) lr 1.9900e-03 eta 0:08:16
epoch [11/200] batch [3/3] time 0.888 (0.879) data 0.097 (0.109) loss 0.7603 (0.7661) acc 81.2500 (78.1250) lr 1.9877e-03 eta 0:08:18
epoch [12/200] batch [1/3] time 0.957 (0.957) data 0.102 (0.102) loss 0.9663 (0.9663) acc 81.2500 (81.2500) lr 1.9877e-03 eta 0:09:01
epoch [12/200] batch [2/3] time 1.833 (1.395) data 1.121 (0.612) loss 0.6504 (0.8083) acc 81.2500 (81.2500) lr 1.9877e-03 eta 0:13:08
epoch [12/200] batch [3/3] time 0.806 (1.199) data 0.091 (0.438) loss 1.2822 (0.9663) acc 59.3750 (73.9583) lr 1.9851e-03 eta 0:11:16
epoch [13/200] batch [1/3] time 0.806 (0.806) data 0.091 (0.091) loss 0.9214 (0.9214) acc 71.8750 (71.8750) lr 1.9851e-03 eta 0:07:33
epoch [13/200] batch [2/3] time 0.859 (0.832) data 0.145 (0.118) loss 0.4766 (0.6990) acc 93.7500 (82.8125) lr 1.9851e-03 eta 0:07:47
epoch [13/200] batch [3/3] time 0.814 (0.826) data 0.099 (0.112) loss 0.3901 (0.5960) acc 87.5000 (84.3750) lr 1.9823e-03 eta 0:07:43
epoch [14/200] batch [1/3] time 0.832 (0.832) data 0.118 (0.118) loss 0.5464 (0.5464) acc 84.3750 (84.3750) lr 1.9823e-03 eta 0:07:45
epoch [14/200] batch [2/3] time 0.812 (0.822) data 0.092 (0.105) loss 0.6860 (0.6162) acc 81.2500 (82.8125) lr 1.9823e-03 eta 0:07:39
epoch [14/200] batch [3/3] time 0.815 (0.820) data 0.099 (0.103) loss 0.2905 (0.5076) acc 87.5000 (84.3750) lr 1.9792e-03 eta 0:07:37
epoch [15/200] batch [1/3] time 0.806 (0.806) data 0.093 (0.093) loss 0.6587 (0.6587) acc 90.6250 (90.6250) lr 1.9792e-03 eta 0:07:28
epoch [15/200] batch [2/3] time 0.817 (0.811) data 0.103 (0.098) loss 0.5215 (0.5901) acc 81.2500 (85.9375) lr 1.9792e-03 eta 0:07:31
epoch [15/200] batch [3/3] time 0.810 (0.811) data 0.096 (0.097) loss 0.4463 (0.5422) acc 87.5000 (86.4583) lr 1.9759e-03 eta 0:07:30
epoch [16/200] batch [1/3] time 0.813 (0.813) data 0.099 (0.099) loss 1.0195 (1.0195) acc 78.1250 (78.1250) lr 1.9759e-03 eta 0:07:30
epoch [16/200] batch [2/3] time 0.811 (0.812) data 0.095 (0.097) loss 0.7686 (0.8940) acc 78.1250 (78.1250) lr 1.9759e-03 eta 0:07:29
epoch [16/200] batch [3/3] time 0.833 (0.819) data 0.111 (0.102) loss 0.5337 (0.7739) acc 87.5000 (81.2500) lr 1.9724e-03 eta 0:07:32
epoch [17/200] batch [1/3] time 0.866 (0.866) data 0.144 (0.144) loss 0.7847 (0.7847) acc 78.1250 (78.1250) lr 1.9724e-03 eta 0:07:57
epoch [17/200] batch [2/3] time 0.878 (0.872) data 0.153 (0.149) loss 0.7539 (0.7693) acc 84.3750 (81.2500) lr 1.9724e-03 eta 0:07:59
epoch [17/200] batch [3/3] time 0.902 (0.882) data 0.105 (0.134) loss 0.6299 (0.7228) acc 78.1250 (80.2083) lr 1.9686e-03 eta 0:08:04
epoch [18/200] batch [1/3] time 0.864 (0.864) data 0.095 (0.095) loss 0.5732 (0.5732) acc 87.5000 (87.5000) lr 1.9686e-03 eta 0:07:53
epoch [18/200] batch [2/3] time 0.833 (0.848) data 0.112 (0.104) loss 0.7061 (0.6396) acc 87.5000 (87.5000) lr 1.9686e-03 eta 0:07:43
epoch [18/200] batch [3/3] time 1.431 (1.043) data 0.248 (0.152) loss 0.4446 (0.5746) acc 93.7500 (89.5833) lr 1.9646e-03 eta 0:09:29
epoch [19/200] batch [1/3] time 1.434 (1.434) data 0.187 (0.187) loss 0.3840 (0.3840) acc 87.5000 (87.5000) lr 1.9646e-03 eta 0:13:01
epoch [19/200] batch [2/3] time 0.835 (1.135) data 0.121 (0.154) loss 0.6416 (0.5128) acc 84.3750 (85.9375) lr 1.9646e-03 eta 0:10:17
epoch [19/200] batch [3/3] time 0.806 (1.025) data 0.094 (0.134) loss 0.5630 (0.5295) acc 90.6250 (87.5000) lr 1.9603e-03 eta 0:09:16
epoch [20/200] batch [1/3] time 0.940 (0.940) data 0.218 (0.218) loss 0.9238 (0.9238) acc 75.0000 (75.0000) lr 1.9603e-03 eta 0:08:29
epoch [20/200] batch [2/3] time 1.066 (1.003) data 0.091 (0.154) loss 0.6577 (0.7908) acc 87.5000 (81.2500) lr 1.9603e-03 eta 0:09:02
epoch [20/200] batch [3/3] time 0.998 (1.001) data 0.164 (0.158) loss 0.8945 (0.8254) acc 78.1250 (80.2083) lr 1.9558e-03 eta 0:09:00
epoch [21/200] batch [1/3] time 0.818 (0.818) data 0.106 (0.106) loss 0.6060 (0.6060) acc 87.5000 (87.5000) lr 1.9558e-03 eta 0:07:21
epoch [21/200] batch [2/3] time 0.919 (0.869) data 0.099 (0.102) loss 0.7168 (0.6614) acc 75.0000 (81.2500) lr 1.9558e-03 eta 0:07:47
epoch [21/200] batch [3/3] time 0.814 (0.850) data 0.101 (0.102) loss 0.4121 (0.5783) acc 93.7500 (85.4167) lr 1.9511e-03 eta 0:07:36
epoch [22/200] batch [1/3] time 0.811 (0.811) data 0.099 (0.099) loss 0.5020 (0.5020) acc 84.3750 (84.3750) lr 1.9511e-03 eta 0:07:14
epoch [22/200] batch [2/3] time 0.806 (0.809) data 0.094 (0.096) loss 0.7734 (0.6377) acc 84.3750 (84.3750) lr 1.9511e-03 eta 0:07:12
epoch [22/200] batch [3/3] time 0.866 (0.828) data 0.155 (0.116) loss 0.3259 (0.5338) acc 90.6250 (86.4583) lr 1.9461e-03 eta 0:07:22
epoch [23/200] batch [1/3] time 0.814 (0.814) data 0.102 (0.102) loss 0.3074 (0.3074) acc 93.7500 (93.7500) lr 1.9461e-03 eta 0:07:13
epoch [23/200] batch [2/3] time 0.853 (0.833) data 0.141 (0.121) loss 0.2820 (0.2947) acc 90.6250 (92.1875) lr 1.9461e-03 eta 0:07:23
epoch [23/200] batch [3/3] time 0.807 (0.824) data 0.095 (0.113) loss 1.1494 (0.5796) acc 78.1250 (87.5000) lr 1.9409e-03 eta 0:07:17
epoch [24/200] batch [1/3] time 0.839 (0.839) data 0.126 (0.126) loss 0.5132 (0.5132) acc 90.6250 (90.6250) lr 1.9409e-03 eta 0:07:24
epoch [24/200] batch [2/3] time 0.810 (0.825) data 0.099 (0.113) loss 0.5186 (0.5159) acc 87.5000 (89.0625) lr 1.9409e-03 eta 0:07:16
epoch [24/200] batch [3/3] time 0.806 (0.818) data 0.095 (0.107) loss 0.5381 (0.5233) acc 84.3750 (87.5000) lr 1.9354e-03 eta 0:07:12
epoch [25/200] batch [1/3] time 0.938 (0.938) data 0.228 (0.228) loss 0.7471 (0.7471) acc 87.5000 (87.5000) lr 1.9354e-03 eta 0:08:14
epoch [25/200] batch [2/3] time 0.806 (0.872) data 0.095 (0.161) loss 0.9365 (0.8418) acc 81.2500 (84.3750) lr 1.9354e-03 eta 0:07:38
epoch [25/200] batch [3/3] time 0.804 (0.849) data 0.093 (0.139) loss 0.9429 (0.8755) acc 75.0000 (81.2500) lr 1.9298e-03 eta 0:07:25
epoch [26/200] batch [1/3] time 0.919 (0.919) data 0.091 (0.091) loss 0.4692 (0.4692) acc 90.6250 (90.6250) lr 1.9298e-03 eta 0:08:01
epoch [26/200] batch [2/3] time 1.096 (1.008) data 0.187 (0.139) loss 0.3535 (0.4114) acc 90.6250 (90.6250) lr 1.9298e-03 eta 0:08:46
epoch [26/200] batch [3/3] time 0.872 (0.962) data 0.160 (0.146) loss 0.7578 (0.5269) acc 75.0000 (85.4167) lr 1.9239e-03 eta 0:08:22
epoch [27/200] batch [1/3] time 0.802 (0.802) data 0.091 (0.091) loss 0.9751 (0.9751) acc 75.0000 (75.0000) lr 1.9239e-03 eta 0:06:58
epoch [27/200] batch [2/3] time 0.806 (0.804) data 0.095 (0.093) loss 0.6782 (0.8267) acc 84.3750 (79.6875) lr 1.9239e-03 eta 0:06:58
epoch [27/200] batch [3/3] time 0.808 (0.805) data 0.095 (0.094) loss 0.2720 (0.6418) acc 96.8750 (85.4167) lr 1.9178e-03 eta 0:06:57
epoch [28/200] batch [1/3] time 0.808 (0.808) data 0.096 (0.096) loss 0.5020 (0.5020) acc 90.6250 (90.6250) lr 1.9178e-03 eta 0:06:58
epoch [28/200] batch [2/3] time 0.990 (0.899) data 0.280 (0.188) loss 0.4814 (0.4917) acc 90.6250 (90.6250) lr 1.9178e-03 eta 0:07:44
epoch [28/200] batch [3/3] time 0.810 (0.869) data 0.098 (0.158) loss 0.5469 (0.5101) acc 84.3750 (88.5417) lr 1.9114e-03 eta 0:07:28
epoch [29/200] batch [1/3] time 0.983 (0.983) data 0.095 (0.095) loss 0.5483 (0.5483) acc 87.5000 (87.5000) lr 1.9114e-03 eta 0:08:26
epoch [29/200] batch [2/3] time 1.069 (1.026) data 0.144 (0.119) loss 0.7051 (0.6267) acc 81.2500 (84.3750) lr 1.9114e-03 eta 0:08:47
epoch [29/200] batch [3/3] time 1.231 (1.094) data 0.191 (0.143) loss 0.3894 (0.5476) acc 93.7500 (87.5000) lr 1.9048e-03 eta 0:09:21
epoch [30/200] batch [1/3] time 0.980 (0.980) data 0.100 (0.100) loss 0.4045 (0.4045) acc 93.7500 (93.7500) lr 1.9048e-03 eta 0:08:21
epoch [30/200] batch [2/3] time 0.937 (0.959) data 0.190 (0.145) loss 0.5454 (0.4750) acc 84.3750 (89.0625) lr 1.9048e-03 eta 0:08:09
epoch [30/200] batch [3/3] time 0.923 (0.947) data 0.098 (0.130) loss 0.5635 (0.5045) acc 87.5000 (88.5417) lr 1.8980e-03 eta 0:08:02
epoch [31/200] batch [1/3] time 0.929 (0.929) data 0.098 (0.098) loss 0.3892 (0.3892) acc 90.6250 (90.6250) lr 1.8980e-03 eta 0:07:52
epoch [31/200] batch [2/3] time 0.934 (0.931) data 0.139 (0.118) loss 0.8545 (0.6218) acc 84.3750 (87.5000) lr 1.8980e-03 eta 0:07:53
epoch [31/200] batch [3/3] time 0.905 (0.923) data 0.132 (0.123) loss 0.5005 (0.5814) acc 90.6250 (88.5417) lr 1.8910e-03 eta 0:07:47
epoch [32/200] batch [1/3] time 0.922 (0.922) data 0.097 (0.097) loss 0.6416 (0.6416) acc 90.6250 (90.6250) lr 1.8910e-03 eta 0:07:46
epoch [32/200] batch [2/3] time 0.804 (0.863) data 0.093 (0.095) loss 0.2847 (0.4631) acc 90.6250 (90.6250) lr 1.8910e-03 eta 0:07:15
epoch [32/200] batch [3/3] time 0.815 (0.847) data 0.103 (0.098) loss 0.5122 (0.4795) acc 87.5000 (89.5833) lr 1.8838e-03 eta 0:07:06
epoch [33/200] batch [1/3] time 0.898 (0.898) data 0.089 (0.089) loss 0.4478 (0.4478) acc 87.5000 (87.5000) lr 1.8838e-03 eta 0:07:31
epoch [33/200] batch [2/3] time 0.836 (0.867) data 0.121 (0.105) loss 0.5703 (0.5090) acc 93.7500 (90.6250) lr 1.8838e-03 eta 0:07:15
epoch [33/200] batch [3/3] time 0.874 (0.869) data 0.132 (0.114) loss 1.0381 (0.6854) acc 81.2500 (87.5000) lr 1.8763e-03 eta 0:07:15
epoch [34/200] batch [1/3] time 0.811 (0.811) data 0.098 (0.098) loss 0.3613 (0.3613) acc 93.7500 (93.7500) lr 1.8763e-03 eta 0:06:45
epoch [34/200] batch [2/3] time 0.830 (0.821) data 0.119 (0.109) loss 0.1052 (0.2333) acc 100.0000 (96.8750) lr 1.8763e-03 eta 0:06:49
epoch [34/200] batch [3/3] time 0.818 (0.820) data 0.104 (0.107) loss 0.2627 (0.2431) acc 93.7500 (95.8333) lr 1.8686e-03 eta 0:06:48
epoch [35/200] batch [1/3] time 0.823 (0.823) data 0.109 (0.109) loss 0.5889 (0.5889) acc 75.0000 (75.0000) lr 1.8686e-03 eta 0:06:48
epoch [35/200] batch [2/3] time 0.833 (0.828) data 0.121 (0.115) loss 0.3018 (0.4453) acc 90.6250 (82.8125) lr 1.8686e-03 eta 0:06:50
epoch [35/200] batch [3/3] time 0.807 (0.821) data 0.096 (0.108) loss 0.3640 (0.4182) acc 87.5000 (84.3750) lr 1.8607e-03 eta 0:06:46
epoch [36/200] batch [1/3] time 0.806 (0.806) data 0.092 (0.092) loss 0.5679 (0.5679) acc 90.6250 (90.6250) lr 1.8607e-03 eta 0:06:38
epoch [36/200] batch [2/3] time 0.811 (0.808) data 0.099 (0.095) loss 0.8267 (0.6973) acc 81.2500 (85.9375) lr 1.8607e-03 eta 0:06:38
epoch [36/200] batch [3/3] time 0.809 (0.809) data 0.096 (0.096) loss 0.7554 (0.7166) acc 78.1250 (83.3333) lr 1.8526e-03 eta 0:06:37
epoch [37/200] batch [1/3] time 0.830 (0.830) data 0.116 (0.116) loss 0.3870 (0.3870) acc 90.6250 (90.6250) lr 1.8526e-03 eta 0:06:47
epoch [37/200] batch [2/3] time 0.813 (0.822) data 0.102 (0.109) loss 0.6865 (0.5367) acc 81.2500 (85.9375) lr 1.8526e-03 eta 0:06:42
epoch [37/200] batch [3/3] time 0.809 (0.817) data 0.095 (0.105) loss 0.6182 (0.5639) acc 84.3750 (85.4167) lr 1.8443e-03 eta 0:06:39
epoch [38/200] batch [1/3] time 0.959 (0.959) data 0.113 (0.113) loss 0.3691 (0.3691) acc 87.5000 (87.5000) lr 1.8443e-03 eta 0:07:48
epoch [38/200] batch [2/3] time 1.037 (0.998) data 0.324 (0.219) loss 0.1283 (0.2487) acc 96.8750 (92.1875) lr 1.8443e-03 eta 0:08:06
epoch [38/200] batch [3/3] time 0.831 (0.942) data 0.111 (0.183) loss 0.3586 (0.2854) acc 93.7500 (92.7083) lr 1.8358e-03 eta 0:07:37
epoch [39/200] batch [1/3] time 0.834 (0.834) data 0.106 (0.106) loss 0.5649 (0.5649) acc 90.6250 (90.6250) lr 1.8358e-03 eta 0:06:44
epoch [39/200] batch [2/3] time 0.830 (0.832) data 0.106 (0.106) loss 0.3091 (0.4370) acc 93.7500 (92.1875) lr 1.8358e-03 eta 0:06:42
epoch [39/200] batch [3/3] time 0.841 (0.835) data 0.096 (0.102) loss 0.4412 (0.4384) acc 90.6250 (91.6667) lr 1.8271e-03 eta 0:06:43
epoch [40/200] batch [1/3] time 0.864 (0.864) data 0.152 (0.152) loss 0.9023 (0.9023) acc 84.3750 (84.3750) lr 1.8271e-03 eta 0:06:56
epoch [40/200] batch [2/3] time 0.833 (0.849) data 0.120 (0.136) loss 0.2756 (0.5890) acc 93.7500 (89.0625) lr 1.8271e-03 eta 0:06:48
epoch [40/200] batch [3/3] time 0.835 (0.844) data 0.122 (0.131) loss 0.5752 (0.5844) acc 87.5000 (88.5417) lr 1.8181e-03 eta 0:06:45
epoch [41/200] batch [1/3] time 0.816 (0.816) data 0.105 (0.105) loss 0.2089 (0.2089) acc 93.7500 (93.7500) lr 1.8181e-03 eta 0:06:30
epoch [41/200] batch [2/3] time 0.829 (0.823) data 0.117 (0.111) loss 0.7651 (0.4870) acc 78.1250 (85.9375) lr 1.8181e-03 eta 0:06:33
epoch [41/200] batch [3/3] time 0.816 (0.820) data 0.104 (0.108) loss 0.7500 (0.5747) acc 87.5000 (86.4583) lr 1.8090e-03 eta 0:06:31
epoch [42/200] batch [1/3] time 0.829 (0.829) data 0.118 (0.118) loss 0.7549 (0.7549) acc 78.1250 (78.1250) lr 1.8090e-03 eta 0:06:34
epoch [42/200] batch [2/3] time 0.836 (0.833) data 0.108 (0.113) loss 0.2666 (0.5107) acc 93.7500 (85.9375) lr 1.8090e-03 eta 0:06:35
epoch [42/200] batch [3/3] time 0.830 (0.832) data 0.106 (0.111) loss 0.6816 (0.5677) acc 87.5000 (86.4583) lr 1.7997e-03 eta 0:06:34
epoch [43/200] batch [1/3] time 0.827 (0.827) data 0.109 (0.109) loss 0.4036 (0.4036) acc 90.6250 (90.6250) lr 1.7997e-03 eta 0:06:31
epoch [43/200] batch [2/3] time 0.846 (0.836) data 0.130 (0.120) loss 0.6646 (0.5341) acc 87.5000 (89.0625) lr 1.7997e-03 eta 0:06:34
epoch [43/200] batch [3/3] time 0.904 (0.859) data 0.104 (0.114) loss 0.2991 (0.4557) acc 93.7500 (90.6250) lr 1.7902e-03 eta 0:06:44
epoch [44/200] batch [1/3] time 0.912 (0.912) data 0.144 (0.144) loss 0.6953 (0.6953) acc 87.5000 (87.5000) lr 1.7902e-03 eta 0:07:08
epoch [44/200] batch [2/3] time 0.911 (0.911) data 0.115 (0.130) loss 0.3748 (0.5350) acc 87.5000 (87.5000) lr 1.7902e-03 eta 0:07:07
epoch [44/200] batch [3/3] time 1.110 (0.978) data 0.236 (0.165) loss 0.3149 (0.4617) acc 96.8750 (90.6250) lr 1.7804e-03 eta 0:07:37
epoch [45/200] batch [1/3] time 1.071 (1.071) data 0.278 (0.278) loss 0.2257 (0.2257) acc 93.7500 (93.7500) lr 1.7804e-03 eta 0:08:19
epoch [45/200] batch [2/3] time 0.988 (1.029) data 0.146 (0.212) loss 0.5215 (0.3736) acc 81.2500 (87.5000) lr 1.7804e-03 eta 0:07:59
epoch [45/200] batch [3/3] time 1.149 (1.069) data 0.267 (0.230) loss 0.2888 (0.3453) acc 93.7500 (89.5833) lr 1.7705e-03 eta 0:08:17
epoch [46/200] batch [1/3] time 0.810 (0.810) data 0.094 (0.094) loss 0.1912 (0.1912) acc 96.8750 (96.8750) lr 1.7705e-03 eta 0:06:15
epoch [46/200] batch [2/3] time 1.002 (0.906) data 0.160 (0.127) loss 0.9473 (0.5692) acc 78.1250 (87.5000) lr 1.7705e-03 eta 0:06:59
epoch [46/200] batch [3/3] time 0.819 (0.877) data 0.102 (0.119) loss 0.7012 (0.6132) acc 87.5000 (87.5000) lr 1.7604e-03 eta 0:06:45
epoch [47/200] batch [1/3] time 0.821 (0.821) data 0.102 (0.102) loss 0.7686 (0.7686) acc 84.3750 (84.3750) lr 1.7604e-03 eta 0:06:18
epoch [47/200] batch [2/3] time 0.850 (0.835) data 0.117 (0.109) loss 0.3181 (0.5433) acc 90.6250 (87.5000) lr 1.7604e-03 eta 0:06:24
epoch [47/200] batch [3/3] time 0.930 (0.867) data 0.118 (0.112) loss 0.5068 (0.5312) acc 90.6250 (88.5417) lr 1.7501e-03 eta 0:06:37
epoch [48/200] batch [1/3] time 0.899 (0.899) data 0.148 (0.148) loss 0.1522 (0.1522) acc 96.8750 (96.8750) lr 1.7501e-03 eta 0:06:51
epoch [48/200] batch [2/3] time 0.839 (0.869) data 0.113 (0.131) loss 0.3022 (0.2272) acc 96.8750 (96.8750) lr 1.7501e-03 eta 0:06:37
epoch [48/200] batch [3/3] time 0.809 (0.849) data 0.096 (0.119) loss 0.4678 (0.3074) acc 93.7500 (95.8333) lr 1.7396e-03 eta 0:06:27
epoch [49/200] batch [1/3] time 0.850 (0.850) data 0.128 (0.128) loss 0.3235 (0.3235) acc 96.8750 (96.8750) lr 1.7396e-03 eta 0:06:26
epoch [49/200] batch [2/3] time 0.832 (0.841) data 0.113 (0.120) loss 0.5532 (0.4384) acc 93.7500 (95.3125) lr 1.7396e-03 eta 0:06:21
epoch [49/200] batch [3/3] time 0.829 (0.837) data 0.113 (0.118) loss 0.4424 (0.4397) acc 90.6250 (93.7500) lr 1.7290e-03 eta 0:06:19
epoch [50/200] batch [1/3] time 0.809 (0.809) data 0.096 (0.096) loss 0.5088 (0.5088) acc 87.5000 (87.5000) lr 1.7290e-03 eta 0:06:05
epoch [50/200] batch [2/3] time 0.821 (0.815) data 0.104 (0.100) loss 0.6733 (0.5911) acc 87.5000 (87.5000) lr 1.7290e-03 eta 0:06:07
epoch [50/200] batch [3/3] time 0.885 (0.838) data 0.163 (0.121) loss 0.4302 (0.5374) acc 93.7500 (89.5833) lr 1.7181e-03 eta 0:06:17
epoch [51/200] batch [1/3] time 0.986 (0.986) data 0.114 (0.114) loss 0.5312 (0.5312) acc 84.3750 (84.3750) lr 1.7181e-03 eta 0:07:22
epoch [51/200] batch [2/3] time 0.826 (0.906) data 0.106 (0.110) loss 0.5142 (0.5227) acc 90.6250 (87.5000) lr 1.7181e-03 eta 0:06:45
epoch [51/200] batch [3/3] time 0.820 (0.877) data 0.105 (0.109) loss 0.2397 (0.4284) acc 96.8750 (90.6250) lr 1.7071e-03 eta 0:06:32
epoch [52/200] batch [1/3] time 0.889 (0.889) data 0.131 (0.131) loss 0.1242 (0.1242) acc 96.8750 (96.8750) lr 1.7071e-03 eta 0:06:36
epoch [52/200] batch [2/3] time 1.158 (1.023) data 0.354 (0.242) loss 0.4758 (0.3000) acc 90.6250 (93.7500) lr 1.7071e-03 eta 0:07:35
epoch [52/200] batch [3/3] time 0.855 (0.967) data 0.092 (0.192) loss 0.3838 (0.3279) acc 93.7500 (93.7500) lr 1.6959e-03 eta 0:07:09
epoch [53/200] batch [1/3] time 0.821 (0.821) data 0.100 (0.100) loss 0.6328 (0.6328) acc 84.3750 (84.3750) lr 1.6959e-03 eta 0:06:03
epoch [53/200] batch [2/3] time 0.862 (0.842) data 0.143 (0.122) loss 0.2903 (0.4615) acc 93.7500 (89.0625) lr 1.6959e-03 eta 0:06:12
epoch [53/200] batch [3/3] time 0.899 (0.861) data 0.105 (0.116) loss 0.4375 (0.4535) acc 90.6250 (89.5833) lr 1.6845e-03 eta 0:06:19
epoch [54/200] batch [1/3] time 0.981 (0.981) data 0.179 (0.179) loss 0.4248 (0.4248) acc 87.5000 (87.5000) lr 1.6845e-03 eta 0:07:11
epoch [54/200] batch [2/3] time 0.827 (0.904) data 0.105 (0.142) loss 0.5854 (0.5051) acc 81.2500 (84.3750) lr 1.6845e-03 eta 0:06:36
epoch [54/200] batch [3/3] time 0.820 (0.876) data 0.100 (0.128) loss 0.6738 (0.5614) acc 84.3750 (84.3750) lr 1.6730e-03 eta 0:06:23
epoch [55/200] batch [1/3] time 0.827 (0.827) data 0.108 (0.108) loss 0.6860 (0.6860) acc 84.3750 (84.3750) lr 1.6730e-03 eta 0:06:01
epoch [55/200] batch [2/3] time 0.848 (0.837) data 0.116 (0.112) loss 0.2035 (0.4448) acc 90.6250 (87.5000) lr 1.6730e-03 eta 0:06:05
epoch [55/200] batch [3/3] time 0.983 (0.886) data 0.192 (0.139) loss 0.2717 (0.3871) acc 93.7500 (89.5833) lr 1.6613e-03 eta 0:06:25
epoch [56/200] batch [1/3] time 1.038 (1.038) data 0.196 (0.196) loss 0.4404 (0.4404) acc 90.6250 (90.6250) lr 1.6613e-03 eta 0:07:30
epoch [56/200] batch [2/3] time 0.806 (0.922) data 0.093 (0.145) loss 0.1814 (0.3109) acc 96.8750 (93.7500) lr 1.6613e-03 eta 0:06:39
epoch [56/200] batch [3/3] time 0.876 (0.907) data 0.095 (0.128) loss 0.1251 (0.2490) acc 96.8750 (94.7917) lr 1.6494e-03 eta 0:06:31
epoch [57/200] batch [1/3] time 0.880 (0.880) data 0.097 (0.097) loss 0.4189 (0.4189) acc 93.7500 (93.7500) lr 1.6494e-03 eta 0:06:19
epoch [57/200] batch [2/3] time 0.920 (0.900) data 0.198 (0.148) loss 0.5811 (0.5000) acc 87.5000 (90.6250) lr 1.6494e-03 eta 0:06:27
epoch [57/200] batch [3/3] time 0.824 (0.875) data 0.108 (0.134) loss 0.5894 (0.5298) acc 84.3750 (88.5417) lr 1.6374e-03 eta 0:06:15
epoch [58/200] batch [1/3] time 0.986 (0.986) data 0.274 (0.274) loss 0.2100 (0.2100) acc 93.7500 (93.7500) lr 1.6374e-03 eta 0:07:02
epoch [58/200] batch [2/3] time 0.810 (0.898) data 0.096 (0.185) loss 0.6611 (0.4355) acc 84.3750 (89.0625) lr 1.6374e-03 eta 0:06:23
epoch [58/200] batch [3/3] time 0.803 (0.866) data 0.089 (0.153) loss 0.6582 (0.5098) acc 81.2500 (86.4583) lr 1.6252e-03 eta 0:06:09
epoch [59/200] batch [1/3] time 0.809 (0.809) data 0.095 (0.095) loss 0.2766 (0.2766) acc 96.8750 (96.8750) lr 1.6252e-03 eta 0:05:43
epoch [59/200] batch [2/3] time 0.807 (0.808) data 0.093 (0.094) loss 0.4751 (0.3759) acc 87.5000 (92.1875) lr 1.6252e-03 eta 0:05:42
epoch [59/200] batch [3/3] time 0.830 (0.815) data 0.118 (0.102) loss 0.3931 (0.3816) acc 90.6250 (91.6667) lr 1.6129e-03 eta 0:05:44
epoch [60/200] batch [1/3] time 0.812 (0.812) data 0.100 (0.100) loss 0.2637 (0.2637) acc 90.6250 (90.6250) lr 1.6129e-03 eta 0:05:42
epoch [60/200] batch [2/3] time 0.807 (0.809) data 0.094 (0.097) loss 0.3718 (0.3177) acc 87.5000 (89.0625) lr 1.6129e-03 eta 0:05:40
epoch [60/200] batch [3/3] time 0.803 (0.807) data 0.091 (0.095) loss 0.7466 (0.4607) acc 81.2500 (86.4583) lr 1.6004e-03 eta 0:05:39
epoch [61/200] batch [1/3] time 0.805 (0.805) data 0.093 (0.093) loss 0.7051 (0.7051) acc 81.2500 (81.2500) lr 1.6004e-03 eta 0:05:37
epoch [61/200] batch [2/3] time 0.810 (0.808) data 0.097 (0.095) loss 0.3230 (0.5140) acc 96.8750 (89.0625) lr 1.6004e-03 eta 0:05:37
epoch [61/200] batch [3/3] time 0.803 (0.806) data 0.091 (0.094) loss 0.3521 (0.4600) acc 90.6250 (89.5833) lr 1.5878e-03 eta 0:05:36
epoch [62/200] batch [1/3] time 0.814 (0.814) data 0.102 (0.102) loss 0.3386 (0.3386) acc 90.6250 (90.6250) lr 1.5878e-03 eta 0:05:38
epoch [62/200] batch [2/3] time 0.810 (0.812) data 0.096 (0.099) loss 0.4861 (0.4124) acc 93.7500 (92.1875) lr 1.5878e-03 eta 0:05:36
epoch [62/200] batch [3/3] time 0.888 (0.837) data 0.175 (0.124) loss 0.7217 (0.5155) acc 87.5000 (90.6250) lr 1.5750e-03 eta 0:05:46
epoch [63/200] batch [1/3] time 0.802 (0.802) data 0.090 (0.090) loss 0.2372 (0.2372) acc 96.8750 (96.8750) lr 1.5750e-03 eta 0:05:31
epoch [63/200] batch [2/3] time 0.804 (0.803) data 0.091 (0.091) loss 0.4438 (0.3405) acc 90.6250 (93.7500) lr 1.5750e-03 eta 0:05:30
epoch [63/200] batch [3/3] time 0.814 (0.807) data 0.102 (0.094) loss 0.5806 (0.4205) acc 78.1250 (88.5417) lr 1.5621e-03 eta 0:05:31
epoch [64/200] batch [1/3] time 0.804 (0.804) data 0.092 (0.092) loss 0.2944 (0.2944) acc 90.6250 (90.6250) lr 1.5621e-03 eta 0:05:29
epoch [64/200] batch [2/3] time 0.805 (0.804) data 0.093 (0.092) loss 0.6519 (0.4731) acc 81.2500 (85.9375) lr 1.5621e-03 eta 0:05:28
epoch [64/200] batch [3/3] time 0.818 (0.809) data 0.097 (0.094) loss 0.2744 (0.4069) acc 90.6250 (87.5000) lr 1.5490e-03 eta 0:05:29
epoch [65/200] batch [1/3] time 0.829 (0.829) data 0.101 (0.101) loss 0.6812 (0.6812) acc 78.1250 (78.1250) lr 1.5490e-03 eta 0:05:37
epoch [65/200] batch [2/3] time 0.828 (0.828) data 0.109 (0.105) loss 0.1348 (0.4080) acc 100.0000 (89.0625) lr 1.5490e-03 eta 0:05:36
epoch [65/200] batch [3/3] time 0.815 (0.824) data 0.093 (0.101) loss 0.7583 (0.5247) acc 81.2500 (86.4583) lr 1.5358e-03 eta 0:05:33
epoch [66/200] batch [1/3] time 0.822 (0.822) data 0.095 (0.095) loss 0.5215 (0.5215) acc 84.3750 (84.3750) lr 1.5358e-03 eta 0:05:32
epoch [66/200] batch [2/3] time 0.838 (0.830) data 0.118 (0.107) loss 1.0322 (0.7769) acc 81.2500 (82.8125) lr 1.5358e-03 eta 0:05:34
epoch [66/200] batch [3/3] time 0.823 (0.828) data 0.098 (0.104) loss 0.6743 (0.7427) acc 90.6250 (85.4167) lr 1.5225e-03 eta 0:05:32
epoch [67/200] batch [1/3] time 0.822 (0.822) data 0.105 (0.105) loss 0.3755 (0.3755) acc 93.7500 (93.7500) lr 1.5225e-03 eta 0:05:29
epoch [67/200] batch [2/3] time 0.812 (0.817) data 0.100 (0.102) loss 0.1722 (0.2739) acc 96.8750 (95.3125) lr 1.5225e-03 eta 0:05:26
epoch [67/200] batch [3/3] time 0.839 (0.825) data 0.114 (0.106) loss 0.4736 (0.3405) acc 90.6250 (93.7500) lr 1.5090e-03 eta 0:05:29
epoch [68/200] batch [1/3] time 0.828 (0.828) data 0.111 (0.111) loss 0.4043 (0.4043) acc 96.8750 (96.8750) lr 1.5090e-03 eta 0:05:29
epoch [68/200] batch [2/3] time 0.818 (0.823) data 0.095 (0.103) loss 0.5459 (0.4751) acc 84.3750 (90.6250) lr 1.5090e-03 eta 0:05:26
epoch [68/200] batch [3/3] time 0.818 (0.821) data 0.097 (0.101) loss 0.3069 (0.4190) acc 93.7500 (91.6667) lr 1.4955e-03 eta 0:05:25
epoch [69/200] batch [1/3] time 0.869 (0.869) data 0.149 (0.149) loss 0.1388 (0.1388) acc 100.0000 (100.0000) lr 1.4955e-03 eta 0:05:43
epoch [69/200] batch [2/3] time 0.825 (0.847) data 0.111 (0.130) loss 0.3713 (0.2551) acc 90.6250 (95.3125) lr 1.4955e-03 eta 0:05:33
epoch [69/200] batch [3/3] time 0.834 (0.843) data 0.097 (0.119) loss 0.4243 (0.3115) acc 87.5000 (92.7083) lr 1.4818e-03 eta 0:05:31
epoch [70/200] batch [1/3] time 0.833 (0.833) data 0.111 (0.111) loss 0.4873 (0.4873) acc 90.6250 (90.6250) lr 1.4818e-03 eta 0:05:26
epoch [70/200] batch [2/3] time 0.825 (0.829) data 0.098 (0.105) loss 0.4636 (0.4755) acc 84.3750 (87.5000) lr 1.4818e-03 eta 0:05:24
epoch [70/200] batch [3/3] time 0.857 (0.838) data 0.144 (0.118) loss 0.2646 (0.4052) acc 96.8750 (90.6250) lr 1.4679e-03 eta 0:05:26
epoch [71/200] batch [1/3] time 0.829 (0.829) data 0.111 (0.111) loss 0.5010 (0.5010) acc 84.3750 (84.3750) lr 1.4679e-03 eta 0:05:22
epoch [71/200] batch [2/3] time 0.988 (0.909) data 0.276 (0.194) loss 0.4221 (0.4615) acc 87.5000 (85.9375) lr 1.4679e-03 eta 0:05:52
epoch [71/200] batch [3/3] time 0.809 (0.875) data 0.095 (0.161) loss 0.4368 (0.4533) acc 90.6250 (87.5000) lr 1.4540e-03 eta 0:05:38
epoch [72/200] batch [1/3] time 0.811 (0.811) data 0.089 (0.089) loss 0.2496 (0.2496) acc 93.7500 (93.7500) lr 1.4540e-03 eta 0:05:13
epoch [72/200] batch [2/3] time 0.826 (0.819) data 0.101 (0.095) loss 0.2125 (0.2311) acc 96.8750 (95.3125) lr 1.4540e-03 eta 0:05:15
epoch [72/200] batch [3/3] time 0.806 (0.815) data 0.094 (0.095) loss 0.3325 (0.2649) acc 87.5000 (92.7083) lr 1.4399e-03 eta 0:05:12
epoch [73/200] batch [1/3] time 0.818 (0.818) data 0.100 (0.100) loss 0.3159 (0.3159) acc 93.7500 (93.7500) lr 1.4399e-03 eta 0:05:13
epoch [73/200] batch [2/3] time 0.829 (0.824) data 0.112 (0.106) loss 0.3135 (0.3147) acc 93.7500 (93.7500) lr 1.4399e-03 eta 0:05:14
epoch [73/200] batch [3/3] time 0.817 (0.822) data 0.102 (0.105) loss 0.1615 (0.2636) acc 96.8750 (94.7917) lr 1.4258e-03 eta 0:05:13
epoch [74/200] batch [1/3] time 0.825 (0.825) data 0.109 (0.109) loss 0.6689 (0.6689) acc 78.1250 (78.1250) lr 1.4258e-03 eta 0:05:13
epoch [74/200] batch [2/3] time 0.859 (0.842) data 0.140 (0.125) loss 0.3560 (0.5125) acc 90.6250 (84.3750) lr 1.4258e-03 eta 0:05:19
epoch [74/200] batch [3/3] time 0.807 (0.830) data 0.092 (0.114) loss 0.5107 (0.5119) acc 87.5000 (85.4167) lr 1.4115e-03 eta 0:05:13
epoch [75/200] batch [1/3] time 0.946 (0.946) data 0.228 (0.228) loss 0.2216 (0.2216) acc 90.6250 (90.6250) lr 1.4115e-03 eta 0:05:56
epoch [75/200] batch [2/3] time 0.831 (0.888) data 0.111 (0.169) loss 0.1597 (0.1906) acc 93.7500 (92.1875) lr 1.4115e-03 eta 0:05:33
epoch [75/200] batch [3/3] time 0.822 (0.866) data 0.101 (0.147) loss 0.4832 (0.2881) acc 90.6250 (91.6667) lr 1.3971e-03 eta 0:05:24
epoch [76/200] batch [1/3] time 0.816 (0.816) data 0.096 (0.096) loss 0.6445 (0.6445) acc 87.5000 (87.5000) lr 1.3971e-03 eta 0:05:05
epoch [76/200] batch [2/3] time 0.810 (0.813) data 0.094 (0.095) loss 0.5850 (0.6147) acc 90.6250 (89.0625) lr 1.3971e-03 eta 0:05:03
epoch [76/200] batch [3/3] time 0.809 (0.812) data 0.097 (0.096) loss 0.3896 (0.5397) acc 90.6250 (89.5833) lr 1.3827e-03 eta 0:05:01
epoch [77/200] batch [1/3] time 0.959 (0.959) data 0.240 (0.240) loss 0.3491 (0.3491) acc 93.7500 (93.7500) lr 1.3827e-03 eta 0:05:55
epoch [77/200] batch [2/3] time 0.905 (0.932) data 0.187 (0.214) loss 0.5039 (0.4265) acc 90.6250 (92.1875) lr 1.3827e-03 eta 0:05:44
epoch [77/200] batch [3/3] time 0.821 (0.895) data 0.108 (0.179) loss 0.2610 (0.3713) acc 96.8750 (93.7500) lr 1.3681e-03 eta 0:05:30
epoch [78/200] batch [1/3] time 0.810 (0.810) data 0.097 (0.097) loss 0.2211 (0.2211) acc 96.8750 (96.8750) lr 1.3681e-03 eta 0:04:58
epoch [78/200] batch [2/3] time 0.817 (0.813) data 0.096 (0.096) loss 0.2864 (0.2537) acc 93.7500 (95.3125) lr 1.3681e-03 eta 0:04:58
epoch [78/200] batch [3/3] time 0.822 (0.816) data 0.100 (0.098) loss 0.5200 (0.3425) acc 81.2500 (90.6250) lr 1.3535e-03 eta 0:04:58
epoch [79/200] batch [1/3] time 0.828 (0.828) data 0.105 (0.105) loss 0.1555 (0.1555) acc 96.8750 (96.8750) lr 1.3535e-03 eta 0:05:02
epoch [79/200] batch [2/3] time 0.823 (0.826) data 0.098 (0.101) loss 0.4053 (0.2804) acc 90.6250 (93.7500) lr 1.3535e-03 eta 0:05:00
epoch [79/200] batch [3/3] time 0.821 (0.824) data 0.096 (0.100) loss 0.1573 (0.2394) acc 93.7500 (93.7500) lr 1.3387e-03 eta 0:04:59
epoch [80/200] batch [1/3] time 0.810 (0.810) data 0.098 (0.098) loss 0.4497 (0.4497) acc 90.6250 (90.6250) lr 1.3387e-03 eta 0:04:53
epoch [80/200] batch [2/3] time 0.817 (0.814) data 0.100 (0.099) loss 0.0972 (0.2735) acc 93.7500 (92.1875) lr 1.3387e-03 eta 0:04:53
epoch [80/200] batch [3/3] time 0.810 (0.812) data 0.096 (0.098) loss 0.3574 (0.3015) acc 93.7500 (92.7083) lr 1.3239e-03 eta 0:04:52
epoch [81/200] batch [1/3] time 0.812 (0.812) data 0.101 (0.101) loss 0.2365 (0.2365) acc 90.6250 (90.6250) lr 1.3239e-03 eta 0:04:51
epoch [81/200] batch [2/3] time 0.816 (0.814) data 0.102 (0.101) loss 0.2119 (0.2242) acc 93.7500 (92.1875) lr 1.3239e-03 eta 0:04:51
epoch [81/200] batch [3/3] time 0.803 (0.810) data 0.089 (0.097) loss 0.3474 (0.2653) acc 87.5000 (90.6250) lr 1.3090e-03 eta 0:04:49
epoch [82/200] batch [1/3] time 0.811 (0.811) data 0.099 (0.099) loss 0.4880 (0.4880) acc 87.5000 (87.5000) lr 1.3090e-03 eta 0:04:48
epoch [82/200] batch [2/3] time 0.809 (0.810) data 0.095 (0.097) loss 0.4377 (0.4629) acc 90.6250 (89.0625) lr 1.3090e-03 eta 0:04:47
epoch [82/200] batch [3/3] time 0.803 (0.808) data 0.090 (0.095) loss 0.2869 (0.4042) acc 90.6250 (89.5833) lr 1.2940e-03 eta 0:04:45
epoch [83/200] batch [1/3] time 0.814 (0.814) data 0.103 (0.103) loss 0.0891 (0.0891) acc 96.8750 (96.8750) lr 1.2940e-03 eta 0:04:47
epoch [83/200] batch [2/3] time 0.809 (0.812) data 0.095 (0.099) loss 0.2415 (0.1653) acc 96.8750 (96.8750) lr 1.2940e-03 eta 0:04:45
epoch [83/200] batch [3/3] time 0.807 (0.810) data 0.094 (0.098) loss 0.4714 (0.2673) acc 90.6250 (94.7917) lr 1.2790e-03 eta 0:04:44
epoch [84/200] batch [1/3] time 0.821 (0.821) data 0.108 (0.108) loss 0.1945 (0.1945) acc 93.7500 (93.7500) lr 1.2790e-03 eta 0:04:47
epoch [84/200] batch [2/3] time 0.812 (0.817) data 0.098 (0.103) loss 0.2413 (0.2179) acc 93.7500 (93.7500) lr 1.2790e-03 eta 0:04:45
epoch [84/200] batch [3/3] time 0.829 (0.821) data 0.117 (0.108) loss 0.3782 (0.2713) acc 93.7500 (93.7500) lr 1.2639e-03 eta 0:04:45
epoch [85/200] batch [1/3] time 0.833 (0.833) data 0.116 (0.116) loss 0.4570 (0.4570) acc 93.7500 (93.7500) lr 1.2639e-03 eta 0:04:49
epoch [85/200] batch [2/3] time 0.809 (0.821) data 0.095 (0.105) loss 0.0587 (0.2579) acc 100.0000 (96.8750) lr 1.2639e-03 eta 0:04:43
epoch [85/200] batch [3/3] time 0.906 (0.849) data 0.191 (0.134) loss 0.1172 (0.2110) acc 96.8750 (96.8750) lr 1.2487e-03 eta 0:04:52
epoch [86/200] batch [1/3] time 0.811 (0.811) data 0.094 (0.094) loss 0.6499 (0.6499) acc 87.5000 (87.5000) lr 1.2487e-03 eta 0:04:39
epoch [86/200] batch [2/3] time 0.800 (0.806) data 0.087 (0.091) loss 0.4033 (0.5266) acc 87.5000 (87.5000) lr 1.2487e-03 eta 0:04:36
epoch [86/200] batch [3/3] time 0.821 (0.811) data 0.105 (0.095) loss 0.1869 (0.4134) acc 93.7500 (89.5833) lr 1.2334e-03 eta 0:04:37
epoch [87/200] batch [1/3] time 0.820 (0.820) data 0.094 (0.094) loss 0.3398 (0.3398) acc 90.6250 (90.6250) lr 1.2334e-03 eta 0:04:39
epoch [87/200] batch [2/3] time 0.831 (0.825) data 0.104 (0.099) loss 0.8560 (0.5979) acc 87.5000 (89.0625) lr 1.2334e-03 eta 0:04:40
epoch [87/200] batch [3/3] time 0.815 (0.822) data 0.099 (0.099) loss 0.1227 (0.4395) acc 100.0000 (92.7083) lr 1.2181e-03 eta 0:04:38
epoch [88/200] batch [1/3] time 0.820 (0.820) data 0.102 (0.102) loss 0.3621 (0.3621) acc 90.6250 (90.6250) lr 1.2181e-03 eta 0:04:37
epoch [88/200] batch [2/3] time 0.853 (0.836) data 0.136 (0.119) loss 0.3486 (0.3553) acc 90.6250 (90.6250) lr 1.2181e-03 eta 0:04:41
epoch [88/200] batch [3/3] time 0.804 (0.825) data 0.090 (0.109) loss 0.2443 (0.3183) acc 93.7500 (91.6667) lr 1.2028e-03 eta 0:04:37
epoch [89/200] batch [1/3] time 0.809 (0.809) data 0.094 (0.094) loss 0.3723 (0.3723) acc 93.7500 (93.7500) lr 1.2028e-03 eta 0:04:31
epoch [89/200] batch [2/3] time 0.814 (0.811) data 0.100 (0.097) loss 0.6812 (0.5267) acc 84.3750 (89.0625) lr 1.2028e-03 eta 0:04:31
epoch [89/200] batch [3/3] time 0.804 (0.809) data 0.093 (0.095) loss 0.3813 (0.4783) acc 90.6250 (89.5833) lr 1.1874e-03 eta 0:04:29
epoch [90/200] batch [1/3] time 0.819 (0.819) data 0.104 (0.104) loss 0.2307 (0.2307) acc 93.7500 (93.7500) lr 1.1874e-03 eta 0:04:31
epoch [90/200] batch [2/3] time 0.810 (0.814) data 0.090 (0.097) loss 0.9053 (0.5680) acc 81.2500 (87.5000) lr 1.1874e-03 eta 0:04:29
epoch [90/200] batch [3/3] time 0.819 (0.816) data 0.102 (0.098) loss 0.2089 (0.4483) acc 93.7500 (89.5833) lr 1.1719e-03 eta 0:04:29
epoch [91/200] batch [1/3] time 0.807 (0.807) data 0.090 (0.090) loss 0.4646 (0.4646) acc 90.6250 (90.6250) lr 1.1719e-03 eta 0:04:25
epoch [91/200] batch [2/3] time 0.829 (0.818) data 0.111 (0.101) loss 0.6538 (0.5592) acc 93.7500 (92.1875) lr 1.1719e-03 eta 0:04:28
epoch [91/200] batch [3/3] time 0.808 (0.815) data 0.092 (0.098) loss 0.4895 (0.5360) acc 84.3750 (89.5833) lr 1.1564e-03 eta 0:04:26
epoch [92/200] batch [1/3] time 0.825 (0.825) data 0.105 (0.105) loss 0.2510 (0.2510) acc 93.7500 (93.7500) lr 1.1564e-03 eta 0:04:29
epoch [92/200] batch [2/3] time 0.840 (0.833) data 0.115 (0.110) loss 0.4165 (0.3337) acc 87.5000 (90.6250) lr 1.1564e-03 eta 0:04:30
epoch [92/200] batch [3/3] time 0.963 (0.876) data 0.111 (0.110) loss 0.3694 (0.3456) acc 84.3750 (88.5417) lr 1.1409e-03 eta 0:04:43
epoch [93/200] batch [1/3] time 0.853 (0.853) data 0.139 (0.139) loss 0.2605 (0.2605) acc 93.7500 (93.7500) lr 1.1409e-03 eta 0:04:35
epoch [93/200] batch [2/3] time 1.012 (0.932) data 0.300 (0.220) loss 0.3547 (0.3076) acc 87.5000 (90.6250) lr 1.1409e-03 eta 0:05:00
epoch [93/200] batch [3/3] time 0.860 (0.908) data 0.148 (0.196) loss 0.2018 (0.2723) acc 90.6250 (90.6250) lr 1.1253e-03 eta 0:04:51
epoch [94/200] batch [1/3] time 0.888 (0.888) data 0.176 (0.176) loss 0.5332 (0.5332) acc 87.5000 (87.5000) lr 1.1253e-03 eta 0:04:44
epoch [94/200] batch [2/3] time 0.900 (0.894) data 0.189 (0.182) loss 0.2183 (0.3757) acc 93.7500 (90.6250) lr 1.1253e-03 eta 0:04:45
epoch [94/200] batch [3/3] time 0.860 (0.883) data 0.147 (0.170) loss 0.2205 (0.3240) acc 96.8750 (92.7083) lr 1.1097e-03 eta 0:04:40
epoch [95/200] batch [1/3] time 0.864 (0.864) data 0.152 (0.152) loss 0.4885 (0.4885) acc 87.5000 (87.5000) lr 1.1097e-03 eta 0:04:34
epoch [95/200] batch [2/3] time 0.878 (0.871) data 0.165 (0.159) loss 0.2429 (0.3657) acc 90.6250 (89.0625) lr 1.1097e-03 eta 0:04:35
epoch [95/200] batch [3/3] time 0.890 (0.878) data 0.178 (0.165) loss 0.6060 (0.4458) acc 78.1250 (85.4167) lr 1.0941e-03 eta 0:04:36
epoch [96/200] batch [1/3] time 0.845 (0.845) data 0.133 (0.133) loss 0.2700 (0.2700) acc 96.8750 (96.8750) lr 1.0941e-03 eta 0:04:25
epoch [96/200] batch [2/3] time 0.821 (0.833) data 0.109 (0.121) loss 0.1122 (0.1911) acc 96.8750 (96.8750) lr 1.0941e-03 eta 0:04:20
epoch [96/200] batch [3/3] time 0.823 (0.830) data 0.110 (0.117) loss 0.3408 (0.2410) acc 90.6250 (94.7917) lr 1.0785e-03 eta 0:04:18
epoch [97/200] batch [1/3] time 0.883 (0.883) data 0.170 (0.170) loss 0.3696 (0.3696) acc 93.7500 (93.7500) lr 1.0785e-03 eta 0:04:34
epoch [97/200] batch [2/3] time 0.812 (0.847) data 0.100 (0.135) loss 0.2793 (0.3245) acc 96.8750 (95.3125) lr 1.0785e-03 eta 0:04:22
epoch [97/200] batch [3/3] time 0.846 (0.847) data 0.133 (0.134) loss 0.4636 (0.3708) acc 87.5000 (92.7083) lr 1.0628e-03 eta 0:04:21
epoch [98/200] batch [1/3] time 0.861 (0.861) data 0.145 (0.145) loss 0.4333 (0.4333) acc 87.5000 (87.5000) lr 1.0628e-03 eta 0:04:25
epoch [98/200] batch [2/3] time 0.799 (0.830) data 0.089 (0.117) loss 0.2416 (0.3375) acc 93.7500 (90.6250) lr 1.0628e-03 eta 0:04:14
epoch [98/200] batch [3/3] time 0.828 (0.830) data 0.095 (0.110) loss 0.1477 (0.2742) acc 93.7500 (91.6667) lr 1.0471e-03 eta 0:04:13
epoch [99/200] batch [1/3] time 0.841 (0.841) data 0.122 (0.122) loss 0.3259 (0.3259) acc 90.6250 (90.6250) lr 1.0471e-03 eta 0:04:16
epoch [99/200] batch [2/3] time 0.967 (0.904) data 0.163 (0.142) loss 0.5483 (0.4371) acc 87.5000 (89.0625) lr 1.0471e-03 eta 0:04:34
epoch [99/200] batch [3/3] time 1.009 (0.939) data 0.240 (0.175) loss 0.3716 (0.4153) acc 93.7500 (90.6250) lr 1.0314e-03 eta 0:04:44
epoch [100/200] batch [1/3] time 0.834 (0.834) data 0.111 (0.111) loss 0.4980 (0.4980) acc 90.6250 (90.6250) lr 1.0314e-03 eta 0:04:11
epoch [100/200] batch [2/3] time 0.824 (0.829) data 0.103 (0.107) loss 0.6226 (0.5603) acc 84.3750 (87.5000) lr 1.0314e-03 eta 0:04:09
epoch [100/200] batch [3/3] time 0.873 (0.843) data 0.156 (0.124) loss 0.4155 (0.5120) acc 87.5000 (87.5000) lr 1.0157e-03 eta 0:04:13
epoch [101/200] batch [1/3] time 0.819 (0.819) data 0.097 (0.097) loss 0.5664 (0.5664) acc 81.2500 (81.2500) lr 1.0157e-03 eta 0:04:04
epoch [101/200] batch [2/3] time 0.818 (0.818) data 0.098 (0.098) loss 0.2810 (0.4237) acc 90.6250 (85.9375) lr 1.0157e-03 eta 0:04:03
epoch [101/200] batch [3/3] time 0.810 (0.815) data 0.094 (0.096) loss 0.0695 (0.3056) acc 100.0000 (90.6250) lr 1.0000e-03 eta 0:04:02
epoch [102/200] batch [1/3] time 0.820 (0.820) data 0.107 (0.107) loss 0.2583 (0.2583) acc 96.8750 (96.8750) lr 1.0000e-03 eta 0:04:02
epoch [102/200] batch [2/3] time 0.938 (0.879) data 0.102 (0.104) loss 0.2391 (0.2487) acc 93.7500 (95.3125) lr 1.0000e-03 eta 0:04:19
epoch [102/200] batch [3/3] time 0.948 (0.902) data 0.191 (0.133) loss 0.3521 (0.2832) acc 93.7500 (94.7917) lr 9.8429e-04 eta 0:04:25
epoch [103/200] batch [1/3] time 0.844 (0.844) data 0.127 (0.127) loss 0.1080 (0.1080) acc 96.8750 (96.8750) lr 9.8429e-04 eta 0:04:07
epoch [103/200] batch [2/3] time 0.815 (0.829) data 0.101 (0.114) loss 0.4888 (0.2984) acc 90.6250 (93.7500) lr 9.8429e-04 eta 0:04:02
epoch [103/200] batch [3/3] time 0.803 (0.821) data 0.089 (0.106) loss 0.5684 (0.3884) acc 87.5000 (91.6667) lr 9.6859e-04 eta 0:03:58
epoch [104/200] batch [1/3] time 0.807 (0.807) data 0.095 (0.095) loss 0.1642 (0.1642) acc 96.8750 (96.8750) lr 9.6859e-04 eta 0:03:54
epoch [104/200] batch [2/3] time 0.859 (0.833) data 0.099 (0.097) loss 0.5688 (0.3665) acc 84.3750 (90.6250) lr 9.6859e-04 eta 0:04:00
epoch [104/200] batch [3/3] time 0.834 (0.833) data 0.105 (0.099) loss 0.4514 (0.3948) acc 93.7500 (91.6667) lr 9.5289e-04 eta 0:03:59
epoch [105/200] batch [1/3] time 1.134 (1.134) data 0.425 (0.425) loss 0.0471 (0.0471) acc 100.0000 (100.0000) lr 9.5289e-04 eta 0:05:25
epoch [105/200] batch [2/3] time 0.808 (0.971) data 0.092 (0.259) loss 0.3303 (0.1887) acc 87.5000 (93.7500) lr 9.5289e-04 eta 0:04:37
epoch [105/200] batch [3/3] time 0.812 (0.918) data 0.096 (0.204) loss 0.2178 (0.1984) acc 96.8750 (94.7917) lr 9.3721e-04 eta 0:04:21
epoch [106/200] batch [1/3] time 0.825 (0.825) data 0.111 (0.111) loss 0.5186 (0.5186) acc 87.5000 (87.5000) lr 9.3721e-04 eta 0:03:54
epoch [106/200] batch [2/3] time 0.809 (0.817) data 0.093 (0.102) loss 0.2583 (0.3884) acc 93.7500 (90.6250) lr 9.3721e-04 eta 0:03:51
epoch [106/200] batch [3/3] time 0.807 (0.814) data 0.093 (0.099) loss 0.6016 (0.4595) acc 84.3750 (88.5417) lr 9.2154e-04 eta 0:03:49
epoch [107/200] batch [1/3] time 0.813 (0.813) data 0.099 (0.099) loss 0.1295 (0.1295) acc 100.0000 (100.0000) lr 9.2154e-04 eta 0:03:48
epoch [107/200] batch [2/3] time 0.823 (0.818) data 0.106 (0.103) loss 0.4092 (0.2693) acc 84.3750 (92.1875) lr 9.2154e-04 eta 0:03:48
epoch [107/200] batch [3/3] time 0.820 (0.819) data 0.101 (0.102) loss 0.6685 (0.4024) acc 90.6250 (91.6667) lr 9.0589e-04 eta 0:03:48
epoch [108/200] batch [1/3] time 0.819 (0.819) data 0.105 (0.105) loss 0.4102 (0.4102) acc 87.5000 (87.5000) lr 9.0589e-04 eta 0:03:47
epoch [108/200] batch [2/3] time 0.807 (0.813) data 0.092 (0.098) loss 0.3167 (0.3634) acc 96.8750 (92.1875) lr 9.0589e-04 eta 0:03:45
epoch [108/200] batch [3/3] time 0.811 (0.812) data 0.097 (0.098) loss 0.8076 (0.5115) acc 81.2500 (88.5417) lr 8.9027e-04 eta 0:03:44
epoch [109/200] batch [1/3] time 0.852 (0.852) data 0.135 (0.135) loss 0.0683 (0.0683) acc 100.0000 (100.0000) lr 8.9027e-04 eta 0:03:54
epoch [109/200] batch [2/3] time 0.831 (0.841) data 0.115 (0.125) loss 0.2876 (0.1779) acc 93.7500 (96.8750) lr 8.9027e-04 eta 0:03:50
epoch [109/200] batch [3/3] time 0.844 (0.842) data 0.100 (0.117) loss 0.4104 (0.2554) acc 90.6250 (94.7917) lr 8.7467e-04 eta 0:03:49
epoch [110/200] batch [1/3] time 0.828 (0.828) data 0.109 (0.109) loss 0.4492 (0.4492) acc 90.6250 (90.6250) lr 8.7467e-04 eta 0:03:45
epoch [110/200] batch [2/3] time 0.806 (0.817) data 0.090 (0.099) loss 0.4565 (0.4529) acc 93.7500 (92.1875) lr 8.7467e-04 eta 0:03:41
epoch [110/200] batch [3/3] time 0.808 (0.814) data 0.093 (0.097) loss 0.1826 (0.3628) acc 93.7500 (92.7083) lr 8.5910e-04 eta 0:03:39
epoch [111/200] batch [1/3] time 0.815 (0.815) data 0.097 (0.097) loss 0.1930 (0.1930) acc 96.8750 (96.8750) lr 8.5910e-04 eta 0:03:39
epoch [111/200] batch [2/3] time 0.819 (0.817) data 0.101 (0.099) loss 0.2262 (0.2096) acc 96.8750 (96.8750) lr 8.5910e-04 eta 0:03:38
epoch [111/200] batch [3/3] time 0.824 (0.819) data 0.107 (0.102) loss 0.0290 (0.1494) acc 100.0000 (97.9167) lr 8.4357e-04 eta 0:03:38
epoch [112/200] batch [1/3] time 0.919 (0.919) data 0.203 (0.203) loss 0.4092 (0.4092) acc 93.7500 (93.7500) lr 8.4357e-04 eta 0:04:04
epoch [112/200] batch [2/3] time 0.875 (0.897) data 0.106 (0.155) loss 0.5088 (0.4590) acc 87.5000 (90.6250) lr 8.4357e-04 eta 0:03:57
epoch [112/200] batch [3/3] time 1.939 (1.244) data 1.030 (0.446) loss 0.3469 (0.4216) acc 90.6250 (90.6250) lr 8.2807e-04 eta 0:05:28
epoch [113/200] batch [1/3] time 0.827 (0.827) data 0.108 (0.108) loss 0.3738 (0.3738) acc 93.7500 (93.7500) lr 8.2807e-04 eta 0:03:37
epoch [113/200] batch [2/3] time 0.817 (0.822) data 0.096 (0.102) loss 0.4548 (0.4143) acc 90.6250 (92.1875) lr 8.2807e-04 eta 0:03:35
epoch [113/200] batch [3/3] time 0.819 (0.821) data 0.102 (0.102) loss 0.0710 (0.2999) acc 100.0000 (94.7917) lr 8.1262e-04 eta 0:03:34
epoch [114/200] batch [1/3] time 0.825 (0.825) data 0.110 (0.110) loss 0.4077 (0.4077) acc 84.3750 (84.3750) lr 8.1262e-04 eta 0:03:34
epoch [114/200] batch [2/3] time 0.815 (0.820) data 0.099 (0.105) loss 0.3149 (0.3613) acc 90.6250 (87.5000) lr 8.1262e-04 eta 0:03:32
epoch [114/200] batch [3/3] time 0.812 (0.817) data 0.097 (0.102) loss 0.1454 (0.2893) acc 96.8750 (90.6250) lr 7.9721e-04 eta 0:03:30
epoch [115/200] batch [1/3] time 0.821 (0.821) data 0.104 (0.104) loss 0.1444 (0.1444) acc 96.8750 (96.8750) lr 7.9721e-04 eta 0:03:30
epoch [115/200] batch [2/3] time 0.823 (0.822) data 0.100 (0.102) loss 0.1340 (0.1392) acc 96.8750 (96.8750) lr 7.9721e-04 eta 0:03:30
epoch [115/200] batch [3/3] time 0.806 (0.817) data 0.091 (0.099) loss 0.3147 (0.1977) acc 90.6250 (94.7917) lr 7.8186e-04 eta 0:03:28
epoch [116/200] batch [1/3] time 0.808 (0.808) data 0.092 (0.092) loss 0.2771 (0.2771) acc 93.7500 (93.7500) lr 7.8186e-04 eta 0:03:25
epoch [116/200] batch [2/3] time 0.853 (0.830) data 0.127 (0.110) loss 0.3467 (0.3119) acc 96.8750 (95.3125) lr 7.8186e-04 eta 0:03:30
epoch [116/200] batch [3/3] time 0.844 (0.835) data 0.126 (0.115) loss 0.6187 (0.4141) acc 81.2500 (90.6250) lr 7.6655e-04 eta 0:03:30
epoch [117/200] batch [1/3] time 1.301 (1.301) data 0.577 (0.577) loss 0.1743 (0.1743) acc 93.7500 (93.7500) lr 7.6655e-04 eta 0:05:26
epoch [117/200] batch [2/3] time 0.848 (1.075) data 0.126 (0.351) loss 0.2502 (0.2123) acc 93.7500 (93.7500) lr 7.6655e-04 eta 0:04:28
epoch [117/200] batch [3/3] time 0.912 (1.021) data 0.192 (0.298) loss 0.2715 (0.2320) acc 93.7500 (93.7500) lr 7.5131e-04 eta 0:04:14
epoch [118/200] batch [1/3] time 0.855 (0.855) data 0.120 (0.120) loss 0.2556 (0.2556) acc 96.8750 (96.8750) lr 7.5131e-04 eta 0:03:32
epoch [118/200] batch [2/3] time 0.842 (0.849) data 0.114 (0.117) loss 0.1525 (0.2040) acc 96.8750 (96.8750) lr 7.5131e-04 eta 0:03:29
epoch [118/200] batch [3/3] time 0.870 (0.856) data 0.145 (0.126) loss 0.4167 (0.2749) acc 87.5000 (93.7500) lr 7.3613e-04 eta 0:03:30
epoch [119/200] batch [1/3] time 0.848 (0.848) data 0.129 (0.129) loss 0.3184 (0.3184) acc 93.7500 (93.7500) lr 7.3613e-04 eta 0:03:27
epoch [119/200] batch [2/3] time 0.854 (0.851) data 0.135 (0.132) loss 0.3313 (0.3248) acc 93.7500 (93.7500) lr 7.3613e-04 eta 0:03:27
epoch [119/200] batch [3/3] time 0.860 (0.854) data 0.105 (0.123) loss 0.1222 (0.2573) acc 100.0000 (95.8333) lr 7.2101e-04 eta 0:03:27
epoch [120/200] batch [1/3] time 1.306 (1.306) data 0.226 (0.226) loss 0.2979 (0.2979) acc 93.7500 (93.7500) lr 7.2101e-04 eta 0:05:15
epoch [120/200] batch [2/3] time 2.218 (1.762) data 1.029 (0.627) loss 0.6626 (0.4802) acc 87.5000 (90.6250) lr 7.2101e-04 eta 0:07:04
epoch [120/200] batch [3/3] time 1.549 (1.691) data 0.592 (0.615) loss 0.3489 (0.4364) acc 93.7500 (91.6667) lr 7.0596e-04 eta 0:06:45
epoch [121/200] batch [1/3] time 1.502 (1.502) data 0.548 (0.548) loss 0.3191 (0.3191) acc 96.8750 (96.8750) lr 7.0596e-04 eta 0:05:59
epoch [121/200] batch [2/3] time 1.508 (1.505) data 0.409 (0.479) loss 0.5439 (0.4315) acc 84.3750 (90.6250) lr 7.0596e-04 eta 0:05:58
epoch [121/200] batch [3/3] time 1.748 (1.586) data 0.711 (0.556) loss 0.2428 (0.3686) acc 93.7500 (91.6667) lr 6.9098e-04 eta 0:06:15
epoch [122/200] batch [1/3] time 1.591 (1.591) data 0.524 (0.524) loss 0.3181 (0.3181) acc 93.7500 (93.7500) lr 6.9098e-04 eta 0:06:15
epoch [122/200] batch [2/3] time 1.285 (1.438) data 0.346 (0.435) loss 0.1790 (0.2485) acc 93.7500 (93.7500) lr 6.9098e-04 eta 0:05:37
epoch [122/200] batch [3/3] time 1.320 (1.399) data 0.263 (0.378) loss 0.1704 (0.2225) acc 96.8750 (94.7917) lr 6.7608e-04 eta 0:05:27
epoch [123/200] batch [1/3] time 1.180 (1.180) data 0.219 (0.219) loss 0.3787 (0.3787) acc 90.6250 (90.6250) lr 6.7608e-04 eta 0:04:35
epoch [123/200] batch [2/3] time 1.035 (1.108) data 0.182 (0.200) loss 0.2123 (0.2955) acc 93.7500 (92.1875) lr 6.7608e-04 eta 0:04:16
epoch [123/200] batch [3/3] time 1.072 (1.096) data 0.214 (0.205) loss 0.2162 (0.2690) acc 96.8750 (93.7500) lr 6.6126e-04 eta 0:04:13
epoch [124/200] batch [1/3] time 1.217 (1.217) data 0.322 (0.322) loss 0.0638 (0.0638) acc 100.0000 (100.0000) lr 6.6126e-04 eta 0:04:39
epoch [124/200] batch [2/3] time 1.174 (1.196) data 0.237 (0.279) loss 0.5610 (0.3124) acc 84.3750 (92.1875) lr 6.6126e-04 eta 0:04:33
epoch [124/200] batch [3/3] time 0.927 (1.106) data 0.143 (0.234) loss 0.1450 (0.2566) acc 96.8750 (93.7500) lr 6.4653e-04 eta 0:04:12
epoch [125/200] batch [1/3] time 0.950 (0.950) data 0.168 (0.168) loss 0.1243 (0.1243) acc 96.8750 (96.8750) lr 6.4653e-04 eta 0:03:35
epoch [125/200] batch [2/3] time 0.913 (0.932) data 0.129 (0.148) loss 0.2021 (0.1632) acc 96.8750 (96.8750) lr 6.4653e-04 eta 0:03:30
epoch [125/200] batch [3/3] time 0.897 (0.920) data 0.111 (0.136) loss 0.0907 (0.1391) acc 100.0000 (97.9167) lr 6.3188e-04 eta 0:03:27
epoch [126/200] batch [1/3] time 0.898 (0.898) data 0.115 (0.115) loss 0.3811 (0.3811) acc 90.6250 (90.6250) lr 6.3188e-04 eta 0:03:21
epoch [126/200] batch [2/3] time 0.910 (0.904) data 0.124 (0.120) loss 0.3857 (0.3834) acc 93.7500 (92.1875) lr 6.3188e-04 eta 0:03:21
epoch [126/200] batch [3/3] time 0.935 (0.914) data 0.148 (0.129) loss 0.0446 (0.2705) acc 100.0000 (94.7917) lr 6.1732e-04 eta 0:03:22
epoch [127/200] batch [1/3] time 0.899 (0.899) data 0.112 (0.112) loss 0.5132 (0.5132) acc 90.6250 (90.6250) lr 6.1732e-04 eta 0:03:18
epoch [127/200] batch [2/3] time 0.930 (0.914) data 0.143 (0.127) loss 0.4241 (0.4686) acc 87.5000 (89.0625) lr 6.1732e-04 eta 0:03:21
epoch [127/200] batch [3/3] time 0.919 (0.916) data 0.135 (0.130) loss 0.3022 (0.4132) acc 96.8750 (91.6667) lr 6.0285e-04 eta 0:03:20
epoch [128/200] batch [1/3] time 0.921 (0.921) data 0.135 (0.135) loss 0.0826 (0.0826) acc 100.0000 (100.0000) lr 6.0285e-04 eta 0:03:20
epoch [128/200] batch [2/3] time 0.906 (0.913) data 0.122 (0.128) loss 0.4353 (0.2590) acc 90.6250 (95.3125) lr 6.0285e-04 eta 0:03:18
epoch [128/200] batch [3/3] time 0.900 (0.909) data 0.116 (0.124) loss 0.2825 (0.2668) acc 90.6250 (93.7500) lr 5.8849e-04 eta 0:03:16
epoch [129/200] batch [1/3] time 0.921 (0.921) data 0.135 (0.135) loss 0.5137 (0.5137) acc 84.3750 (84.3750) lr 5.8849e-04 eta 0:03:18
epoch [129/200] batch [2/3] time 0.912 (0.917) data 0.124 (0.130) loss 0.2527 (0.3832) acc 93.7500 (89.0625) lr 5.8849e-04 eta 0:03:16
epoch [129/200] batch [3/3] time 0.921 (0.918) data 0.134 (0.131) loss 0.5508 (0.4390) acc 87.5000 (88.5417) lr 5.7422e-04 eta 0:03:15
epoch [130/200] batch [1/3] time 0.927 (0.927) data 0.141 (0.141) loss 0.2484 (0.2484) acc 93.7500 (93.7500) lr 5.7422e-04 eta 0:03:16
epoch [130/200] batch [2/3] time 0.904 (0.916) data 0.117 (0.129) loss 0.3555 (0.3019) acc 90.6250 (92.1875) lr 5.7422e-04 eta 0:03:13
epoch [130/200] batch [3/3] time 0.908 (0.913) data 0.122 (0.127) loss 0.3337 (0.3125) acc 84.3750 (89.5833) lr 5.6006e-04 eta 0:03:11
epoch [131/200] batch [1/3] time 0.940 (0.940) data 0.155 (0.155) loss 0.1896 (0.1896) acc 93.7500 (93.7500) lr 5.6006e-04 eta 0:03:16
epoch [131/200] batch [2/3] time 0.921 (0.931) data 0.133 (0.144) loss 0.1877 (0.1887) acc 96.8750 (95.3125) lr 5.6006e-04 eta 0:03:13
epoch [131/200] batch [3/3] time 0.913 (0.925) data 0.130 (0.139) loss 0.0951 (0.1575) acc 96.8750 (95.8333) lr 5.4601e-04 eta 0:03:11
epoch [132/200] batch [1/3] time 0.911 (0.911) data 0.125 (0.125) loss 0.1722 (0.1722) acc 96.8750 (96.8750) lr 5.4601e-04 eta 0:03:07
epoch [132/200] batch [2/3] time 0.915 (0.913) data 0.127 (0.126) loss 0.1547 (0.1635) acc 96.8750 (96.8750) lr 5.4601e-04 eta 0:03:07
epoch [132/200] batch [3/3] time 0.912 (0.913) data 0.128 (0.127) loss 0.2349 (0.1873) acc 93.7500 (95.8333) lr 5.3207e-04 eta 0:03:06
epoch [133/200] batch [1/3] time 0.927 (0.927) data 0.142 (0.142) loss 0.1299 (0.1299) acc 96.8750 (96.8750) lr 5.3207e-04 eta 0:03:08
epoch [133/200] batch [2/3] time 0.933 (0.930) data 0.146 (0.144) loss 0.5488 (0.3394) acc 84.3750 (90.6250) lr 5.3207e-04 eta 0:03:07
epoch [133/200] batch [3/3] time 0.908 (0.923) data 0.123 (0.137) loss 0.2766 (0.3184) acc 96.8750 (92.7083) lr 5.1825e-04 eta 0:03:05
epoch [134/200] batch [1/3] time 0.908 (0.908) data 0.121 (0.121) loss 0.2864 (0.2864) acc 90.6250 (90.6250) lr 5.1825e-04 eta 0:03:01
epoch [134/200] batch [2/3] time 0.921 (0.915) data 0.138 (0.130) loss 0.3848 (0.3356) acc 93.7500 (92.1875) lr 5.1825e-04 eta 0:03:02
epoch [134/200] batch [3/3] time 0.917 (0.916) data 0.130 (0.130) loss 0.6060 (0.4257) acc 75.0000 (86.4583) lr 5.0454e-04 eta 0:03:01
epoch [135/200] batch [1/3] time 0.907 (0.907) data 0.123 (0.123) loss 0.2744 (0.2744) acc 93.7500 (93.7500) lr 5.0454e-04 eta 0:02:58
epoch [135/200] batch [2/3] time 0.926 (0.916) data 0.137 (0.130) loss 0.3516 (0.3130) acc 93.7500 (93.7500) lr 5.0454e-04 eta 0:02:59
epoch [135/200] batch [3/3] time 0.914 (0.916) data 0.131 (0.131) loss 0.0947 (0.2402) acc 96.8750 (94.7917) lr 4.9096e-04 eta 0:02:58
epoch [136/200] batch [1/3] time 0.916 (0.916) data 0.131 (0.131) loss 0.4551 (0.4551) acc 87.5000 (87.5000) lr 4.9096e-04 eta 0:02:57
epoch [136/200] batch [2/3] time 0.930 (0.923) data 0.143 (0.137) loss 0.1826 (0.3188) acc 96.8750 (92.1875) lr 4.9096e-04 eta 0:02:58
epoch [136/200] batch [3/3] time 0.911 (0.919) data 0.124 (0.133) loss 0.3206 (0.3194) acc 93.7500 (92.7083) lr 4.7750e-04 eta 0:02:56
epoch [137/200] batch [1/3] time 0.899 (0.899) data 0.111 (0.111) loss 0.4492 (0.4492) acc 90.6250 (90.6250) lr 4.7750e-04 eta 0:02:51
epoch [137/200] batch [2/3] time 0.925 (0.912) data 0.138 (0.125) loss 0.1836 (0.3164) acc 96.8750 (93.7500) lr 4.7750e-04 eta 0:02:53
epoch [137/200] batch [3/3] time 0.914 (0.913) data 0.130 (0.126) loss 0.2732 (0.3020) acc 93.7500 (93.7500) lr 4.6417e-04 eta 0:02:52
epoch [138/200] batch [1/3] time 1.311 (1.311) data 0.530 (0.530) loss 0.4082 (0.4082) acc 93.7500 (93.7500) lr 4.6417e-04 eta 0:04:06
epoch [138/200] batch [2/3] time 0.977 (1.144) data 0.190 (0.360) loss 0.4910 (0.4496) acc 90.6250 (92.1875) lr 4.6417e-04 eta 0:03:33
epoch [138/200] batch [3/3] time 0.928 (1.072) data 0.142 (0.288) loss 0.2576 (0.3856) acc 93.7500 (92.7083) lr 4.5098e-04 eta 0:03:19
epoch [139/200] batch [1/3] time 0.914 (0.914) data 0.131 (0.131) loss 0.1250 (0.1250) acc 96.8750 (96.8750) lr 4.5098e-04 eta 0:02:49
epoch [139/200] batch [2/3] time 0.930 (0.922) data 0.142 (0.136) loss 0.4497 (0.2874) acc 81.2500 (89.0625) lr 4.5098e-04 eta 0:02:49
epoch [139/200] batch [3/3] time 0.931 (0.925) data 0.144 (0.139) loss 0.2480 (0.2743) acc 93.7500 (90.6250) lr 4.3792e-04 eta 0:02:49
epoch [140/200] batch [1/3] time 0.970 (0.970) data 0.187 (0.187) loss 0.2142 (0.2142) acc 96.8750 (96.8750) lr 4.3792e-04 eta 0:02:56
epoch [140/200] batch [2/3] time 0.913 (0.941) data 0.127 (0.157) loss 0.0191 (0.1167) acc 100.0000 (98.4375) lr 4.3792e-04 eta 0:02:50
epoch [140/200] batch [3/3] time 0.947 (0.943) data 0.161 (0.158) loss 0.1401 (0.1245) acc 100.0000 (98.9583) lr 4.2499e-04 eta 0:02:49
epoch [141/200] batch [1/3] time 0.903 (0.903) data 0.118 (0.118) loss 0.1912 (0.1912) acc 100.0000 (100.0000) lr 4.2499e-04 eta 0:02:41
epoch [141/200] batch [2/3] time 0.913 (0.908) data 0.127 (0.123) loss 0.0863 (0.1387) acc 96.8750 (98.4375) lr 4.2499e-04 eta 0:02:41
epoch [141/200] batch [3/3] time 0.902 (0.906) data 0.116 (0.120) loss 0.5762 (0.2845) acc 90.6250 (95.8333) lr 4.1221e-04 eta 0:02:40
epoch [142/200] batch [1/3] time 0.925 (0.925) data 0.142 (0.142) loss 0.4670 (0.4670) acc 90.6250 (90.6250) lr 4.1221e-04 eta 0:02:42
epoch [142/200] batch [2/3] time 1.034 (0.979) data 0.125 (0.133) loss 0.1448 (0.3059) acc 100.0000 (95.3125) lr 4.1221e-04 eta 0:02:51
epoch [142/200] batch [3/3] time 1.282 (1.080) data 0.434 (0.234) loss 0.1017 (0.2379) acc 96.8750 (95.8333) lr 3.9958e-04 eta 0:03:07
epoch [143/200] batch [1/3] time 1.202 (1.202) data 0.154 (0.154) loss 0.1909 (0.1909) acc 96.8750 (96.8750) lr 3.9958e-04 eta 0:03:27
epoch [143/200] batch [2/3] time 1.038 (1.120) data 0.147 (0.151) loss 0.1938 (0.1924) acc 93.7500 (95.3125) lr 3.9958e-04 eta 0:03:12
epoch [143/200] batch [3/3] time 0.905 (1.048) data 0.120 (0.140) loss 0.0655 (0.1501) acc 100.0000 (96.8750) lr 3.8709e-04 eta 0:02:59
epoch [144/200] batch [1/3] time 1.150 (1.150) data 0.196 (0.196) loss 0.0762 (0.0762) acc 100.0000 (100.0000) lr 3.8709e-04 eta 0:03:15
epoch [144/200] batch [2/3] time 1.662 (1.406) data 0.579 (0.387) loss 0.1638 (0.1200) acc 96.8750 (98.4375) lr 3.8709e-04 eta 0:03:57
epoch [144/200] batch [3/3] time 1.239 (1.350) data 0.305 (0.360) loss 0.2551 (0.1651) acc 96.8750 (97.9167) lr 3.7476e-04 eta 0:03:46
epoch [145/200] batch [1/3] time 1.042 (1.042) data 0.301 (0.301) loss 0.6396 (0.6396) acc 84.3750 (84.3750) lr 3.7476e-04 eta 0:02:53
epoch [145/200] batch [2/3] time 1.404 (1.223) data 0.689 (0.495) loss 0.4846 (0.5621) acc 87.5000 (85.9375) lr 3.7476e-04 eta 0:03:22
epoch [145/200] batch [3/3] time 1.091 (1.179) data 0.114 (0.368) loss 0.6992 (0.6078) acc 90.6250 (87.5000) lr 3.6258e-04 eta 0:03:14
epoch [146/200] batch [1/3] time 1.178 (1.178) data 0.218 (0.218) loss 0.1381 (0.1381) acc 100.0000 (100.0000) lr 3.6258e-04 eta 0:03:13
epoch [146/200] batch [2/3] time 0.877 (1.027) data 0.158 (0.188) loss 0.1951 (0.1666) acc 93.7500 (96.8750) lr 3.6258e-04 eta 0:02:47
epoch [146/200] batch [3/3] time 0.910 (0.988) data 0.173 (0.183) loss 0.3181 (0.2171) acc 90.6250 (94.7917) lr 3.5055e-04 eta 0:02:40
epoch [147/200] batch [1/3] time 0.844 (0.844) data 0.110 (0.110) loss 0.7319 (0.7319) acc 81.2500 (81.2500) lr 3.5055e-04 eta 0:02:15
epoch [147/200] batch [2/3] time 1.874 (1.359) data 0.396 (0.253) loss 0.3225 (0.5272) acc 93.7500 (87.5000) lr 3.5055e-04 eta 0:03:37
epoch [147/200] batch [3/3] time 0.920 (1.213) data 0.194 (0.233) loss 0.5688 (0.5411) acc 87.5000 (87.5000) lr 3.3869e-04 eta 0:03:12
epoch [148/200] batch [1/3] time 0.822 (0.822) data 0.106 (0.106) loss 0.1495 (0.1495) acc 96.8750 (96.8750) lr 3.3869e-04 eta 0:02:09
epoch [148/200] batch [2/3] time 1.164 (0.993) data 0.146 (0.126) loss 0.4521 (0.3008) acc 87.5000 (92.1875) lr 3.3869e-04 eta 0:02:35
epoch [148/200] batch [3/3] time 1.402 (1.129) data 0.251 (0.168) loss 0.1587 (0.2535) acc 96.8750 (93.7500) lr 3.2699e-04 eta 0:02:56
epoch [149/200] batch [1/3] time 1.120 (1.120) data 0.173 (0.173) loss 0.4373 (0.4373) acc 84.3750 (84.3750) lr 3.2699e-04 eta 0:02:53
epoch [149/200] batch [2/3] time 0.823 (0.972) data 0.103 (0.138) loss 0.5083 (0.4728) acc 84.3750 (84.3750) lr 3.2699e-04 eta 0:02:29
epoch [149/200] batch [3/3] time 0.916 (0.953) data 0.193 (0.156) loss 0.4775 (0.4744) acc 93.7500 (87.5000) lr 3.1545e-04 eta 0:02:25
epoch [150/200] batch [1/3] time 0.890 (0.890) data 0.161 (0.161) loss 0.4883 (0.4883) acc 87.5000 (87.5000) lr 3.1545e-04 eta 0:02:15
epoch [150/200] batch [2/3] time 0.845 (0.868) data 0.095 (0.128) loss 0.1962 (0.3422) acc 96.8750 (92.1875) lr 3.1545e-04 eta 0:02:10
epoch [150/200] batch [3/3] time 1.002 (0.912) data 0.112 (0.123) loss 0.2374 (0.3073) acc 96.8750 (93.7500) lr 3.0409e-04 eta 0:02:16
epoch [151/200] batch [1/3] time 0.893 (0.893) data 0.140 (0.140) loss 0.1990 (0.1990) acc 96.8750 (96.8750) lr 3.0409e-04 eta 0:02:13
epoch [151/200] batch [2/3] time 0.820 (0.857) data 0.099 (0.120) loss 0.4209 (0.3099) acc 93.7500 (95.3125) lr 3.0409e-04 eta 0:02:06
epoch [151/200] batch [3/3] time 0.926 (0.880) data 0.121 (0.120) loss 0.4504 (0.3568) acc 87.5000 (92.7083) lr 2.9289e-04 eta 0:02:09
epoch [152/200] batch [1/3] time 1.007 (1.007) data 0.168 (0.168) loss 0.1450 (0.1450) acc 96.8750 (96.8750) lr 2.9289e-04 eta 0:02:27
epoch [152/200] batch [2/3] time 0.817 (0.912) data 0.106 (0.137) loss 0.1659 (0.1555) acc 96.8750 (96.8750) lr 2.9289e-04 eta 0:02:12
epoch [152/200] batch [3/3] time 0.826 (0.883) data 0.102 (0.125) loss 0.3320 (0.2143) acc 87.5000 (93.7500) lr 2.8187e-04 eta 0:02:07
epoch [153/200] batch [1/3] time 0.843 (0.843) data 0.120 (0.120) loss 0.1261 (0.1261) acc 96.8750 (96.8750) lr 2.8187e-04 eta 0:02:00
epoch [153/200] batch [2/3] time 0.813 (0.828) data 0.102 (0.111) loss 0.5806 (0.3533) acc 90.6250 (93.7500) lr 2.8187e-04 eta 0:01:57
epoch [153/200] batch [3/3] time 0.811 (0.822) data 0.095 (0.105) loss 0.4961 (0.4009) acc 84.3750 (90.6250) lr 2.7103e-04 eta 0:01:55
epoch [154/200] batch [1/3] time 0.809 (0.809) data 0.093 (0.093) loss 0.4639 (0.4639) acc 90.6250 (90.6250) lr 2.7103e-04 eta 0:01:53
epoch [154/200] batch [2/3] time 0.805 (0.807) data 0.093 (0.093) loss 0.1547 (0.3093) acc 93.7500 (92.1875) lr 2.7103e-04 eta 0:01:52
epoch [154/200] batch [3/3] time 0.834 (0.816) data 0.123 (0.103) loss 0.0597 (0.2261) acc 96.8750 (93.7500) lr 2.6037e-04 eta 0:01:52
epoch [155/200] batch [1/3] time 0.807 (0.807) data 0.091 (0.091) loss 0.3442 (0.3442) acc 93.7500 (93.7500) lr 2.6037e-04 eta 0:01:50
epoch [155/200] batch [2/3] time 0.808 (0.807) data 0.095 (0.093) loss 0.1569 (0.2505) acc 93.7500 (93.7500) lr 2.6037e-04 eta 0:01:49
epoch [155/200] batch [3/3] time 0.814 (0.809) data 0.101 (0.096) loss 0.0276 (0.1762) acc 100.0000 (95.8333) lr 2.4989e-04 eta 0:01:49
epoch [156/200] batch [1/3] time 0.812 (0.812) data 0.095 (0.095) loss 0.4412 (0.4412) acc 87.5000 (87.5000) lr 2.4989e-04 eta 0:01:48
epoch [156/200] batch [2/3] time 0.805 (0.808) data 0.094 (0.094) loss 0.1115 (0.2763) acc 100.0000 (93.7500) lr 2.4989e-04 eta 0:01:47
epoch [156/200] batch [3/3] time 0.802 (0.806) data 0.091 (0.093) loss 0.3330 (0.2952) acc 90.6250 (92.7083) lr 2.3959e-04 eta 0:01:46
epoch [157/200] batch [1/3] time 0.831 (0.831) data 0.115 (0.115) loss 0.1991 (0.1991) acc 96.8750 (96.8750) lr 2.3959e-04 eta 0:01:48
epoch [157/200] batch [2/3] time 0.808 (0.819) data 0.091 (0.103) loss 0.0811 (0.1401) acc 96.8750 (96.8750) lr 2.3959e-04 eta 0:01:46
epoch [157/200] batch [3/3] time 0.805 (0.814) data 0.092 (0.099) loss 0.2878 (0.1894) acc 93.7500 (95.8333) lr 2.2949e-04 eta 0:01:45
epoch [158/200] batch [1/3] time 0.813 (0.813) data 0.102 (0.102) loss 0.1416 (0.1416) acc 96.8750 (96.8750) lr 2.2949e-04 eta 0:01:44
epoch [158/200] batch [2/3] time 0.804 (0.809) data 0.092 (0.097) loss 0.5146 (0.3281) acc 87.5000 (92.1875) lr 2.2949e-04 eta 0:01:42
epoch [158/200] batch [3/3] time 0.805 (0.807) data 0.093 (0.096) loss 0.2864 (0.3142) acc 93.7500 (92.7083) lr 2.1957e-04 eta 0:01:41
epoch [159/200] batch [1/3] time 0.810 (0.810) data 0.099 (0.099) loss 0.1534 (0.1534) acc 93.7500 (93.7500) lr 2.1957e-04 eta 0:01:41
epoch [159/200] batch [2/3] time 0.805 (0.807) data 0.093 (0.096) loss 0.2598 (0.2066) acc 96.8750 (95.3125) lr 2.1957e-04 eta 0:01:40
epoch [159/200] batch [3/3] time 0.806 (0.807) data 0.095 (0.096) loss 0.3162 (0.2431) acc 90.6250 (93.7500) lr 2.0984e-04 eta 0:01:39
epoch [160/200] batch [1/3] time 0.822 (0.822) data 0.111 (0.111) loss 0.5557 (0.5557) acc 84.3750 (84.3750) lr 2.0984e-04 eta 0:01:40
epoch [160/200] batch [2/3] time 0.806 (0.814) data 0.094 (0.103) loss 0.2010 (0.3784) acc 96.8750 (90.6250) lr 2.0984e-04 eta 0:01:38
epoch [160/200] batch [3/3] time 0.809 (0.812) data 0.098 (0.101) loss 0.5200 (0.4256) acc 90.6250 (90.6250) lr 2.0032e-04 eta 0:01:37
epoch [161/200] batch [1/3] time 0.807 (0.807) data 0.095 (0.095) loss 0.4985 (0.4985) acc 84.3750 (84.3750) lr 2.0032e-04 eta 0:01:36
epoch [161/200] batch [2/3] time 0.810 (0.808) data 0.098 (0.096) loss 0.4402 (0.4694) acc 90.6250 (87.5000) lr 2.0032e-04 eta 0:01:35
epoch [161/200] batch [3/3] time 0.837 (0.818) data 0.125 (0.106) loss 0.2051 (0.3813) acc 96.8750 (90.6250) lr 1.9098e-04 eta 0:01:35
epoch [162/200] batch [1/3] time 0.807 (0.807) data 0.094 (0.094) loss 0.3416 (0.3416) acc 90.6250 (90.6250) lr 1.9098e-04 eta 0:01:33
epoch [162/200] batch [2/3] time 0.803 (0.805) data 0.091 (0.093) loss 0.3438 (0.3427) acc 93.7500 (92.1875) lr 1.9098e-04 eta 0:01:32
epoch [162/200] batch [3/3] time 0.823 (0.811) data 0.111 (0.099) loss 0.3481 (0.3445) acc 87.5000 (90.6250) lr 1.8185e-04 eta 0:01:32
epoch [163/200] batch [1/3] time 0.808 (0.808) data 0.096 (0.096) loss 0.1340 (0.1340) acc 100.0000 (100.0000) lr 1.8185e-04 eta 0:01:31
epoch [163/200] batch [2/3] time 0.807 (0.808) data 0.096 (0.096) loss 0.1516 (0.1428) acc 96.8750 (98.4375) lr 1.8185e-04 eta 0:01:30
epoch [163/200] batch [3/3] time 0.844 (0.820) data 0.132 (0.108) loss 0.2673 (0.1843) acc 93.7500 (96.8750) lr 1.7292e-04 eta 0:01:30
epoch [164/200] batch [1/3] time 0.805 (0.805) data 0.093 (0.093) loss 0.5371 (0.5371) acc 90.6250 (90.6250) lr 1.7292e-04 eta 0:01:28
epoch [164/200] batch [2/3] time 0.876 (0.841) data 0.165 (0.129) loss 0.2068 (0.3719) acc 96.8750 (93.7500) lr 1.7292e-04 eta 0:01:31
epoch [164/200] batch [3/3] time 0.803 (0.828) data 0.090 (0.116) loss 0.2754 (0.3398) acc 96.8750 (94.7917) lr 1.6419e-04 eta 0:01:29
epoch [165/200] batch [1/3] time 0.806 (0.806) data 0.094 (0.094) loss 0.1225 (0.1225) acc 96.8750 (96.8750) lr 1.6419e-04 eta 0:01:26
epoch [165/200] batch [2/3] time 0.805 (0.805) data 0.092 (0.093) loss 0.0638 (0.0932) acc 96.8750 (96.8750) lr 1.6419e-04 eta 0:01:25
epoch [165/200] batch [3/3] time 0.804 (0.805) data 0.093 (0.093) loss 0.1448 (0.1104) acc 96.8750 (96.8750) lr 1.5567e-04 eta 0:01:24
epoch [166/200] batch [1/3] time 0.805 (0.805) data 0.093 (0.093) loss 0.1510 (0.1510) acc 93.7500 (93.7500) lr 1.5567e-04 eta 0:01:23
epoch [166/200] batch [2/3] time 0.816 (0.810) data 0.104 (0.099) loss 0.4094 (0.2802) acc 90.6250 (92.1875) lr 1.5567e-04 eta 0:01:23
epoch [166/200] batch [3/3] time 0.805 (0.809) data 0.094 (0.097) loss 0.0497 (0.2034) acc 100.0000 (94.7917) lr 1.4736e-04 eta 0:01:22
epoch [167/200] batch [1/3] time 0.805 (0.805) data 0.094 (0.094) loss 0.0826 (0.0826) acc 100.0000 (100.0000) lr 1.4736e-04 eta 0:01:21
epoch [167/200] batch [2/3] time 0.802 (0.804) data 0.090 (0.092) loss 0.0486 (0.0656) acc 100.0000 (100.0000) lr 1.4736e-04 eta 0:01:20
epoch [167/200] batch [3/3] time 0.812 (0.806) data 0.100 (0.095) loss 0.3718 (0.1677) acc 90.6250 (96.8750) lr 1.3926e-04 eta 0:01:19
epoch [168/200] batch [1/3] time 0.816 (0.816) data 0.105 (0.105) loss 0.1177 (0.1177) acc 96.8750 (96.8750) lr 1.3926e-04 eta 0:01:19
epoch [168/200] batch [2/3] time 0.805 (0.811) data 0.093 (0.099) loss 0.3330 (0.2254) acc 87.5000 (92.1875) lr 1.3926e-04 eta 0:01:18
epoch [168/200] batch [3/3] time 0.806 (0.809) data 0.095 (0.097) loss 0.3645 (0.2717) acc 93.7500 (92.7083) lr 1.3137e-04 eta 0:01:17
epoch [169/200] batch [1/3] time 0.804 (0.804) data 0.092 (0.092) loss 0.1731 (0.1731) acc 96.8750 (96.8750) lr 1.3137e-04 eta 0:01:16
epoch [169/200] batch [2/3] time 0.808 (0.806) data 0.096 (0.094) loss 0.0657 (0.1194) acc 100.0000 (98.4375) lr 1.3137e-04 eta 0:01:15
epoch [169/200] batch [3/3] time 0.806 (0.806) data 0.094 (0.094) loss 0.1963 (0.1450) acc 96.8750 (97.9167) lr 1.2369e-04 eta 0:01:14
epoch [170/200] batch [1/3] time 0.804 (0.804) data 0.092 (0.092) loss 0.4016 (0.4016) acc 87.5000 (87.5000) lr 1.2369e-04 eta 0:01:14
epoch [170/200] batch [2/3] time 0.817 (0.811) data 0.105 (0.098) loss 0.1937 (0.2977) acc 96.8750 (92.1875) lr 1.2369e-04 eta 0:01:13
epoch [170/200] batch [3/3] time 0.809 (0.810) data 0.097 (0.098) loss 0.3271 (0.3075) acc 93.7500 (92.7083) lr 1.1623e-04 eta 0:01:12
epoch [171/200] batch [1/3] time 0.807 (0.807) data 0.094 (0.094) loss 0.3350 (0.3350) acc 96.8750 (96.8750) lr 1.1623e-04 eta 0:01:11
epoch [171/200] batch [2/3] time 0.821 (0.814) data 0.109 (0.102) loss 0.3171 (0.3260) acc 93.7500 (95.3125) lr 1.1623e-04 eta 0:01:11
epoch [171/200] batch [3/3] time 0.807 (0.812) data 0.096 (0.100) loss 0.4224 (0.3582) acc 87.5000 (92.7083) lr 1.0899e-04 eta 0:01:10
epoch [172/200] batch [1/3] time 0.841 (0.841) data 0.130 (0.130) loss 0.2861 (0.2861) acc 90.6250 (90.6250) lr 1.0899e-04 eta 0:01:12
epoch [172/200] batch [2/3] time 0.803 (0.822) data 0.090 (0.110) loss 0.4885 (0.3873) acc 84.3750 (87.5000) lr 1.0899e-04 eta 0:01:09
epoch [172/200] batch [3/3] time 0.820 (0.821) data 0.108 (0.109) loss 0.2896 (0.3547) acc 93.7500 (89.5833) lr 1.0197e-04 eta 0:01:08
epoch [173/200] batch [1/3] time 0.809 (0.809) data 0.097 (0.097) loss 0.3254 (0.3254) acc 90.6250 (90.6250) lr 1.0197e-04 eta 0:01:07
epoch [173/200] batch [2/3] time 0.808 (0.809) data 0.096 (0.096) loss 0.1603 (0.2429) acc 96.8750 (93.7500) lr 1.0197e-04 eta 0:01:06
epoch [173/200] batch [3/3] time 0.809 (0.809) data 0.097 (0.096) loss 0.1978 (0.2278) acc 96.8750 (94.7917) lr 9.5173e-05 eta 0:01:05
epoch [174/200] batch [1/3] time 0.813 (0.813) data 0.101 (0.101) loss 0.4968 (0.4968) acc 87.5000 (87.5000) lr 9.5173e-05 eta 0:01:05
epoch [174/200] batch [2/3] time 0.808 (0.811) data 0.097 (0.099) loss 0.1017 (0.2993) acc 100.0000 (93.7500) lr 9.5173e-05 eta 0:01:04
epoch [174/200] batch [3/3] time 0.819 (0.814) data 0.090 (0.096) loss 0.2534 (0.2840) acc 93.7500 (93.7500) lr 8.8597e-05 eta 0:01:03
epoch [175/200] batch [1/3] time 0.830 (0.830) data 0.100 (0.100) loss 0.3162 (0.3162) acc 90.6250 (90.6250) lr 8.8597e-05 eta 0:01:03
epoch [175/200] batch [2/3] time 0.888 (0.859) data 0.152 (0.126) loss 0.1805 (0.2484) acc 93.7500 (92.1875) lr 8.8597e-05 eta 0:01:05
epoch [175/200] batch [3/3] time 0.814 (0.844) data 0.092 (0.115) loss 0.3345 (0.2771) acc 93.7500 (92.7083) lr 8.2245e-05 eta 0:01:03
epoch [176/200] batch [1/3] time 0.818 (0.818) data 0.094 (0.094) loss 0.1148 (0.1148) acc 100.0000 (100.0000) lr 8.2245e-05 eta 0:01:00
epoch [176/200] batch [2/3] time 0.827 (0.823) data 0.110 (0.102) loss 0.3838 (0.2493) acc 87.5000 (93.7500) lr 8.2245e-05 eta 0:01:00
epoch [176/200] batch [3/3] time 0.831 (0.826) data 0.110 (0.105) loss 0.2839 (0.2608) acc 90.6250 (92.7083) lr 7.6120e-05 eta 0:00:59
epoch [177/200] batch [1/3] time 0.886 (0.886) data 0.159 (0.159) loss 0.3723 (0.3723) acc 87.5000 (87.5000) lr 7.6120e-05 eta 0:01:02
epoch [177/200] batch [2/3] time 0.819 (0.852) data 0.102 (0.130) loss 0.3647 (0.3685) acc 93.7500 (90.6250) lr 7.6120e-05 eta 0:00:59
epoch [177/200] batch [3/3] time 0.826 (0.844) data 0.096 (0.119) loss 0.1469 (0.2946) acc 96.8750 (92.7083) lr 7.0224e-05 eta 0:00:58
epoch [178/200] batch [1/3] time 0.829 (0.829) data 0.097 (0.097) loss 0.1136 (0.1136) acc 96.8750 (96.8750) lr 7.0224e-05 eta 0:00:56
epoch [178/200] batch [2/3] time 0.811 (0.820) data 0.090 (0.094) loss 0.5112 (0.3124) acc 93.7500 (95.3125) lr 7.0224e-05 eta 0:00:54
epoch [178/200] batch [3/3] time 0.839 (0.826) data 0.108 (0.098) loss 0.2830 (0.3026) acc 93.7500 (94.7917) lr 6.4556e-05 eta 0:00:54
epoch [179/200] batch [1/3] time 0.814 (0.814) data 0.097 (0.097) loss 0.2484 (0.2484) acc 93.7500 (93.7500) lr 6.4556e-05 eta 0:00:52
epoch [179/200] batch [2/3] time 0.835 (0.824) data 0.121 (0.109) loss 0.1780 (0.2132) acc 93.7500 (93.7500) lr 6.4556e-05 eta 0:00:52
epoch [179/200] batch [3/3] time 0.957 (0.868) data 0.244 (0.154) loss 0.6353 (0.3539) acc 87.5000 (91.6667) lr 5.9119e-05 eta 0:00:54
epoch [180/200] batch [1/3] time 0.828 (0.828) data 0.112 (0.112) loss 0.2712 (0.2712) acc 87.5000 (87.5000) lr 5.9119e-05 eta 0:00:51
epoch [180/200] batch [2/3] time 0.809 (0.819) data 0.093 (0.102) loss 0.2979 (0.2845) acc 96.8750 (92.1875) lr 5.9119e-05 eta 0:00:49
epoch [180/200] batch [3/3] time 0.857 (0.831) data 0.145 (0.116) loss 0.1027 (0.2239) acc 100.0000 (94.7917) lr 5.3915e-05 eta 0:00:49
epoch [181/200] batch [1/3] time 0.836 (0.836) data 0.100 (0.100) loss 0.3552 (0.3552) acc 90.6250 (90.6250) lr 5.3915e-05 eta 0:00:49
epoch [181/200] batch [2/3] time 0.813 (0.824) data 0.097 (0.098) loss 0.1343 (0.2448) acc 96.8750 (93.7500) lr 5.3915e-05 eta 0:00:47
epoch [181/200] batch [3/3] time 0.811 (0.820) data 0.099 (0.098) loss 0.2446 (0.2447) acc 87.5000 (91.6667) lr 4.8943e-05 eta 0:00:46
epoch [182/200] batch [1/3] time 0.812 (0.812) data 0.095 (0.095) loss 0.4468 (0.4468) acc 90.6250 (90.6250) lr 4.8943e-05 eta 0:00:45
epoch [182/200] batch [2/3] time 0.816 (0.814) data 0.100 (0.097) loss 0.2959 (0.3713) acc 93.7500 (92.1875) lr 4.8943e-05 eta 0:00:44
epoch [182/200] batch [3/3] time 0.818 (0.815) data 0.093 (0.096) loss 0.5566 (0.4331) acc 87.5000 (90.6250) lr 4.4207e-05 eta 0:00:44
epoch [183/200] batch [1/3] time 0.833 (0.833) data 0.099 (0.099) loss 0.5059 (0.5059) acc 90.6250 (90.6250) lr 4.4207e-05 eta 0:00:44
epoch [183/200] batch [2/3] time 0.823 (0.828) data 0.091 (0.095) loss 0.1530 (0.3294) acc 93.7500 (92.1875) lr 4.4207e-05 eta 0:00:43
epoch [183/200] batch [3/3] time 0.850 (0.835) data 0.113 (0.101) loss 0.5410 (0.3999) acc 90.6250 (91.6667) lr 3.9706e-05 eta 0:00:42
epoch [184/200] batch [1/3] time 0.832 (0.832) data 0.111 (0.111) loss 0.2427 (0.2427) acc 93.7500 (93.7500) lr 3.9706e-05 eta 0:00:41
epoch [184/200] batch [2/3] time 0.807 (0.820) data 0.091 (0.101) loss 0.3311 (0.2869) acc 93.7500 (93.7500) lr 3.9706e-05 eta 0:00:40
epoch [184/200] batch [3/3] time 0.805 (0.815) data 0.092 (0.098) loss 0.1708 (0.2482) acc 96.8750 (94.7917) lr 3.5443e-05 eta 0:00:39
epoch [185/200] batch [1/3] time 0.839 (0.839) data 0.104 (0.104) loss 0.1456 (0.1456) acc 96.8750 (96.8750) lr 3.5443e-05 eta 0:00:39
epoch [185/200] batch [2/3] time 0.833 (0.836) data 0.093 (0.099) loss 0.1770 (0.1613) acc 96.8750 (96.8750) lr 3.5443e-05 eta 0:00:38
epoch [185/200] batch [3/3] time 0.828 (0.834) data 0.097 (0.098) loss 0.4314 (0.2513) acc 90.6250 (94.7917) lr 3.1417e-05 eta 0:00:37
epoch [186/200] batch [1/3] time 0.832 (0.832) data 0.096 (0.096) loss 0.2812 (0.2812) acc 93.7500 (93.7500) lr 3.1417e-05 eta 0:00:36
epoch [186/200] batch [2/3] time 0.840 (0.836) data 0.108 (0.102) loss 0.3179 (0.2996) acc 93.7500 (93.7500) lr 3.1417e-05 eta 0:00:35
epoch [186/200] batch [3/3] time 0.815 (0.829) data 0.089 (0.097) loss 0.2854 (0.2948) acc 90.6250 (92.7083) lr 2.7630e-05 eta 0:00:34
epoch [187/200] batch [1/3] time 0.828 (0.828) data 0.096 (0.096) loss 0.5059 (0.5059) acc 84.3750 (84.3750) lr 2.7630e-05 eta 0:00:33
epoch [187/200] batch [2/3] time 0.814 (0.821) data 0.097 (0.097) loss 0.3110 (0.4084) acc 90.6250 (87.5000) lr 2.7630e-05 eta 0:00:32
epoch [187/200] batch [3/3] time 0.842 (0.828) data 0.120 (0.104) loss 0.7422 (0.5197) acc 81.2500 (85.4167) lr 2.4083e-05 eta 0:00:32
epoch [188/200] batch [1/3] time 0.845 (0.845) data 0.132 (0.132) loss 0.2844 (0.2844) acc 93.7500 (93.7500) lr 2.4083e-05 eta 0:00:32
epoch [188/200] batch [2/3] time 0.814 (0.830) data 0.098 (0.115) loss 0.2134 (0.2489) acc 93.7500 (93.7500) lr 2.4083e-05 eta 0:00:30
epoch [188/200] batch [3/3] time 0.808 (0.822) data 0.091 (0.107) loss 0.2063 (0.2347) acc 93.7500 (93.7500) lr 2.0777e-05 eta 0:00:29
epoch [189/200] batch [1/3] time 0.809 (0.809) data 0.097 (0.097) loss 0.2433 (0.2433) acc 96.8750 (96.8750) lr 2.0777e-05 eta 0:00:28
epoch [189/200] batch [2/3] time 0.809 (0.809) data 0.092 (0.094) loss 0.2335 (0.2384) acc 96.8750 (96.8750) lr 2.0777e-05 eta 0:00:27
epoch [189/200] batch [3/3] time 0.819 (0.812) data 0.103 (0.097) loss 0.1249 (0.2006) acc 96.8750 (96.8750) lr 1.7713e-05 eta 0:00:26
epoch [190/200] batch [1/3] time 0.800 (0.800) data 0.089 (0.089) loss 0.4514 (0.4514) acc 90.6250 (90.6250) lr 1.7713e-05 eta 0:00:25
epoch [190/200] batch [2/3] time 0.809 (0.804) data 0.092 (0.090) loss 0.1478 (0.2996) acc 96.8750 (93.7500) lr 1.7713e-05 eta 0:00:24
epoch [190/200] batch [3/3] time 0.862 (0.824) data 0.092 (0.091) loss 0.3074 (0.3022) acc 90.6250 (92.7083) lr 1.4891e-05 eta 0:00:24
epoch [191/200] batch [1/3] time 0.863 (0.863) data 0.124 (0.124) loss 0.3374 (0.3374) acc 93.7500 (93.7500) lr 1.4891e-05 eta 0:00:25
epoch [191/200] batch [2/3] time 1.288 (1.075) data 0.255 (0.189) loss 0.1099 (0.2236) acc 96.8750 (95.3125) lr 1.4891e-05 eta 0:00:30
epoch [191/200] batch [3/3] time 0.984 (1.045) data 0.227 (0.202) loss 0.1863 (0.2112) acc 96.8750 (95.8333) lr 1.2312e-05 eta 0:00:28
epoch [192/200] batch [1/3] time 0.858 (0.858) data 0.133 (0.133) loss 0.5513 (0.5513) acc 87.5000 (87.5000) lr 1.2312e-05 eta 0:00:22
epoch [192/200] batch [2/3] time 0.832 (0.845) data 0.104 (0.119) loss 0.2861 (0.4187) acc 93.7500 (90.6250) lr 1.2312e-05 eta 0:00:21
epoch [192/200] batch [3/3] time 0.846 (0.845) data 0.116 (0.118) loss 0.0202 (0.2859) acc 100.0000 (93.7500) lr 9.9763e-06 eta 0:00:20
epoch [193/200] batch [1/3] time 1.006 (1.006) data 0.195 (0.195) loss 0.7520 (0.7520) acc 84.3750 (84.3750) lr 9.9763e-06 eta 0:00:23
epoch [193/200] batch [2/3] time 0.974 (0.990) data 0.124 (0.159) loss 0.4124 (0.5822) acc 90.6250 (87.5000) lr 9.9763e-06 eta 0:00:21
epoch [193/200] batch [3/3] time 1.112 (1.031) data 0.294 (0.204) loss 0.1530 (0.4391) acc 93.7500 (89.5833) lr 7.8853e-06 eta 0:00:21
epoch [194/200] batch [1/3] time 0.980 (0.980) data 0.126 (0.126) loss 0.1147 (0.1147) acc 96.8750 (96.8750) lr 7.8853e-06 eta 0:00:19
epoch [194/200] batch [2/3] time 1.057 (1.019) data 0.124 (0.125) loss 0.1492 (0.1320) acc 96.8750 (96.8750) lr 7.8853e-06 eta 0:00:19
epoch [194/200] batch [3/3] time 0.938 (0.992) data 0.101 (0.117) loss 0.2104 (0.1581) acc 93.7500 (95.8333) lr 6.0390e-06 eta 0:00:17
epoch [195/200] batch [1/3] time 1.048 (1.048) data 0.143 (0.143) loss 0.0952 (0.0952) acc 96.8750 (96.8750) lr 6.0390e-06 eta 0:00:17
epoch [195/200] batch [2/3] time 0.841 (0.945) data 0.095 (0.119) loss 0.3884 (0.2418) acc 87.5000 (92.1875) lr 6.0390e-06 eta 0:00:15
epoch [195/200] batch [3/3] time 1.011 (0.967) data 0.091 (0.110) loss 0.2776 (0.2537) acc 96.8750 (93.7500) lr 4.4380e-06 eta 0:00:14
epoch [196/200] batch [1/3] time 0.825 (0.825) data 0.088 (0.088) loss 0.5659 (0.5659) acc 87.5000 (87.5000) lr 4.4380e-06 eta 0:00:11
epoch [196/200] batch [2/3] time 0.832 (0.829) data 0.104 (0.096) loss 0.1444 (0.3552) acc 96.8750 (92.1875) lr 4.4380e-06 eta 0:00:10
epoch [196/200] batch [3/3] time 0.817 (0.825) data 0.093 (0.095) loss 0.2583 (0.3229) acc 93.7500 (92.7083) lr 3.0827e-06 eta 0:00:09
epoch [197/200] batch [1/3] time 0.850 (0.850) data 0.108 (0.108) loss 0.4739 (0.4739) acc 90.6250 (90.6250) lr 3.0827e-06 eta 0:00:09
epoch [197/200] batch [2/3] time 1.017 (0.933) data 0.106 (0.107) loss 0.1425 (0.3082) acc 96.8750 (93.7500) lr 3.0827e-06 eta 0:00:09
epoch [197/200] batch [3/3] time 0.861 (0.909) data 0.123 (0.112) loss 0.1356 (0.2507) acc 96.8750 (94.7917) lr 1.9733e-06 eta 0:00:08
epoch [198/200] batch [1/3] time 0.829 (0.829) data 0.102 (0.102) loss 0.1057 (0.1057) acc 96.8750 (96.8750) lr 1.9733e-06 eta 0:00:06
epoch [198/200] batch [2/3] time 1.008 (0.918) data 0.097 (0.099) loss 0.1246 (0.1151) acc 93.7500 (95.3125) lr 1.9733e-06 eta 0:00:06
epoch [198/200] batch [3/3] time 0.834 (0.890) data 0.098 (0.099) loss 0.3132 (0.1812) acc 87.5000 (92.7083) lr 1.1101e-06 eta 0:00:05
epoch [199/200] batch [1/3] time 0.829 (0.829) data 0.094 (0.094) loss 0.0288 (0.0288) acc 100.0000 (100.0000) lr 1.1101e-06 eta 0:00:04
epoch [199/200] batch [2/3] time 0.812 (0.820) data 0.099 (0.097) loss 0.5469 (0.2878) acc 87.5000 (93.7500) lr 1.1101e-06 eta 0:00:03
epoch [199/200] batch [3/3] time 0.815 (0.819) data 0.099 (0.097) loss 0.0637 (0.2131) acc 96.8750 (94.7917) lr 4.9344e-07 eta 0:00:02
epoch [200/200] batch [1/3] time 0.939 (0.939) data 0.216 (0.216) loss 0.2395 (0.2395) acc 93.7500 (93.7500) lr 4.9344e-07 eta 0:00:01
epoch [200/200] batch [2/3] time 0.808 (0.874) data 0.091 (0.154) loss 0.2194 (0.2294) acc 96.8750 (95.3125) lr 4.9344e-07 eta 0:00:00
epoch [200/200] batch [3/3] time 0.810 (0.852) data 0.098 (0.135) loss 0.1973 (0.2187) acc 96.8750 (95.8333) lr 1.2337e-07 eta 0:00:00
Checkpoint saved to output/Caltech/1/2/prompt_learner/model.pth.tar-200
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
=> result
* total: 2,465
* correct: 2,129
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 82.8%
Elapsed: 0:09:21
args2: backbone=, config_file=configs/trainers/CoOp/vit_b32.yaml, dataset_config_file=configs/datasets/caltech101.yaml, eval_only=False, head=, load_epoch=None, model_dir=, no_train=False,  opts: ['TRAINER.COOP.N_CTX', '16', 'TRAINER.COOP.CSC', 'False', 'TRAINER.COOP.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '1'], output_dir=output/Caltech/1/2/3, resume=, root=/home/brandnerkasper/Uni/MP/MP_CustomCoOp/data, seed=3, source_domains=None, target_domains=None, trainer=CoOp, transforms=None
Setting fixed seed: 3
***************
** Arguments **
***************
config_file: configs/trainers/CoOp/vit_b32.yaml
csc: False
ctp: end
dataset_config_file: configs/datasets/caltech101.yaml
n_ctx: 16
opts: ['TRAINER.COOP.N_CTX', '16', 'TRAINER.COOP.CSC', 'False', 'TRAINER.COOP.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '1']
output_dir: output/Caltech/1/2/3
root: /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data
seed: 3
shots: 1
trainer: CoOp
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 0
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 1
  ROOT: /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/32
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/Caltech/1/2/3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 2.0.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 22.04.3 LTS (x86_64)
GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.35

Python version: 3.10.12 (main, Jul  5 2023, 18:54:27) [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-6.2.0-32-generic-x86_64-with-glibc2.35
Is CUDA available: True
CUDA runtime version: 11.5.119
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce GTX 970
Nvidia driver version: 525.125.06
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                       x86_64
CPU op-mode(s):                     32-bit, 64-bit
Address sizes:                      39 bits physical, 48 bits virtual
Byte Order:                         Little Endian
CPU(s):                             4
On-line CPU(s) list:                0-3
Vendor ID:                          GenuineIntel
Model name:                         Intel(R) Xeon(R) CPU E3-1225 v3 @ 3.20GHz
CPU family:                         6
Model:                              60
Thread(s) per core:                 1
Core(s) per socket:                 4
Socket(s):                          1
Stepping:                           3
CPU max MHz:                        3600,0000
CPU min MHz:                        800,0000
BogoMIPS:                           6397.79
Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt dtherm ida arat pln pts md_clear flush_l1d
Virtualization:                     VT-x
L1d cache:                          128 KiB (4 instances)
L1i cache:                          128 KiB (4 instances)
L2 cache:                           1 MiB (4 instances)
L3 cache:                           8 MiB (1 instance)
NUMA node(s):                       1
NUMA node0 CPU(s):                  0-3
Vulnerability Gather data sampling: Not affected
Vulnerability Itlb multihit:        KVM: Mitigation: VMX disabled
Vulnerability L1tf:                 Mitigation; PTE Inversion; VMX conditional cache flushes, SMT disabled
Vulnerability Mds:                  Mitigation; Clear CPU buffers; SMT disabled
Vulnerability Meltdown:             Mitigation; PTI
Vulnerability Mmio stale data:      Unknown: No mitigations
Vulnerability Retbleed:             Not affected
Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl
Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:           Mitigation; Retpolines, IBPB conditional, IBRS_FW, STIBP disabled, RSB filling, PBRSB-eIBRS Not affected
Vulnerability Srbds:                Mitigation; Microcode
Vulnerability Tsx async abort:      Not affected

Versions of relevant libraries:
[pip3] numpy==1.25.2
[pip3] open-clip-torch==2.20.0
[pip3] torch==2.0.1
[pip3] torchaudio==2.0.2
[pip3] torchvision==0.15.2
[conda] blas                      1.0                         mkl  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] mkl                       2023.1.0         h213fc3f_46343  
[conda] mkl-service               2.4.0           py310h5eee18b_1  
[conda] mkl_fft                   1.3.6           py310h1128e8f_1  
[conda] mkl_random                1.2.2           py310h1128e8f_1  
[conda] numpy                     1.25.2          py310h5f9d8c6_0  
[conda] numpy-base                1.25.2          py310hb5e798b_0  
[conda] open-clip-torch           2.20.0                   pypi_0    pypi
[conda] pytorch                   2.0.1           py3.10_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchaudio                2.0.2               py310_cu117    pytorch
[conda] torchtriton               2.0.0                     py310    pytorch
[conda] torchvision               0.15.2              py310_cu117    pytorch
        Pillow (9.4.0)

Loading trainer: CoOp
Loading dataset: Caltech101
Reading split from /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data/caltech-101/split_zhou_Caltech101.json
Creating a 1-shot dataset
Creating a 1-shot dataset
Saving preprocessed few-shot data to /home/brandnerkasper/Uni/MP/MP_CustomCoOp/data/caltech-101/split_fewshot/shot_1-seed_3.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  100
# train_x  100
# val      100
# test     2,465
---------  ----------
Loading CLIP (backbone: ViT-B/32)
CLIP(
  (visual): VisionTransformer(
    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (transformer): Transformer(
    (resblocks): Sequential(
      (0): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (6): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (7): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (8): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (9): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (10): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (11): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (token_embedding): Embedding(49408, 512)
  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
)
Building custom CLIP
Initializing a generic context
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Turning off gradients in both the image and the text encoder
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/Caltech/1/2/3/tensorboard)
epoch [1/200] batch [1/3] time 0.963 (0.963) data 0.170 (0.170) loss 2.1953 (2.1953) acc 65.6250 (65.6250) lr 1.0000e-05 eta 0:09:36
epoch [1/200] batch [2/3] time 0.851 (0.907) data 0.108 (0.139) loss 1.7373 (1.9663) acc 75.0000 (70.3125) lr 1.0000e-05 eta 0:09:02
epoch [1/200] batch [3/3] time 0.882 (0.898) data 0.131 (0.137) loss 1.7812 (1.9046) acc 71.8750 (70.8333) lr 2.0000e-03 eta 0:08:56
epoch [2/200] batch [1/3] time 0.921 (0.921) data 0.151 (0.151) loss 2.2656 (2.2656) acc 65.6250 (65.6250) lr 2.0000e-03 eta 0:09:08
epoch [2/200] batch [2/3] time 0.838 (0.879) data 0.098 (0.124) loss 1.1367 (1.7012) acc 71.8750 (68.7500) lr 2.0000e-03 eta 0:08:43
epoch [2/200] batch [3/3] time 0.845 (0.868) data 0.103 (0.117) loss 1.0664 (1.4896) acc 68.7500 (68.7500) lr 1.9999e-03 eta 0:08:35
epoch [3/200] batch [1/3] time 0.829 (0.829) data 0.092 (0.092) loss 0.6211 (0.6211) acc 84.3750 (84.3750) lr 1.9999e-03 eta 0:08:11
epoch [3/200] batch [2/3] time 0.952 (0.890) data 0.101 (0.097) loss 0.7163 (0.6687) acc 78.1250 (81.2500) lr 1.9999e-03 eta 0:08:46
epoch [3/200] batch [3/3] time 1.015 (0.932) data 0.119 (0.104) loss 1.2295 (0.8556) acc 75.0000 (79.1667) lr 1.9995e-03 eta 0:09:10
epoch [4/200] batch [1/3] time 0.971 (0.971) data 0.098 (0.098) loss 0.6138 (0.6138) acc 78.1250 (78.1250) lr 1.9995e-03 eta 0:09:32
epoch [4/200] batch [2/3] time 0.980 (0.976) data 0.093 (0.095) loss 1.0107 (0.8123) acc 75.0000 (76.5625) lr 1.9995e-03 eta 0:09:34
epoch [4/200] batch [3/3] time 1.276 (1.076) data 0.132 (0.108) loss 0.5566 (0.7271) acc 75.0000 (76.0417) lr 1.9989e-03 eta 0:10:32
epoch [5/200] batch [1/3] time 0.835 (0.835) data 0.097 (0.097) loss 0.8271 (0.8271) acc 84.3750 (84.3750) lr 1.9989e-03 eta 0:08:10
epoch [5/200] batch [2/3] time 0.840 (0.838) data 0.099 (0.098) loss 0.8110 (0.8191) acc 81.2500 (82.8125) lr 1.9989e-03 eta 0:08:10
epoch [5/200] batch [3/3] time 1.089 (0.921) data 0.135 (0.111) loss 0.5645 (0.7342) acc 81.2500 (82.2917) lr 1.9980e-03 eta 0:08:58
epoch [6/200] batch [1/3] time 0.834 (0.834) data 0.095 (0.095) loss 0.4834 (0.4834) acc 81.2500 (81.2500) lr 1.9980e-03 eta 0:08:07
epoch [6/200] batch [2/3] time 0.835 (0.835) data 0.096 (0.095) loss 0.7617 (0.6226) acc 78.1250 (79.6875) lr 1.9980e-03 eta 0:08:06
epoch [6/200] batch [3/3] time 0.863 (0.844) data 0.101 (0.097) loss 1.1670 (0.8040) acc 71.8750 (77.0833) lr 1.9969e-03 eta 0:08:11
epoch [7/200] batch [1/3] time 0.851 (0.851) data 0.102 (0.102) loss 0.5278 (0.5278) acc 84.3750 (84.3750) lr 1.9969e-03 eta 0:08:14
epoch [7/200] batch [2/3] time 0.834 (0.842) data 0.095 (0.099) loss 0.8154 (0.6716) acc 78.1250 (81.2500) lr 1.9969e-03 eta 0:08:08
epoch [7/200] batch [3/3] time 0.856 (0.847) data 0.102 (0.100) loss 0.5854 (0.6429) acc 81.2500 (81.2500) lr 1.9956e-03 eta 0:08:10
epoch [8/200] batch [1/3] time 1.243 (1.243) data 0.114 (0.114) loss 0.5479 (0.5479) acc 84.3750 (84.3750) lr 1.9956e-03 eta 0:11:58
epoch [8/200] batch [2/3] time 0.919 (1.081) data 0.167 (0.140) loss 0.8145 (0.6812) acc 84.3750 (84.3750) lr 1.9956e-03 eta 0:10:23
epoch [8/200] batch [3/3] time 0.949 (1.037) data 0.186 (0.156) loss 0.6108 (0.6577) acc 81.2500 (83.3333) lr 1.9940e-03 eta 0:09:57
epoch [9/200] batch [1/3] time 0.903 (0.903) data 0.150 (0.150) loss 0.4761 (0.4761) acc 90.6250 (90.6250) lr 1.9940e-03 eta 0:08:39
epoch [9/200] batch [2/3] time 0.978 (0.941) data 0.129 (0.139) loss 0.4441 (0.4601) acc 90.6250 (90.6250) lr 1.9940e-03 eta 0:08:59
epoch [9/200] batch [3/3] time 1.138 (1.006) data 0.121 (0.133) loss 0.6436 (0.5212) acc 78.1250 (86.4583) lr 1.9921e-03 eta 0:09:36
epoch [10/200] batch [1/3] time 1.282 (1.282) data 0.100 (0.100) loss 0.5884 (0.5884) acc 87.5000 (87.5000) lr 1.9921e-03 eta 0:12:13
epoch [10/200] batch [2/3] time 1.008 (1.145) data 0.129 (0.115) loss 0.5435 (0.5659) acc 81.2500 (84.3750) lr 1.9921e-03 eta 0:10:53
epoch [10/200] batch [3/3] time 0.911 (1.067) data 0.134 (0.121) loss 0.6660 (0.5993) acc 84.3750 (84.3750) lr 1.9900e-03 eta 0:10:08
epoch [11/200] batch [1/3] time 0.852 (0.852) data 0.098 (0.098) loss 0.6333 (0.6333) acc 81.2500 (81.2500) lr 1.9900e-03 eta 0:08:04
epoch [11/200] batch [2/3] time 0.842 (0.847) data 0.104 (0.101) loss 0.4236 (0.5284) acc 90.6250 (85.9375) lr 1.9900e-03 eta 0:08:01
epoch [11/200] batch [3/3] time 0.854 (0.849) data 0.104 (0.102) loss 0.4399 (0.4989) acc 87.5000 (86.4583) lr 1.9877e-03 eta 0:08:01
epoch [12/200] batch [1/3] time 0.870 (0.870) data 0.115 (0.115) loss 0.8994 (0.8994) acc 75.0000 (75.0000) lr 1.9877e-03 eta 0:08:12
epoch [12/200] batch [2/3] time 0.860 (0.865) data 0.094 (0.104) loss 0.4963 (0.6979) acc 78.1250 (76.5625) lr 1.9877e-03 eta 0:08:08
epoch [12/200] batch [3/3] time 0.858 (0.862) data 0.095 (0.101) loss 0.2025 (0.5328) acc 93.7500 (82.2917) lr 1.9851e-03 eta 0:08:06
epoch [13/200] batch [1/3] time 0.858 (0.858) data 0.097 (0.097) loss 0.7153 (0.7153) acc 78.1250 (78.1250) lr 1.9851e-03 eta 0:08:02
epoch [13/200] batch [2/3] time 0.927 (0.892) data 0.175 (0.136) loss 0.5342 (0.6248) acc 84.3750 (81.2500) lr 1.9851e-03 eta 0:08:21
epoch [13/200] batch [3/3] time 0.848 (0.877) data 0.102 (0.125) loss 0.1982 (0.4826) acc 96.8750 (86.4583) lr 1.9823e-03 eta 0:08:12
epoch [14/200] batch [1/3] time 0.839 (0.839) data 0.094 (0.094) loss 0.3237 (0.3237) acc 96.8750 (96.8750) lr 1.9823e-03 eta 0:07:49
epoch [14/200] batch [2/3] time 0.870 (0.854) data 0.115 (0.105) loss 0.6426 (0.4832) acc 81.2500 (89.0625) lr 1.9823e-03 eta 0:07:57
epoch [14/200] batch [3/3] time 0.916 (0.875) data 0.155 (0.121) loss 0.5376 (0.5013) acc 81.2500 (86.4583) lr 1.9792e-03 eta 0:08:08
epoch [15/200] batch [1/3] time 1.299 (1.299) data 0.093 (0.093) loss 0.6553 (0.6553) acc 84.3750 (84.3750) lr 1.9792e-03 eta 0:12:03
epoch [15/200] batch [2/3] time 0.973 (1.136) data 0.189 (0.141) loss 0.6924 (0.6738) acc 81.2500 (82.8125) lr 1.9792e-03 eta 0:10:31
epoch [15/200] batch [3/3] time 0.881 (1.051) data 0.114 (0.132) loss 0.2290 (0.5256) acc 93.7500 (86.4583) lr 1.9759e-03 eta 0:09:43
epoch [16/200] batch [1/3] time 0.876 (0.876) data 0.118 (0.118) loss 0.8394 (0.8394) acc 81.2500 (81.2500) lr 1.9759e-03 eta 0:08:05
epoch [16/200] batch [2/3] time 0.850 (0.863) data 0.109 (0.114) loss 0.4197 (0.6295) acc 87.5000 (84.3750) lr 1.9759e-03 eta 0:07:57
epoch [16/200] batch [3/3] time 0.848 (0.858) data 0.107 (0.111) loss 0.9917 (0.7502) acc 75.0000 (81.2500) lr 1.9724e-03 eta 0:07:53
epoch [17/200] batch [1/3] time 0.837 (0.837) data 0.093 (0.093) loss 0.4663 (0.4663) acc 84.3750 (84.3750) lr 1.9724e-03 eta 0:07:41
epoch [17/200] batch [2/3] time 0.840 (0.838) data 0.097 (0.095) loss 0.5947 (0.5305) acc 84.3750 (84.3750) lr 1.9724e-03 eta 0:07:41
epoch [17/200] batch [3/3] time 0.881 (0.853) data 0.142 (0.110) loss 0.5151 (0.5254) acc 84.3750 (84.3750) lr 1.9686e-03 eta 0:07:48
epoch [18/200] batch [1/3] time 0.990 (0.990) data 0.242 (0.242) loss 0.1943 (0.1943) acc 90.6250 (90.6250) lr 1.9686e-03 eta 0:09:02
epoch [18/200] batch [2/3] time 0.863 (0.926) data 0.122 (0.182) loss 0.5400 (0.3672) acc 87.5000 (89.0625) lr 1.9686e-03 eta 0:08:26
epoch [18/200] batch [3/3] time 0.869 (0.907) data 0.117 (0.161) loss 0.5190 (0.4178) acc 81.2500 (86.4583) lr 1.9646e-03 eta 0:08:15
epoch [19/200] batch [1/3] time 0.902 (0.902) data 0.129 (0.129) loss 0.3762 (0.3762) acc 90.6250 (90.6250) lr 1.9646e-03 eta 0:08:11
epoch [19/200] batch [2/3] time 0.869 (0.885) data 0.125 (0.127) loss 0.3293 (0.3528) acc 90.6250 (90.6250) lr 1.9646e-03 eta 0:08:01
epoch [19/200] batch [3/3] time 0.864 (0.878) data 0.121 (0.125) loss 0.5054 (0.4036) acc 78.1250 (86.4583) lr 1.9603e-03 eta 0:07:56
epoch [20/200] batch [1/3] time 0.843 (0.843) data 0.106 (0.106) loss 0.2457 (0.2457) acc 96.8750 (96.8750) lr 1.9603e-03 eta 0:07:36
epoch [20/200] batch [2/3] time 0.863 (0.853) data 0.116 (0.111) loss 0.3438 (0.2947) acc 90.6250 (93.7500) lr 1.9603e-03 eta 0:07:41
epoch [20/200] batch [3/3] time 0.851 (0.852) data 0.107 (0.109) loss 0.1294 (0.2396) acc 96.8750 (94.7917) lr 1.9558e-03 eta 0:07:40
epoch [21/200] batch [1/3] time 0.852 (0.852) data 0.107 (0.107) loss 0.4565 (0.4565) acc 87.5000 (87.5000) lr 1.9558e-03 eta 0:07:38
epoch [21/200] batch [2/3] time 0.948 (0.900) data 0.208 (0.158) loss 0.5015 (0.4790) acc 87.5000 (87.5000) lr 1.9558e-03 eta 0:08:03
epoch [21/200] batch [3/3] time 0.852 (0.884) data 0.108 (0.141) loss 0.6528 (0.5369) acc 81.2500 (85.4167) lr 1.9511e-03 eta 0:07:54
epoch [22/200] batch [1/3] time 0.845 (0.845) data 0.103 (0.103) loss 0.5601 (0.5601) acc 71.8750 (71.8750) lr 1.9511e-03 eta 0:07:32
epoch [22/200] batch [2/3] time 0.843 (0.844) data 0.103 (0.103) loss 0.3364 (0.4482) acc 93.7500 (82.8125) lr 1.9511e-03 eta 0:07:31
epoch [22/200] batch [3/3] time 0.840 (0.842) data 0.099 (0.101) loss 0.2527 (0.3831) acc 96.8750 (87.5000) lr 1.9461e-03 eta 0:07:29
epoch [23/200] batch [1/3] time 0.867 (0.867) data 0.124 (0.124) loss 0.5396 (0.5396) acc 87.5000 (87.5000) lr 1.9461e-03 eta 0:07:42
epoch [23/200] batch [2/3] time 0.839 (0.853) data 0.095 (0.110) loss 0.5288 (0.5342) acc 84.3750 (85.9375) lr 1.9461e-03 eta 0:07:33
epoch [23/200] batch [3/3] time 0.855 (0.854) data 0.102 (0.107) loss 0.5864 (0.5516) acc 81.2500 (84.3750) lr 1.9409e-03 eta 0:07:33
epoch [24/200] batch [1/3] time 0.849 (0.849) data 0.108 (0.108) loss 0.5469 (0.5469) acc 81.2500 (81.2500) lr 1.9409e-03 eta 0:07:29
epoch [24/200] batch [2/3] time 0.839 (0.844) data 0.100 (0.104) loss 0.3677 (0.4573) acc 84.3750 (82.8125) lr 1.9409e-03 eta 0:07:26
epoch [24/200] batch [3/3] time 0.840 (0.843) data 0.100 (0.102) loss 0.8442 (0.5863) acc 81.2500 (82.2917) lr 1.9354e-03 eta 0:07:24
epoch [25/200] batch [1/3] time 0.835 (0.835) data 0.092 (0.092) loss 0.2203 (0.2203) acc 93.7500 (93.7500) lr 1.9354e-03 eta 0:07:19
epoch [25/200] batch [2/3] time 0.837 (0.836) data 0.094 (0.093) loss 0.5142 (0.3672) acc 90.6250 (92.1875) lr 1.9354e-03 eta 0:07:19
epoch [25/200] batch [3/3] time 0.833 (0.835) data 0.094 (0.093) loss 0.4419 (0.3921) acc 93.7500 (92.7083) lr 1.9298e-03 eta 0:07:18
epoch [26/200] batch [1/3] time 0.840 (0.840) data 0.097 (0.097) loss 0.3726 (0.3726) acc 90.6250 (90.6250) lr 1.9298e-03 eta 0:07:20
epoch [26/200] batch [2/3] time 0.841 (0.841) data 0.099 (0.098) loss 0.5981 (0.4854) acc 87.5000 (89.0625) lr 1.9298e-03 eta 0:07:19
epoch [26/200] batch [3/3] time 0.832 (0.838) data 0.091 (0.096) loss 0.9102 (0.6270) acc 78.1250 (85.4167) lr 1.9239e-03 eta 0:07:17
epoch [27/200] batch [1/3] time 0.838 (0.838) data 0.093 (0.093) loss 0.2917 (0.2917) acc 90.6250 (90.6250) lr 1.9239e-03 eta 0:07:16
epoch [27/200] batch [2/3] time 0.877 (0.857) data 0.133 (0.113) loss 0.9697 (0.6307) acc 78.1250 (84.3750) lr 1.9239e-03 eta 0:07:25
epoch [27/200] batch [3/3] time 0.834 (0.850) data 0.095 (0.107) loss 0.8130 (0.6915) acc 78.1250 (82.2917) lr 1.9178e-03 eta 0:07:20
epoch [28/200] batch [1/3] time 0.853 (0.853) data 0.109 (0.109) loss 0.3735 (0.3735) acc 87.5000 (87.5000) lr 1.9178e-03 eta 0:07:21
epoch [28/200] batch [2/3] time 0.848 (0.850) data 0.107 (0.108) loss 0.2448 (0.3091) acc 93.7500 (90.6250) lr 1.9178e-03 eta 0:07:19
epoch [28/200] batch [3/3] time 0.832 (0.844) data 0.092 (0.103) loss 0.5596 (0.3926) acc 84.3750 (88.5417) lr 1.9114e-03 eta 0:07:15
epoch [29/200] batch [1/3] time 0.878 (0.878) data 0.137 (0.137) loss 0.4707 (0.4707) acc 81.2500 (81.2500) lr 1.9114e-03 eta 0:07:32
epoch [29/200] batch [2/3] time 0.840 (0.859) data 0.099 (0.118) loss 0.2620 (0.3663) acc 93.7500 (87.5000) lr 1.9114e-03 eta 0:07:21
epoch [29/200] batch [3/3] time 0.834 (0.851) data 0.093 (0.110) loss 0.3079 (0.3468) acc 93.7500 (89.5833) lr 1.9048e-03 eta 0:07:16
epoch [30/200] batch [1/3] time 0.988 (0.988) data 0.241 (0.241) loss 0.4026 (0.4026) acc 90.6250 (90.6250) lr 1.9048e-03 eta 0:08:26
epoch [30/200] batch [2/3] time 0.842 (0.915) data 0.095 (0.168) loss 0.1942 (0.2984) acc 93.7500 (92.1875) lr 1.9048e-03 eta 0:07:47
epoch [30/200] batch [3/3] time 0.871 (0.900) data 0.108 (0.148) loss 0.5669 (0.3879) acc 90.6250 (91.6667) lr 1.8980e-03 eta 0:07:39
epoch [31/200] batch [1/3] time 0.888 (0.888) data 0.134 (0.134) loss 0.5376 (0.5376) acc 84.3750 (84.3750) lr 1.8980e-03 eta 0:07:32
epoch [31/200] batch [2/3] time 0.850 (0.869) data 0.107 (0.121) loss 0.3311 (0.4343) acc 96.8750 (90.6250) lr 1.8980e-03 eta 0:07:21
epoch [31/200] batch [3/3] time 0.839 (0.859) data 0.098 (0.113) loss 0.2944 (0.3877) acc 96.8750 (92.7083) lr 1.8910e-03 eta 0:07:15
epoch [32/200] batch [1/3] time 0.838 (0.838) data 0.095 (0.095) loss 0.6938 (0.6938) acc 84.3750 (84.3750) lr 1.8910e-03 eta 0:07:04
epoch [32/200] batch [2/3] time 0.860 (0.849) data 0.118 (0.107) loss 0.4629 (0.5784) acc 84.3750 (84.3750) lr 1.8910e-03 eta 0:07:08
epoch [32/200] batch [3/3] time 0.844 (0.847) data 0.104 (0.106) loss 0.5176 (0.5581) acc 87.5000 (85.4167) lr 1.8838e-03 eta 0:07:07
epoch [33/200] batch [1/3] time 0.835 (0.835) data 0.093 (0.093) loss 0.3975 (0.3975) acc 87.5000 (87.5000) lr 1.8838e-03 eta 0:06:59
epoch [33/200] batch [2/3] time 0.843 (0.839) data 0.103 (0.098) loss 0.3965 (0.3970) acc 90.6250 (89.0625) lr 1.8838e-03 eta 0:07:01
epoch [33/200] batch [3/3] time 0.835 (0.838) data 0.091 (0.096) loss 0.7524 (0.5155) acc 78.1250 (85.4167) lr 1.8763e-03 eta 0:06:59
epoch [34/200] batch [1/3] time 0.839 (0.839) data 0.097 (0.097) loss 0.3105 (0.3105) acc 90.6250 (90.6250) lr 1.8763e-03 eta 0:06:59
epoch [34/200] batch [2/3] time 0.837 (0.838) data 0.095 (0.096) loss 0.4963 (0.4034) acc 84.3750 (87.5000) lr 1.8763e-03 eta 0:06:58
epoch [34/200] batch [3/3] time 0.837 (0.838) data 0.098 (0.097) loss 0.1052 (0.3040) acc 96.8750 (90.6250) lr 1.8686e-03 eta 0:06:57
epoch [35/200] batch [1/3] time 0.862 (0.862) data 0.118 (0.118) loss 0.3643 (0.3643) acc 90.6250 (90.6250) lr 1.8686e-03 eta 0:07:08
epoch [35/200] batch [2/3] time 0.848 (0.855) data 0.104 (0.111) loss 0.3064 (0.3353) acc 90.6250 (90.6250) lr 1.8686e-03 eta 0:07:04
epoch [35/200] batch [3/3] time 0.837 (0.849) data 0.095 (0.106) loss 0.2178 (0.2961) acc 96.8750 (92.7083) lr 1.8607e-03 eta 0:07:00
epoch [36/200] batch [1/3] time 0.840 (0.840) data 0.098 (0.098) loss 0.6064 (0.6064) acc 81.2500 (81.2500) lr 1.8607e-03 eta 0:06:54
epoch [36/200] batch [2/3] time 0.837 (0.839) data 0.098 (0.098) loss 0.6147 (0.6106) acc 81.2500 (81.2500) lr 1.8607e-03 eta 0:06:53
epoch [36/200] batch [3/3] time 0.835 (0.837) data 0.093 (0.097) loss 0.4465 (0.5559) acc 90.6250 (84.3750) lr 1.8526e-03 eta 0:06:52
epoch [37/200] batch [1/3] time 0.841 (0.841) data 0.094 (0.094) loss 0.4604 (0.4604) acc 84.3750 (84.3750) lr 1.8526e-03 eta 0:06:53
epoch [37/200] batch [2/3] time 0.877 (0.859) data 0.122 (0.108) loss 0.5796 (0.5200) acc 78.1250 (81.2500) lr 1.8526e-03 eta 0:07:00
epoch [37/200] batch [3/3] time 0.850 (0.856) data 0.106 (0.108) loss 0.7109 (0.5837) acc 81.2500 (81.2500) lr 1.8443e-03 eta 0:06:58
epoch [38/200] batch [1/3] time 0.850 (0.850) data 0.092 (0.092) loss 0.7090 (0.7090) acc 84.3750 (84.3750) lr 1.8443e-03 eta 0:06:54
epoch [38/200] batch [2/3] time 0.862 (0.856) data 0.102 (0.097) loss 0.4048 (0.5569) acc 90.6250 (87.5000) lr 1.8443e-03 eta 0:06:56
epoch [38/200] batch [3/3] time 0.852 (0.855) data 0.104 (0.099) loss 0.9131 (0.6756) acc 84.3750 (86.4583) lr 1.8358e-03 eta 0:06:55
epoch [39/200] batch [1/3] time 0.853 (0.853) data 0.104 (0.104) loss 0.5884 (0.5884) acc 84.3750 (84.3750) lr 1.8358e-03 eta 0:06:53
epoch [39/200] batch [2/3] time 0.848 (0.850) data 0.104 (0.104) loss 0.1953 (0.3918) acc 96.8750 (90.6250) lr 1.8358e-03 eta 0:06:51
epoch [39/200] batch [3/3] time 0.866 (0.856) data 0.112 (0.107) loss 0.4714 (0.4184) acc 84.3750 (88.5417) lr 1.8271e-03 eta 0:06:53
epoch [40/200] batch [1/3] time 0.846 (0.846) data 0.098 (0.098) loss 0.1647 (0.1647) acc 96.8750 (96.8750) lr 1.8271e-03 eta 0:06:47
epoch [40/200] batch [2/3] time 0.858 (0.852) data 0.116 (0.107) loss 0.2727 (0.2187) acc 90.6250 (93.7500) lr 1.8271e-03 eta 0:06:49
epoch [40/200] batch [3/3] time 0.844 (0.849) data 0.098 (0.104) loss 0.3340 (0.2571) acc 96.8750 (94.7917) lr 1.8181e-03 eta 0:06:47
epoch [41/200] batch [1/3] time 0.938 (0.938) data 0.199 (0.199) loss 0.2710 (0.2710) acc 87.5000 (87.5000) lr 1.8181e-03 eta 0:07:29
epoch [41/200] batch [2/3] time 0.873 (0.905) data 0.109 (0.154) loss 0.3574 (0.3142) acc 87.5000 (87.5000) lr 1.8181e-03 eta 0:07:12
epoch [41/200] batch [3/3] time 0.863 (0.891) data 0.101 (0.136) loss 0.3076 (0.3120) acc 87.5000 (87.5000) lr 1.8090e-03 eta 0:07:05
epoch [42/200] batch [1/3] time 0.974 (0.974) data 0.214 (0.214) loss 0.4399 (0.4399) acc 84.3750 (84.3750) lr 1.8090e-03 eta 0:07:43
epoch [42/200] batch [2/3] time 0.861 (0.917) data 0.112 (0.163) loss 0.3250 (0.3824) acc 90.6250 (87.5000) lr 1.8090e-03 eta 0:07:15
epoch [42/200] batch [3/3] time 0.864 (0.900) data 0.103 (0.143) loss 0.6221 (0.4623) acc 90.6250 (88.5417) lr 1.7997e-03 eta 0:07:06
epoch [43/200] batch [1/3] time 0.934 (0.934) data 0.184 (0.184) loss 0.2471 (0.2471) acc 96.8750 (96.8750) lr 1.7997e-03 eta 0:07:21
epoch [43/200] batch [2/3] time 0.891 (0.912) data 0.144 (0.164) loss 0.5220 (0.3845) acc 84.3750 (90.6250) lr 1.7997e-03 eta 0:07:10
epoch [43/200] batch [3/3] time 0.883 (0.903) data 0.135 (0.154) loss 0.4795 (0.4162) acc 84.3750 (88.5417) lr 1.7902e-03 eta 0:07:05
epoch [44/200] batch [1/3] time 0.860 (0.860) data 0.098 (0.098) loss 0.2803 (0.2803) acc 96.8750 (96.8750) lr 1.7902e-03 eta 0:06:44
epoch [44/200] batch [2/3] time 0.848 (0.854) data 0.108 (0.103) loss 0.7095 (0.4949) acc 87.5000 (92.1875) lr 1.7902e-03 eta 0:06:40
epoch [44/200] batch [3/3] time 0.926 (0.878) data 0.179 (0.128) loss 0.0438 (0.3445) acc 100.0000 (94.7917) lr 1.7804e-03 eta 0:06:50
epoch [45/200] batch [1/3] time 1.409 (1.409) data 0.432 (0.432) loss 0.4673 (0.4673) acc 90.6250 (90.6250) lr 1.7804e-03 eta 0:10:57
epoch [45/200] batch [2/3] time 1.086 (1.247) data 0.168 (0.300) loss 0.3799 (0.4236) acc 84.3750 (87.5000) lr 1.7804e-03 eta 0:09:41
epoch [45/200] batch [3/3] time 0.919 (1.138) data 0.094 (0.231) loss 0.2201 (0.3558) acc 93.7500 (89.5833) lr 1.7705e-03 eta 0:08:49
epoch [46/200] batch [1/3] time 1.627 (1.627) data 0.648 (0.648) loss 0.5195 (0.5195) acc 90.6250 (90.6250) lr 1.7705e-03 eta 0:12:34
epoch [46/200] batch [2/3] time 1.199 (1.413) data 0.199 (0.424) loss 0.3335 (0.4265) acc 90.6250 (90.6250) lr 1.7705e-03 eta 0:10:54
epoch [46/200] batch [3/3] time 0.944 (1.257) data 0.102 (0.316) loss 0.6924 (0.5151) acc 87.5000 (89.5833) lr 1.7604e-03 eta 0:09:40
epoch [47/200] batch [1/3] time 1.024 (1.024) data 0.200 (0.200) loss 0.5391 (0.5391) acc 84.3750 (84.3750) lr 1.7604e-03 eta 0:07:51
epoch [47/200] batch [2/3] time 0.988 (1.006) data 0.140 (0.170) loss 0.4368 (0.4879) acc 81.2500 (82.8125) lr 1.7604e-03 eta 0:07:42
epoch [47/200] batch [3/3] time 1.049 (1.020) data 0.129 (0.156) loss 0.2371 (0.4043) acc 90.6250 (85.4167) lr 1.7501e-03 eta 0:07:48
epoch [48/200] batch [1/3] time 0.841 (0.841) data 0.102 (0.102) loss 0.4895 (0.4895) acc 81.2500 (81.2500) lr 1.7501e-03 eta 0:06:25
epoch [48/200] batch [2/3] time 1.133 (0.987) data 0.100 (0.101) loss 0.5381 (0.5138) acc 84.3750 (82.8125) lr 1.7501e-03 eta 0:07:31
epoch [48/200] batch [3/3] time 0.863 (0.946) data 0.122 (0.108) loss 0.2837 (0.4371) acc 90.6250 (85.4167) lr 1.7396e-03 eta 0:07:11
epoch [49/200] batch [1/3] time 1.012 (1.012) data 0.113 (0.113) loss 0.2150 (0.2150) acc 96.8750 (96.8750) lr 1.7396e-03 eta 0:07:40
epoch [49/200] batch [2/3] time 0.835 (0.924) data 0.093 (0.103) loss 0.1649 (0.1899) acc 96.8750 (96.8750) lr 1.7396e-03 eta 0:06:59
epoch [49/200] batch [3/3] time 1.025 (0.957) data 0.129 (0.112) loss 0.1869 (0.1889) acc 96.8750 (96.8750) lr 1.7290e-03 eta 0:07:13
epoch [50/200] batch [1/3] time 0.838 (0.838) data 0.100 (0.100) loss 0.8184 (0.8184) acc 75.0000 (75.0000) lr 1.7290e-03 eta 0:06:18
epoch [50/200] batch [2/3] time 0.836 (0.837) data 0.098 (0.099) loss 0.4768 (0.6476) acc 87.5000 (81.2500) lr 1.7290e-03 eta 0:06:17
epoch [50/200] batch [3/3] time 0.958 (0.877) data 0.091 (0.096) loss 0.3210 (0.5387) acc 93.7500 (85.4167) lr 1.7181e-03 eta 0:06:34
epoch [51/200] batch [1/3] time 0.904 (0.904) data 0.104 (0.104) loss 0.3000 (0.3000) acc 87.5000 (87.5000) lr 1.7181e-03 eta 0:06:45
epoch [51/200] batch [2/3] time 1.154 (1.029) data 0.261 (0.182) loss 0.6470 (0.4735) acc 78.1250 (82.8125) lr 1.7181e-03 eta 0:07:41
epoch [51/200] batch [3/3] time 1.070 (1.043) data 0.120 (0.162) loss 0.1943 (0.3805) acc 93.7500 (86.4583) lr 1.7071e-03 eta 0:07:46
epoch [52/200] batch [1/3] time 1.092 (1.092) data 0.134 (0.134) loss 0.7310 (0.7310) acc 81.2500 (81.2500) lr 1.7071e-03 eta 0:08:06
epoch [52/200] batch [2/3] time 1.013 (1.052) data 0.108 (0.121) loss 0.5278 (0.6294) acc 81.2500 (81.2500) lr 1.7071e-03 eta 0:07:48
epoch [52/200] batch [3/3] time 0.964 (1.023) data 0.098 (0.113) loss 0.2751 (0.5113) acc 96.8750 (86.4583) lr 1.6959e-03 eta 0:07:34
epoch [53/200] batch [1/3] time 0.994 (0.994) data 0.098 (0.098) loss 0.2383 (0.2383) acc 93.7500 (93.7500) lr 1.6959e-03 eta 0:07:20
epoch [53/200] batch [2/3] time 0.832 (0.913) data 0.094 (0.096) loss 0.1990 (0.2186) acc 96.8750 (95.3125) lr 1.6959e-03 eta 0:06:43
epoch [53/200] batch [3/3] time 0.911 (0.912) data 0.094 (0.095) loss 0.2720 (0.2364) acc 90.6250 (93.7500) lr 1.6845e-03 eta 0:06:42
epoch [54/200] batch [1/3] time 0.923 (0.923) data 0.091 (0.091) loss 0.2313 (0.2313) acc 90.6250 (90.6250) lr 1.6845e-03 eta 0:06:46
epoch [54/200] batch [2/3] time 0.847 (0.885) data 0.104 (0.098) loss 0.0903 (0.1608) acc 96.8750 (93.7500) lr 1.6845e-03 eta 0:06:28
epoch [54/200] batch [3/3] time 0.919 (0.896) data 0.114 (0.103) loss 0.5610 (0.2942) acc 87.5000 (91.6667) lr 1.6730e-03 eta 0:06:32
epoch [55/200] batch [1/3] time 0.853 (0.853) data 0.091 (0.091) loss 0.1354 (0.1354) acc 100.0000 (100.0000) lr 1.6730e-03 eta 0:06:12
epoch [55/200] batch [2/3] time 0.860 (0.856) data 0.112 (0.102) loss 0.2793 (0.2073) acc 93.7500 (96.8750) lr 1.6730e-03 eta 0:06:13
epoch [55/200] batch [3/3] time 0.900 (0.871) data 0.108 (0.104) loss 0.5278 (0.3142) acc 87.5000 (93.7500) lr 1.6613e-03 eta 0:06:18
epoch [56/200] batch [1/3] time 0.845 (0.845) data 0.104 (0.104) loss 0.4065 (0.4065) acc 93.7500 (93.7500) lr 1.6613e-03 eta 0:06:06
epoch [56/200] batch [2/3] time 0.881 (0.863) data 0.101 (0.102) loss 0.7495 (0.5780) acc 84.3750 (89.0625) lr 1.6613e-03 eta 0:06:13
epoch [56/200] batch [3/3] time 0.850 (0.858) data 0.100 (0.102) loss 0.6572 (0.6044) acc 84.3750 (87.5000) lr 1.6494e-03 eta 0:06:10
epoch [57/200] batch [1/3] time 0.840 (0.840) data 0.092 (0.092) loss 0.3804 (0.3804) acc 87.5000 (87.5000) lr 1.6494e-03 eta 0:06:02
epoch [57/200] batch [2/3] time 0.876 (0.858) data 0.099 (0.095) loss 0.2947 (0.3375) acc 90.6250 (89.0625) lr 1.6494e-03 eta 0:06:09
epoch [57/200] batch [3/3] time 0.852 (0.856) data 0.108 (0.099) loss 0.3955 (0.3569) acc 84.3750 (87.5000) lr 1.6374e-03 eta 0:06:07
epoch [58/200] batch [1/3] time 0.842 (0.842) data 0.098 (0.098) loss 0.1912 (0.1912) acc 96.8750 (96.8750) lr 1.6374e-03 eta 0:06:00
epoch [58/200] batch [2/3] time 0.835 (0.839) data 0.097 (0.098) loss 0.5312 (0.3612) acc 90.6250 (93.7500) lr 1.6374e-03 eta 0:05:58
epoch [58/200] batch [3/3] time 0.838 (0.838) data 0.099 (0.098) loss 0.3352 (0.3525) acc 90.6250 (92.7083) lr 1.6252e-03 eta 0:05:57
epoch [59/200] batch [1/3] time 0.840 (0.840) data 0.097 (0.097) loss 0.2612 (0.2612) acc 90.6250 (90.6250) lr 1.6252e-03 eta 0:05:57
epoch [59/200] batch [2/3] time 0.836 (0.838) data 0.092 (0.094) loss 0.4758 (0.3685) acc 84.3750 (87.5000) lr 1.6252e-03 eta 0:05:55
epoch [59/200] batch [3/3] time 0.837 (0.838) data 0.099 (0.096) loss 0.6099 (0.4490) acc 87.5000 (87.5000) lr 1.6129e-03 eta 0:05:54
epoch [60/200] batch [1/3] time 0.837 (0.837) data 0.094 (0.094) loss 0.2727 (0.2727) acc 90.6250 (90.6250) lr 1.6129e-03 eta 0:05:53
epoch [60/200] batch [2/3] time 0.846 (0.842) data 0.101 (0.098) loss 0.2629 (0.2678) acc 90.6250 (90.6250) lr 1.6129e-03 eta 0:05:54
epoch [60/200] batch [3/3] time 0.832 (0.838) data 0.093 (0.096) loss 0.5356 (0.3571) acc 84.3750 (88.5417) lr 1.6004e-03 eta 0:05:52
epoch [61/200] batch [1/3] time 0.841 (0.841) data 0.096 (0.096) loss 0.4353 (0.4353) acc 90.6250 (90.6250) lr 1.6004e-03 eta 0:05:52
epoch [61/200] batch [2/3] time 0.852 (0.847) data 0.101 (0.098) loss 0.3743 (0.4048) acc 90.6250 (90.6250) lr 1.6004e-03 eta 0:05:53
epoch [61/200] batch [3/3] time 0.857 (0.850) data 0.116 (0.104) loss 0.3162 (0.3752) acc 90.6250 (90.6250) lr 1.5878e-03 eta 0:05:54
epoch [62/200] batch [1/3] time 0.856 (0.856) data 0.104 (0.104) loss 0.2493 (0.2493) acc 93.7500 (93.7500) lr 1.5878e-03 eta 0:05:55
epoch [62/200] batch [2/3] time 0.849 (0.852) data 0.096 (0.100) loss 0.5913 (0.4203) acc 84.3750 (89.0625) lr 1.5878e-03 eta 0:05:53
epoch [62/200] batch [3/3] time 0.862 (0.856) data 0.095 (0.098) loss 0.1047 (0.3151) acc 96.8750 (91.6667) lr 1.5750e-03 eta 0:05:54
epoch [63/200] batch [1/3] time 0.837 (0.837) data 0.099 (0.099) loss 0.3535 (0.3535) acc 90.6250 (90.6250) lr 1.5750e-03 eta 0:05:45
epoch [63/200] batch [2/3] time 0.860 (0.849) data 0.114 (0.106) loss 0.3093 (0.3314) acc 96.8750 (93.7500) lr 1.5750e-03 eta 0:05:49
epoch [63/200] batch [3/3] time 0.847 (0.848) data 0.107 (0.107) loss 0.4929 (0.3853) acc 84.3750 (90.6250) lr 1.5621e-03 eta 0:05:48
epoch [64/200] batch [1/3] time 0.845 (0.845) data 0.097 (0.097) loss 0.4570 (0.4570) acc 93.7500 (93.7500) lr 1.5621e-03 eta 0:05:46
epoch [64/200] batch [2/3] time 0.863 (0.854) data 0.105 (0.101) loss 0.0970 (0.2770) acc 100.0000 (96.8750) lr 1.5621e-03 eta 0:05:49
epoch [64/200] batch [3/3] time 1.513 (1.074) data 0.366 (0.189) loss 0.4521 (0.3354) acc 90.6250 (94.7917) lr 1.5490e-03 eta 0:07:18
epoch [65/200] batch [1/3] time 1.175 (1.175) data 0.105 (0.105) loss 0.3032 (0.3032) acc 90.6250 (90.6250) lr 1.5490e-03 eta 0:07:58
epoch [65/200] batch [2/3] time 0.834 (1.004) data 0.094 (0.099) loss 0.2262 (0.2647) acc 90.6250 (90.6250) lr 1.5490e-03 eta 0:06:47
epoch [65/200] batch [3/3] time 0.873 (0.961) data 0.115 (0.105) loss 0.3821 (0.3038) acc 87.5000 (89.5833) lr 1.5358e-03 eta 0:06:29
epoch [66/200] batch [1/3] time 0.901 (0.901) data 0.095 (0.095) loss 0.3325 (0.3325) acc 90.6250 (90.6250) lr 1.5358e-03 eta 0:06:03
epoch [66/200] batch [2/3] time 0.847 (0.874) data 0.106 (0.100) loss 0.3120 (0.3223) acc 93.7500 (92.1875) lr 1.5358e-03 eta 0:05:52
epoch [66/200] batch [3/3] time 0.854 (0.867) data 0.097 (0.099) loss 0.4099 (0.3515) acc 87.5000 (90.6250) lr 1.5225e-03 eta 0:05:48
epoch [67/200] batch [1/3] time 0.849 (0.849) data 0.110 (0.110) loss 0.4346 (0.4346) acc 90.6250 (90.6250) lr 1.5225e-03 eta 0:05:40
epoch [67/200] batch [2/3] time 0.852 (0.851) data 0.094 (0.102) loss 0.5039 (0.4692) acc 84.3750 (87.5000) lr 1.5225e-03 eta 0:05:40
epoch [67/200] batch [3/3] time 1.070 (0.924) data 0.102 (0.102) loss 0.3198 (0.4194) acc 87.5000 (87.5000) lr 1.5090e-03 eta 0:06:08
epoch [68/200] batch [1/3] time 1.132 (1.132) data 0.118 (0.118) loss 0.3481 (0.3481) acc 90.6250 (90.6250) lr 1.5090e-03 eta 0:07:30
epoch [68/200] batch [2/3] time 0.916 (1.024) data 0.132 (0.125) loss 0.4348 (0.3915) acc 87.5000 (89.0625) lr 1.5090e-03 eta 0:06:46
epoch [68/200] batch [3/3] time 1.111 (1.053) data 0.108 (0.119) loss 0.3015 (0.3615) acc 93.7500 (90.6250) lr 1.4955e-03 eta 0:06:56
epoch [69/200] batch [1/3] time 1.045 (1.045) data 0.093 (0.093) loss 0.6172 (0.6172) acc 87.5000 (87.5000) lr 1.4955e-03 eta 0:06:52
epoch [69/200] batch [2/3] time 1.164 (1.104) data 0.134 (0.114) loss 0.2554 (0.4363) acc 96.8750 (92.1875) lr 1.4955e-03 eta 0:07:15
epoch [69/200] batch [3/3] time 1.040 (1.083) data 0.096 (0.108) loss 0.1777 (0.3501) acc 96.8750 (93.7500) lr 1.4818e-03 eta 0:07:05
epoch [70/200] batch [1/3] time 1.058 (1.058) data 0.101 (0.101) loss 0.2883 (0.2883) acc 93.7500 (93.7500) lr 1.4818e-03 eta 0:06:54
epoch [70/200] batch [2/3] time 1.035 (1.047) data 0.115 (0.108) loss 0.3027 (0.2955) acc 93.7500 (93.7500) lr 1.4818e-03 eta 0:06:49
epoch [70/200] batch [3/3] time 1.128 (1.074) data 0.112 (0.109) loss 0.4880 (0.3597) acc 90.6250 (92.7083) lr 1.4679e-03 eta 0:06:58
epoch [71/200] batch [1/3] time 0.907 (0.907) data 0.101 (0.101) loss 0.7734 (0.7734) acc 75.0000 (75.0000) lr 1.4679e-03 eta 0:05:52
epoch [71/200] batch [2/3] time 0.951 (0.929) data 0.104 (0.103) loss 0.4580 (0.6157) acc 84.3750 (79.6875) lr 1.4679e-03 eta 0:06:00
epoch [71/200] batch [3/3] time 1.886 (1.248) data 1.125 (0.443) loss 0.2834 (0.5050) acc 90.6250 (83.3333) lr 1.4540e-03 eta 0:08:02
epoch [72/200] batch [1/3] time 0.987 (0.987) data 0.250 (0.250) loss 0.5073 (0.5073) acc 87.5000 (87.5000) lr 1.4540e-03 eta 0:06:21
epoch [72/200] batch [2/3] time 0.845 (0.916) data 0.102 (0.176) loss 0.1781 (0.3427) acc 93.7500 (90.6250) lr 1.4540e-03 eta 0:05:52
epoch [72/200] batch [3/3] time 0.856 (0.896) data 0.117 (0.156) loss 0.0964 (0.2606) acc 96.8750 (92.7083) lr 1.4399e-03 eta 0:05:44
epoch [73/200] batch [1/3] time 0.924 (0.924) data 0.182 (0.182) loss 0.2656 (0.2656) acc 87.5000 (87.5000) lr 1.4399e-03 eta 0:05:53
epoch [73/200] batch [2/3] time 0.854 (0.889) data 0.110 (0.146) loss 0.1968 (0.2312) acc 93.7500 (90.6250) lr 1.4399e-03 eta 0:05:39
epoch [73/200] batch [3/3] time 0.841 (0.873) data 0.100 (0.131) loss 0.2944 (0.2523) acc 93.7500 (91.6667) lr 1.4258e-03 eta 0:05:32
epoch [74/200] batch [1/3] time 0.848 (0.848) data 0.107 (0.107) loss 0.3276 (0.3276) acc 90.6250 (90.6250) lr 1.4258e-03 eta 0:05:22
epoch [74/200] batch [2/3] time 0.920 (0.884) data 0.177 (0.142) loss 0.1465 (0.2371) acc 96.8750 (93.7500) lr 1.4258e-03 eta 0:05:35
epoch [74/200] batch [3/3] time 0.933 (0.900) data 0.190 (0.158) loss 0.3103 (0.2615) acc 93.7500 (93.7500) lr 1.4115e-03 eta 0:05:40
epoch [75/200] batch [1/3] time 0.836 (0.836) data 0.093 (0.093) loss 0.0959 (0.0959) acc 96.8750 (96.8750) lr 1.4115e-03 eta 0:05:15
epoch [75/200] batch [2/3] time 0.849 (0.842) data 0.100 (0.097) loss 0.1473 (0.1216) acc 96.8750 (96.8750) lr 1.4115e-03 eta 0:05:16
epoch [75/200] batch [3/3] time 0.838 (0.841) data 0.094 (0.096) loss 0.4282 (0.2238) acc 90.6250 (94.7917) lr 1.3971e-03 eta 0:05:15
epoch [76/200] batch [1/3] time 0.836 (0.836) data 0.088 (0.088) loss 0.3462 (0.3462) acc 93.7500 (93.7500) lr 1.3971e-03 eta 0:05:12
epoch [76/200] batch [2/3] time 0.846 (0.841) data 0.106 (0.097) loss 0.2944 (0.3203) acc 90.6250 (92.1875) lr 1.3971e-03 eta 0:05:13
epoch [76/200] batch [3/3] time 1.073 (0.918) data 0.312 (0.169) loss 0.1837 (0.2748) acc 93.7500 (92.7083) lr 1.3827e-03 eta 0:05:41
epoch [77/200] batch [1/3] time 0.843 (0.843) data 0.104 (0.104) loss 0.2507 (0.2507) acc 93.7500 (93.7500) lr 1.3827e-03 eta 0:05:12
epoch [77/200] batch [2/3] time 0.839 (0.841) data 0.099 (0.101) loss 0.3096 (0.2802) acc 93.7500 (93.7500) lr 1.3827e-03 eta 0:05:11
epoch [77/200] batch [3/3] time 0.983 (0.888) data 0.245 (0.149) loss 0.4421 (0.3341) acc 90.6250 (92.7083) lr 1.3681e-03 eta 0:05:27
epoch [78/200] batch [1/3] time 0.940 (0.940) data 0.201 (0.201) loss 0.2051 (0.2051) acc 93.7500 (93.7500) lr 1.3681e-03 eta 0:05:46
epoch [78/200] batch [2/3] time 0.834 (0.887) data 0.096 (0.148) loss 0.2981 (0.2516) acc 90.6250 (92.1875) lr 1.3681e-03 eta 0:05:25
epoch [78/200] batch [3/3] time 0.877 (0.884) data 0.128 (0.142) loss 0.3093 (0.2708) acc 93.7500 (92.7083) lr 1.3535e-03 eta 0:05:23
epoch [79/200] batch [1/3] time 1.119 (1.119) data 0.384 (0.384) loss 0.4841 (0.4841) acc 90.6250 (90.6250) lr 1.3535e-03 eta 0:06:48
epoch [79/200] batch [2/3] time 1.035 (1.077) data 0.282 (0.333) loss 0.3413 (0.4127) acc 90.6250 (90.6250) lr 1.3535e-03 eta 0:06:31
epoch [79/200] batch [3/3] time 0.844 (0.999) data 0.101 (0.256) loss 0.4031 (0.4095) acc 87.5000 (89.5833) lr 1.3387e-03 eta 0:06:02
epoch [80/200] batch [1/3] time 0.841 (0.841) data 0.106 (0.106) loss 0.1937 (0.1937) acc 96.8750 (96.8750) lr 1.3387e-03 eta 0:05:04
epoch [80/200] batch [2/3] time 0.832 (0.836) data 0.095 (0.101) loss 0.2076 (0.2007) acc 96.8750 (96.8750) lr 1.3387e-03 eta 0:05:01
epoch [80/200] batch [3/3] time 0.842 (0.838) data 0.106 (0.102) loss 0.2703 (0.2239) acc 93.7500 (95.8333) lr 1.3239e-03 eta 0:05:01
epoch [81/200] batch [1/3] time 0.838 (0.838) data 0.096 (0.096) loss 0.3401 (0.3401) acc 90.6250 (90.6250) lr 1.3239e-03 eta 0:05:00
epoch [81/200] batch [2/3] time 0.833 (0.835) data 0.094 (0.095) loss 0.1388 (0.2394) acc 96.8750 (93.7500) lr 1.3239e-03 eta 0:04:59
epoch [81/200] batch [3/3] time 0.978 (0.883) data 0.237 (0.142) loss 0.2515 (0.2434) acc 90.6250 (92.7083) lr 1.3090e-03 eta 0:05:15
epoch [82/200] batch [1/3] time 0.876 (0.876) data 0.140 (0.140) loss 0.1655 (0.1655) acc 96.8750 (96.8750) lr 1.3090e-03 eta 0:05:12
epoch [82/200] batch [2/3] time 0.886 (0.881) data 0.149 (0.144) loss 0.3123 (0.2389) acc 90.6250 (93.7500) lr 1.3090e-03 eta 0:05:12
epoch [82/200] batch [3/3] time 0.923 (0.895) data 0.160 (0.150) loss 0.1171 (0.1983) acc 96.8750 (94.7917) lr 1.2940e-03 eta 0:05:16
epoch [83/200] batch [1/3] time 1.063 (1.063) data 0.308 (0.308) loss 0.1595 (0.1595) acc 96.8750 (96.8750) lr 1.2940e-03 eta 0:06:15
epoch [83/200] batch [2/3] time 0.851 (0.957) data 0.111 (0.209) loss 0.2378 (0.1987) acc 93.7500 (95.3125) lr 1.2940e-03 eta 0:05:36
epoch [83/200] batch [3/3] time 0.911 (0.942) data 0.156 (0.191) loss 0.5630 (0.3201) acc 87.5000 (92.7083) lr 1.2790e-03 eta 0:05:30
epoch [84/200] batch [1/3] time 0.953 (0.953) data 0.219 (0.219) loss 0.2642 (0.2642) acc 93.7500 (93.7500) lr 1.2790e-03 eta 0:05:33
epoch [84/200] batch [2/3] time 0.874 (0.913) data 0.134 (0.177) loss 0.5332 (0.3987) acc 87.5000 (90.6250) lr 1.2790e-03 eta 0:05:18
epoch [84/200] batch [3/3] time 1.233 (1.020) data 0.490 (0.281) loss 0.3110 (0.3695) acc 93.7500 (91.6667) lr 1.2639e-03 eta 0:05:54
epoch [85/200] batch [1/3] time 0.843 (0.843) data 0.111 (0.111) loss 0.2742 (0.2742) acc 93.7500 (93.7500) lr 1.2639e-03 eta 0:04:52
epoch [85/200] batch [2/3] time 0.996 (0.920) data 0.227 (0.169) loss 0.2529 (0.2635) acc 93.7500 (93.7500) lr 1.2639e-03 eta 0:05:18
epoch [85/200] batch [3/3] time 0.861 (0.900) data 0.092 (0.143) loss 0.4524 (0.3265) acc 90.6250 (92.7083) lr 1.2487e-03 eta 0:05:10
epoch [86/200] batch [1/3] time 0.895 (0.895) data 0.119 (0.119) loss 0.2163 (0.2163) acc 93.7500 (93.7500) lr 1.2487e-03 eta 0:05:07
epoch [86/200] batch [2/3] time 0.867 (0.881) data 0.112 (0.115) loss 0.1698 (0.1931) acc 96.8750 (95.3125) lr 1.2487e-03 eta 0:05:02
epoch [86/200] batch [3/3] time 0.951 (0.904) data 0.192 (0.141) loss 0.2260 (0.2040) acc 93.7500 (94.7917) lr 1.2334e-03 eta 0:05:09
epoch [87/200] batch [1/3] time 0.861 (0.861) data 0.103 (0.103) loss 0.0966 (0.0966) acc 96.8750 (96.8750) lr 1.2334e-03 eta 0:04:53
epoch [87/200] batch [2/3] time 0.853 (0.857) data 0.094 (0.098) loss 0.3291 (0.2129) acc 93.7500 (95.3125) lr 1.2334e-03 eta 0:04:51
epoch [87/200] batch [3/3] time 0.971 (0.895) data 0.233 (0.143) loss 0.3508 (0.2589) acc 87.5000 (92.7083) lr 1.2181e-03 eta 0:05:03
epoch [88/200] batch [1/3] time 0.903 (0.903) data 0.126 (0.126) loss 0.6001 (0.6001) acc 87.5000 (87.5000) lr 1.2181e-03 eta 0:05:05
epoch [88/200] batch [2/3] time 0.890 (0.896) data 0.098 (0.112) loss 0.2045 (0.4023) acc 96.8750 (92.1875) lr 1.2181e-03 eta 0:05:02
epoch [88/200] batch [3/3] time 0.878 (0.890) data 0.096 (0.107) loss 0.2681 (0.3575) acc 96.8750 (93.7500) lr 1.2028e-03 eta 0:04:59
epoch [89/200] batch [1/3] time 0.857 (0.857) data 0.090 (0.090) loss 0.2810 (0.2810) acc 93.7500 (93.7500) lr 1.2028e-03 eta 0:04:47
epoch [89/200] batch [2/3] time 0.829 (0.843) data 0.092 (0.091) loss 0.1259 (0.2034) acc 93.7500 (93.7500) lr 1.2028e-03 eta 0:04:41
epoch [89/200] batch [3/3] time 0.852 (0.846) data 0.102 (0.095) loss 0.2169 (0.2079) acc 96.8750 (94.7917) lr 1.1874e-03 eta 0:04:41
epoch [90/200] batch [1/3] time 0.927 (0.927) data 0.186 (0.186) loss 0.3330 (0.3330) acc 90.6250 (90.6250) lr 1.1874e-03 eta 0:05:07
epoch [90/200] batch [2/3] time 0.851 (0.889) data 0.096 (0.141) loss 0.1710 (0.2520) acc 93.7500 (92.1875) lr 1.1874e-03 eta 0:04:54
epoch [90/200] batch [3/3] time 0.844 (0.874) data 0.106 (0.129) loss 0.4194 (0.3078) acc 90.6250 (91.6667) lr 1.1719e-03 eta 0:04:48
epoch [91/200] batch [1/3] time 0.835 (0.835) data 0.097 (0.097) loss 0.1782 (0.1782) acc 93.7500 (93.7500) lr 1.1719e-03 eta 0:04:34
epoch [91/200] batch [2/3] time 0.834 (0.834) data 0.092 (0.095) loss 0.7476 (0.4629) acc 78.1250 (85.9375) lr 1.1719e-03 eta 0:04:33
epoch [91/200] batch [3/3] time 0.878 (0.849) data 0.131 (0.107) loss 0.4651 (0.4636) acc 87.5000 (86.4583) lr 1.1564e-03 eta 0:04:37
epoch [92/200] batch [1/3] time 0.883 (0.883) data 0.142 (0.142) loss 0.2004 (0.2004) acc 90.6250 (90.6250) lr 1.1564e-03 eta 0:04:47
epoch [92/200] batch [2/3] time 0.840 (0.861) data 0.099 (0.120) loss 0.0582 (0.1293) acc 100.0000 (95.3125) lr 1.1564e-03 eta 0:04:39
epoch [92/200] batch [3/3] time 0.910 (0.878) data 0.152 (0.131) loss 0.1997 (0.1528) acc 96.8750 (95.8333) lr 1.1409e-03 eta 0:04:44
epoch [93/200] batch [1/3] time 0.839 (0.839) data 0.100 (0.100) loss 0.1359 (0.1359) acc 100.0000 (100.0000) lr 1.1409e-03 eta 0:04:30
epoch [93/200] batch [2/3] time 0.889 (0.864) data 0.103 (0.101) loss 0.4277 (0.2818) acc 87.5000 (93.7500) lr 1.1409e-03 eta 0:04:38
epoch [93/200] batch [3/3] time 0.872 (0.867) data 0.096 (0.099) loss 0.0781 (0.2139) acc 100.0000 (95.8333) lr 1.1253e-03 eta 0:04:38
epoch [94/200] batch [1/3] time 0.836 (0.836) data 0.097 (0.097) loss 0.0612 (0.0612) acc 100.0000 (100.0000) lr 1.1253e-03 eta 0:04:27
epoch [94/200] batch [2/3] time 0.869 (0.853) data 0.102 (0.100) loss 0.3962 (0.2287) acc 90.6250 (95.3125) lr 1.1253e-03 eta 0:04:32
epoch [94/200] batch [3/3] time 0.879 (0.861) data 0.125 (0.108) loss 0.1342 (0.1972) acc 96.8750 (95.8333) lr 1.1097e-03 eta 0:04:33
epoch [95/200] batch [1/3] time 0.928 (0.928) data 0.097 (0.097) loss 0.1975 (0.1975) acc 96.8750 (96.8750) lr 1.1097e-03 eta 0:04:54
epoch [95/200] batch [2/3] time 0.866 (0.897) data 0.121 (0.109) loss 0.3386 (0.2681) acc 87.5000 (92.1875) lr 1.1097e-03 eta 0:04:43
epoch [95/200] batch [3/3] time 0.862 (0.885) data 0.098 (0.105) loss 0.1797 (0.2386) acc 93.7500 (92.7083) lr 1.0941e-03 eta 0:04:38
epoch [96/200] batch [1/3] time 1.056 (1.056) data 0.279 (0.279) loss 0.3477 (0.3477) acc 90.6250 (90.6250) lr 1.0941e-03 eta 0:05:31
epoch [96/200] batch [2/3] time 1.087 (1.071) data 0.137 (0.208) loss 0.2191 (0.2834) acc 93.7500 (92.1875) lr 1.0941e-03 eta 0:05:35
epoch [96/200] batch [3/3] time 1.019 (1.054) data 0.111 (0.175) loss 0.3398 (0.3022) acc 90.6250 (91.6667) lr 1.0785e-03 eta 0:05:28
epoch [97/200] batch [1/3] time 1.212 (1.212) data 0.169 (0.169) loss 0.2778 (0.2778) acc 96.8750 (96.8750) lr 1.0785e-03 eta 0:06:16
epoch [97/200] batch [2/3] time 1.591 (1.402) data 0.549 (0.359) loss 0.2031 (0.2405) acc 93.7500 (95.3125) lr 1.0785e-03 eta 0:07:14
epoch [97/200] batch [3/3] time 1.205 (1.336) data 0.355 (0.358) loss 0.3711 (0.2840) acc 84.3750 (91.6667) lr 1.0628e-03 eta 0:06:52
epoch [98/200] batch [1/3] time 1.116 (1.116) data 0.151 (0.151) loss 0.3091 (0.3091) acc 90.6250 (90.6250) lr 1.0628e-03 eta 0:05:43
epoch [98/200] batch [2/3] time 1.000 (1.058) data 0.142 (0.146) loss 0.3777 (0.3434) acc 90.6250 (90.6250) lr 1.0628e-03 eta 0:05:24
epoch [98/200] batch [3/3] time 1.150 (1.089) data 0.163 (0.152) loss 0.3286 (0.3385) acc 90.6250 (90.6250) lr 1.0471e-03 eta 0:05:33
epoch [99/200] batch [1/3] time 1.118 (1.118) data 0.162 (0.162) loss 0.3735 (0.3735) acc 90.6250 (90.6250) lr 1.0471e-03 eta 0:05:40
epoch [99/200] batch [2/3] time 1.035 (1.076) data 0.172 (0.167) loss 0.2913 (0.3324) acc 93.7500 (92.1875) lr 1.0471e-03 eta 0:05:27
epoch [99/200] batch [3/3] time 1.082 (1.078) data 0.248 (0.194) loss 0.6172 (0.4273) acc 81.2500 (88.5417) lr 1.0314e-03 eta 0:05:26
epoch [100/200] batch [1/3] time 0.926 (0.926) data 0.123 (0.123) loss 0.4397 (0.4397) acc 84.3750 (84.3750) lr 1.0314e-03 eta 0:04:39
epoch [100/200] batch [2/3] time 1.051 (0.989) data 0.120 (0.121) loss 0.5493 (0.4945) acc 84.3750 (84.3750) lr 1.0314e-03 eta 0:04:57
epoch [100/200] batch [3/3] time 1.101 (1.026) data 0.133 (0.125) loss 0.4158 (0.4683) acc 87.5000 (85.4167) lr 1.0157e-03 eta 0:05:07
epoch [101/200] batch [1/3] time 0.999 (0.999) data 0.137 (0.137) loss 0.1377 (0.1377) acc 96.8750 (96.8750) lr 1.0157e-03 eta 0:04:58
epoch [101/200] batch [2/3] time 1.047 (1.023) data 0.147 (0.142) loss 0.2213 (0.1795) acc 96.8750 (96.8750) lr 1.0157e-03 eta 0:05:04
epoch [101/200] batch [3/3] time 0.911 (0.986) data 0.114 (0.133) loss 0.2502 (0.2031) acc 93.7500 (95.8333) lr 1.0000e-03 eta 0:04:52
epoch [102/200] batch [1/3] time 0.952 (0.952) data 0.148 (0.148) loss 0.3936 (0.3936) acc 90.6250 (90.6250) lr 1.0000e-03 eta 0:04:41
epoch [102/200] batch [2/3] time 0.936 (0.944) data 0.134 (0.141) loss 0.7373 (0.5654) acc 84.3750 (87.5000) lr 1.0000e-03 eta 0:04:38
epoch [102/200] batch [3/3] time 0.931 (0.940) data 0.129 (0.137) loss 0.1420 (0.4243) acc 96.8750 (90.6250) lr 9.8429e-04 eta 0:04:36
epoch [103/200] batch [1/3] time 0.913 (0.913) data 0.114 (0.114) loss 0.4988 (0.4988) acc 84.3750 (84.3750) lr 9.8429e-04 eta 0:04:27
epoch [103/200] batch [2/3] time 0.936 (0.925) data 0.135 (0.124) loss 0.2710 (0.3849) acc 96.8750 (90.6250) lr 9.8429e-04 eta 0:04:30
epoch [103/200] batch [3/3] time 0.949 (0.933) data 0.149 (0.132) loss 0.3826 (0.3841) acc 90.6250 (90.6250) lr 9.6859e-04 eta 0:04:31
epoch [104/200] batch [1/3] time 0.914 (0.914) data 0.116 (0.116) loss 0.1410 (0.1410) acc 96.8750 (96.8750) lr 9.6859e-04 eta 0:04:25
epoch [104/200] batch [2/3] time 0.926 (0.920) data 0.123 (0.119) loss 0.1636 (0.1523) acc 93.7500 (95.3125) lr 9.6859e-04 eta 0:04:25
epoch [104/200] batch [3/3] time 0.937 (0.926) data 0.135 (0.124) loss 0.2126 (0.1724) acc 96.8750 (95.8333) lr 9.5289e-04 eta 0:04:26
epoch [105/200] batch [1/3] time 0.911 (0.911) data 0.110 (0.110) loss 0.2998 (0.2998) acc 93.7500 (93.7500) lr 9.5289e-04 eta 0:04:21
epoch [105/200] batch [2/3] time 0.923 (0.917) data 0.121 (0.115) loss 0.1780 (0.2389) acc 93.7500 (93.7500) lr 9.5289e-04 eta 0:04:22
epoch [105/200] batch [3/3] time 0.927 (0.920) data 0.126 (0.119) loss 0.1444 (0.2074) acc 96.8750 (94.7917) lr 9.3721e-04 eta 0:04:22
epoch [106/200] batch [1/3] time 0.925 (0.925) data 0.124 (0.124) loss 0.4070 (0.4070) acc 87.5000 (87.5000) lr 9.3721e-04 eta 0:04:22
epoch [106/200] batch [2/3] time 0.956 (0.940) data 0.149 (0.136) loss 0.2068 (0.3069) acc 93.7500 (90.6250) lr 9.3721e-04 eta 0:04:26
epoch [106/200] batch [3/3] time 0.928 (0.936) data 0.128 (0.134) loss 0.3286 (0.3141) acc 90.6250 (90.6250) lr 9.2154e-04 eta 0:04:24
epoch [107/200] batch [1/3] time 0.937 (0.937) data 0.134 (0.134) loss 0.0723 (0.0723) acc 100.0000 (100.0000) lr 9.2154e-04 eta 0:04:23
epoch [107/200] batch [2/3] time 0.925 (0.931) data 0.125 (0.129) loss 0.2639 (0.1681) acc 93.7500 (96.8750) lr 9.2154e-04 eta 0:04:20
epoch [107/200] batch [3/3] time 0.917 (0.926) data 0.116 (0.125) loss 0.2859 (0.2074) acc 93.7500 (95.8333) lr 9.0589e-04 eta 0:04:18
epoch [108/200] batch [1/3] time 0.927 (0.927) data 0.124 (0.124) loss 0.3513 (0.3513) acc 93.7500 (93.7500) lr 9.0589e-04 eta 0:04:17
epoch [108/200] batch [2/3] time 0.932 (0.930) data 0.130 (0.127) loss 0.5186 (0.4349) acc 81.2500 (87.5000) lr 9.0589e-04 eta 0:04:17
epoch [108/200] batch [3/3] time 0.931 (0.930) data 0.128 (0.127) loss 0.3396 (0.4032) acc 90.6250 (88.5417) lr 8.9027e-04 eta 0:04:16
epoch [109/200] batch [1/3] time 0.932 (0.932) data 0.128 (0.128) loss 0.4233 (0.4233) acc 84.3750 (84.3750) lr 8.9027e-04 eta 0:04:16
epoch [109/200] batch [2/3] time 0.926 (0.929) data 0.125 (0.127) loss 0.3032 (0.3633) acc 93.7500 (89.0625) lr 8.9027e-04 eta 0:04:14
epoch [109/200] batch [3/3] time 0.981 (0.946) data 0.177 (0.144) loss 0.1572 (0.2946) acc 96.8750 (91.6667) lr 8.7467e-04 eta 0:04:18
epoch [110/200] batch [1/3] time 0.943 (0.943) data 0.146 (0.146) loss 0.0596 (0.0596) acc 100.0000 (100.0000) lr 8.7467e-04 eta 0:04:16
epoch [110/200] batch [2/3] time 0.926 (0.935) data 0.124 (0.135) loss 0.2937 (0.1767) acc 90.6250 (95.3125) lr 8.7467e-04 eta 0:04:13
epoch [110/200] batch [3/3] time 0.929 (0.933) data 0.125 (0.132) loss 0.2664 (0.2066) acc 93.7500 (94.7917) lr 8.5910e-04 eta 0:04:11
epoch [111/200] batch [1/3] time 0.940 (0.940) data 0.137 (0.137) loss 0.0394 (0.0394) acc 100.0000 (100.0000) lr 8.5910e-04 eta 0:04:12
epoch [111/200] batch [2/3] time 1.100 (1.020) data 0.165 (0.151) loss 0.0584 (0.0489) acc 96.8750 (98.4375) lr 8.5910e-04 eta 0:04:33
epoch [111/200] batch [3/3] time 1.168 (1.069) data 0.268 (0.190) loss 0.2307 (0.1095) acc 96.8750 (97.9167) lr 8.4357e-04 eta 0:04:45
epoch [112/200] batch [1/3] time 0.945 (0.945) data 0.155 (0.155) loss 0.2159 (0.2159) acc 96.8750 (96.8750) lr 8.4357e-04 eta 0:04:11
epoch [112/200] batch [2/3] time 0.846 (0.896) data 0.108 (0.131) loss 0.3984 (0.3072) acc 90.6250 (93.7500) lr 8.4357e-04 eta 0:03:57
epoch [112/200] batch [3/3] time 0.898 (0.896) data 0.140 (0.134) loss 0.3242 (0.3129) acc 90.6250 (92.7083) lr 8.2807e-04 eta 0:03:56
epoch [113/200] batch [1/3] time 0.856 (0.856) data 0.112 (0.112) loss 0.2151 (0.2151) acc 93.7500 (93.7500) lr 8.2807e-04 eta 0:03:45
epoch [113/200] batch [2/3] time 0.902 (0.879) data 0.155 (0.134) loss 0.4434 (0.3292) acc 90.6250 (92.1875) lr 8.2807e-04 eta 0:03:50
epoch [113/200] batch [3/3] time 0.930 (0.896) data 0.153 (0.140) loss 0.0656 (0.2413) acc 100.0000 (94.7917) lr 8.1262e-04 eta 0:03:53
epoch [114/200] batch [1/3] time 0.890 (0.890) data 0.115 (0.115) loss 0.4419 (0.4419) acc 90.6250 (90.6250) lr 8.1262e-04 eta 0:03:51
epoch [114/200] batch [2/3] time 0.892 (0.891) data 0.120 (0.117) loss 0.1661 (0.3040) acc 96.8750 (93.7500) lr 8.1262e-04 eta 0:03:50
epoch [114/200] batch [3/3] time 0.868 (0.883) data 0.130 (0.122) loss 0.5557 (0.3879) acc 93.7500 (93.7500) lr 7.9721e-04 eta 0:03:47
epoch [115/200] batch [1/3] time 1.352 (1.352) data 0.302 (0.302) loss 0.0446 (0.0446) acc 100.0000 (100.0000) lr 7.9721e-04 eta 0:05:47
epoch [115/200] batch [2/3] time 0.979 (1.165) data 0.239 (0.271) loss 0.0790 (0.0618) acc 100.0000 (100.0000) lr 7.9721e-04 eta 0:04:58
epoch [115/200] batch [3/3] time 0.832 (1.054) data 0.094 (0.212) loss 0.1519 (0.0918) acc 93.7500 (97.9167) lr 7.8186e-04 eta 0:04:28
epoch [116/200] batch [1/3] time 0.834 (0.834) data 0.094 (0.094) loss 0.2388 (0.2388) acc 96.8750 (96.8750) lr 7.8186e-04 eta 0:03:31
epoch [116/200] batch [2/3] time 0.928 (0.881) data 0.098 (0.096) loss 0.4773 (0.3580) acc 87.5000 (92.1875) lr 7.8186e-04 eta 0:03:42
epoch [116/200] batch [3/3] time 0.857 (0.873) data 0.109 (0.100) loss 0.2966 (0.3376) acc 87.5000 (90.6250) lr 7.6655e-04 eta 0:03:39
epoch [117/200] batch [1/3] time 0.834 (0.834) data 0.098 (0.098) loss 0.0943 (0.0943) acc 96.8750 (96.8750) lr 7.6655e-04 eta 0:03:29
epoch [117/200] batch [2/3] time 0.839 (0.837) data 0.100 (0.099) loss 0.4963 (0.2953) acc 87.5000 (92.1875) lr 7.6655e-04 eta 0:03:29
epoch [117/200] batch [3/3] time 0.830 (0.834) data 0.095 (0.098) loss 0.2581 (0.2829) acc 93.7500 (92.7083) lr 7.5131e-04 eta 0:03:27
epoch [118/200] batch [1/3] time 0.834 (0.834) data 0.097 (0.097) loss 0.4048 (0.4048) acc 93.7500 (93.7500) lr 7.5131e-04 eta 0:03:26
epoch [118/200] batch [2/3] time 0.836 (0.835) data 0.093 (0.095) loss 0.2109 (0.3079) acc 96.8750 (95.3125) lr 7.5131e-04 eta 0:03:26
epoch [118/200] batch [3/3] time 0.837 (0.836) data 0.094 (0.094) loss 0.1833 (0.2664) acc 93.7500 (94.7917) lr 7.3613e-04 eta 0:03:25
epoch [119/200] batch [1/3] time 0.835 (0.835) data 0.092 (0.092) loss 0.1398 (0.1398) acc 96.8750 (96.8750) lr 7.3613e-04 eta 0:03:24
epoch [119/200] batch [2/3] time 1.227 (1.031) data 0.352 (0.222) loss 0.1920 (0.1659) acc 90.6250 (93.7500) lr 7.3613e-04 eta 0:04:11
epoch [119/200] batch [3/3] time 1.053 (1.038) data 0.091 (0.178) loss 0.1312 (0.1543) acc 96.8750 (94.7917) lr 7.2101e-04 eta 0:04:12
epoch [120/200] batch [1/3] time 0.846 (0.846) data 0.100 (0.100) loss 0.4717 (0.4717) acc 87.5000 (87.5000) lr 7.2101e-04 eta 0:03:24
epoch [120/200] batch [2/3] time 0.854 (0.850) data 0.112 (0.106) loss 0.2998 (0.3857) acc 90.6250 (89.0625) lr 7.2101e-04 eta 0:03:24
epoch [120/200] batch [3/3] time 0.845 (0.848) data 0.095 (0.102) loss 0.0634 (0.2783) acc 96.8750 (91.6667) lr 7.0596e-04 eta 0:03:23
epoch [121/200] batch [1/3] time 0.839 (0.839) data 0.095 (0.095) loss 0.3345 (0.3345) acc 90.6250 (90.6250) lr 7.0596e-04 eta 0:03:20
epoch [121/200] batch [2/3] time 0.843 (0.841) data 0.100 (0.098) loss 0.1909 (0.2627) acc 96.8750 (93.7500) lr 7.0596e-04 eta 0:03:20
epoch [121/200] batch [3/3] time 0.924 (0.869) data 0.159 (0.118) loss 0.1526 (0.2260) acc 100.0000 (95.8333) lr 6.9098e-04 eta 0:03:25
epoch [122/200] batch [1/3] time 0.976 (0.976) data 0.135 (0.135) loss 0.3584 (0.3584) acc 96.8750 (96.8750) lr 6.9098e-04 eta 0:03:50
epoch [122/200] batch [2/3] time 0.985 (0.981) data 0.183 (0.159) loss 0.6416 (0.5000) acc 87.5000 (92.1875) lr 6.9098e-04 eta 0:03:50
epoch [122/200] batch [3/3] time 1.051 (1.004) data 0.118 (0.145) loss 0.3752 (0.4584) acc 90.6250 (91.6667) lr 6.7608e-04 eta 0:03:54
epoch [123/200] batch [1/3] time 0.958 (0.958) data 0.124 (0.124) loss 0.2546 (0.2546) acc 93.7500 (93.7500) lr 6.7608e-04 eta 0:03:43
epoch [123/200] batch [2/3] time 0.951 (0.954) data 0.115 (0.119) loss 0.3135 (0.2841) acc 90.6250 (92.1875) lr 6.7608e-04 eta 0:03:41
epoch [123/200] batch [3/3] time 1.039 (0.983) data 0.144 (0.127) loss 0.4131 (0.3271) acc 93.7500 (92.7083) lr 6.6126e-04 eta 0:03:46
epoch [124/200] batch [1/3] time 0.999 (0.999) data 0.140 (0.140) loss 0.3201 (0.3201) acc 93.7500 (93.7500) lr 6.6126e-04 eta 0:03:49
epoch [124/200] batch [2/3] time 0.962 (0.980) data 0.134 (0.137) loss 0.6904 (0.5052) acc 87.5000 (90.6250) lr 6.6126e-04 eta 0:03:44
epoch [124/200] batch [3/3] time 0.949 (0.970) data 0.095 (0.123) loss 0.1519 (0.3875) acc 96.8750 (92.7083) lr 6.4653e-04 eta 0:03:41
epoch [125/200] batch [1/3] time 0.936 (0.936) data 0.134 (0.134) loss 0.1639 (0.1639) acc 93.7500 (93.7500) lr 6.4653e-04 eta 0:03:32
epoch [125/200] batch [2/3] time 0.906 (0.921) data 0.098 (0.116) loss 0.0507 (0.1073) acc 100.0000 (96.8750) lr 6.4653e-04 eta 0:03:28
epoch [125/200] batch [3/3] time 0.963 (0.935) data 0.134 (0.122) loss 0.1221 (0.1122) acc 100.0000 (97.9167) lr 6.3188e-04 eta 0:03:30
epoch [126/200] batch [1/3] time 0.992 (0.992) data 0.152 (0.152) loss 0.2822 (0.2822) acc 96.8750 (96.8750) lr 6.3188e-04 eta 0:03:42
epoch [126/200] batch [2/3] time 1.303 (1.148) data 0.216 (0.184) loss 0.5967 (0.4395) acc 90.6250 (93.7500) lr 6.3188e-04 eta 0:04:15
epoch [126/200] batch [3/3] time 0.857 (1.051) data 0.120 (0.163) loss 0.1214 (0.3334) acc 100.0000 (95.8333) lr 6.1732e-04 eta 0:03:53
epoch [127/200] batch [1/3] time 0.828 (0.828) data 0.093 (0.093) loss 0.1422 (0.1422) acc 96.8750 (96.8750) lr 6.1732e-04 eta 0:03:02
epoch [127/200] batch [2/3] time 0.827 (0.827) data 0.092 (0.093) loss 0.3904 (0.2663) acc 90.6250 (93.7500) lr 6.1732e-04 eta 0:03:02
epoch [127/200] batch [3/3] time 0.830 (0.828) data 0.097 (0.094) loss 0.1115 (0.2147) acc 100.0000 (95.8333) lr 6.0285e-04 eta 0:03:01
epoch [128/200] batch [1/3] time 0.832 (0.832) data 0.099 (0.099) loss 0.2966 (0.2966) acc 87.5000 (87.5000) lr 6.0285e-04 eta 0:03:01
epoch [128/200] batch [2/3] time 0.827 (0.830) data 0.094 (0.096) loss 0.1656 (0.2311) acc 100.0000 (93.7500) lr 6.0285e-04 eta 0:03:00
epoch [128/200] batch [3/3] time 0.823 (0.828) data 0.092 (0.095) loss 0.6958 (0.3860) acc 81.2500 (89.5833) lr 5.8849e-04 eta 0:02:58
epoch [129/200] batch [1/3] time 0.827 (0.827) data 0.094 (0.094) loss 0.3059 (0.3059) acc 93.7500 (93.7500) lr 5.8849e-04 eta 0:02:57
epoch [129/200] batch [2/3] time 0.827 (0.827) data 0.094 (0.094) loss 0.1221 (0.2140) acc 96.8750 (95.3125) lr 5.8849e-04 eta 0:02:57
epoch [129/200] batch [3/3] time 0.831 (0.828) data 0.096 (0.094) loss 0.2656 (0.2312) acc 93.7500 (94.7917) lr 5.7422e-04 eta 0:02:56
epoch [130/200] batch [1/3] time 0.830 (0.830) data 0.097 (0.097) loss 0.2922 (0.2922) acc 93.7500 (93.7500) lr 5.7422e-04 eta 0:02:55
epoch [130/200] batch [2/3] time 0.827 (0.828) data 0.092 (0.094) loss 0.3101 (0.3011) acc 93.7500 (93.7500) lr 5.7422e-04 eta 0:02:54
epoch [130/200] batch [3/3] time 0.828 (0.828) data 0.093 (0.094) loss 0.2771 (0.2931) acc 93.7500 (93.7500) lr 5.6006e-04 eta 0:02:53
epoch [131/200] batch [1/3] time 0.834 (0.834) data 0.099 (0.099) loss 0.3774 (0.3774) acc 90.6250 (90.6250) lr 5.6006e-04 eta 0:02:54
epoch [131/200] batch [2/3] time 0.831 (0.833) data 0.096 (0.098) loss 0.2537 (0.3156) acc 93.7500 (92.1875) lr 5.6006e-04 eta 0:02:53
epoch [131/200] batch [3/3] time 0.828 (0.831) data 0.095 (0.097) loss 0.0550 (0.2287) acc 100.0000 (94.7917) lr 5.4601e-04 eta 0:02:52
epoch [132/200] batch [1/3] time 0.825 (0.825) data 0.092 (0.092) loss 0.2092 (0.2092) acc 96.8750 (96.8750) lr 5.4601e-04 eta 0:02:50
epoch [132/200] batch [2/3] time 0.835 (0.830) data 0.097 (0.094) loss 0.0801 (0.1447) acc 100.0000 (98.4375) lr 5.4601e-04 eta 0:02:50
epoch [132/200] batch [3/3] time 0.831 (0.830) data 0.095 (0.094) loss 0.5361 (0.2751) acc 84.3750 (93.7500) lr 5.3207e-04 eta 0:02:49
epoch [133/200] batch [1/3] time 0.856 (0.856) data 0.093 (0.093) loss 0.2441 (0.2441) acc 93.7500 (93.7500) lr 5.3207e-04 eta 0:02:53
epoch [133/200] batch [2/3] time 0.997 (0.927) data 0.119 (0.106) loss 0.2456 (0.2449) acc 90.6250 (92.1875) lr 5.3207e-04 eta 0:03:07
epoch [133/200] batch [3/3] time 1.547 (1.133) data 0.406 (0.206) loss 0.1442 (0.2113) acc 96.8750 (93.7500) lr 5.1825e-04 eta 0:03:47
epoch [134/200] batch [1/3] time 1.505 (1.505) data 0.440 (0.440) loss 0.1305 (0.1305) acc 93.7500 (93.7500) lr 5.1825e-04 eta 0:05:01
epoch [134/200] batch [2/3] time 1.352 (1.429) data 0.359 (0.399) loss 0.3425 (0.2365) acc 93.7500 (93.7500) lr 5.1825e-04 eta 0:04:44
epoch [134/200] batch [3/3] time 1.297 (1.385) data 0.215 (0.338) loss 0.1934 (0.2221) acc 90.6250 (92.7083) lr 5.0454e-04 eta 0:04:34
epoch [135/200] batch [1/3] time 1.112 (1.112) data 0.166 (0.166) loss 0.2690 (0.2690) acc 93.7500 (93.7500) lr 5.0454e-04 eta 0:03:39
epoch [135/200] batch [2/3] time 0.990 (1.051) data 0.152 (0.159) loss 0.2128 (0.2409) acc 93.7500 (93.7500) lr 5.0454e-04 eta 0:03:25
epoch [135/200] batch [3/3] time 0.935 (1.012) data 0.200 (0.173) loss 0.1606 (0.2142) acc 96.8750 (94.7917) lr 4.9096e-04 eta 0:03:17
epoch [136/200] batch [1/3] time 0.875 (0.875) data 0.141 (0.141) loss 0.4292 (0.4292) acc 87.5000 (87.5000) lr 4.9096e-04 eta 0:02:49
epoch [136/200] batch [2/3] time 0.853 (0.864) data 0.113 (0.127) loss 0.1720 (0.3006) acc 96.8750 (92.1875) lr 4.9096e-04 eta 0:02:46
epoch [136/200] batch [3/3] time 0.841 (0.856) data 0.102 (0.119) loss 0.4966 (0.3659) acc 87.5000 (90.6250) lr 4.7750e-04 eta 0:02:44
epoch [137/200] batch [1/3] time 0.832 (0.832) data 0.100 (0.100) loss 0.3616 (0.3616) acc 93.7500 (93.7500) lr 4.7750e-04 eta 0:02:38
epoch [137/200] batch [2/3] time 0.846 (0.839) data 0.106 (0.103) loss 0.4346 (0.3981) acc 93.7500 (93.7500) lr 4.7750e-04 eta 0:02:39
epoch [137/200] batch [3/3] time 0.850 (0.843) data 0.109 (0.105) loss 0.1223 (0.3062) acc 96.8750 (94.7917) lr 4.6417e-04 eta 0:02:39
epoch [138/200] batch [1/3] time 0.856 (0.856) data 0.122 (0.122) loss 0.4248 (0.4248) acc 93.7500 (93.7500) lr 4.6417e-04 eta 0:02:41
epoch [138/200] batch [2/3] time 0.864 (0.860) data 0.129 (0.126) loss 0.1565 (0.2906) acc 96.8750 (95.3125) lr 4.6417e-04 eta 0:02:40
epoch [138/200] batch [3/3] time 0.854 (0.858) data 0.115 (0.122) loss 0.5093 (0.3635) acc 87.5000 (92.7083) lr 4.5098e-04 eta 0:02:39
epoch [139/200] batch [1/3] time 0.847 (0.847) data 0.108 (0.108) loss 0.0936 (0.0936) acc 96.8750 (96.8750) lr 4.5098e-04 eta 0:02:36
epoch [139/200] batch [2/3] time 0.899 (0.873) data 0.165 (0.137) loss 0.5020 (0.2978) acc 87.5000 (92.1875) lr 4.5098e-04 eta 0:02:40
epoch [139/200] batch [3/3] time 0.828 (0.858) data 0.092 (0.122) loss 0.1621 (0.2526) acc 96.8750 (93.7500) lr 4.3792e-04 eta 0:02:36
epoch [140/200] batch [1/3] time 0.833 (0.833) data 0.093 (0.093) loss 0.3208 (0.3208) acc 93.7500 (93.7500) lr 4.3792e-04 eta 0:02:31
epoch [140/200] batch [2/3] time 0.827 (0.830) data 0.093 (0.093) loss 0.3132 (0.3170) acc 96.8750 (95.3125) lr 4.3792e-04 eta 0:02:30
epoch [140/200] batch [3/3] time 0.829 (0.829) data 0.095 (0.094) loss 0.2277 (0.2872) acc 93.7500 (94.7917) lr 4.2499e-04 eta 0:02:29
epoch [141/200] batch [1/3] time 0.825 (0.825) data 0.091 (0.091) loss 0.2874 (0.2874) acc 93.7500 (93.7500) lr 4.2499e-04 eta 0:02:27
epoch [141/200] batch [2/3] time 0.832 (0.828) data 0.094 (0.093) loss 0.1460 (0.2167) acc 93.7500 (93.7500) lr 4.2499e-04 eta 0:02:27
epoch [141/200] batch [3/3] time 0.851 (0.836) data 0.115 (0.100) loss 0.2455 (0.2263) acc 90.6250 (92.7083) lr 4.1221e-04 eta 0:02:27
epoch [142/200] batch [1/3] time 0.830 (0.830) data 0.096 (0.096) loss 0.5718 (0.5718) acc 90.6250 (90.6250) lr 4.1221e-04 eta 0:02:26
epoch [142/200] batch [2/3] time 0.828 (0.829) data 0.093 (0.095) loss 0.0966 (0.3342) acc 96.8750 (93.7500) lr 4.1221e-04 eta 0:02:25
epoch [142/200] batch [3/3] time 0.827 (0.828) data 0.093 (0.094) loss 0.1755 (0.2813) acc 93.7500 (93.7500) lr 3.9958e-04 eta 0:02:24
epoch [143/200] batch [1/3] time 0.829 (0.829) data 0.093 (0.093) loss 0.0284 (0.0284) acc 100.0000 (100.0000) lr 3.9958e-04 eta 0:02:23
epoch [143/200] batch [2/3] time 0.831 (0.830) data 0.094 (0.093) loss 0.1627 (0.0956) acc 93.7500 (96.8750) lr 3.9958e-04 eta 0:02:22
epoch [143/200] batch [3/3] time 0.827 (0.829) data 0.093 (0.093) loss 0.0979 (0.0964) acc 96.8750 (96.8750) lr 3.8709e-04 eta 0:02:21
epoch [144/200] batch [1/3] time 0.824 (0.824) data 0.089 (0.089) loss 0.3206 (0.3206) acc 90.6250 (90.6250) lr 3.8709e-04 eta 0:02:20
epoch [144/200] batch [2/3] time 0.831 (0.828) data 0.096 (0.092) loss 0.1190 (0.2198) acc 96.8750 (93.7500) lr 3.8709e-04 eta 0:02:19
epoch [144/200] batch [3/3] time 0.828 (0.828) data 0.094 (0.093) loss 0.1938 (0.2111) acc 96.8750 (94.7917) lr 3.7476e-04 eta 0:02:19
epoch [145/200] batch [1/3] time 0.828 (0.828) data 0.094 (0.094) loss 0.1174 (0.1174) acc 96.8750 (96.8750) lr 3.7476e-04 eta 0:02:18
epoch [145/200] batch [2/3] time 0.838 (0.833) data 0.104 (0.099) loss 0.0604 (0.0889) acc 100.0000 (98.4375) lr 3.7476e-04 eta 0:02:18
epoch [145/200] batch [3/3] time 0.823 (0.830) data 0.091 (0.096) loss 0.2771 (0.1517) acc 93.7500 (96.8750) lr 3.6258e-04 eta 0:02:16
epoch [146/200] batch [1/3] time 0.829 (0.829) data 0.095 (0.095) loss 0.1240 (0.1240) acc 96.8750 (96.8750) lr 3.6258e-04 eta 0:02:16
epoch [146/200] batch [2/3] time 0.828 (0.828) data 0.093 (0.094) loss 0.2356 (0.1798) acc 93.7500 (95.3125) lr 3.6258e-04 eta 0:02:15
epoch [146/200] batch [3/3] time 0.840 (0.832) data 0.107 (0.098) loss 0.2686 (0.2094) acc 96.8750 (95.8333) lr 3.5055e-04 eta 0:02:14
epoch [147/200] batch [1/3] time 0.869 (0.869) data 0.134 (0.134) loss 0.2433 (0.2433) acc 93.7500 (93.7500) lr 3.5055e-04 eta 0:02:19
epoch [147/200] batch [2/3] time 0.829 (0.849) data 0.094 (0.114) loss 0.0809 (0.1621) acc 96.8750 (95.3125) lr 3.5055e-04 eta 0:02:15
epoch [147/200] batch [3/3] time 0.828 (0.842) data 0.093 (0.107) loss 0.2732 (0.1991) acc 93.7500 (94.7917) lr 3.3869e-04 eta 0:02:13
epoch [148/200] batch [1/3] time 0.831 (0.831) data 0.096 (0.096) loss 0.5171 (0.5171) acc 90.6250 (90.6250) lr 3.3869e-04 eta 0:02:11
epoch [148/200] batch [2/3] time 0.828 (0.829) data 0.092 (0.094) loss 0.1455 (0.3313) acc 96.8750 (93.7500) lr 3.3869e-04 eta 0:02:10
epoch [148/200] batch [3/3] time 0.878 (0.846) data 0.144 (0.111) loss 0.1670 (0.2765) acc 96.8750 (94.7917) lr 3.2699e-04 eta 0:02:11
epoch [149/200] batch [1/3] time 0.828 (0.828) data 0.093 (0.093) loss 0.3533 (0.3533) acc 87.5000 (87.5000) lr 3.2699e-04 eta 0:02:08
epoch [149/200] batch [2/3] time 0.834 (0.831) data 0.100 (0.096) loss 0.1687 (0.2610) acc 96.8750 (92.1875) lr 3.2699e-04 eta 0:02:07
epoch [149/200] batch [3/3] time 0.833 (0.832) data 0.096 (0.096) loss 0.2749 (0.2656) acc 93.7500 (92.7083) lr 3.1545e-04 eta 0:02:07
epoch [150/200] batch [1/3] time 0.828 (0.828) data 0.096 (0.096) loss 0.3354 (0.3354) acc 90.6250 (90.6250) lr 3.1545e-04 eta 0:02:05
epoch [150/200] batch [2/3] time 0.823 (0.825) data 0.087 (0.092) loss 0.2325 (0.2840) acc 93.7500 (92.1875) lr 3.1545e-04 eta 0:02:04
epoch [150/200] batch [3/3] time 0.834 (0.828) data 0.100 (0.094) loss 0.4136 (0.3272) acc 90.6250 (91.6667) lr 3.0409e-04 eta 0:02:04
epoch [151/200] batch [1/3] time 0.824 (0.824) data 0.091 (0.091) loss 0.2321 (0.2321) acc 93.7500 (93.7500) lr 3.0409e-04 eta 0:02:02
epoch [151/200] batch [2/3] time 0.830 (0.827) data 0.094 (0.093) loss 0.1910 (0.2115) acc 93.7500 (93.7500) lr 3.0409e-04 eta 0:02:02
epoch [151/200] batch [3/3] time 0.826 (0.827) data 0.091 (0.092) loss 0.1154 (0.1795) acc 100.0000 (95.8333) lr 2.9289e-04 eta 0:02:01
epoch [152/200] batch [1/3] time 0.824 (0.824) data 0.091 (0.091) loss 0.0778 (0.0778) acc 100.0000 (100.0000) lr 2.9289e-04 eta 0:02:00
epoch [152/200] batch [2/3] time 0.833 (0.829) data 0.101 (0.096) loss 0.4666 (0.2722) acc 87.5000 (93.7500) lr 2.9289e-04 eta 0:02:00
epoch [152/200] batch [3/3] time 0.835 (0.831) data 0.099 (0.097) loss 0.0671 (0.2038) acc 100.0000 (95.8333) lr 2.8187e-04 eta 0:01:59
epoch [153/200] batch [1/3] time 0.828 (0.828) data 0.092 (0.092) loss 0.1906 (0.1906) acc 93.7500 (93.7500) lr 2.8187e-04 eta 0:01:58
epoch [153/200] batch [2/3] time 0.835 (0.831) data 0.100 (0.096) loss 0.0829 (0.1367) acc 96.8750 (95.3125) lr 2.8187e-04 eta 0:01:58
epoch [153/200] batch [3/3] time 0.828 (0.830) data 0.095 (0.096) loss 0.5337 (0.2691) acc 84.3750 (91.6667) lr 2.7103e-04 eta 0:01:57
epoch [154/200] batch [1/3] time 0.826 (0.826) data 0.091 (0.091) loss 0.1731 (0.1731) acc 93.7500 (93.7500) lr 2.7103e-04 eta 0:01:55
epoch [154/200] batch [2/3] time 0.831 (0.828) data 0.094 (0.093) loss 0.2128 (0.1929) acc 93.7500 (93.7500) lr 2.7103e-04 eta 0:01:55
epoch [154/200] batch [3/3] time 0.827 (0.828) data 0.094 (0.093) loss 0.4338 (0.2732) acc 90.6250 (92.7083) lr 2.6037e-04 eta 0:01:54
epoch [155/200] batch [1/3] time 0.830 (0.830) data 0.093 (0.093) loss 0.4446 (0.4446) acc 93.7500 (93.7500) lr 2.6037e-04 eta 0:01:53
epoch [155/200] batch [2/3] time 0.830 (0.830) data 0.096 (0.095) loss 0.1183 (0.2814) acc 100.0000 (96.8750) lr 2.6037e-04 eta 0:01:52
epoch [155/200] batch [3/3] time 0.843 (0.834) data 0.108 (0.099) loss 0.2217 (0.2615) acc 93.7500 (95.8333) lr 2.4989e-04 eta 0:01:52
epoch [156/200] batch [1/3] time 0.830 (0.830) data 0.095 (0.095) loss 0.0889 (0.0889) acc 96.8750 (96.8750) lr 2.4989e-04 eta 0:01:51
epoch [156/200] batch [2/3] time 0.831 (0.830) data 0.094 (0.095) loss 0.1071 (0.0980) acc 96.8750 (96.8750) lr 2.4989e-04 eta 0:01:50
epoch [156/200] batch [3/3] time 0.828 (0.830) data 0.092 (0.094) loss 0.2085 (0.1348) acc 96.8750 (96.8750) lr 2.3959e-04 eta 0:01:49
epoch [157/200] batch [1/3] time 0.832 (0.832) data 0.097 (0.097) loss 0.4280 (0.4280) acc 90.6250 (90.6250) lr 2.3959e-04 eta 0:01:48
epoch [157/200] batch [2/3] time 0.833 (0.832) data 0.098 (0.097) loss 0.1066 (0.2673) acc 96.8750 (93.7500) lr 2.3959e-04 eta 0:01:48
epoch [157/200] batch [3/3] time 0.826 (0.830) data 0.092 (0.096) loss 0.1825 (0.2390) acc 93.7500 (93.7500) lr 2.2949e-04 eta 0:01:47
epoch [158/200] batch [1/3] time 0.831 (0.831) data 0.095 (0.095) loss 0.3965 (0.3965) acc 87.5000 (87.5000) lr 2.2949e-04 eta 0:01:46
epoch [158/200] batch [2/3] time 0.831 (0.831) data 0.096 (0.095) loss 0.2988 (0.3477) acc 93.7500 (90.6250) lr 2.2949e-04 eta 0:01:45
epoch [158/200] batch [3/3] time 0.829 (0.830) data 0.093 (0.094) loss 0.2021 (0.2992) acc 93.7500 (91.6667) lr 2.1957e-04 eta 0:01:44
epoch [159/200] batch [1/3] time 0.825 (0.825) data 0.089 (0.089) loss 0.2981 (0.2981) acc 93.7500 (93.7500) lr 2.1957e-04 eta 0:01:43
epoch [159/200] batch [2/3] time 0.826 (0.826) data 0.095 (0.092) loss 0.1985 (0.2483) acc 96.8750 (95.3125) lr 2.1957e-04 eta 0:01:42
epoch [159/200] batch [3/3] time 0.832 (0.828) data 0.096 (0.094) loss 0.1792 (0.2253) acc 93.7500 (94.7917) lr 2.0984e-04 eta 0:01:41
epoch [160/200] batch [1/3] time 0.828 (0.828) data 0.094 (0.094) loss 0.2571 (0.2571) acc 93.7500 (93.7500) lr 2.0984e-04 eta 0:01:40
epoch [160/200] batch [2/3] time 0.840 (0.834) data 0.106 (0.100) loss 0.1707 (0.2139) acc 93.7500 (93.7500) lr 2.0984e-04 eta 0:01:40
epoch [160/200] batch [3/3] time 0.830 (0.833) data 0.094 (0.098) loss 0.0942 (0.1740) acc 96.8750 (94.7917) lr 2.0032e-04 eta 0:01:39
epoch [161/200] batch [1/3] time 0.825 (0.825) data 0.091 (0.091) loss 0.1279 (0.1279) acc 93.7500 (93.7500) lr 2.0032e-04 eta 0:01:38
epoch [161/200] batch [2/3] time 0.886 (0.855) data 0.152 (0.121) loss 0.5186 (0.3232) acc 93.7500 (93.7500) lr 2.0032e-04 eta 0:01:40
epoch [161/200] batch [3/3] time 0.827 (0.846) data 0.092 (0.112) loss 0.2334 (0.2933) acc 90.6250 (92.7083) lr 1.9098e-04 eta 0:01:38
epoch [162/200] batch [1/3] time 0.839 (0.839) data 0.103 (0.103) loss 0.2896 (0.2896) acc 90.6250 (90.6250) lr 1.9098e-04 eta 0:01:37
epoch [162/200] batch [2/3] time 0.830 (0.834) data 0.094 (0.099) loss 0.2458 (0.2677) acc 96.8750 (93.7500) lr 1.9098e-04 eta 0:01:35
epoch [162/200] batch [3/3] time 0.828 (0.832) data 0.093 (0.097) loss 0.0829 (0.2061) acc 100.0000 (95.8333) lr 1.8185e-04 eta 0:01:34
epoch [163/200] batch [1/3] time 0.839 (0.839) data 0.103 (0.103) loss 0.2117 (0.2117) acc 93.7500 (93.7500) lr 1.8185e-04 eta 0:01:34
epoch [163/200] batch [2/3] time 0.830 (0.834) data 0.095 (0.099) loss 0.0669 (0.1393) acc 100.0000 (96.8750) lr 1.8185e-04 eta 0:01:33
epoch [163/200] batch [3/3] time 0.830 (0.833) data 0.096 (0.098) loss 0.1020 (0.1269) acc 96.8750 (96.8750) lr 1.7292e-04 eta 0:01:32
epoch [164/200] batch [1/3] time 0.829 (0.829) data 0.095 (0.095) loss 0.2610 (0.2610) acc 96.8750 (96.8750) lr 1.7292e-04 eta 0:01:31
epoch [164/200] batch [2/3] time 0.846 (0.838) data 0.111 (0.103) loss 0.0534 (0.1572) acc 96.8750 (96.8750) lr 1.7292e-04 eta 0:01:31
epoch [164/200] batch [3/3] time 0.826 (0.834) data 0.092 (0.099) loss 0.4670 (0.2605) acc 84.3750 (92.7083) lr 1.6419e-04 eta 0:01:30
epoch [165/200] batch [1/3] time 0.832 (0.832) data 0.097 (0.097) loss 0.1913 (0.1913) acc 96.8750 (96.8750) lr 1.6419e-04 eta 0:01:28
epoch [165/200] batch [2/3] time 0.837 (0.835) data 0.100 (0.098) loss 0.2590 (0.2252) acc 96.8750 (96.8750) lr 1.6419e-04 eta 0:01:28
epoch [165/200] batch [3/3] time 0.833 (0.834) data 0.098 (0.098) loss 0.1915 (0.2139) acc 93.7500 (95.8333) lr 1.5567e-04 eta 0:01:27
epoch [166/200] batch [1/3] time 0.829 (0.829) data 0.095 (0.095) loss 0.1742 (0.1742) acc 96.8750 (96.8750) lr 1.5567e-04 eta 0:01:26
epoch [166/200] batch [2/3] time 0.829 (0.829) data 0.094 (0.095) loss 0.1229 (0.1486) acc 93.7500 (95.3125) lr 1.5567e-04 eta 0:01:25
epoch [166/200] batch [3/3] time 0.830 (0.829) data 0.095 (0.095) loss 0.4580 (0.2517) acc 90.6250 (93.7500) lr 1.4736e-04 eta 0:01:24
epoch [167/200] batch [1/3] time 0.827 (0.827) data 0.091 (0.091) loss 0.3022 (0.3022) acc 90.6250 (90.6250) lr 1.4736e-04 eta 0:01:23
epoch [167/200] batch [2/3] time 0.831 (0.829) data 0.095 (0.093) loss 0.2766 (0.2894) acc 90.6250 (90.6250) lr 1.4736e-04 eta 0:01:22
epoch [167/200] batch [3/3] time 0.828 (0.829) data 0.092 (0.093) loss 0.0782 (0.2190) acc 96.8750 (92.7083) lr 1.3926e-04 eta 0:01:22
epoch [168/200] batch [1/3] time 0.837 (0.837) data 0.101 (0.101) loss 0.1761 (0.1761) acc 93.7500 (93.7500) lr 1.3926e-04 eta 0:01:22
epoch [168/200] batch [2/3] time 0.842 (0.840) data 0.107 (0.104) loss 0.2249 (0.2005) acc 93.7500 (93.7500) lr 1.3926e-04 eta 0:01:21
epoch [168/200] batch [3/3] time 0.831 (0.837) data 0.094 (0.101) loss 0.0645 (0.1552) acc 100.0000 (95.8333) lr 1.3137e-04 eta 0:01:20
epoch [169/200] batch [1/3] time 0.830 (0.830) data 0.095 (0.095) loss 0.1295 (0.1295) acc 93.7500 (93.7500) lr 1.3137e-04 eta 0:01:18
epoch [169/200] batch [2/3] time 0.829 (0.829) data 0.093 (0.094) loss 0.3494 (0.2394) acc 90.6250 (92.1875) lr 1.3137e-04 eta 0:01:17
epoch [169/200] batch [3/3] time 0.827 (0.829) data 0.091 (0.093) loss 0.2113 (0.2301) acc 93.7500 (92.7083) lr 1.2369e-04 eta 0:01:17
epoch [170/200] batch [1/3] time 0.833 (0.833) data 0.099 (0.099) loss 0.2328 (0.2328) acc 93.7500 (93.7500) lr 1.2369e-04 eta 0:01:16
epoch [170/200] batch [2/3] time 0.831 (0.832) data 0.098 (0.098) loss 0.2446 (0.2387) acc 93.7500 (93.7500) lr 1.2369e-04 eta 0:01:15
epoch [170/200] batch [3/3] time 0.828 (0.831) data 0.092 (0.096) loss 0.1236 (0.2003) acc 96.8750 (94.7917) lr 1.1623e-04 eta 0:01:14
epoch [171/200] batch [1/3] time 0.828 (0.828) data 0.095 (0.095) loss 0.1904 (0.1904) acc 93.7500 (93.7500) lr 1.1623e-04 eta 0:01:13
epoch [171/200] batch [2/3] time 0.825 (0.827) data 0.095 (0.095) loss 0.1527 (0.1716) acc 93.7500 (93.7500) lr 1.1623e-04 eta 0:01:12
epoch [171/200] batch [3/3] time 0.828 (0.827) data 0.096 (0.095) loss 0.3013 (0.2148) acc 90.6250 (92.7083) lr 1.0899e-04 eta 0:01:11
epoch [172/200] batch [1/3] time 0.828 (0.828) data 0.093 (0.093) loss 0.3076 (0.3076) acc 96.8750 (96.8750) lr 1.0899e-04 eta 0:01:11
epoch [172/200] batch [2/3] time 0.841 (0.834) data 0.106 (0.099) loss 0.0456 (0.1766) acc 96.8750 (96.8750) lr 1.0899e-04 eta 0:01:10
epoch [172/200] batch [3/3] time 0.825 (0.831) data 0.090 (0.096) loss 0.1901 (0.1811) acc 96.8750 (96.8750) lr 1.0197e-04 eta 0:01:09
epoch [173/200] batch [1/3] time 0.826 (0.826) data 0.092 (0.092) loss 0.4844 (0.4844) acc 90.6250 (90.6250) lr 1.0197e-04 eta 0:01:08
epoch [173/200] batch [2/3] time 0.832 (0.829) data 0.095 (0.094) loss 0.0726 (0.2785) acc 96.8750 (93.7500) lr 1.0197e-04 eta 0:01:07
epoch [173/200] batch [3/3] time 0.827 (0.828) data 0.092 (0.093) loss 0.0662 (0.2077) acc 100.0000 (95.8333) lr 9.5173e-05 eta 0:01:07
epoch [174/200] batch [1/3] time 0.824 (0.824) data 0.089 (0.089) loss 0.3643 (0.3643) acc 93.7500 (93.7500) lr 9.5173e-05 eta 0:01:05
epoch [174/200] batch [2/3] time 0.833 (0.828) data 0.097 (0.093) loss 0.1372 (0.2507) acc 96.8750 (95.3125) lr 9.5173e-05 eta 0:01:05
epoch [174/200] batch [3/3] time 0.827 (0.828) data 0.092 (0.093) loss 0.2217 (0.2410) acc 93.7500 (94.7917) lr 8.8597e-05 eta 0:01:04
epoch [175/200] batch [1/3] time 0.833 (0.833) data 0.097 (0.097) loss 0.1389 (0.1389) acc 96.8750 (96.8750) lr 8.8597e-05 eta 0:01:04
epoch [175/200] batch [2/3] time 0.830 (0.832) data 0.092 (0.094) loss 0.0536 (0.0962) acc 100.0000 (98.4375) lr 8.8597e-05 eta 0:01:03
epoch [175/200] batch [3/3] time 0.828 (0.830) data 0.092 (0.093) loss 0.0972 (0.0965) acc 96.8750 (97.9167) lr 8.2245e-05 eta 0:01:02
epoch [176/200] batch [1/3] time 0.828 (0.828) data 0.094 (0.094) loss 0.0559 (0.0559) acc 100.0000 (100.0000) lr 8.2245e-05 eta 0:01:01
epoch [176/200] batch [2/3] time 0.830 (0.829) data 0.095 (0.094) loss 0.1926 (0.1243) acc 100.0000 (100.0000) lr 8.2245e-05 eta 0:01:00
epoch [176/200] batch [3/3] time 0.824 (0.828) data 0.090 (0.093) loss 0.2507 (0.1664) acc 96.8750 (98.9583) lr 7.6120e-05 eta 0:00:59
epoch [177/200] batch [1/3] time 0.844 (0.844) data 0.093 (0.093) loss 0.0612 (0.0612) acc 100.0000 (100.0000) lr 7.6120e-05 eta 0:00:59
epoch [177/200] batch [2/3] time 0.852 (0.848) data 0.113 (0.103) loss 0.1126 (0.0869) acc 96.8750 (98.4375) lr 7.6120e-05 eta 0:00:59
epoch [177/200] batch [3/3] time 1.048 (0.915) data 0.098 (0.101) loss 0.2822 (0.1520) acc 90.6250 (95.8333) lr 7.0224e-05 eta 0:01:03
epoch [178/200] batch [1/3] time 0.841 (0.841) data 0.100 (0.100) loss 0.1283 (0.1283) acc 96.8750 (96.8750) lr 7.0224e-05 eta 0:00:57
epoch [178/200] batch [2/3] time 0.835 (0.838) data 0.099 (0.100) loss 0.2244 (0.1763) acc 96.8750 (96.8750) lr 7.0224e-05 eta 0:00:56
epoch [178/200] batch [3/3] time 0.828 (0.835) data 0.093 (0.097) loss 0.2639 (0.2055) acc 93.7500 (95.8333) lr 6.4556e-05 eta 0:00:55
epoch [179/200] batch [1/3] time 0.837 (0.837) data 0.101 (0.101) loss 0.1700 (0.1700) acc 96.8750 (96.8750) lr 6.4556e-05 eta 0:00:54
epoch [179/200] batch [2/3] time 0.836 (0.836) data 0.096 (0.099) loss 0.3743 (0.2722) acc 93.7500 (95.3125) lr 6.4556e-05 eta 0:00:53
epoch [179/200] batch [3/3] time 0.852 (0.842) data 0.113 (0.103) loss 0.0347 (0.1930) acc 100.0000 (96.8750) lr 5.9119e-05 eta 0:00:53
epoch [180/200] batch [1/3] time 0.829 (0.829) data 0.095 (0.095) loss 0.1648 (0.1648) acc 93.7500 (93.7500) lr 5.9119e-05 eta 0:00:51
epoch [180/200] batch [2/3] time 0.833 (0.831) data 0.094 (0.094) loss 0.1525 (0.1586) acc 96.8750 (95.3125) lr 5.9119e-05 eta 0:00:50
epoch [180/200] batch [3/3] time 0.831 (0.831) data 0.091 (0.093) loss 0.1854 (0.1676) acc 96.8750 (95.8333) lr 5.3915e-05 eta 0:00:49
epoch [181/200] batch [1/3] time 0.826 (0.826) data 0.092 (0.092) loss 0.1978 (0.1978) acc 93.7500 (93.7500) lr 5.3915e-05 eta 0:00:48
epoch [181/200] batch [2/3] time 0.838 (0.832) data 0.100 (0.096) loss 0.2756 (0.2367) acc 93.7500 (93.7500) lr 5.3915e-05 eta 0:00:48
epoch [181/200] batch [3/3] time 0.826 (0.830) data 0.089 (0.093) loss 0.1921 (0.2218) acc 93.7500 (93.7500) lr 4.8943e-05 eta 0:00:47
epoch [182/200] batch [1/3] time 1.439 (1.439) data 0.600 (0.600) loss 0.4265 (0.4265) acc 90.6250 (90.6250) lr 4.8943e-05 eta 0:01:20
epoch [182/200] batch [2/3] time 0.856 (1.148) data 0.101 (0.351) loss 0.1777 (0.3021) acc 96.8750 (93.7500) lr 4.8943e-05 eta 0:01:03
epoch [182/200] batch [3/3] time 0.847 (1.048) data 0.114 (0.272) loss 0.3032 (0.3025) acc 90.6250 (92.7083) lr 4.4207e-05 eta 0:00:56
epoch [183/200] batch [1/3] time 0.845 (0.845) data 0.094 (0.094) loss 0.1141 (0.1141) acc 100.0000 (100.0000) lr 4.4207e-05 eta 0:00:44
epoch [183/200] batch [2/3] time 0.862 (0.853) data 0.104 (0.099) loss 0.2852 (0.1996) acc 93.7500 (96.8750) lr 4.4207e-05 eta 0:00:44
epoch [183/200] batch [3/3] time 0.845 (0.850) data 0.105 (0.101) loss 0.3262 (0.2418) acc 90.6250 (94.7917) lr 3.9706e-05 eta 0:00:43
epoch [184/200] batch [1/3] time 0.871 (0.871) data 0.118 (0.118) loss 0.2820 (0.2820) acc 90.6250 (90.6250) lr 3.9706e-05 eta 0:00:43
epoch [184/200] batch [2/3] time 0.840 (0.855) data 0.094 (0.106) loss 0.4875 (0.3848) acc 90.6250 (90.6250) lr 3.9706e-05 eta 0:00:41
epoch [184/200] batch [3/3] time 0.834 (0.848) data 0.094 (0.102) loss 0.2905 (0.3534) acc 87.5000 (89.5833) lr 3.5443e-05 eta 0:00:40
epoch [185/200] batch [1/3] time 0.848 (0.848) data 0.115 (0.115) loss 0.0458 (0.0458) acc 100.0000 (100.0000) lr 3.5443e-05 eta 0:00:39
epoch [185/200] batch [2/3] time 0.831 (0.840) data 0.092 (0.104) loss 0.2686 (0.1572) acc 87.5000 (93.7500) lr 3.5443e-05 eta 0:00:38
epoch [185/200] batch [3/3] time 0.845 (0.841) data 0.107 (0.105) loss 0.3127 (0.2090) acc 93.7500 (93.7500) lr 3.1417e-05 eta 0:00:37
epoch [186/200] batch [1/3] time 0.851 (0.851) data 0.099 (0.099) loss 0.0887 (0.0887) acc 93.7500 (93.7500) lr 3.1417e-05 eta 0:00:37
epoch [186/200] batch [2/3] time 0.859 (0.855) data 0.100 (0.100) loss 0.2410 (0.1648) acc 96.8750 (95.3125) lr 3.1417e-05 eta 0:00:36
epoch [186/200] batch [3/3] time 0.870 (0.860) data 0.119 (0.106) loss 0.2800 (0.2032) acc 93.7500 (94.7917) lr 2.7630e-05 eta 0:00:36
epoch [187/200] batch [1/3] time 0.862 (0.862) data 0.108 (0.108) loss 0.1711 (0.1711) acc 96.8750 (96.8750) lr 2.7630e-05 eta 0:00:35
epoch [187/200] batch [2/3] time 0.846 (0.854) data 0.096 (0.102) loss 0.1724 (0.1718) acc 96.8750 (96.8750) lr 2.7630e-05 eta 0:00:34
epoch [187/200] batch [3/3] time 0.853 (0.854) data 0.112 (0.105) loss 0.1980 (0.1805) acc 96.8750 (96.8750) lr 2.4083e-05 eta 0:00:33
epoch [188/200] batch [1/3] time 0.852 (0.852) data 0.091 (0.091) loss 0.3000 (0.3000) acc 87.5000 (87.5000) lr 2.4083e-05 eta 0:00:32
epoch [188/200] batch [2/3] time 0.900 (0.876) data 0.142 (0.117) loss 0.3652 (0.3326) acc 87.5000 (87.5000) lr 2.4083e-05 eta 0:00:32
epoch [188/200] batch [3/3] time 0.843 (0.865) data 0.097 (0.110) loss 0.2333 (0.2995) acc 93.7500 (89.5833) lr 2.0777e-05 eta 0:00:31
epoch [189/200] batch [1/3] time 0.868 (0.868) data 0.105 (0.105) loss 0.0497 (0.0497) acc 100.0000 (100.0000) lr 2.0777e-05 eta 0:00:30
epoch [189/200] batch [2/3] time 0.853 (0.861) data 0.105 (0.105) loss 0.4651 (0.2574) acc 90.6250 (95.3125) lr 2.0777e-05 eta 0:00:29
epoch [189/200] batch [3/3] time 0.854 (0.858) data 0.096 (0.102) loss 0.3928 (0.3025) acc 93.7500 (94.7917) lr 1.7713e-05 eta 0:00:28
epoch [190/200] batch [1/3] time 0.845 (0.845) data 0.092 (0.092) loss 0.1997 (0.1997) acc 93.7500 (93.7500) lr 1.7713e-05 eta 0:00:27
epoch [190/200] batch [2/3] time 0.836 (0.841) data 0.098 (0.095) loss 0.3516 (0.2756) acc 90.6250 (92.1875) lr 1.7713e-05 eta 0:00:26
epoch [190/200] batch [3/3] time 1.255 (0.979) data 0.334 (0.175) loss 0.2788 (0.2767) acc 90.6250 (91.6667) lr 1.4891e-05 eta 0:00:29
epoch [191/200] batch [1/3] time 1.075 (1.075) data 0.093 (0.093) loss 0.1191 (0.1191) acc 96.8750 (96.8750) lr 1.4891e-05 eta 0:00:31
epoch [191/200] batch [2/3] time 1.024 (1.049) data 0.276 (0.184) loss 0.0945 (0.1068) acc 96.8750 (96.8750) lr 1.4891e-05 eta 0:00:29
epoch [191/200] batch [3/3] time 0.838 (0.979) data 0.092 (0.154) loss 0.3174 (0.1770) acc 96.8750 (96.8750) lr 1.2312e-05 eta 0:00:26
epoch [192/200] batch [1/3] time 0.860 (0.860) data 0.104 (0.104) loss 0.2034 (0.2034) acc 96.8750 (96.8750) lr 1.2312e-05 eta 0:00:22
epoch [192/200] batch [2/3] time 0.931 (0.895) data 0.095 (0.100) loss 0.4846 (0.3440) acc 87.5000 (92.1875) lr 1.2312e-05 eta 0:00:22
epoch [192/200] batch [3/3] time 0.976 (0.922) data 0.176 (0.125) loss 0.1652 (0.2844) acc 96.8750 (93.7500) lr 9.9763e-06 eta 0:00:22
epoch [193/200] batch [1/3] time 1.008 (1.008) data 0.093 (0.093) loss 0.2371 (0.2371) acc 96.8750 (96.8750) lr 9.9763e-06 eta 0:00:23
epoch [193/200] batch [2/3] time 0.847 (0.927) data 0.095 (0.094) loss 0.5483 (0.3927) acc 90.6250 (93.7500) lr 9.9763e-06 eta 0:00:20
epoch [193/200] batch [3/3] time 1.137 (0.997) data 0.152 (0.114) loss 0.2140 (0.3331) acc 96.8750 (94.7917) lr 7.8853e-06 eta 0:00:20
epoch [194/200] batch [1/3] time 0.979 (0.979) data 0.135 (0.135) loss 0.0814 (0.0814) acc 96.8750 (96.8750) lr 7.8853e-06 eta 0:00:19
epoch [194/200] batch [2/3] time 1.133 (1.056) data 0.211 (0.173) loss 0.1699 (0.1256) acc 96.8750 (96.8750) lr 7.8853e-06 eta 0:00:20
epoch [194/200] batch [3/3] time 1.043 (1.052) data 0.108 (0.151) loss 0.4189 (0.2234) acc 90.6250 (94.7917) lr 6.0390e-06 eta 0:00:18
epoch [195/200] batch [1/3] time 0.846 (0.846) data 0.110 (0.110) loss 0.1454 (0.1454) acc 96.8750 (96.8750) lr 6.0390e-06 eta 0:00:14
epoch [195/200] batch [2/3] time 0.837 (0.842) data 0.098 (0.104) loss 0.1111 (0.1282) acc 96.8750 (96.8750) lr 6.0390e-06 eta 0:00:13
epoch [195/200] batch [3/3] time 0.831 (0.838) data 0.095 (0.101) loss 0.2515 (0.1693) acc 90.6250 (94.7917) lr 4.4380e-06 eta 0:00:12
epoch [196/200] batch [1/3] time 0.827 (0.827) data 0.093 (0.093) loss 0.2003 (0.2003) acc 93.7500 (93.7500) lr 4.4380e-06 eta 0:00:11
epoch [196/200] batch [2/3] time 0.830 (0.829) data 0.095 (0.094) loss 0.1293 (0.1648) acc 96.8750 (95.3125) lr 4.4380e-06 eta 0:00:10
epoch [196/200] batch [3/3] time 0.830 (0.829) data 0.095 (0.095) loss 0.2321 (0.1872) acc 93.7500 (94.7917) lr 3.0827e-06 eta 0:00:09
epoch [197/200] batch [1/3] time 0.828 (0.828) data 0.095 (0.095) loss 0.2781 (0.2781) acc 93.7500 (93.7500) lr 3.0827e-06 eta 0:00:09
epoch [197/200] batch [2/3] time 0.830 (0.829) data 0.097 (0.096) loss 0.0407 (0.1594) acc 100.0000 (96.8750) lr 3.0827e-06 eta 0:00:08
epoch [197/200] batch [3/3] time 0.827 (0.828) data 0.092 (0.095) loss 0.0512 (0.1234) acc 100.0000 (97.9167) lr 1.9733e-06 eta 0:00:07
epoch [198/200] batch [1/3] time 0.830 (0.830) data 0.095 (0.095) loss 0.1965 (0.1965) acc 93.7500 (93.7500) lr 1.9733e-06 eta 0:00:06
epoch [198/200] batch [2/3] time 0.828 (0.829) data 0.093 (0.094) loss 0.2976 (0.2471) acc 90.6250 (92.1875) lr 1.9733e-06 eta 0:00:05
epoch [198/200] batch [3/3] time 0.828 (0.829) data 0.095 (0.094) loss 0.0934 (0.1959) acc 100.0000 (94.7917) lr 1.1101e-06 eta 0:00:04
epoch [199/200] batch [1/3] time 0.824 (0.824) data 0.092 (0.092) loss 0.2039 (0.2039) acc 93.7500 (93.7500) lr 1.1101e-06 eta 0:00:04
epoch [199/200] batch [2/3] time 0.828 (0.826) data 0.094 (0.093) loss 0.2155 (0.2097) acc 90.6250 (92.1875) lr 1.1101e-06 eta 0:00:03
epoch [199/200] batch [3/3] time 0.828 (0.827) data 0.092 (0.093) loss 0.2925 (0.2373) acc 96.8750 (93.7500) lr 4.9344e-07 eta 0:00:02
epoch [200/200] batch [1/3] time 0.831 (0.831) data 0.096 (0.096) loss 0.0823 (0.0823) acc 96.8750 (96.8750) lr 4.9344e-07 eta 0:00:01
epoch [200/200] batch [2/3] time 0.828 (0.829) data 0.092 (0.094) loss 0.3589 (0.2206) acc 90.6250 (93.7500) lr 4.9344e-07 eta 0:00:00
epoch [200/200] batch [3/3] time 0.829 (0.829) data 0.095 (0.094) loss 0.1848 (0.2087) acc 96.8750 (94.7917) lr 1.2337e-07 eta 0:00:00
Checkpoint saved to output/Caltech/1/2/3/prompt_learner/model.pth.tar-200
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
=> result
* total: 2,465
* correct: 2,184
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 84.1%
Elapsed: 0:09:32
